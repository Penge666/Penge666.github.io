<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Penge666</title>
  
  
  <link href="https://penge666.github.io/atom.xml" rel="self"/>
  
  <link href="https://penge666.github.io/"/>
  <updated>2024-06-17T02:29:29.821Z</updated>
  <id>https://penge666.github.io/</id>
  
  <author>
    <name>Penge666</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>容器网络模式</title>
    <link href="https://penge666.github.io/posts/c67182ed.html"/>
    <id>https://penge666.github.io/posts/c67182ed.html</id>
    <published>2024-06-16T08:27:10.000Z</published>
    <updated>2024-06-17T02:29:29.821Z</updated>
    
    <content type="html"><![CDATA[<p>《再见少年拉满弓》</p><p>东风吹破少年梦，从此再无赤子心。<br>黄昏重铸英雄梦，再见少年拉满弓。<br>再见少年拉满弓，不惧岁月不惧风，<br>少年扶摇上九重，胸中豪情破苍穹。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240617101725751.png" alt="image-20240617101725751"></p><ul><li><strong>bridge模式：–net=bridge 桥接模式（默认设置，自己创建也使用bridge 模式）</strong></li><li><strong>host模式：–net=host 和宿主即共享网络</strong></li><li><strong>container模式：–net=container:NAME_or_ID 容器网络连通!(很少用，局限性很大！)</strong></li><li><strong>none模式：–net=none 不配置网络</strong></li></ul><h2 id="查看所有的docker网络">查看所有的docker网络</h2><p>命令：<code>docker network ls</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">@penge ➜ toktik git(main)  docker network <span class="built_in">ls</span></span><br><span class="line">NETWORK ID     NAME           DRIVER    SCOPE</span><br><span class="line">151c5fe4b87c   bridge         bridge    <span class="built_in">local</span></span><br><span class="line">5c21b13981a4   host           host      <span class="built_in">local</span></span><br><span class="line">c51c6b57875f   none           null      <span class="built_in">local</span></span><br><span class="line">b0165c5b9c95   yaml_default   bridge    <span class="built_in">local</span></span><br></pre></td></tr></table></figure><h2 id="bridge-网桥模式">bridge 网桥模式</h2><p>Docker安装启动后会在宿主主机上创建一个名为 docker0 的虚拟网桥，处于七层网络模型的数据链路层，后续每当我们创建一个新的docker容器，在不指定容器网络模式的情况下，docker会通过 docker0 与主机的网络连接，docker0 相当于网桥。</p><p>补充：网桥，也被称为网络桥接器或桥接器，是一种用于连接同一种或不同种类的网络段以形成一个大网络的设备。它的工作方式类似于路由器，但是它通常只用于连接本地网络（LAN）。</p><p>使用 bridge 模式新创建的容器，容器内部都会有一个虚拟网卡，名为 eth0，容器之间可以通过容器内部的IP相互通信。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240617102059535.png" alt="image-20240617102059535"></p><p>解释上图：在该模式中，Docker 会创建一个虚拟以太网桥 <code>docker0</code>，新建的容器会自动桥接到这个接口，然后docker会依据docker0在创建的时候设立的网络段给容器分配ip。</p><p><strong>Note</strong>：但默认的方式存在一个问题，就是每次重启docker默认的网络段也会发生变化，而采用该网络段的docker容器也会跟着发生变化。当然我们也可以自定义一个网络段，然后自己给创建的容器分配指定的ip。</p><p>命令：<code>docker run -d -name tomcat01 --net=bridge -p 8085:80 tomcat:latest</code><br>说明：</p><ul><li>–net=bridge 可省略 ，-p 指定端口映射</li><li>网桥默认 IP 范围是一般都是 172.17.x.x</li></ul><h2 id="host-模式">host 模式</h2><p>如果指定的host模式容器不会拥有一个独立network namespace，而是与宿主主机共用network namespace。也就说明容器本身不会有的网卡信息，而是使用宿主主机的网络信息。容器除了网络，其他比如文件系统、进程等依然都是隔离的。</p><ul><li>host 网络模式需要在创建容器时通过参数 <code>--net host</code> 或者 <code>--network host</code> 指定；</li><li>采用 host 网络模式的 Docker Container，可以直接使用宿主机的 IP 地址与外界进行通信，若宿主机的 eth0 是一个公有 IP，那么容器也拥有这个公有 IP。同时容器内服务的端口也可以使用宿主机的端口，无需额外进行 NAT 转换；</li><li>host 网络模式可以让容器共享宿主机网络栈，这样的好处是外部主机与容器直接通信，但是容器的网络缺少隔离性。</li></ul><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240617102245846.png" alt="image-20240617102245846"></p><p>说明：</p><ul><li>–net=host 指定</li><li>容器和宿主主机共享 Network namespace</li><li>host模式因为和宿主主机共享network namespace，会有可能出现端口冲突的情况。</li></ul><h2 id="container模式">container模式</h2><p>container模式和host模式很类似，host模式和宿主主机共享network namespace;container模式和指定的容器共享，两者之间除了网络共享（网卡、主机名、IP 地址），其他方面还是隔离的。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240617102450256.png" alt="image-20240617102450256"></p><p>命令：<code>docker run -d -name tomcat02 --net=container:name/id -p 8000:80 tomcat:latest</code><br>说明：</p><ul><li>–-net={容器id 或容器name} 指定</li><li>当前容器和另外一个容器共享 Network namespace</li></ul><h2 id="none模式">none模式</h2><p>如果dockers容器指定的网络模式为none,该容器没有办法联网，外界也无法访问它，可以用来本次测试。</p><p>命令：<code>docker run -d -name tomcat02 --net=none -p 8000:80 tomcat:latest</code><br>说明：</p><ul><li>–net=none 指定</li><li>容器有独立的Network namespace，但并没有对其进行任何网络设置，如果需要的话，需要自定义配置网络</li></ul><h2 id="Docker-网络桥接模式和-Host-模式的区别">Docker 网络桥接模式和 Host 模式的区别</h2><p>首先，我们需要了解一下 Docker 的两种网络模式之间的区别。在桥接网络模式下，Docker 将为每个容器创建一个独立的网络命名空间，并为容器分配一个|P 地址。而在 Host 网络模式下，容器将直接使用主机的网络栈，与主机共享网络接口和 IP 地址，这意味着容器可以直接访问主机上的所有网络服务，同时也会导致容器与主机网络之间的隔离性降低。</p><p>学习自：<a href="https://www.cnblogs.com/xiongzaiqiren/p/18177383/docker-network">docker网络配置：bridge模式、host模式、container模式、none模式</a></p><p>优秀教程：<a href="https://www.cnblogs.com/taoxiaoxin/p/18082633">Docker 网络模式详解及容器间网络通信 </a></p>]]></content>
    
    
    <summary type="html">容器网络4种模式</summary>
    
    
    
    <category term="Docker" scheme="https://penge666.github.io/categories/Docker/"/>
    
    <category term="微服务" scheme="https://penge666.github.io/categories/Docker/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
    
    <category term="Docker" scheme="https://penge666.github.io/tags/Docker/"/>
    
    <category term="微服务" scheme="https://penge666.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Kafka核心知识总结</title>
    <link href="https://penge666.github.io/posts/68ad5ab4.html"/>
    <id>https://penge666.github.io/posts/68ad5ab4.html</id>
    <published>2024-06-06T14:48:06.000Z</published>
    <updated>2024-06-06T14:49:11.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本简介">基本简介</h2><p>Apache Kafka是由LinkedIn采用Scala和Java开发的开源流处理软件平台，并捐赠给了Apache Software Foundation。</p><p>该项目旨在提供统一的、高吞吐量、低延迟的平台来处理实时数据流。</p><p>Kafka可以通过Kafka Connect连接到外部系统，并提供了Kafka Streams。</p><p><strong>「Kafka的特性」</strong></p><p>Kafka是一种分布式的，基于发布/订阅的消息系统，主要特性如下：</p><table><thead><tr><th style="text-align:left">特性</th><th style="text-align:left">分布式</th><th style="text-align:left"><strong>「高性能」</strong></th><th style="text-align:left"><strong>「持久性和扩展性」</strong></th></tr></thead><tbody><tr><td style="text-align:left">描述</td><td style="text-align:left">多分区</td><td style="text-align:left">高吞吐量</td><td style="text-align:left">数据可持久化</td></tr><tr><td style="text-align:left">多副本</td><td style="text-align:left">低延迟</td><td style="text-align:left">容错性</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">多订阅者</td><td style="text-align:left">高并发</td><td style="text-align:left">支持水平在线扩展</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">基于ZooKeeper调度</td><td style="text-align:left">时间复杂度为O(1)</td><td style="text-align:left">消息自动平衡</td><td style="text-align:left"></td></tr></tbody></table><h2 id="版本号">版本号</h2><p><strong>「Kafka版本命名」</strong></p><p>我们在官网上下载Kafka时，会看到这样的版本：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606215953532.png" alt="image-20240606215953532"></p><p>前面的版本号是编译Kafka源代码的Scala编译器版本。</p><p><strong>Kafka服务器端的代码完全由Scala语言编写</strong>，Scala同时支持面向对象编程和函数式编程，用Scala写成的源代码编译之后也是普通的<code>.class</code>文件，因此我们说Scala是JVM系的语言。</p><p>真正的Kafka版本号实际上是<code>2.1.1</code>。</p><p>前面的2表示大版本号，即Major Version；中间的1表示小版本号或次版本号，即Minor Version；最后的1表示修订版本号，也就是Patch号。</p><p>Kafka社区在发布1.0.0版本后写过一篇文章，宣布Kafka版本命名规则正式从4位演进到3位，比如0.11.0.0版本就是4位版本号。</p><p>有个建议，不论用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多Kafka为你提供的性能优化收益。</p><p><strong>「版本演进」</strong></p><p>0.7版本：只提供了最基础的消息队列功能。</p><p>0.8版本：引入了副本机制，至此kafka成为了一个整整意义上完备的分布式可靠消息队列解决方案</p><p>0.9.0.0版本：增加了基础的安全认证/权限功能；使用Java重新了新版本消费者API；引入了Kafka Connect组件。</p><p>0.11.0.0版本：提供了幂等性Producer API以及事务API；对Kafka消息格式做了重构。</p><p>1.0和2.0版本：主要还是Kafka Streams的各种改进</p><h2 id="基本概念">基本概念</h2><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606220052414.png" alt="image-20240606220052414"></p><p><strong>「主题」</strong></p><p>发布订阅的对象是主题（<code>Topic</code>），可以为每 个业务、每个应用甚至是每类数据都创建专属的主题</p><p><strong>「生产者和消费者」</strong></p><p>向主题发布消息的客户端应用程序称为生产者，生产者程序通常持续不断地 向一个或多个主题发送消息</p><p>订阅这些主题消息的客户端应用程序就被称为消费者，消费者也能够同时订阅多个主题的消息</p><p><strong>「Broker」</strong></p><p>集群由多个 Broker 组成，<strong><code>Broker</code> 负责接收和处理客户端发送过来的请求，以及对消息进行持久化</strong></p><p>虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将 不同的 <code>Broker</code> 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面 运行的所有 Broker 进程都挂掉了，其他机器上的 <code>Broker</code> 也依然能够对外提供服务</p><p><strong>「备份机制」</strong></p><p>备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝被称为副本</p><p>定义了两类副本：领导者副本和追随者副本</p><p>前者对外提供服务，这里的对外指的是与 客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互</p><p><strong>「分区」</strong></p><p>分区机制指的是将每个主题划分成多个分区，每个分区是一组有序的消息日志</p><p>生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区 0 中，要么在分区 1 中</p><p>每个分区下可以配置若干个副本，其中只能有 1 个领 导者副本和 N-1 个追随者副本</p><p>生产者向分区写入消息，每条消息在分区中的位置信息叫位移</p><p><strong>「消费者组」</strong></p><p>多个消费者实例共同组成一个组来 消费一组主题</p><p>这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它</p><p>如果所有实例都属于同一个 <code>Group</code>， 那么它实现的就是消息队列模型；</p><p>如果所有实例分别属于不 同的 <code>Group</code>，那么它实现的就是发布/订阅模型</p><p><strong>「Coordinator：协调者」</strong></p><p>所谓<strong>协调者</strong>，它专门为Consumer Group服务，负责为Group<strong>执行Rebalance以及提供位移管理和组成员管理</strong>等。</p><p>具体来讲，Consumer端应用程序在提交位移时，其实是向Coordinator所在的Broker提交位移，同样地，当Consumer应用启动时，也是向Coordinator所在的Broker发送各种请求，然后由Coordinator负责执行消费者组的注册、成员管理记录等元数据管理操作。</p><p>所有Broker在启动时，都会创建和开启相应的Coordinator组件。</p><p>也就是说，<strong>「所有Broker都有各自的Coordinator组件」</strong>。</p><p>那么，Consumer Group如何确定为它服务的Coordinator在哪台Broker上呢？</p><p>【简单说，知道你哪个分区，找到该分区的leader】</p><p>【※】生活中的例子</p><p>在Kafka中，主题<code>__consumer_offsets</code>是一个特别的内部主题，它用于存储所有消费者组的消费进度，也就是offset。</p><p>举个例子，假设你正在看一本有很多章节的书，你可能会用一个书签来记住你读到哪一页，这样当你下次继续阅读时，你就知道从哪里开始。在这个例子中，书签就像是Kafka中的offset，它记录了消费者读取到消息队列的哪个位置。</p><p>然后假设你和你的朋友们一起在读这本书，每个人可能会在不同的时间阅读，所以每个人的书签位置可能会不同。你们可能需要一个地方来记录每个人的书签位置，这样每个人都可以知道自己应该从哪里开始阅读。在这个例子中，记录书签位置的地方就像是Kafka中的<code>__consumer_offsets</code>主题，它存储了每个消费者组的消费进度。</p><p>所以，<code>__consumer_offsets</code>主题在Kafka中扮演了非常重要的角色，它确保了即使消费者挂掉或者重新启动，也能从上次消费的位置继续消费，保证了消息的连续性。</p><hr><p>首先，Kafka会计算该Group的<code>group.id</code>参数的哈希值。</p><p>比如你有个Group的<code>group.id</code>设置成了<code>test-group</code>，那么它的hashCode值就应该是627841412。</p><p>其次，Kafka会计算<code>__consumer_offsets</code>的分区数，通常是50个分区，之后将刚才那个哈希值对分区数进行取模加求绝对值计算，即<code>abs(627841412 % 50) = 12</code>。【判断在哪个分区上，因为分区是轮询确定的】</p><p>此时，我们就知道了<code>__consumer_offsets</code>主题的分区12负责保存这个Group的数据。</p><p>有了分区号，我们只需要找出<code>__consumer_offsets</code>主题分区12的Leader副本在哪个Broker上就可以了，这个Broker，就是我们要找的Coordinator。</p><p><strong>「消费者位移：Consumer Offset」</strong></p><p>消费者消费进度，每个消费者都有自己的消费者位移。</p><p><strong>「重平衡：Rebalance」</strong></p><p>消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。</p><p>Rebalance是Kafka消费者端实现高可用的重要手段。</p><p><strong>「AR（Assigned Replicas）」</strong>：分区中的所有副本统称为AR。</p><p>所有消息会先发送到leader副本，然后follower副本才能从leader中拉取消息进行同步。</p><p>但是在同步期间，follower对于leader而言会有一定程度的滞后，这个时候follower和leader并非完全同步状态</p><p><strong>「OSR（Out Sync Replicas）」</strong>：follower副本与leader副本没有完全同步或滞后的副本集合</p><p><strong>「ISR（In Sync Replicas）：「AR中的一个子集，ISR中的副本都」是与leader保持完全同步的副本」</strong>，如果某个在ISR中的follower副本落后于leader副本太多，则会被从ISR中移除，否则如果完全同步，会从OSR中移至ISR集合。</p><p>在默认情况下，当leader副本发生故障时，只有在ISR集合中的follower副本才有资格被选举为新leader，而OSR中的副本没有机会（可以通过<code>unclean.leader.election.enable</code>进行配置）</p><p><strong>「ISR（In Sync Replicas）：**「AR中的一个子集，ISR中的副本都」**是与leader保持完全同步的副本」</strong>，如果某个在ISR中的follower副本落后于leader副本太多，则会被从ISR中移除，否则如果完全同步，会从OSR中移至ISR集合。</p><p>在默认情况下，当leader副本发生故障时，只有在ISR集合中的follower副本才有资格被选举为新leader，而OSR中的副本没有机会（可以通过<code>unclean.leader.election.enable</code>进行配置）</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606220849989.png" alt="image-20240606220849989"></p><p><strong>「LEO（Log End Offset）」</strong>：标识当前日志文件中下一条待写入的消息的offset</p><p>上图中offset为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的offset值加1</p><p>分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。</p><h2 id="系统架构">系统架构</h2><p><strong>「kafka设计思想」</strong></p><p>一个最基本的架构是生产者发布一个消息到Kafka的一个Topic ，该Topic的消息存放于的Broker中，消费者订阅这个Topic，然后从Broker中消费消息，下面这个图可以更直观的描述这个场景：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606220909898.png" alt="image-20240606220909898"></p><p><strong>「消息状态：」</strong> 在Kafka中，消息是否被消费的状态保存在Consumer中，Broker不会关心消息是否被消费或被谁消费，Consumer会记录一个offset值（指向partition中下一条将要被消费的消息位置），如果offset被错误设置可能导致同一条消息被多次消费或者消息丢失。</p><p><strong>「消息持久化：」</strong> Kafka会把消息持久化到本地文件系统中，并且具有极高的性能。</p><p><strong>「批量发送：」</strong> Kafka支持以消息集合为单位进行批量发送，以提高效率。</p><p><strong>「Push-and-Pull：」</strong> Kafka中的Producer和Consumer采用的是Push-and-Pull模式，即Producer向Broker Push消息，Consumer从Broker Pull消息。</p><p><strong>「分区机制（Partition）：」</strong> Kafka的Broker端支持消息分区，Producer可以决定把消息发到哪个Partition，在一个Partition中消息的顺序就是Producer发送消息的顺序，一个Topic中的Partition数是可配置的，Partition是Kafka高吞吐量的重要保证。</p><p><strong>「系统架构」</strong></p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606221119878.png" alt="image-20240606221119878"></p><p>通常情况下，一个kafka体系架构包括**「多个Producer」<strong>、</strong>「多个Consumer」<strong>、</strong>「多个broker」<strong>以及</strong>「一个Zookeeper集群」**。</p><p><strong>「Producer」</strong>：生产者，负责将消息发送到kafka中。</p><p><strong>「Consumer」</strong>：消费者，负责从kafka中拉取消息进行消费。</p><p><strong>「Broker」</strong>：Kafka服务节点，一个或多个Broker组成了一个Kafka集群</p><p><strong>「Zookeeper集群」</strong>：负责管理kafka集群元数据以及控制器选举等。</p><h2 id="生产者分区">生产者分区</h2><p><strong>「为什么分区？」</strong></p><p>Kafka的消息组织方式实际上是三级结构：<strong>主题-分区-消息。</strong></p><p>主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份。</p><p>其实分区的作用就是提供负载均衡的能力，或者说对数据进行分区的主要原因，就是为了实现系统的高伸缩性（Scalability）。</p><p>不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理，并且，我们还可以通过添加新的节点机器来增加整体系统的吞吐量。</p><p><strong>解释下</strong>：</p><p>高伸缩性（Scalability）可以理解为一个系统在处理更大负载时，有能力通过升级或增加资源来提升处理能力的特性。在Kafka中，分区就是实现高伸缩性的一种方式。</p><p>比如，我们可以把一个超市看作是一个系统。如果超市的客流量增加，那么超市就需要提高处理能力来满足更多顾客的需求。一种方式是增加收银员的数量，这就相当于在Kafka中增加分区。每个收银员可以同时为一个顾客结账，就像每个分区可以同时处理一部分数据。当我们增加收银员的数量时，超市就能同时处理更多的顾客，这就提高了系统的伸缩性。</p><p>同样地，如果一个主题的数据量非常大，超过了一个服务器的处理能力，那么可以将这个主题分为多个分区，然后分布在多个服务器上。这样，就可以利用多台服务器的处理能力来处理这个主题的数据，从而提高系统的伸缩性。</p><p>总的来说，通过分区，Kafka可以实现高伸缩性，满足大数据处理的需求。</p><p><strong>「都有哪些分区策略？」</strong></p><p><strong>「所谓分区策略是决定生产者将消息发送到哪个分区的算法。」</strong></p><p>Kafka为我们提供了默认的分区策略，同时它也支持你自定义分区策略。</p><p><strong>「自定义分区策略」</strong></p><p>如果要自定义分区策略，你需要显式地配置生产者端的参数p<code>artitioner.class</code>。</p><p>在编写生产者程序时，你可以编写一个具体的类实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口。</p><p>这个接口也很简单，只定义了两个方法：partition()和close()，通常你只需要实现最重要的partition方法。</p><p>我们来看看这个方法的方法签名：</p><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">partition</span>(<span class="built_in">String</span> topic, <span class="built_in">Object</span> <span class="built_in">key</span>, <span class="type">byte</span>[] keyBytes, <span class="built_in">Object</span> value, <span class="type">byte</span>[] valueBytes, Cluster cluster);</span><br></pre></td></tr></table></figure><p>这里的topic、key、keyBytes、value和valueBytes都属于消息数据，cluster则是集群信息（比如当前Kafka集群共有多少主题、多少Broker等）。</p><p>Kafka给你这么多信息，就是希望让你能够充分地利用这些信息对消息进行分区，计算出它要被发送到哪个分区中。</p><p>只要你自己的实现类定义好了partition方法，同时设置<code>partitioner.class</code>参数为你自己实现类的Full Qualified Name，那么生产者程序就会按照你的代码逻辑对消息进行分区。</p><p><strong>「轮询策略」</strong></p><p>也称Round-robin策略，即顺序分配。</p><p>比如一个主题下有3个分区，那么第一条消息被发送到分区0，第二条被发送到分区1，第三条被发送到分区2，以此类推。当生产第4条消息时又会重新开始，即将其分配到分区0</p><p>这就是所谓的轮询策略。轮询策略是Kafka Java生产者API默认提供的分区策略。</p><p><strong>「轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。」</strong></p><p><strong>「随机策略」</strong></p><p>也称Randomness策略。所谓随机就是我们随意地将消息放置到任意一个分区上。</p><p>如果要实现随机策略版的partition方法，很简单，只需要两行代码即可：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List partitions <span class="operator">=</span> cluster.partitionsForTopic(topic)<span class="comment">;</span></span><br><span class="line">return ThreadLocalRandom.current().nextInt(partitions.size())<span class="comment">;</span></span><br></pre></td></tr></table></figure><p>先计算出该主题总的分区数，然后随机地返回一个小于它的正整数。</p><p>本质上看随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要逊于轮询策略，所以**「如果追求数据的均匀分布，还是使用轮询策略比较好」**。事实上，随机策略是老版本生产者使用的分区策略，在新版本中已经改为轮询了。</p><p><strong>「按消息键保序策略」</strong></p><p>Kafka允许为每条消息定义消息键，简称为Key。</p><p>这个Key的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务ID等；也可以用来表征消息元数据。</p><p>特别是在Kafka不支持时间戳的年代，在一些场景中，工程师们都是直接将消息创建时间封装进Key里面的。</p><p>一旦消息被定义了Key，那么你就可以保证同一个Key的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略</p><p>实现这个策略的partition方法同样简单，只需要下面两行代码即可：</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List partitions = <span class="keyword">cluster</span>.partitionsForTopic(topic);</span><br><span class="line"><span class="keyword">return</span> Math.<span class="keyword">abs</span>(key.hashCode()) % partitions.<span class="keyword">size</span>();</span><br></pre></td></tr></table></figure><p>前面提到的Kafka默认分区策略实际上同时实现了两种策略：如果指定了Key，那么默认实现按消息键保序策略；如果没有指定Key，则使用轮询策略。</p><p><strong>「其他分区策略」</strong></p><p>其实还有一种比较常见的，即所谓的基于地理位置的分区策略。</p><p>当然这种策略一般只针对那些大规模的Kafka集群，特别是跨城市、跨国家甚至是跨大洲的集群。</p><p>我们可以根据Broker所在的IP地址实现定制化的分区策略。比如下面这段代码：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List partitions = <span class="keyword">cluster</span>.partitionsForTopic(topic);</span><br><span class="line"><span class="keyword">return</span> partitions.stream().<span class="keyword">filter</span>(p -&gt; isSouth(p.leader().host())).map(PartitionInfo::<span class="keyword">partition</span>).findAny().<span class="keyword">get</span>();</span><br></pre></td></tr></table></figure><p>我们可以从所有分区中找出那些Leader副本在南方的所有分区，然后随机挑选一个进行消息发送。</p><h2 id="生产者压缩算法">生产者压缩算法</h2><p><strong>「Kafka是如何压缩消息的呢？」</strong></p><p>目前Kafka共有两大类消息格式，社区分别称之为V1版本和V2版本。</p><p>V2版本是Kafka 0.11.0.0中正式引入的。</p><p>不论是哪个版本，Kafka的消息层次都分为两层：消息集合以及消息。</p><p>一个消息集合中包含若干条日志项，而日志项才是真正封装消息的地方。</p><p>Kafka底层的消息日志由一系列消息集合日志项组成。</p><p>Kafka通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。</p><p><strong>「那么社区引入V2版本的目的是什么呢？」</strong></p><p>V2版本主要是针对V1版本的一些弊端做了修正，比如把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。</p><p>举个例子：原来在V1版本中，每条消息都需要执行CRC校验，但有些情况下消息的CRC值是会发生变化的。</p><p>比如在Broker端可能会对消息时间戳字段进行更新，那么重新计算之后的CRC值也会相应更新；再比如Broker端在执行消息格式转换时（主要是为了兼容老版本客户端程序），也会带来CRC值的变化。</p><p>鉴于这些情况，再对每条消息都执行CRC校验就有点没必要了，不仅浪费空间还耽误CPU时间，因此在V2版本中，消息的CRC校验工作就被移到了消息集合这一层。</p><p>V2版本还有一个和压缩息息相关的改进，就是保存压缩消息的方法发生了变化。</p><p>之前V1版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而V2版本的做法是对整个消息集合进行压缩，显然后者应该比前者有更好的压缩效果。</p><p><strong>「何时压缩？」</strong></p><p>在Kafka中，压缩可能发生在两个地方：生产者端和Broker端。</p><p>生产者程序中配置<code>compression.type</code>参数即表示启用指定类型的压缩算法。</p><p>比如下面这段程序代码展示了如何构建一个开启GZIP的Producer对象：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Properties <span class="built_in">props</span> = <span class="built_in">new</span> Properties(); </span><br><span class="line"><span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>); </span><br><span class="line"><span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>); </span><br><span class="line"><span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>); <span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>); // 开启GZIP压缩 </span><br><span class="line"><span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;compression.type&quot;</span>, <span class="string">&quot;gzip&quot;</span>); </span><br><span class="line">Producer producer = <span class="built_in">new</span> KafkaProducer&lt;&gt;(<span class="built_in">props</span>);</span><br></pre></td></tr></table></figure><p>这里比较关键的代码行是<code>props.put(“compression.type”, “gzip”)</code>，它表明该Producer的压缩算法使用的是GZIP。</p><p>这样Producer启动后生产的每个消息集合都是经GZIP压缩过的，故而能很好地节省网络传输带宽以及Kafka Broker端的磁盘占用。</p><p>有两种例外情况就可能让Broker重新压缩消息：</p><p><strong>「情况一：Broker端指定了和Producer端不同的压缩算法。」</strong></p><p>一旦你在Broker端设置了不同的<code>compression.type</code>值，就一定要小心了，因为可能会发生预料之外的压缩/解压缩操作，通常表现为Broker端CPU使用率飙升。</p><p><strong>「情况二：Broker端发生了消息格式转换。」</strong></p><p>所谓的消息格式转换主要是为了兼容老版本的消费者程序。</p><p>在一个生产环境中，Kafka集群中同时保存多种版本的消息格式非常常见。</p><p>为了兼容老版本的格式，Broker端会对新版本消息执行向老版本格式的转换。</p><p>这个过程中会涉及消息的解压缩和重新压缩。</p><p>一般情况下这种消息格式转换对性能是有很大影响的，除了这里的压缩之外，它还让Kafka丧失了Zero Copy特性。</p><p><strong>「何时解压缩？」</strong></p><p>有压缩必有解压缩！通常来说解压缩发生在消费者程序中，也就是说Producer发送压缩消息到Broker后，Broker照单全收并原样保存起来。当Consumer程序请求这部分消息时，Broker依然原样发送出去，当消息到达Consumer端后，由Consumer自行解压缩还原成之前的消息。</p><p><strong>「基本过程：Producer端压缩、Broker端保持、Consumer端解压缩。」</strong></p><p>注意：除了在Consumer端解压缩，Broker端也会进行解压缩。</p><p>每个压缩过的消息集合在Broker端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。</p><p>我们必须承认这种解压缩对Broker端性能是有一定影响的，特别是对CPU的使用率而言。</p><p><strong>「各种压缩算法对比」</strong></p><p>在Kafka 2.1.0版本之前，Kafka支持3种压缩算法：GZIP、Snappy和LZ4。</p><p>从2.1.0开始，Kafka正式支持Zstandard算法（简写为zstd）。</p><p>它是Facebook开源的一个压缩算法，能够提供超高的压缩比。</p><p>在实际使用中，GZIP、Snappy、LZ4和zstd的表现各有千秋。</p><p>但对于Kafka而言，在吞吐量方面：LZ4 &gt; Snappy &gt; zstd和GZIP；而在压缩比方面，zstd &gt; LZ4 &gt; GZIP &gt; Snappy。</p><p>具体到物理资源，使用Snappy算法占用的网络带宽最多，zstd最少；</p><p>在CPU使用率方面，各个算法表现得差不多，只是在压缩时Snappy算法使用的CPU较多一些，而在解压缩时GZIP算法则可能使用更多的CPU。</p><p><strong>「最佳实践」</strong></p><blockquote><p>❝</p><p>何时启用压缩是比较合适的时机呢？</p><p>❞</p></blockquote><p>启用压缩的一个条件就是Producer程序运行机器上的CPU资源要很充足。</p><p>除了CPU资源充足这一条件，如果你的环境中带宽资源有限，那么建议你开启压缩。</p><h2 id="消费者组">消费者组</h2><p><strong>「Consumer Group是Kafka提供的可扩展且具有容错性的消费者机制」</strong>。</p><p>既然是一个组，那么组内必然可以有多个消费者或消费者实例，它们共享一个公共的ID，这个ID被称为Group ID。</p><p>组内的所有消费者协调在一起来消费订阅主题的所有分区。</p><blockquote><p>❝</p><p><strong>每个分区只能由同一个消费者组内的一个Consumer实例来消费。</strong></p><p>❞</p></blockquote><p><strong>「Consumer Group三个特性：」</strong></p><ol><li>Consumer Group下可以有一个或多个Consumer实例，这里的实例可以是一个单独的进程，也可以是同一进程下的线程。</li><li>Group ID是一个字符串，在一个Kafka集群中，它标识唯一的一个Consumer Group。</li><li>Consumer Group下所有实例订阅的主题的单个分区，只能分配给组内的某个Consumer实例消费，这个分区当然也可以被其他的Group消费。</li></ol><p>当Consumer Group订阅了多个主题后，组内的每个实例不要求一定要订阅主题的所有分区，它只会消费部分分区中的消息。</p><p>Consumer Group之间彼此独立，互不影响，它们能够订阅相同的一组主题而互不干涉。</p><p><strong>「Kafka仅仅使用Consumer Group这一种机制，却同时实现了传统消息引擎系统的两大模型」</strong>：</p><ul><li>如果所有实例都属于同一个Group，那么它实现的就是消息队列模型；</li><li>如果所有实例分别属于不同的Group，那么它实现的就是发布/订阅模型。</li></ul><p><strong>「一个Group下该有多少个Consumer实例呢？」</strong></p><p><strong>「理想情况下，Consumer实例的数量应该等于该Group订阅主题的分区总数。」</strong></p><p>假设一个Consumer Group订阅了3个主题，分别是A、B、C，它们的分区数依次是1、2、3，那么通常情况下，为该Group设置6个Consumer实例是比较理想的情形，因为它能最大限度地实现高伸缩性。</p><p><strong>「针对Consumer Group，Kafka是怎么管理位移的呢？」</strong></p><p><strong>「位移Offset」</strong></p><p>老版本的Consumer Group把位移保存在ZooKeeper中。</p><p>Apache ZooKeeper是一个分布式的协调服务框架，Kafka重度依赖它实现各种各样的协调管理。</p><p>将位移保存在ZooKeeper外部系统的做法，最显而易见的好处就是减少了Kafka Broker端的状态保存开销。</p><p>不过，慢慢地发现了一个问题，即ZooKeeper这类元框架其实并不适合进行频繁的写更新，而Consumer Group的位移更新却是一个非常频繁的操作。</p><p>这种大吞吐量的写操作会极大地拖慢ZooKeeper集群的性能。</p><p>于是，在新版本的Consumer Group中，Kafka社区重新设计了Consumer Group的位移管理方式，采用了将位移保存在Kafka内部主题的方法。</p><p>这个内部主题就是<code>__consumer_offsets</code>。</p><h2 id="消费者策略">消费者策略</h2><p><strong>「第一种是Round」</strong></p><p>默认，也叫轮循，说的是对于同一组消费者来说，使用轮训分配的方式，决定消费者消费的分区</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606221917493.png" alt="image-20240606221917493"></p><p><strong>「第二种叫做Range」</strong></p><p>对一个消费者组来说决定消费方式是以分区总数除以消费者总数来决定，一般如果不能整除，往往是从头开始将剩余的分区分配开</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606221943589.png" alt="image-20240606221943589"></p><p><strong>「第三种叫Sticky」</strong></p><p>是在0.11.x，新增的，它和前面两个不是很一样，它是在Range上的一种升华，且前面两个当同组内有新的消费者加入或者旧的消费者退出的时候，会从新开始决定消费者消费方式，但是Sticky，在同组中有新的新的消费者加入或者旧的消费者退出时，不会直接开始新的Range分配，而是保留现有消费者原来的消费策略，将退出的消费者所消费的分区平均分配给现有消费者，新增消费者同理，同其他现存消费者的消费策略中分离</p><h2 id="位移提交">位移提交</h2><p>假设一个分区中有10条消息，位移分别是0到9。</p><p>某个Consumer应用已消费了5条消息，这就说明该Consumer消费了位移为0到4的5条消息，此时Consumer的位移是5，指向了下一条消息的位移。</p><p>因为Consumer能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即**「Consumer需要为分配给它的每个分区提交各自的位移数据」**。</p><p><strong>「位移提交分为自动提交和手动提交；从Consumer端的角度来说，位移提交分为同步提交和异步提交」</strong>。</p><p>开启自动提交位移的方法：Consumer端有个参数<code>enable.auto.commit</code>，把它设置为true或者压根不设置它就可以了。</p><p>因为它的默认值就是true，即Java Consumer默认就是自动提交位移的。</p><p>如果启用了自动提交，Consumer端还有个参数：<code>auto.commit.interval.ms</code>。</p><p>它的默认值是5秒，表明Kafka每5秒会为你自动提交一次位移。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Properties <span class="built_in">props</span> = <span class="built_in">new</span> Properties();</span><br><span class="line">     <span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;localhost:9092&quot;</span>);</span><br><span class="line">     <span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">     <span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">     <span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;2000&quot;</span>);</span><br><span class="line">     <span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">     <span class="built_in">props</span>.<span class="built_in">put</span>(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">     KafkaConsumer consumer = <span class="built_in">new</span> KafkaConsumer&lt;&gt;(<span class="built_in">props</span>);</span><br><span class="line">     consumer.subscribe(Arrays.asList(<span class="string">&quot;foo&quot;</span>, <span class="string">&quot;bar&quot;</span>));</span><br><span class="line">     <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">         ConsumerRecords records = consumer.poll(<span class="number">100</span>);</span><br><span class="line">         <span class="keyword">for</span> (ConsumerRecord record : records)</span><br><span class="line">             System.out.<span class="built_in">printf</span>(<span class="string">&quot;offset = %d, key = %s, value = %s%n&quot;</span>, record.offset(), record.<span class="built_in">key</span>(), record.value());</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure><p>上面的第3、第4行代码，就是开启自动提交位移的方法。</p><p>开启手动提交位移的方法就是设置<code>enable.auto.commit为false</code>。</p><p>还需要调用相应的API手动提交位移。最简单的API就是**「KafkaConsumer#commitSync()」**。</p><p>该方法会提交<code>KafkaConsumer#poll()</code>返回的最新位移。</p><p>从名字上来看，它是一个同步操作，即该方法会一直等待，直到位移被成功提交才会返回。</p><p>如果提交过程中出现异常，该方法会将异常信息抛出。</p><p>下面这段代码展示了commitSync()的使用方法：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords <span class="keyword">records</span> =</span><br><span class="line">                        consumer.poll(<span class="built_in">Duration</span>.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            process(<span class="keyword">records</span>); <span class="comment">// 处理消息</span></span><br><span class="line">            try &#123;</span><br><span class="line">                        consumer.commitSync();</span><br><span class="line">            &#125; catch (CommitFailedException e) &#123;</span><br><span class="line">                        <span class="keyword">handle</span>(e); <span class="comment">// 处理提交失败异常</span></span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一旦设置了<code>enable.auto.commit</code>为true，Kafka会保证在开始调用poll方法时，提交上次poll返回的所有消息。</p><p>从顺序上来说，poll方法的逻辑是先提交上一批消息的位移，再处理下一批消息，因此它能保证不出现消费丢失的情况。</p><p>但自动提交位移的一个问题在于，<strong>「它可能会出现重复消费」</strong>。</p><p>而手动提交位移，它的好处就在于更加灵活，你完全能够把控位移提交的时机和频率。</p><p>但是，它也有一个缺陷，就是在调用commitSync()时，Consumer程序会处于阻塞状态，直到远端的Broker返回提交结果，这个状态才会结束。</p><p>鉴于这个问题，Kafka社区为手动提交位移提供了另一个API方法：<strong>「KafkaConsumer#commitAsync()」</strong>。</p><p>从名字上来看它就不是同步的，而是一个异步操作。</p><p>调用commitAsync()之后，它会立即返回，不会阻塞，因此不会影响Consumer应用的TPS。</p><p>由于它是异步的，Kafka提供了回调函数（callback），供你实现提交之后的逻辑，比如记录日志或处理异常等。</p><p>下面这段代码展示了调用commitAsync()的方法：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">            ConsumerRecords <span class="keyword">records</span> = </span><br><span class="line"> consumer.poll(<span class="built_in">Duration</span>.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            process(<span class="keyword">records</span>); <span class="comment">// 处理消息</span></span><br><span class="line">            consumer.commitAsync((offsets, exception) -&gt; &#123;</span><br><span class="line"> <span class="keyword">if</span> (exception != <span class="built_in">null</span>)</span><br><span class="line"> <span class="keyword">handle</span>(exception);</span><br><span class="line"> &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>commitAsync的问题在于，出现问题时它不会自动重试。</p><p>显然，如果是手动提交，我们需要将commitSync和commitAsync组合使用才能到达最理想的效果，原因有两个：</p><ol><li>我们可以利用commitSync的自动重试来规避那些瞬时错误，比如网络的瞬时抖动，Broker端GC等，因为这些问题都是短暂的，自动重试通常都会成功。</li><li>我们不希望程序总处于阻塞状态，影响TPS。</li></ol><p>我们来看一下下面这段代码，它展示的是如何将两个API方法结合使用进行手动提交。</p><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">                        ConsumerRecords records = </span><br><span class="line">                                    consumer.poll(<span class="built_in">Duration</span>.ofSeconds(<span class="number">1</span>));</span><br><span class="line">                        process(records); <span class="comment">// 处理消息</span></span><br><span class="line">                        commitAysnc(); <span class="comment">// 使用异步提交规避阻塞</span></span><br><span class="line">            &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">            handle(e); <span class="comment">// 处理异常</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                        consumer.commitSync(); <span class="comment">// 最后一次提交使用同步阻塞式提交</span></span><br><span class="line"> &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      consumer.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样一个场景：你的poll方法返回的不是500条消息，而是5000条。</p><p>那么，你肯定不想把这5000条消息都处理完之后再提交位移，因为一旦中间出现差错，之前处理的全部都要重来一遍。</p><p>比如前面这个5000条消息的例子，你可能希望每处理完100条消息就提交一次位移，这样能够避免大批量的消息重新消费。</p><p>Kafka Consumer API为手动提交提供了这样的方法：commitSync(Map)和commitAsync(Map)。</p><p>它们的参数是一个Map对象，键就是TopicPartition，即消费的分区，而值是一个OffsetAndMetadata对象，保存的主要是位移数据。</p><blockquote><p>❝</p><p>如何每处理100条消息就提交一次位移呢？</p><p>❞</p></blockquote><p>在这里，我以commitAsync为例，展示一段代码，实际上，commitSync的调用方法和它是一模一样的。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">private Map offsets = <span class="built_in">new</span> HashMap&lt;&gt;();</span><br><span class="line"><span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">……</span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            ConsumerRecords records = </span><br><span class="line"> consumer.poll(Duration.ofSeconds(<span class="number">1</span>));</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord <span class="type">record</span>: records) &#123;</span><br><span class="line">                        process(<span class="type">record</span>);  // 处理消息</span><br><span class="line">                        offsets.put(<span class="built_in">new</span> TopicPartition(<span class="type">record</span>.topic(), <span class="type">record</span>.<span class="keyword">partition</span>()),</span><br><span class="line">                                   <span class="built_in">new</span> OffsetAndMetadata(<span class="type">record</span>.<span class="keyword">offset</span>() + <span class="number">1</span>)；</span><br><span class="line">                       <span class="keyword">if</span>（count % <span class="number">100</span> == <span class="number">0</span>）</span><br><span class="line">                                    consumer.commitAsync(offsets, <span class="keyword">null</span>); // 回调处理逻辑是<span class="keyword">null</span></span><br><span class="line">                        count++;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>程序先是创建了一个Map对象，用于保存Consumer消费处理过程中要提交的分区位移，之后开始逐条处理消息，并构造要提交的位移值。</p><p>代码的最后部分是做位移的提交。设置了一个计数器，每累计100条消息就统一提交一次位移。</p><p>与调用无参的commitAsync不同，这里调用了带Map对象参数的commitAsync进行细粒度的位移提交。</p><p>这样，这段代码就能够实现每处理100条消息就提交一次位移，不用再受poll方法返回的消息总数的限制了。</p><h2 id="重平衡">重平衡</h2><p><strong>「（重平衡）Rebalance本质上是一种协议，规定了一个Consumer Group下的所有Consumer如何达成一致，来分配订阅Topic的每个分区」</strong>。</p><p>比如某个Group下有20个Consumer实例，它订阅了一个具有100个分区的Topic。</p><p>正常情况下，Kafka平均会为每个Consumer分配5个分区。这个分配的过程就叫Rebalance。</p><p><strong>「Rebalance的触发条件有3个。」</strong></p><ol><li>组成员数发生变更。比如有新的Consumer实例加入组或者离开组，或是有Consumer实例崩溃被踢出组。</li><li>订阅主题数发生变更。Consumer Group可以使用正则表达式的方式订阅主题，比如<code>consumer.subscribe(Pattern.compile(“t.*c”))</code>就表明该Group订阅所有以字母t开头、字母c结尾的主题，在Consumer Group的运行过程中，你新创建了一个满足这样条件的主题，那么该Group就会发生Rebalance。</li><li>订阅主题的分区数发生变更。Kafka当前只能允许增加一个主题的分区数，当分区数增加时，就会触发订阅该主题的所有Group开启Rebalance。</li></ol><p>Rebalance发生时，Group下所有的Consumer实例都会协调在一起共同参与。</p><p><strong>「分配策略」</strong></p><p>当前Kafka默认提供了3种分配策略，每种策略都有一定的优势和劣势，社区会不断地完善这些策略，保证提供最公平的分配策略，即每个Consumer实例都能够得到较为平均的分区数。</p><p>比如一个Group内有10个Consumer实例，要消费100个分区，理想的分配策略自然是每个实例平均得到10个分区。</p><p>这就叫公平的分配策略。</p><p>举个简单的例子来说明一下Consumer Group发生Rebalance的过程。</p><p>假设目前某个Consumer Group下有两个Consumer，比如A和B，当第三个成员C加入时，Kafka会触发Rebalance，并根据默认的分配策略重新为A、B和C分配分区</p><p>Rebalance之后的分配依然是公平的，即每个Consumer实例都获得了2个分区的消费权。</p><p>在Rebalance过程中，所有Consumer实例都会停止消费，等待Rebalance完成，这是Rebalance为人诟病的一个方面。</p><p>目前Rebalance的设计是所有Consumer实例共同参与，全部重新分配所有分区。</p><p><strong>「Coordinator会在什么情况下认为某个Consumer实例已挂从而要退组呢？」</strong></p><p>当Consumer Group完成Rebalance之后，每个Consumer实例都会定期地向Coordinator发送心跳请求，表明它还存活着。</p><p>如果某个Consumer实例不能及时地发送这些心跳请求，Coordinator就会认为该Consumer已经死了，从而将其从Group中移除，然后开启新一轮Rebalance。</p><p>Consumer端有个参数，叫<code>session.timeout.ms</code>。</p><p>该参数的默认值是10秒，即如果Coordinator在10秒之内没有收到Group下某Consumer实例的心跳，它就会认为这个Consumer实例已经挂了。</p><p>除了这个参数，Consumer还提供了一个允许你控制发送心跳请求频率的参数，就是<code>heartbeat.interval.ms</code>。</p><p>这个值设置得越小，Consumer实例发送心跳请求的频率就越高。</p><p>频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启Rebalance，因为，目前Coordinator通知各个Consumer实例开启Rebalance的方法，就是将<code>REBALANCE_NEEDED</code>标志封装进心跳请求的响应体中。</p><p>除了以上两个参数，Consumer端还有一个参数，用于控制Consumer实际消费能力对Rebalance的影响，即<code>max.poll.interval.ms</code>参数。</p><p>它限定了Consumer端应用程序两次调用poll方法的最大时间间隔。</p><p>它的默认值是5分钟，表示你的Consumer程序如果在5分钟之内无法消费完poll方法返回的消息，那么Consumer会主动发起离开组的请求，Coordinator也会开启新一轮Rebalance。</p><p><strong>「可避免Rebalance的配置」</strong></p><p>第一类Rebalance是因为未能及时发送心跳，导致Consumer被踢出Group而引发的</p><p>因此可以设置**「<a href="http://session.timeout.xn--msheartbeat-804s.interval.ms">session.timeout.ms和heartbeat.interval.ms</a>」**的值。</p><ul><li>设置<code>session.timeout.ms</code> = 6s。</li><li>设置<code>heartbeat.interval.ms</code> = 2s。</li><li>要保证Consumer实例在被判定为dead之前，能够发送至少3轮的心跳请求，即<code>session.timeout.ms &gt;= 3 * heartbeat.interval.ms</code>。</li></ul><p>将<code>session.timeout.ms</code>设置成6s主要是为了让Coordinator能够更快地定位已经挂掉的Consumer。</p><p><strong>「第二类Rebalance是Consumer消费时间过长导致的」</strong>。</p><p>你要为你的业务处理逻辑留下充足的时间，这样Consumer就不会因为处理这些消息的时间太长而引发Rebalance了。</p><h2 id="ConsumerOffsets">ConsumerOffsets</h2><p><strong>「Kafka将Consumer的位移数据作为一条条普通的Kafka消息，提交到__consumer_offsets中。」</strong></p><p><strong>「__consumer_offsets的主要作用是保存Kafka消费者的位移信息。」</strong></p><p>它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。</p><p><code>__consumer_offsets</code>主题就是普通的Kafka主题。你可以手动地创建它、修改它，甚至是删除它。</p><p>虽说<code>__consumer_offsets</code>主题是一个普通的Kafka主题，但**「它的消息格式却是Kafka自己定义的」**，用户不能修改，也就是说你不能随意地向这个主题写消息，因为一旦你写入的消息不满足Kafka规定的格式，那么Kafka内部无法成功解析，就会造成Broker的崩溃。</p><p>Kafka Consumer有API帮你提交位移，也就是向<code>__consumer_offsets</code>主题写消息，千万不要自己写个Producer随意向该主题发送消息。</p><p><code>__consumer_offsets</code>有3种消息格式：</p><ol><li>用于保存Consumer Group信息的消息。</li><li>用于删除Group过期位移甚至是删除Group的消息。</li><li>保存了位移值。</li></ol><p>第2种格式它有个专属的名字：tombstone消息，即墓碑消息，也称delete mark，它的主要特点是它的消息体是null，即空消息体。</p><p>一旦某个Consumer Group下的所有Consumer实例都停止了，而且它们的位移数据都已被删除时，Kafka会向<code>__consumer_offsets</code>主题的对应分区写入tombstone消息，表明要彻底删除这个Group的信息。</p><p><code>__consumer_offsets</code>是怎么被创建的？</p><p>通常来说，<strong>「当Kafka集群中的第一个Consumer程序启动时，Kafka会自动创建位移主题」</strong>。</p><p><strong>「默认该主题的分区数是50，副本数是3」</strong>。</p><p>目前Kafka Consumer提交位移的方式有两种：<strong>「自动提交位移和手动提交位移。」</strong></p><p>Consumer端有个参数叫<code>enable.auto.commit</code>，如果值是true，则Consumer在后台默默地为你定期提交位移，提交间隔由一个专属的参数<code>auto.commit.interval.ms</code>来控制。</p><p>自动提交位移有一个显著的优点，就是省事，你不用操心位移提交的事情，就能保证消息消费不会丢失。</p><p>但这一点同时也是缺点，丧失了很大的灵活性和可控性，你完全没法把控Consumer端的位移管理。</p><p>Kafka Consumer API为你提供了位移提交的方法，如<code>consumer.commitSync</code>等。</p><p>当调用这些方法时，Kafka会向<code>__consumer_offsets</code>主题写入相应的消息。</p><p>如果你选择的是自动提交位移，那么就可能存在一个问题：只要Consumer一直启动着，它就会无限期地向位移主题写入消息。</p><p><strong>「举个极端一点的例子。」</strong></p><p>假设Consumer当前消费到了某个主题的最新一条消息，位移是100，之后该主题没有任何新消息产生，故Consumer无消息可消费了，所以位移永远保持在100。</p><p>由于是自动提交位移，位移主题中会不停地写入位移=100的消息。</p><p>显然Kafka只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。</p><p>这就要求Kafka必须要有针对位移主题消息特点的消息删除策略，否则这种消息会越来越多，最终撑爆整个磁盘。</p><p><strong>「Compact策略」</strong></p><p>Kafka使用**「Compact策略」**来删除<code>__consumer_offsets</code>主题中的过期消息，避免该主题无限期膨胀。</p><p>比如对于同一个Key的两条消息M1和M2，如果M1的发送时间早于M2，那么M1就是过期消息。</p><p>Compact的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。</p><p>我在这里贴一张来自官网的图片，来说明Compact过程。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606222941632.png" alt="image-20240606222941632"></p><p>图中位移为0、2和3的消息的Key都是K1，Compact之后，分区只需要保存位移为3的消息，因为它是最新发送的。</p><p><strong>「Kafka提供了专门的后台线程定期地巡检待Compact的主题，看看是否存在满足条件的可删除数据」</strong>。</p><p>这个后台线程叫Log Cleaner。</p><p>很多实际生产环境中都出现过位移主题无限膨胀占用过多磁盘空间的问题，如果你的环境中也有这个问题，建议你去检查一下Log Cleaner线程的状态，通常都是这个线程挂掉了导致的。</p><h2 id="副本机制">副本机制</h2><p>根据Kafka副本机制的定义，同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的Broker上，从而能够对抗部分Broker宕机带来的数据不可用。</p><p>下面展示的是一个有3台Broker的Kafka集群上的副本分布情况。</p><p>从这张图中，我们可以看到，主题1分区0的3个副本分散在3台Broker上，其他主题分区的副本也都散落在不同的Broker上，从而实现数据冗余。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223053208.png" alt="image-20240606223053208"></p><p><strong>「副本角色」</strong></p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223111422.png" alt="image-20240606223111422"></p><p>在Kafka中，副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。</p><p>每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。</p><p>在Kafka中，追随者副本是不对外提供服务的。这就是说，任何一个追随者副本都不能响应消费者和生产者的读写请求。所有的请求都必须由领导者副本来处理，或者说，所有的读写请求都必须发往领导者副本所在的Broker，由该Broker负责处理。</p><p>追随者副本不处理客户端请求，它唯一的任务就是从领导者副本**「异步拉取」**消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。</p><p>当领导者副本挂掉了，或者说领导者副本所在的Broker宕机时，Kafka依托于ZooKeeper提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。老Leader副本重启回来后，只能作为追随者副本加入到集群中。</p><p>对于客户端用户而言，Kafka的追随者副本没有任何作用，Kafka为什么要这样设计呢？</p><p>这种副本机制有两个方面的好处。</p><p>1.<strong>「方便实现Read-your-writes」</strong>。</p><p>所谓Read-your-writes，顾名思义就是，当你使用生产者API向Kafka成功写入消息后，马上使用消费者API去读取刚才生产的消息。</p><p>2.<strong>「方便实现单调读（Monotonic Reads）」</strong>。</p><p>假设当前有2个追随者副本F1和F2，它们异步地拉取领导者副本数据。倘若F1拉取了Leader的最新消息而F2还未及时拉取，那么，此时如果有一个消费者先从F1读取消息之后又从F2拉取消息，它可能会看到这样的现象：第一次消费时看到的最新消息在第二次消费时不见了，这就不是单调读一致性。</p><p>但是，如果所有的读请求都是由Leader来处理，那么Kafka就很容易实现单调读一致性。</p><h3 id="ISR机制">ISR机制</h3><p>In-sync Replicas，也就是所谓的ISR副本集合。</p><p>ISR中的副本都是与Leader同步的副本，相反，不在ISR中的追随者副本就被认为是与Leader不同步的。</p><blockquote><p>❝</p><p>什么副本能够进入到ISR中呢？</p><p>❞</p></blockquote><p>Leader副本天然就在ISR中。也就是说，<strong>「ISR不只是追随者副本集合，它必然包括Leader副本。甚至在某些情况下，ISR只有Leader这一个副本」</strong>。</p><p>另外，能够进入到ISR的追随者副本要满足一定的条件。</p><p><strong>「通过Broker端参数replica.lag.time.max.ms参数值」</strong>。</p><p>这个参数的含义是Follower副本能够落后Leader副本的最长时间间隔，当前默认值是10秒。</p><p>这就是说，只要一个Follower副本落后Leader副本的时间不连续超过10秒，那么Kafka就认为该Follower副本与Leader是同步的，即使此时Follower副本中保存的消息明显少于Leader副本中的消息。</p><p>Follower副本唯一的工作就是不断地从Leader副本拉取消息，然后写入到自己的提交日志中。</p><p>倘若该副本后面慢慢地追上了Leader的进度，那么它是能够重新被加回ISR的。</p><p>ISR是一个动态调整的集合，而非静态不变的。</p><h3 id="Unclean领导者选举">Unclean领导者选举</h3><p><strong>「Kafka把所有不在ISR中的存活副本都称为非同步副本」</strong>。</p><p>通常来说，非同步副本落后Leader太多，因此，如果选择这些副本作为新Leader，就可能出现数据的丢失。</p><p>毕竟，这些副本中保存的消息远远落后于老Leader中的消息。</p><p>在Kafka中，选举这种副本的过程称为Unclean领导者选举。</p><p><strong>「Broker端参数unclean.leader.election.enable控制是否允许Unclean领导者选举」</strong>。</p><p>开启Unclean领导者选举可能会造成数据丢失，但好处是，它使得分区Leader副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止Unclean领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。</p><h3 id="副本选举">副本选举</h3><p>对于kafka集群中对于任意的topic的分区以及副本leader的设定，都需要考虑到集群整体的负载能力的平衡性，会尽量分配每一个partition的副本leader在不同的broker中，这样会避免多个leader在同一个broker，导致集群中的broker负载不平衡</p><p>kafka引入了优先副本的概念，优先副本的意思在AR（分区中的所有副本）集合列表中的第一个副本，在理想状态下该副本就是该分区的leader副本</p><p>例如kafka集群由3台broker组成，创建了一个名为<code>topic-partitions</code>的topic，设置partition为3，副本数为3，partition0中AR列表为 <code>[1,2,0]</code>，那么分区0的优先副本为1</p><p>kafka使用多副本机制提高可靠性，但是只有leader副本对外提供读写服务，follow副本只是做消息同步。</p><p><strong>「如果一个分区的leader副本不可用，就意味着整个分区不可用，此时需要从follower副本中选举出新的leader副本提供服务」</strong>。</p><p><strong>「在创建主题的时候，该分区的主题和副本会尽可能的均匀发布到kafka的各个broker上」</strong>。</p><p>比如我们在包含3个broker节点的kafka集群上创建一个分区数为3，副本因子为3的主题<code>topic-partitions</code>时，leader副本会均匀的分布在3台broker节点上。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223147685.png" alt="image-20240606223147685"></p><p><strong>「针对同一个分区，在同一个broker节点上不可能出现它的多个副本」</strong>。</p><p>我们可以把leader副本所在的节点叫作分区的leader节点，把follower副本所在的节点叫作follower节点。</p><p>在上面的例子中，分区0的leader节点是broker1，分区1的leader节点是broker2，分区2的leader节点是broker0。</p><p>当分区leader节点发生故障时，其中的一个follower节点就会选举为新的leader节点。</p><p>当原来leader的节点恢复之后，它只能成为一个follower节点，此时就导致了集群负载不均衡。</p><p>比如分区1的leader节点broker2崩溃了，此时选举了在broker1上的分区1follower节点作为新的leader节点。</p><p>当broker2重新恢复时，此时的kafka集群状态如下：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223202013.png" alt="image-20240606223202013"></p><p>可以看到，此时broker1上负载更大，而broker2上没有负载。</p><p><strong>「为了解决上述负载不均衡的情况，kafka支持了优先副本选举，优先副本指的是一个分区所在的AR集合的第一个副本」</strong>。</p><p>比如上面的分区1，它的AR集合是<code>[2,0,1]</code>，表示分区1的优先副本就是在broker2上。</p><p>理想情况下，优先副本应该就是leader副本，kafka保证了优先副本的均衡分布，而这与broker节点宕机与否没有关系。</p><p><strong>「优先副本选举就是对分区leader副本进行选举的时候，尽可能让优先副本成为leader副本」</strong>，针对上述的情况，只要再触发一次优先副本选举就能保证分区负载均衡。</p><p>kafka支持自动优先副本选举功能，默认每5分钟触发一次优先副本选举操作。</p><p><strong>解释</strong>：</p><p>Kafka的副本选举是指在Kafka集群中，当一个分区的Leader副本发生故障后，从该分区的Follower副本中选举一个新的Leader副本的过程。</p><p>举个例子，假设你正在和一群朋友玩一个团队游戏，其中一个人（我们称他为&quot;Leader&quot;）是队长，负责制定策略和指挥大家。其他人（我们称他们为&quot;Follower&quot;）则是队员，他们跟随队长的指令行动。</p><p>突然，由于某种原因，队长不能再继续指挥大家（比如他需要暂时离开或者他的手机没电了）。这个时候，你们需要从剩下的队员中选出一个新的队长，这个过程就像Kafka的副本选举。</p><p>在Kafka中，如果当前的Leader副本发生了故障，那么Kafka会从ISR（In-Sync Replicas，与Leader保持同步的Follower副本集合）中选举一个新的Leader。这样可以确保数据的一致性，因为ISR中的副本都有最新的数据。</p><p>如果ISR中没有可用的副本，Kafka还可以进行&quot;Unclean Leader Election&quot;，也就是从OSR（Out-of-Sync Replicas，与Leader不完全同步的Follower副本集合）中选举新的Leader，但这可能会导致一些数据的丢失。</p><p>总的来说，Kafka的副本选举机制是为了保持系统的高可用性和数据的一致性。</p><h2 id="网络通信模型">网络通信模型</h2><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223313048.png" alt="image-20240606223313048"></p><p>Broker 中有个<code>Acceptor(mainReactor)</code>监听新连接的到来，与新连接建连之后轮询选择一个<code>Processor(subReactor)</code>管理这个连接。</p><p>而<code>Processor</code>会监听其管理的连接，当事件到达之后，读取封装成<code>Request</code>，并将<code>Request</code>放入共享请求队列中。</p><p>然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的<code>Processor</code>的响应队列中，然后由<code>Processor</code>将<code>Response</code>返还给客户端。</p><p>每个<code>listener</code>只有一个<code>Acceptor线程</code>，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量。</p><p><code>Processor</code> 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是<code>num.network.threads</code>，并且可以根据实际的业务动态增减。</p><p>还有个 IO 线程池，即<code>KafkaRequestHandlerPool</code>，执行真正的处理，对应的参数是<code>num.io.threads</code>，默认值是 8。</p><p>IO线程处理完之后会将<code>Response</code>放入对应的<code>Processor</code>中，由<code>Processor</code>将响应返还给客户端。</p><p>可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。</p><h2 id="幂等性">幂等性</h2><p><strong>「幂等性Producer」</strong></p><p>在Kafka中，Producer默认不是幂等性的，但我们可以创建幂等性Producer。</p><p>它其实是0.11.0.0版本引入的新功能，在此之前，Kafka向分区发送数据时，可能会出现同一条消息被发送了多次，导致消息重复的情况。</p><p>在0.11之后，指定Producer幂等性的方法很简单，仅需要设置一个参数即可，即</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">props</span>.<span class="built_in">put</span>(“enable.idempotence”, ture)，</span><br><span class="line">或<span class="built_in">props</span>.<span class="built_in">put</span>(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， <span class="literal">true</span>)。</span><br></pre></td></tr></table></figure><p><code>enable.idempotence</code>被设置成true后，Producer自动升级成幂等性Producer，其他所有的代码逻辑都不需要改变。</p><p>Kafka自动帮你做消息的重复去重。</p><p>底层具体的原理很简单，就是经典的用空间去换时间的优化思路，即在Broker端多保存一些字段。</p><p><strong>当Producer发送了具有相同字段值的消息后，Broker能够自动知晓这些消息已经重复了，于是可以在后台默默地把它们丢弃掉。</strong></p><p><strong>「幂等性Producer的作用范围」</strong></p><p>首先，它只能保证单分区上的幂等性，即一个幂等性Producer能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。</p><p>其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。</p><p>这里的会话，你可以理解为Producer进程的一次运行，当你重启了Producer进程之后，这种幂等性保证就丧失了。</p><h2 id="事务">事务</h2><p>Kafka自0.11版本开始也提供了对事务的支持，目前主要是在read committed隔离级别上做事情。</p><p>它能保证多条消息原子性地写入到目标分区，同时也能保证Consumer只能看到事务成功提交的消息。</p><p><strong>「事务型Producer」</strong></p><p>事务型Producer能够保证将消息原子性地写入到多个分区中。</p><p>这批消息要么全部写入成功，要么全部失败，另外，事务型Producer也不惧进程的重启。</p><p>Producer重启回来后，Kafka依然保证它们发送消息的精确一次处理。</p><p>设置事务型Producer的方法也很简单，满足两个要求即可：</p><ul><li>和幂等性Producer一样，开启<code>enable.idempotence = true</code>。</li><li>设置Producer端参数<code>transactional. id</code>，最好为其设置一个有意义的名字。</li></ul><p>此外，你还需要在Producer代码中做一些调整，如这段代码所示：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">producer<span class="selector-class">.initTransactions</span>();</span><br><span class="line">try &#123;</span><br><span class="line">            producer<span class="selector-class">.beginTransaction</span>();</span><br><span class="line">            producer<span class="selector-class">.send</span>(record1);</span><br><span class="line">            producer<span class="selector-class">.send</span>(record2);</span><br><span class="line">            producer<span class="selector-class">.commitTransaction</span>();</span><br><span class="line">&#125; catch (KafkaException e) &#123;</span><br><span class="line">            producer<span class="selector-class">.abortTransaction</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和普通Producer代码相比，事务型Producer的显著特点是调用了一些事务API，如initTransaction、beginTransaction、commitTransaction和abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。</p><p>这段代码能够保证Record1和Record2被当作一个事务统一提交到Kafka，要么它们全部提交成功，要么全部写入失败。</p><p>实际上即使写入失败，Kafka也会把它们写入到底层的日志中，也就是说Consumer还是会看到这些消息。</p><p>有一个<code>isolation.level</code>参数，这个参数有两个取值：</p><ol><li><code>read_uncommitted</code>：这是默认值，表明Consumer能够读取到Kafka写入的任何消息，不论事务型Producer提交事务还是终止事务，其写入的消息都可以读取，如果你用了事务型Producer，那么对应的Consumer就不要使用这个值。</li><li><code>read_committed</code>：表明Consumer只会读取事务型Producer成功提交事务写入的消息，它也能看到非事务型Producer写入的所有消息。</li></ol><h2 id="拦截器">拦截器</h2><p><strong>「Kafka拦截器分为生产者拦截器和消费者拦截器」</strong>。</p><p>生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；</p><p>而消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。</p><p>可以将一组拦截器串连成一个大的拦截器，Kafka会按照添加顺序依次执行拦截器逻辑。</p><p>当前Kafka拦截器的设置方法是通过参数配置完成的，生产者和消费者两端有一个相同的参数<code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Properties props = <span class="built_in">new</span> Properties(); </span><br><span class="line">List interceptors = <span class="built_in">new</span> ArrayList&lt;&gt;(); </span><br><span class="line">interceptors.<span class="built_in">add</span>(<span class="string">&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;</span>);<span class="comment"> // 拦截器1 </span></span><br><span class="line">interceptors.<span class="built_in">add</span>(<span class="string">&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;</span>);<span class="comment"> // 拦截器2 </span></span><br><span class="line">props.<span class="built_in">put</span>(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors); </span><br><span class="line">…… </span><br></pre></td></tr></table></figure><blockquote><p>❝</p><p>怎么编写AddTimeStampInterceptor和UpdateCounterInterceptor类呢？</p><p>❞</p></blockquote><p>这两个类以及你自己编写的所有Producer端拦截器实现类都要继承<code>org.apache.kafka.clients.producer.ProducerInterceptor</code>接口。</p><p>该接口是Kafka提供的，里面有两个核心的方法。</p><ol><li>onSend：该方法会在消息发送之前被调用。</li><li>onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。onAcknowledgement的调用要早于callback的调用。值得注意的是，这个方法和onSend不是在同一个线程中被调用的，因此如果你在这两个方法中调用了某个共享可变对象，一定要保证线程安全。</li></ol><p>同理，指定消费者拦截器也是同样的方法，只是具体的实现类要实现<code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code>接口，这里面也有两个核心方法。</p><ol><li>onConsume：该方法在消息返回给Consumer程序之前调用。</li><li>onCommit：Consumer在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。</li></ol><p>一定要注意的是，<strong>「指定拦截器类时要指定它们的全限定名」</strong>。</p><p>通俗点说就是要把完整包名也加上，不要只有一个类名在那里，并且还要保证你的Producer程序能够正确加载你的拦截器类。</p><h2 id="控制器">控制器</h2><p>【我的理解是从Broker中找到最快给zookeeper创文件的作为控制器，控制器帮助分区的缩减，领导者选举等】</p><p><strong>「控制器组件（Controller），它的主要作用是在Apache ZooKeeper的帮助下管理和协调整个Kafka集群」</strong>。</p><p>集群中任意一台Broker都能充当控制器的角色，但是，在运行过程中，只能有一个Broker成为控制器，行使其管理和协调的职责。</p><p>Kafka控制器大量使用ZooKeeper的Watch功能实现对集群的协调管理。</p><p><strong>「控制器是如何被选出来的」</strong></p><p>实际上，Broker在启动时，会尝试去ZooKeeper中创建<code>/controller</code>节点。</p><p>Kafka当前选举控制器的规则是：<strong>「第一个成功创建/controller节点的Broker会被指定为控制器」</strong>。</p><p><strong>「控制器是做什么的」</strong></p><p>控制器的职责大致可以分为5种：</p><p>1.<strong>「主题管理（创建、删除、增加分区）」</strong></p><p>控制器帮助我们完成对Kafka主题的创建、删除以及分区增加的操作。</p><p>2.<strong>「分区重分配」</strong></p><p>3.<strong>「Preferred领导者选举」</strong></p><p>Preferred领导者选举主要是Kafka为了避免部分Broker负载过重而提供的一种换Leader的方案。</p><p>4.<strong>「集群成员管理（新增Broker、Broker主动关闭、Broker宕机）」</strong></p><p>包括自动检测新增Broker、Broker主动关闭及被动宕机。</p><p>这种自动检测是依赖于Watch功能和ZooKeeper临时节点组合实现的。</p><p>比如，控制器组件会利用**「Watch机制」**检查ZooKeeper的<code>/brokers/ids</code>节点下的子节点数量变更。</p><p>目前，当有新Broker启动后，它会在<code>/brokers</code>下创建专属的znode节点。</p><p>一旦创建完毕，ZooKeeper会通过Watch机制将消息通知推送给控制器，这样，控制器就能自动地感知到这个变化，进而开启后续的新增Broker作业。</p><p>侦测Broker存活性则是依赖于刚刚提到的另一个机制：<strong>「临时节点」</strong>。</p><p>每个Broker启动后，会在<code>/brokers/ids</code>下创建一个临时znode。</p><p>当Broker宕机或主动关闭后，该Broker与ZooKeeper的会话结束，这个znode会被自动删除。</p><p>同理，ZooKeeper的Watch机制将这一变更推送给控制器，这样控制器就能知道有Broker关闭或宕机了，从而进行善后。</p><p>5.<strong>「数据服务」</strong></p><p>控制器上保存了最全的集群元数据信息，其他所有Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。</p><p><strong>「控制器故障转移（Failover）」</strong></p><p><strong>「故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器」</strong>。这个过程就被称为Failover，该过程是自动完成的，无需你手动干预。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223803292.png" alt="image-20240606223803292"></p><p>最开始时，Broker 0是控制器。当Broker 0宕机后，ZooKeeper通过Watch机制感知到并删除了<code>/controller</code>临时节点。</p><p>之后，所有存活的Broker开始竞选新的控制器身份。</p><p>Broker 3最终赢得了选举，成功地在ZooKeeper上重建了<code>/controller</code>节点。</p><p>之后，Broker 3会从ZooKeeper中读取集群元数据信息，并初始化到自己的缓存中。</p><p>至此，控制器的Failover完成，可以行使正常的工作职责了。</p><h2 id="日志存储">日志存储</h2><p>Kafka中的消息是以主题为基本单位进行归类的，每个主题在逻辑上相互独立。</p><p>每个主题又可以分为一个或多个分区，在不考虑副本的情况下，一个分区会对应一个日志。</p><p>但设计者考虑到随着时间推移，日志文件会不断扩大，因此为了防止Log过大，设计者引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，便于后续的消息维护和清理工作。</p><p>下图描绘了主题、分区、副本、Log、LogSegment五者之间的关系。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223930968.png" alt="image-20240606223930968"></p><p><strong>「LogSegment」</strong></p><p>在Kafka中，每个Log对象又可以划分为多个LogSegment文件，每个LogSegment文件包括一个日志数据文件和两个索引文件（偏移量索引文件和消息时间戳索引文件）。</p><p>其中，每个LogSegment中的日志数据文件大小均相等（该日志数据文件的大小可以通过在Kafka Broker的<code>config/server.properties</code>配置文件的中的**「log.segment.bytes」**进行设置，默认为1G大小（1073741824字节），在顺序写入消息时如果超出该设定的阈值，将会创建一组新的日志数据和索引文件）。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606223951739.png" alt="image-20240606223951739"></p><h2 id="常用参数">常用参数</h2><p><strong>「broker端配置」</strong></p><ul><li><a href="http://broker.id">broker.id</a></li></ul><p>每个 kafka broker 都有一个唯一的标识来表示，这个唯一的标识符即是 <code>broker.id</code>，它的默认值是 0。</p><p>这个值在 kafka 集群中必须是唯一的，这个值可以任意设定，</p><ul><li>port</li></ul><p>如果使用配置样本来启动 kafka，它会监听 9092 端口，修改 port 配置参数可以把它设置成任意的端口。</p><p>要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 kakfa。</p><ul><li>zookeeper.connect</li></ul><p>用于保存 broker 元数据的 Zookeeper 地址是通过 <code>zookeeper.connect</code> 来指定的。</p><p>比如可以这么指定 <code>localhost:2181</code> 表示这个 Zookeeper 是运行在本地 2181 端口上的。</p><p>我们也可以通过 比如我们可以通过 <code>zk1:2181,zk2:2181,zk3:2181</code> 来指定 <code>zookeeper.connect</code> 的多个参数值。</p><p>该配置参数是用冒号分割的一组 <code>hostname:port/path</code> 列表，其含义如下</p><ul><li>hostname 是 Zookeeper 服务器的机器名或者 ip 地址。</li><li>port 是 Zookeeper 客户端的端口号</li><li>/path 是可选择的 Zookeeper 路径，Kafka 路径是使用了 <code>chroot</code> 环境，如果不指定默认使用跟路径。</li></ul><blockquote><p>❝</p><p>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的<code>zookeeper.connect</code>参数可以这样指定：<code>zk1:2181,zk2:2181,zk3:2181/kafka1</code>和<code>zk1:2181,zk2:2181,zk3:2181/kafka2</code></p><p>❞</p></blockquote><ul><li>log.dirs</li></ul><p>Kafka 把所有的消息都保存到磁盘上，存放这些日志片段的目录是通过 <code>log.dirs</code> 来制定的，它是用一组逗号来分割的本地系统路径，<code>log.dirs</code> 是没有默认值的，<strong>「你必须手动指定他的默认值」</strong>。</p><p>其实还有一个参数是 <code>log.dir</code>，这个配置是没有 <code>s</code> 的，默认情况下只用配置 <code>log.dirs</code> 就好了，比如你可以通过 <code>/home/kafka1,/home/kafka2,/home/kafka3</code> 这样来配置这个参数的值。</p><ul><li>auto.create.topics.enable</li></ul><p>默认情况下，kafka 会自动创建主题</p><p><code>auto.create.topics.enable</code>参数建议最好设置成 false，即不允许自动创建 Topic。</p><p><strong>「主题相关配置」</strong></p><ul><li>num.partitions</li></ul><p>num.partitions 参数指定了新创建的主题需要包含多少个分区，该参数的默认值是 1。</p><ul><li>default.replication.factor</li></ul><p>这个参数比较简单，它表示 kafka保存消息的副本数。</p><ul><li><a href="http://log.retention.ms">log.retention.ms</a></li></ul><p>Kafka 通常根据时间来决定数据可以保留多久。</p><p>默认使用<code>log.retention.hours</code>参数来配置时间，默认是 168 个小时，也就是一周。</p><p>除此之外，还有两个参数<code>log.retention.minutes</code> 和<code>log.retentiion.ms</code> 。</p><p>这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用<code>log.retention.ms</code>。</p><ul><li>message.max.bytes</li></ul><p>broker 通过设置 <code>message.max.bytes</code> 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。</p><ul><li><a href="http://retention.ms">retention.ms</a></li></ul><p>规定了该主题消息被保存的时常，默认是7天，即该主题只能保存7天的消息，一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。</p><h2 id="消息丢失问题">消息丢失问题</h2><p><strong>「生产者程序丢失数据」</strong></p><p>目前Kafka Producer是异步发送消息的，也就是说如果你调用的是<code>producer.send(msg)</code>这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。</p><p>如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？</p><p>其实原因有很多，例如网络抖动，导致消息压根就没有发送到Broker端；或者消息本身不合格导致Broker拒绝接收（比如消息太大了，超过了Broker的承受能力）等。</p><p>实际上，解决此问题的方法非常简单：Producer永远要使用带有回调通知的发送API，也就是说不要使用<code>producer.send(msg)</code>，而要使用<code>producer.send(msg, callback)</code>。</p><p>它能准确地告诉你消息是否真的提交成功了。</p><p>一旦出现消息提交失败的情况，你就可以有针对性地进行处理。</p><p><strong>「消费者程序丢失数据」</strong></p><p>Consumer端丢失数据主要体现在Consumer端要消费的消息不见了。</p><p>下面这张图它清晰地展示了Consumer端的位移数据。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606224115640.png" alt="image-20240606224115640"></p><p>比如对于Consumer A而言，它当前的位移值就是9；Consumer B的位移值是11。</p><p>Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。</p><p>假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。</p><p>这里的关键在于Consumer自动提交位移。</p><p>这个问题的解决方案也很简单：</p><p><strong>「如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移」</strong>。</p><h2 id="最佳实践">最佳实践</h2><p>总结Kafka无消息丢失的配置：</p><ol><li>不要使用<code>producer.send(msg)</code>，而要使用<code>producer.send(msg, callback)</code>，一定要使用带有回调通知的send方法。</li><li>设置<code>acks = all</code>，acks是Producer的一个参数，代表了你对已提交消息的定义，如果设置成all，则表明所有副本Broker都要接收到消息，该消息才算是已提交。</li><li>设置retries为一个较大的值。这里的retries同样是Producer的参数，对应前面提到的Producer自动重试，当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了<code>retries &gt; 0</code>的Producer能够自动重试消息发送，避免消息丢失。</li><li>设置<code>unclean.leader.election.enable = false</code>，这是Broker端的参数，它控制的是哪些Broker有资格竞选分区的Leader，如果一个Broker落后原先的Leader太多，那么它一旦成为新的Leader，必然会造成消息的丢失，故一般都要将该参数设置成false，即不允许这种情况的发生。</li><li>设置<code>replication.factor &gt;= 3</code>，这也是Broker端的参数，将消息多保存几份，目前防止消息丢失的主要机制就是冗余。</li><li>设置<code>min.insync.replicas &gt; 1</code>，这依然是Broker端参数，控制的是消息至少要被写入到多少个副本才算是已提交，设置成大于1可以提升消息持久性，在实际环境中千万不要使用默认值1。</li><li>确保<code>replication.factor &gt; min.insync.replicas</code>，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了，我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成，推荐设置成<code>replication.factor = min.insync.replicas + 1</code>。</li><li>确保消息消费完成再提交，Consumer端有个参数<code>enable.auto.commit</code>，最好把它设置成false，并采用手动提交位移的方式。</li></ol><h2 id="重复消费问题">重复消费问题</h2><p><strong>「消费重复的场景」</strong></p><p>在<code>enable.auto.commit</code> 默认值true情况下，出现重复消费的场景有以下几种：</p><blockquote><p>❝</p><p>consumer 在消费过程中，应用进程被强制kill掉或发生异常退出。</p><p>❞</p></blockquote><p>例如在一次poll 500条消息后，消费到200条时，进程被强制kill消费到offset未提交，或出现异常退出导致消费到offset未提交。</p><p>下次重启时，依然会重新拉取500消息，造成之前消费到200条消息重复消费了两次。</p><p>解决方案：在发生异常时正确处理未提交的offset</p><p><strong>「消费者消费时间过长」</strong></p><p><code>max.poll.interval.ms</code>参数定义了两次poll的最大间隔，它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开组的请求，Coordinator 也会开启新一轮 Rebalance。</p><p>举例：单次拉取11条消息，每条消息耗时30s，11条消息耗时5分钟30秒，由于<code>max.poll.interval.ms</code> 默认值5分钟，所以消费者无法在5分钟内消费完，consumer会离开组，导致rebalance。</p><p>在消费完11条消息后，consumer会重新连接broker，再次rebalance，因为上次消费的offset未提交，再次拉取的消息是之前消费过的消息，造成重复消费。</p><p><strong>「解决方案：」</strong></p><p>1、提高消费能力，提高单条消息的处理速度；根据实际场景可讲<code>max.poll.interval.ms</code>值设置大一点，避免不必要的rebalance；可适当减小<code>max.poll.records</code>的值，默认值是500，可根据实际消息速率适当调小。</p><p>2、生成消息时，可加入唯一标识符如消息id，在消费端，保存最近的1000条消息id存入到redis或mysql中，消费的消息时通过前置去重。</p><h2 id="消息顺序问题">消息顺序问题</h2><p>我们都知道<code>kafka</code>的<code>topic</code>是无序的，但是一个<code>topic</code>包含多个<code>partition</code>，每个<code>partition</code>内部是有序的</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606224242118.png" alt="image-20240606224242118"></p><p><strong>「乱序场景1」</strong></p><p>因为一个topic可以有多个partition，kafka只能保证partition内部有序</p><p><strong>「解决方案」</strong></p><p>1、可以设置topic，有且只有一个partition</p><p>2、根据业务需要，需要顺序的 指定为同一个partition</p><p>3、根据业务需要，比如同一个订单，使用同一个key，可以保证分配到同一个partition上</p><p><strong>「乱序场景2」</strong></p><p>对于同一业务进入了同一个消费者组之后，用了多线程来处理消息，会导致消息的乱序</p><p><strong>「解决方案」</strong></p><p>消费者内部根据线程数量创建等量的内存队列，对于需要顺序的一系列业务数据，根据key或者业务数据，放到同一个内存队列中，然后线程从对应的内存队列中取出并操作</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606224303633.png" alt="image-20240606224303633"></p><p><strong>「通过设置相同key来保证消息有序性，会有一点缺陷：」</strong></p><p>例如消息发送设置了重试机制，并且异步发送，消息A和B设置相同的key，业务上A先发，B后发，由于网络或者其他原因A发送失败，B发送成功；A由于发送失败就会重试且重试成功，这时候消息顺序B在前A在后，与业务发送顺序不一致，如果需要解决这个问题，需要设置参数<code>max.in.flight.requests.per.connection=1</code>，其含义是限制客户端在单个连接上能够发送的未响应请求的个数，设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求，这个参数默认值是5</p><blockquote><p>❝</p><p>官方文档说明，这个参数如果大于1，由于重试消息顺序可能重排</p></blockquote><h2 id="高性能原因">高性能原因</h2><p><strong>「顺序读写」</strong></p><p>kafka的消息是不断追加到文件中的，这个特性使<code>kafka</code>可以充分利用磁盘的顺序读写性能</p><p>顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写</p><p>Kafka 可以配置异步刷盘，不开启同步刷盘，异步刷盘不需要等写入磁盘后返回消息投递的 ACK，所以它提高了消息发送的吞吐量，降低了请求的延时</p><p><strong>「零拷贝」</strong></p><p>传统的 IO 流程，需要先把数据拷贝到内核缓冲区，再从内核缓冲拷贝到用户空间，应用程序处理完成以后，再拷贝回内核缓冲区</p><p>这个过程中发生了多次数据拷贝</p><p>为了减少不必要的拷贝，<code>Kafka</code> 依赖 Linux 内核提供的 <code>Sendfile</code> 系统调用</p><p>在 Sendfile 方法中，数据在内核缓冲区完成输入和输出，不需要拷贝到用户空间处理，这也就避免了重复的数据拷贝</p><p>在具体的操作中，Kafka 把所有的消息都存放在单独的文件里，在消息投递时直接通过 <code>Sendfile</code> 方法发送文件，减少了上下文切换，因此大大提高了性能</p><p><strong>「MMAP技术」</strong></p><p>除了 <code>Sendfile</code> 之外，还有一种零拷贝的实现技术，即 Memory Mapped Files</p><p>Kafka 使用 <code>Memory Mapped Files</code> 完成内存映射，<code>Memory Mapped Files</code> 对文件的操作不是 <code>write/read</code>，而是直接对内存地址的操作，如果是调用文件的 <code>read</code> 操作，则把数据先读取到内核空间中，然后再复制到用户空间，但 <code>MMAP</code>可以将文件直接映射到用户态的内存空间，省去了用户空间到内核空间复制的开销</p><p>Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入</p><p>Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。</p><p><strong>「批量发送读取」</strong></p><p>Kafka 的批量包括批量写入、批量发布等。它在消息投递时会将消息缓存起来，然后批量发送</p><p>同样，消费端在消费消息时，也不是一条一条处理的，而是批量进行拉取，提高了消息的处理速度</p><p><strong>「数据压缩」</strong></p><p>Kafka还支持对消息集合进行压缩，<code>Producer</code>可以通过<code>GZIP</code>或<code>Snappy</code>格式对消息集合进行压缩</p><p>压缩的好处就是减少传输的数据量，减轻对网络传输的压力</p><p>Producer压缩之后，在<code>Consumer</code>需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得</p><p><strong>「分区机制」</strong></p><p>kafka中的topic中的内容可以被分为多partition存在，每个partition又分为多个段segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加<code>并行操作</code>的能力</p><h2 id="常见面试题">常见面试题</h2><p><strong>「Kafka是Push还是Pull模式？」</strong></p><p>Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer。</p><p>在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。</p><p>push模式由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。</p><p>消息系统都致力于让consumer以最大的速率最快速的消费消息，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。</p><blockquote><p>❝</p><p>Kafka中的Producer和Consumer采用的是Push-and-Pull模式，即Producer向Broker Push消息，Consumer从Broker Pull消息。</p><p>❞</p></blockquote><p>Pull模式的一个好处是consumer可以自主决定是否批量的从broker拉取数据。</p><p>Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。</p><p>[<a href="https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&amp;mid=2247484980&amp;idx=1&amp;sn=6e0c7112dd72d0edc284009e7503b2ac&amp;scene=21#wechat_redirect">面试题：Kafka如何保证高可用？有图有真相</a>](<a href="https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&amp;mid=2247484980&amp;idx=1&amp;sn=6e0c7112dd72d0edc284009e7503b2ac&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&amp;mid=2247484980&amp;idx=1&amp;sn=6e0c7112dd72d0edc284009e7503b2ac&amp;scene=21#wechat_redirect</a>)</p><p><strong>「Kafk的使用场景」</strong></p><p>业界Kafka实际应用场景</p><blockquote><p>❝</p><p>异步通信</p><p>❞</p></blockquote><p>消息中间件在异步通信中用的最多，很多业务流程中，如果所有步骤都同步进行可能会导致核心流程耗时非常长，更重要的是所有步骤都同步进行一旦非核心步骤失败会导致核心流程整体失败，因此在很多业务流程中Kafka就充当了异步通信角色。</p><blockquote><p>❝</p><p>日志同步</p><p>❞</p></blockquote><p>大规模分布式系统中的机器非常多而且分散在不同机房中，分布式系统带来的一个明显问题就是业务日志的查看、追踪和分析等行为变得十分困难，对于集群规模在百台以上的系统，查询线上日志很恐怖。</p><p>为了应对这种场景统一日志系统应运而生，日志数据都是海量数据，通常为了不给系统带来额外负担一般会采用异步上报，这里Kafka以其高吞吐量在日志处理中得到了很好的应用。</p><blockquote><p>❝</p><p>实时计算</p><p>❞</p></blockquote><p>随着据量的增加，离线的计算会越来越慢，难以满足用户在某些场景下的实时性要求，因此很多解决方案中引入了实时计算。</p><p>很多时候，即使是海量数据，我们也希望即时去查看一些数据指标，实时流计算应运而生。</p><p>实时流计算有两个特点，一个是实时，随时可以看数据；另一个是流。</p><p>转载·自：<a href="https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&amp;mid=2247487063&amp;idx=1&amp;sn=d7c65359630a67695a079d62fce989c0&amp;chksm=fa5bda68cd2c537ed32003d5a98705e85c6b7a47afe0f837cebd27a5f33a8a11231d3eb9c1c5&amp;scene=27#wechat_redirect">Kafka核心知识总结！</a></p>]]></content>
    
    
    <summary type="html">Kafka核心知识总结!</summary>
    
    
    
    <category term="消息队列" scheme="https://penge666.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://penge666.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>Kafka基本术语</title>
    <link href="https://penge666.github.io/posts/93a1f5a2.html"/>
    <id>https://penge666.github.io/posts/93a1f5a2.html</id>
    <published>2024-06-06T12:44:25.000Z</published>
    <updated>2024-06-06T14:49:11.709Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Apache Kafka是一款开源的消息引擎系统</strong>。</p><p>Kafka-Messaging-System</p><p>常见的有两种方法：</p><ul><li><strong>点对点模型</strong>：也叫消息队列模型。如果拿上面那个“民间版”的定义来说，那么系统A发送的消息只能被系统B接收，其他任何系统都不能读取A发送的消息。日常生活的例子比如电话客服就属于这种模型：同一个客户呼入电话只能被一位客服人员处理，第二个客服人员不能为该客户服务。</li><li><strong>发布/订阅模型</strong>：与上面不同的是，它有一个主题（Topic）的概念，你可以理解成逻辑语义相近的消息容器。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布/订阅模型。</li></ul><p><strong>基本术语概念</strong></p><p>Kafka属于分布式的消息引擎系统，它的主要功能是提供一套完备的消息发布与订阅解决方案。在Kafka中，发布订阅的对象是主题（Topic），你可以为每个业务、每个应用甚至是每类数据都创建专属的主题。</p><p>向主题发布消息的客户端应用程序称为生产者（Producer），生产者程序通常持续不断地向一个或多个主题发送消息，而订阅这些主题消息的客户端应用程序就被称为消费者（Consumer）。和生产者类似，消费者也能够同时订阅多个主题的消息。我们把生产者和消费者统称为客户端（Clients）。你可以同时运行多个生产者和消费者实例，这些实例会不断地向Kafka集群中的多个主题生产和消费消息。</p><p>有客户端自然也就有服务器端。Kafka的服务器端由被称为Broker的服务进程构成，即一个Kafka集群由多个Broker组成，Broker负责接收和处理客户端发送过来的请求，以及对消息进行持久化。虽然多个Broker进程能够运行在同一台机器上，但更常见的做法是将不同的Broker分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有Broker进程都挂掉了，其他机器上的Broker也依然能够对外提供服务。这其实就是Kafka提供高可用的手段之一。</p><p>实现高可用的另一个手段就是备份机制（Replication）。备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在Kafka中被称为副本（Replica）。好吧，其实在整个分布式系统里好像都叫这个名字。副本的数量是可以配置的，这些副本保存着相同的数据，但却有不同的角色和作用。Kafka定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。当然了，你可能知道在很多其他系统中追随者副本是可以对外提供服务的，比如MySQL的从库是可以处理读操作的，但是在Kafka中追随者副本不会对外提供服务。对了，一个有意思的事情是现在已经不提倡使用Master-Slave来指代这种主从关系了，毕竟Slave有奴隶的意思，在美国这种严禁种族歧视的国度，这种表述有点政治不正确了，所以目前大部分的系统都改成Leader-Follower了。</p><p>副本的工作机制也很简单：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。</p><p>虽然有了副本机制可以保证数据的持久化或消息不丢失，但没有解决伸缩性的问题。伸缩性即所谓的Scalability，是分布式系统中非常重要且必须要谨慎对待的问题。什么是伸缩性呢？我们拿副本来说，虽然现在有了领导者副本和追随者副本，但倘若领导者副本积累了太多的数据以至于单台Broker机器都无法容纳了，此时应该怎么办呢？一个很自然的想法就是，能否把数据分割成多份保存在不同的Broker上？如果你就是这么想的，那么恭喜你，Kafka就是这么设计的。</p><p>这种机制就是所谓的分区（Partitioning）。如果你了解其他分布式系统，你可能听说过分片、分区域等提法，比如MongoDB和Elasticsearch中的Sharding、HBase中的Region，其实它们都是相同的原理，只是Partitioning是最标准的名称。</p><p>Kafka中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区0中，要么在分区1中。如你所见，Kafka的分区编号是从0开始的，如果Topic有100个分区，那么它们的分区号就是从0到99。</p><p>讲到这里，你可能有这样的疑问：刚才提到的副本如何与这里的分区联系在一起呢？实际上，副本是在分区这个层级定义的。每个分区下可以配置若干个副本，其中只能有1个领导者副本和N-1个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。分区位移总是从0开始，假设一个生产者向一个空分区写入了10条消息，那么这10条消息的位移依次是0、1、2、……、9。</p><p>至此我们能够完整地串联起Kafka的三层消息架构：</p><ul><li>第一层是主题层，每个主题可以配置M个分区，而每个分区又可以配置N个副本。</li><li>第二层是分区层，每个分区的N个副本中只能有一个充当领导者角色，对外提供服务；其他N-1个副本是追随者副本，只是提供数据冗余之用。</li><li>第三层是消息层，分区中包含若干条消息，每条消息的位移从0开始，依次递增。</li><li>最后，客户端程序只能与分区的领导者副本进行交互。</li></ul><p>讲完了消息层次，我们来说说Kafka Broker是如何持久化数据的。总的来说，Kafka使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机I/O操作，改为性能较好的顺序I/O写操作，这也是实现Kafka高吞吐量特性的一个重要手段。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此Kafka必然要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。在Kafka底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。</p><p>这里再重点说说消费者。在专栏的第一期中我提到过两种消息模型，即点对点模型（Peer to Peer，P2P）和发布订阅模型。这里面的点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在Kafka中实现这种P2P模型的方法就是引入了消费者组（Consumer Group）。所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。我会在专栏的后面详细介绍消费者组机制，所以现在你只需要了解消费者组是做什么的即可。另外这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。</p><p>消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka能够自动检测到，然后把这个Failed实例之前负责的分区转移给其他活着的消费者。这个过程就是Kafka中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的Bug社区都无力解决。</p><p>每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。我个人把消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。</p><p><strong>总结</strong></p><p>我来总结一下今天提到的所有名词术语：</p><ul><li>消息：Record。Kafka是消息引擎嘛，这里的消息就是指Kafka处理的主要对象。</li><li>主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。</li><li>分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。</li><li>消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。</li><li>副本：Replica。Kafka中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。</li><li>生产者：Producer。向主题发布新消息的应用程序。</li><li>消费者：Consumer。从主题订阅新消息的应用程序。</li><li>消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。</li><li>消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。</li><li>重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance是Kafka消费者端实现高可用的重要手段。</li></ul><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606204014760.png" alt="image-20240606204014760"></p><p><strong>Kafka消息引擎系统的意义</strong></p><p>当引入了Kafka之后。上游订单服务不再直接与下游子服务进行交互。当新订单生成后它仅仅是向Kafka Broker发送一条订单消息即可。类似地，下游的各个子服务订阅Kafka中的对应主题，并实时从该主题的各自分区（Partition）中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。这样当出现秒杀业务时，Kafka能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的TPS，同时也给下游子服务留出了充足的时间去消费它们。</p><p><strong>Kafka只是消息引擎系统吗?</strong></p><ol><li>Kafka在设计之初就旨在提供三个方面的特性:提供一套API实现生产者和消费者;降低网络传输和磁盘存储开销;实现高伸缩性架构。</li><li>作为<strong>流处理平台</strong>，Kafka与其他主流大数据流式计算框架相比,优势有两点:更容易实现端到端的正确性;它自己对于流式计算的定位。</li><li>Apache Kafka是消息引擎系统,也是一个分布式流处理平台。除此之外，Kafka还能够被用作分布式存储系统。不过我觉得你姑且了解下就好了，我从没有见过在实际生产环境中，有人把Kafka当作持久化存储来用。</li></ol><p><strong>Kafka介绍</strong></p><ul><li>Apache Kafka，也称社区版Kafka。优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度；缺陷在于仅提供基础核心组件，缺失一些高级的特性。</li><li>Confluent Kafka，Confluent公司提供的Kafka。优势在于集成了很多高级特性且由Kafka原班人马打造，质量上有保证；缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。</li><li>CDH/HDP Kafka，大数据云公司提供的Kafka，内嵌Apache Kafka。优势在于操作简单，节省运维成本；缺陷在于把控度低，演进速度较慢。</li></ul><p><strong>Kafka版本号</strong></p><ul><li>0.7版本:只提供了最基础的消息队列功能。</li><li>0.8版本:引入了副本机制，至此Kafka成为了一个真正意义上完备的分布式高可靠消息队列解决方案。</li><li>0.9.0.0版本:增加了基础的安全认证/权限功能;使用Java重写了新版本消费者API;引入了Kafka Connect组件。</li><li>0.10.0.0版本:引入了Kafka Streams，正式升级成分布式流处理平台。</li><li>0.11.0.0版本:提供了幂等性Producer API以及事务API;对Kafka消息格式做了重构。</li><li>1.0和2.0版本:主要还是Kafka Streams的各种改进。</li></ul><p><strong>Kafka客户端底层使用了Java的selector，selector在Linux上的实现机制是epoll，而在Windows平台上的实现机制是select。因此在这一点上将Kafka部署在Linux上是有优势的，因为能够获得更高效的I/O性能。</strong></p>]]></content>
    
    
    <summary type="html">Kafka概念介绍</summary>
    
    
    
    <category term="消息队列" scheme="https://penge666.github.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
    <category term="消息队列" scheme="https://penge666.github.io/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>etcd的读写请求</title>
    <link href="https://penge666.github.io/posts/5e31aad7.html"/>
    <id>https://penge666.github.io/posts/5e31aad7.html</id>
    <published>2024-06-06T08:41:45.000Z</published>
    <updated>2024-06-06T08:47:24.405Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基础架构">基础架构</h2><p>基础架构</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164308547.png" alt="image-20240606164308547"></p><p>按照分层模型，etcd可分为Client层、API网络层、Raft算法层、逻辑层和存储层。这些层的功能如下：</p><ul><li><strong>Client层</strong>：Client层包括client v2和v3两个大版本API客户端库，提供了简洁易用的API，同时支持负载均衡、节点间故障自动转移，可极大降低业务使用etcd复杂度，提升开发效率、服务可用性。</li><li><strong>API网络层</strong>：API网络层主要包括client访问server和server节点之间的通信协议。一方面，client访问etcd server的API分为v2和v3两个大版本。v2 API使用HTTP/1.x协议，v3 API使用gRPC协议。同时v3通过etcd grpc-gateway组件也支持HTTP/1.x协议，便于各种语言的服务调用。另一方面，server之间通信协议，是指节点间通过Raft算法实现数据复制和Leader选举等功能时使用的HTTP协议。</li><li><strong>Raft算法层</strong>：Raft算法层实现了Leader选举、日志复制、ReadIndex等核心算法特性，用于保障etcd多个节点间的数据一致性、提升服务可用性等，是etcd的基石和亮点。</li><li><strong>功能逻辑层</strong>：etcd核心特性实现层，如典型的KVServer模块、MVCC模块、Auth鉴权模块、Lease租约模块、Compactor压缩模块等，其中MVCC模块主要由treeIndex模块和boltdb模块组成。</li><li><strong>存储层</strong>：存储层包含预写日志(WAL)模块、快照(Snapshot)模块、boltdb模块。其中WAL可保障etcd crash后数据不丢失，boltdb则保存了集群元数据和用户写入的数据。</li></ul><p>etcd是典型的<strong>读多写少存储</strong>。</p><h2 id="etcd读请求">etcd读请求</h2><p>读请求流程图</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164336292.png" alt="image-20240606164336292"></p><h3 id="KVServer模块">KVServer模块</h3><p>client发送Range RPC请求到了server后，就开始进入我们架构图中的流程二，也就是KVServer模块了。</p><p>etcd提供了丰富的metrics、日志、请求行为检查等机制，可记录所有请求的执行耗时及错误码、来源IP等，也可控制请求是否允许通过，比如etcd Learner节点只允许指定接口和参数的访问，帮助大家定位问题、提高服务可观测性等，而这些特性是怎么非侵入式的实现呢？</p><p>答案就是拦截器。</p><h4 id="拦截器">拦截器</h4><p>etcd server定义了如下的Service KV和Range方法，启动的时候它会将实现KV各方法的对象注册到gRPC Server，并在其上注册对应的拦截器。下面的代码中的Range接口就是负责读取etcd key-value的的RPC接口。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">service KV &#123;  </span><br><span class="line">  <span class="comment">// Range gets the keys in the range from the key-value store.  </span></span><br><span class="line">  <span class="function">rpc <span class="title">Range</span><span class="params">(RangeRequest)</span> <span class="title">returns</span> <span class="params">(RangeResponse)</span> </span>&#123;  </span><br><span class="line">      <span class="built_in">option</span> (google.api.http) = &#123;  </span><br><span class="line">        post: <span class="string">&quot;/v3/kv/range&quot;</span>  </span><br><span class="line">        body: <span class="string">&quot;*&quot;</span>  </span><br><span class="line">      &#125;;  </span><br><span class="line">  &#125;  </span><br><span class="line">  ....</span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>拦截器提供了在执行一个请求前后的hook能力，除了我们上面提到的debug日志、metrics统计、对etcd Learner节点请求接口和参数限制等能力，etcd还基于它实现了以下特性:</p><ul><li>要求执行一个操作前集群必须有Leader；</li><li>请求延时超过指定阈值的，打印包含来源IP的慢查询日志(3.5版本)。</li></ul><p>server收到client的Range RPC请求后，根据ServiceName和RPC Method将请求转发到对应的handler实现，handler首先会将上面描述的一系列拦截器串联成一个执行，在拦截器逻辑中，通过调用KVServer模块的Range接口获取数据。</p><h4 id="串行读与线性读">串行读与线性读</h4><p>进入KVServer模块后，我们就进入核心的读流程了，对应架构图中的流程三和四。我们知道etcd为了保证服务高可用，生产环境一般部署多个节点，那各个节点数据在任意时间点读出来都是一致的吗？什么情况下会读到旧数据呢？</p><p>这里为了帮助你更好的理解读流程，我先简单提下写流程。如下图所示，当client发起一个更新hello为world请求后，若Leader收到写请求，它会将此请求持久化到WAL日志，并广播给各个节点，若一半以上节点持久化成功，则该请求对应的日志条目被标识为已提交，etcdserver模块异步从Raft模块获取已提交的日志条目，应用到状态机(boltdb等)。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164413824.png" alt="image-20240606164413824"></p><p>此时若client发起一个读取hello的请求，假设此请求直接从状态机中读取， 如果连接到的是C节点，若C节点磁盘I/O出现波动，可能导致它应用已提交的日志条目很慢，则会出现更新hello为world的写命令，在client读hello的时候还未被提交到状态机，因此就可能读取到旧数据，如上图查询hello流程所示。</p><p>从以上介绍我们可以看出，在多节点etcd集群中，各个节点的状态机数据一致性存在差异。而我们不同业务场景的读请求对数据是否最新的容忍度是不一样的，有的场景它可以容忍数据落后几秒甚至几分钟，有的场景要求必须读到反映集群共识的最新数据。</p><p>我们首先来看一个<strong>对数据敏感度较低的场景</strong>。</p><p>假如老板让你做一个旁路数据统计服务，希望你每分钟统计下etcd里的服务、配置信息等，这种场景其实对数据时效性要求并不高，读请求可直接从节点的状态机获取数据。即便数据落后一点，也不影响业务，毕竟这是一个定时统计的旁路服务而已。</p><p>这种直接读状态机数据返回、无需通过Raft协议与集群进行交互的模式，在etcd里叫做<strong>串行(<strong><strong>Serializable</strong></strong>)读</strong>，它具有低延时、高吞吐量的特点，适合对数据一致性要求不高的场景。</p><p>我们再看一个<strong>对数据敏感性高的场景</strong>。</p><p>当你发布服务，更新服务的镜像的时候，提交的时候显示更新成功，结果你一刷新页面，发现显示的镜像的还是旧的，再刷新又是新的，这就会导致混乱。再比如说一个转账场景，Alice给Bob转账成功，钱被正常扣出，一刷新页面发现钱又回来了，这也是令人不可接受的。</p><p>以上的业务场景就对数据准确性要求极高了，在etcd里面，提供了一种线性读模式来解决对数据一致性要求高的场景。</p><p><strong>什么是线性读呢?</strong></p><p>你可以理解一旦一个值更新成功，随后任何通过线性读的client都能及时访问到。虽然集群中有多个节点，但client通过线性读就如访问一个节点一样。etcd默认读模式是线性读，因为它需要经过Raft协议模块，反应的是集群共识，因此在延时和吞吐量上相比串行读略差一点，适用于对数据一致性要求高的场景。</p><p>如果你的etcd读请求显示指定了是串行读，就不会经过架构图流程中的流程三、四。默认是线性读，因此接下来我们看看读请求进入线性读模块，它是如何工作的。</p><p><strong>在etcd中，读操作主要有两种模式：串行读（Serialize）和线性读（Linearizable）。</strong></p><ol><li>串行读：这种读模式是在同一个节点上进行的，它不需要经过Raft协议模块的处理。串行读可以快速地读取数据，因为它不需要等待其他节点的确认，但是它可能无法读取到最新的数据。这种模式在对数据一致性要求不高，但对读取速度有较大需求的场景下比较适用。</li><li>线性读：这种读模式需要经过Raft协议模块的处理，它能反应集群的共识状态，也就是说，它可以保证读取到的数据是最新的。但是，因为需要经过Raft协议的处理，所以在延时和吞吐量上，线性读可能会比串行读略差一些。这种模式在对数据一致性要求高的场景下比较适用。</li></ol><p>举个例子，假设我们有一个在线购物网站，用户在浏览商品信息时，我们可以使用串行读来快速获取商品信息，因为这些信息一般不会频繁更新，即使偶尔读取到的是稍微旧一点的数据，也不会影响用户的使用体验。而在用户下单购买商品时，我们需要使用线性读来获取商品的库存信息，因为这个信息可能会被其他用户的购买行为实时改变，我们需要确保读取到的库存信息是最新的，以防止出现超卖的情况。</p><h4 id="线性读之ReadIndex">线性读之ReadIndex</h4><p>前面我们聊到串行读时提到，它之所以能读到旧数据，主要原因是Follower节点收到Leader节点同步的写请求后，应用日志条目到状态机是个异步过程，那么我们能否有一种机制在读取的时候，确保最新的数据已经应用到状态机中？</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164512356.png" alt="image-20240606164512356"></p><p>其实这个机制就是叫ReadIndex，它是在etcd 3.1中引入的，我把简化后的原理图放在了上面。当收到一个线性读请求时，它首先会从Leader获取集群最新的已提交的日志索引(committed index)，如上图中的流程二所示。</p><p>Leader收到ReadIndex请求时，为防止脑裂等异常场景，会向Follower节点发送心跳确认，一半以上节点确认Leader身份后才能将已提交的索引(committed index)返回给节点C(上图中的流程三)。</p><p>C节点则会等待，直到状态机已应用索引(applied index)大于等于Leader的已提交索引时(committed Index)(上图中的流程四)，然后去通知读请求，数据已赶上Leader，你可以去状态机中访问数据了(上图中的流程五)。</p><p>以上就是线性读通过ReadIndex机制保证数据一致性原理， 当然还有其它机制也能实现线性读，如在早期etcd 3.0中读请求通过走一遍Raft协议保证一致性， 这种Raft log read机制依赖磁盘IO， 性能相比ReadIndex较差。</p><p>总体而言，KVServer模块收到线性读请求后，通过架构图中流程三向Raft模块发起ReadIndex请求，Raft模块将Leader最新的已提交日志索引封装在流程四的ReadState结构体，通过channel层层返回给线性读模块，线性读模块等待本节点状态机追赶上Leader进度，追赶完成后，就通知KVServer模块，进行架构图中流程五，与状态机中的MVCC模块进行进行交互了。</p><h2 id="etcd写请求">etcd写请求</h2><p>写请求流程图</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164533960.png" alt="image-20240606164533960"></p><h3 id="Quota模块">Quota模块</h3><p>首先是流程一client端发起gRPC调用到etcd节点，和读请求不一样的是，写请求需要经过流程二db配额（Quota）模块，它有什么功能呢？</p><p>我们先从此模块的一个常见错误说起，你在使用etcd过程中是否遇到过”etcdserver: mvcc: database space exceeded”错误呢？</p><p>我相信只要你使用过etcd或者Kubernetes，大概率见过这个错误。它是指当前etcd db文件大小超过了配额，当出现此错误后，你的整个集群将不可写入，只读，对业务的影响非常大。</p><p>哪些情况会触发这个错误呢？</p><p>一方面默认db配额仅为2G，当你的业务数据、写入QPS、Kubernetes集群规模增大后，你的etcd db大小就可能会超过2G。</p><p>另一方面我们知道etcd v3是个MVCC数据库，保存了key的历史版本，当你未配置压缩策略的时候，随着数据不断写入，db大小会不断增大，导致超限。</p><p>最后你要特别注意的是，如果你使用的是etcd 3.2.10之前的旧版本，请注意备份可能会触发boltdb的一个Bug，它会导致db大小不断上涨，最终达到配额限制。</p><p>了解完触发Quota限制的原因后，我们再详细了解下Quota模块它是如何工作的。</p><p>当etcd server收到put/txn等写请求的时候，会首先检查下当前etcd db大小加上你请求的key-value大小之和是否超过了配额（quota-backend-bytes）。</p><p>如果超过了配额，它会产生一个告警（Alarm）请求，告警类型是NO SPACE，并通过Raft日志同步给其它节点，告知db无空间了，并将告警持久化存储到db中。</p><p>最终，无论是API层gRPC模块还是负责将Raft侧已提交的日志条目应用到状态机的Apply模块，都拒绝写入，集群只读。</p><p>那遇到这个错误时应该如何解决呢？</p><p>首先当然是调大配额。具体多大合适呢？etcd社区建议不超过8G。遇到过这个错误的你是否还记得，为什么当你把配额（quota-backend-bytes）调大后，集群依然拒绝写入呢?</p><p>原因就是我们前面提到的NO SPACE告警。Apply模块在执行每个命令的时候，都会去检查当前是否存在NO SPACE告警，如果有则拒绝写入。所以还需要你额外发送一个取消告警（etcdctl alarm disarm）的命令，以消除所有告警。</p><p>其次你需要检查etcd的压缩（compact）配置是否开启、配置是否合理。etcd保存了一个key所有变更历史版本，如果没有一个机制去回收旧的版本，那么内存和db大小就会一直膨胀，在etcd里面，压缩模块负责回收旧版本的工作。</p><p>压缩模块支持按多种方式回收旧版本，比如保留最近一段时间内的历史版本。不过你要注意，它仅仅是将旧版本占用的空间打个空闲（Free）标记，后续新的数据写入的时候可复用这块空间，而无需申请新的空间。</p><p>如果你需要回收空间，减少db大小，得使用碎片整理（defrag）， 它会遍历旧的db文件数据，写入到一个新的db文件。但是它对服务性能有较大影响，不建议你在生产集群频繁使用。</p><p>最后你需要注意配额（quota-backend-bytes）的行为，默认’0’就是使用etcd默认的2GB大小，你需要根据你的业务场景适当调优。如果你填的是个小于0的数，就会禁用配额功能，这可能会让你的db大小处于失控，导致性能下降，不建议你禁用配额。</p><h3 id="KVServer模块-2">KVServer模块</h3><p>通过流程二的配额检查后，请求就从API层转发到了流程三的KVServer模块的put方法，我们知道etcd是基于Raft算法实现节点间数据复制的，因此它需要将put写请求内容打包成一个提案消息，提交给Raft模块。不过KVServer模块在提交提案前，还有如下的一系列检查和限速。</p><h4 id="Preflight-Check">Preflight Check</h4><p>为了保证集群稳定性，避免雪崩，任何提交到Raft模块的请求，都会做一些简单的限速判断。如下面的流程图所示，首先，如果Raft模块已提交的日志索引（committed index）比已应用到状态机的日志索引（applied index）超过了5000，那么它就返回一个”etcdserver: too many requests”错误给client。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164603041.png" alt="image-20240606164603041"></p><p>然后它会尝试去获取请求中的鉴权信息，若使用了密码鉴权、请求中携带了token，如果token无效，则返回”auth: invalid auth token”错误给client。</p><p>其次它会检查你写入的包大小是否超过默认的1.5MB， 如果超过了会返回”etcdserver: request is too large”错误给给client。</p><h4 id="Propose">Propose</h4><p>最后通过一系列检查之后，会生成一个唯一的ID，将此请求关联到一个对应的消息通知channel，然后向Raft模块发起（Propose）一个提案（Proposal），提案内容为“大家好，请使用put方法执行一个key为hello，value为world的命令”，也就是整体架构图里的流程四。</p><p>向Raft模块发起提案后，KVServer模块会等待此put请求，等待写入结果通过消息通知channel返回或者超时。etcd默认超时时间是7秒（5秒磁盘IO延时+2*1秒竞选超时时间），如果一个请求超时未返回结果，则可能会出现你熟悉的etcdserver: request timed out错误。</p><h3 id="WAL模块">WAL模块</h3><p>Raft模块收到提案后，如果当前节点是Follower，它会转发给Leader，只有Leader才能处理写请求。Leader收到提案后，通过Raft模块输出待转发给Follower节点的消息和待持久化的日志条目，日志条目则封装了我们上面所说的put hello提案内容。</p><p>etcdserver从Raft模块获取到以上消息和日志条目后，作为Leader，它会将put提案消息广播给集群各个节点，同时需要把集群Leader任期号、投票信息、已提交索引、提案内容持久化到一个WAL（Write Ahead Log）日志文件中，用于保证集群的一致性、可恢复性，也就是我们图中的流程五模块。</p><p>WAL日志结构是怎样的呢？</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164635657.png" alt="image-20240606164635657"></p><p>上图是WAL结构，它由多种类型的WAL记录顺序追加写入组成，每个记录由类型、数据、循环冗余校验码组成。不同类型的记录通过Type字段区分，Data为对应记录内容，CRC为循环校验码信息。</p><p>WAL记录类型目前支持5种，分别是文件元数据记录、日志条目记录、状态信息记录、CRC记录、快照记录：</p><ul><li>文件元数据记录包含节点ID、集群ID信息，它在WAL文件创建的时候写入；</li><li>日志条目记录包含Raft日志信息，如put提案内容；</li><li>状态信息记录，包含集群的任期号、节点投票信息等，一个日志文件中会有多条，以最后的记录为准；</li><li>CRC记录包含上一个WAL文件的最后的CRC（循环冗余校验码）信息， 在创建、切割WAL文件时，作为第一条记录写入到新的WAL文件， 用于校验数据文件的完整性、准确性等；</li><li>快照记录包含快照的任期号、日志索引信息，用于检查快照文件的准确性。</li></ul><p>WAL模块又是如何持久化一个put提案的日志条目类型记录呢?</p><p>首先我们来看看put写请求如何封装在Raft日志条目里面。下面是Raft日志条目的数据结构信息，它由以下字段组成：</p><ul><li>Term是Leader任期号，随着Leader选举增加；</li><li>Index是日志条目的索引，单调递增增加；</li><li>Type是日志类型，比如是普通的命令日志（EntryNormal）还是集群配置变更日志（EntryConfChange）；</li><li>Data保存我们上面描述的put提案内容。</li></ul><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">type Entry <span class="keyword">struct</span> &#123;</span><br><span class="line">   Term             uint64    `protobuf:<span class="string">&quot;varint，2，opt，name=Term&quot;</span> json:<span class="string">&quot;Term&quot;</span>`</span><br><span class="line">   Index            uint64    `protobuf:<span class="string">&quot;varint，3，opt，name=Index&quot;</span> json:<span class="string">&quot;Index&quot;</span>`</span><br><span class="line">   Type             EntryType `protobuf:<span class="string">&quot;varint，1，opt，name=Type，enum=Raftpb.EntryType&quot;</span> json:<span class="string">&quot;Type&quot;</span>`</span><br><span class="line">   Data             []<span class="built_in">byte</span>    `protobuf:<span class="string">&quot;bytes，4，opt，name=Data&quot;</span> json:<span class="string">&quot;Data，omitempty&quot;</span>`</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>了解完Raft日志条目数据结构后，我们再看WAL模块如何持久化Raft日志条目。它首先先将Raft日志条目内容（含任期号、索引、提案内容）序列化后保存到WAL记录的Data字段， 然后计算Data的CRC值，设置Type为Entry Type， 以上信息就组成了一个完整的WAL记录。</p><p>最后计算WAL记录的长度，顺序先写入WAL长度（Len Field），然后写入记录内容，调用fsync持久化到磁盘，完成将日志条目保存到持久化存储中。</p><p>当一半以上节点持久化此日志条目后， Raft模块就会通过channel告知etcdserver模块，put提案已经被集群多数节点确认，提案状态为已提交，你可以执行此提案内容了。</p><p>于是进入流程六，etcdserver模块从channel取出提案内容，添加到先进先出（FIFO）调度队列，随后通过Apply模块按入队顺序，异步、依次执行提案内容。</p><h3 id="Apply模块">Apply模块</h3><p>执行put提案内容对应我们架构图中的流程七，其细节图如下。那么Apply模块是如何执行put请求的呢？若put请求提案在执行流程七的时候etcd突然crash了， 重启恢复的时候，etcd是如何找回异常提案，再次执行的呢？</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606164651171.png" alt="image-20240606164651171"></p><p>核心就是我们上面介绍的WAL日志，因为提交给Apply模块执行的提案已获得多数节点确认、持久化，etcd重启时，会从WAL中解析出Raft日志条目内容，追加到Raft日志的存储中，并重放已提交的日志提案给Apply模块执行。</p><p>然而这又引发了另外一个问题，如何确保幂等性，防止提案重复执行导致数据混乱呢?</p><p>我们在上一节课里讲到，etcd是个MVCC数据库，每次更新都会生成新的版本号。如果没有幂等性保护，同样的命令，一部分节点执行一次，一部分节点遭遇异常故障后执行多次，则系统的各节点一致性状态无法得到保证，导致数据混乱，这是严重故障。</p><p>因此etcd必须要确保幂等性。怎么做呢？Apply模块从Raft模块获得的日志条目信息里，是否有唯一的字段能标识这个提案？</p><p>答案就是我们上面介绍Raft日志条目中的索引（index）字段。日志条目索引是全局单调递增的，每个日志条目索引对应一个提案， 如果一个命令执行后，我们在db里面也记录下当前已经执行过的日志条目索引，是不是就可以解决幂等性问题呢？</p><p>是的。但是这还不够安全，如果执行命令的请求更新成功了，更新index的请求却失败了，是不是一样会导致异常？</p><p>因此我们在实现上，还需要将两个操作作为原子性事务提交，才能实现幂等。</p><p>正如我们上面的讨论的这样，etcd通过引入一个consistent index的字段，来存储系统当前已经执行过的日志条目索引，实现幂等性。</p><p>Apply模块在执行提案内容前，首先会判断当前提案是否已经执行过了，如果执行了则直接返回，若未执行同时无db配额满告警，则进入到MVCC模块，开始与持久化存储模块打交道。</p><p><strong>总结</strong>：</p><p>首先我们介绍了Quota模块工作原理和我们熟悉的database space exceeded错误触发原因，写请求导致db大小增加、compact策略不合理、boltdb Bug等都会导致db大小超限。</p><p>其次介绍了WAL模块的存储结构，它由一条条记录顺序写入组成，每个记录含有Type、CRC、Data，每个提案被提交前都会被持久化到WAL文件中，以保证集群的一致性和可恢复性。</p><p>随后我们介绍了Apply模块基于consistent index和事务实现了幂等性，保证了节点在异常情况下不会重复执行重放的提案。</p>]]></content>
    
    
    <summary type="html">etcd的读写请求</summary>
    
    
    
    <category term="etcd" scheme="https://penge666.github.io/categories/etcd/"/>
    
    <category term="数据库" scheme="https://penge666.github.io/categories/etcd/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="数据库" scheme="https://penge666.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="etcd" scheme="https://penge666.github.io/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>etcd中的MVCC</title>
    <link href="https://penge666.github.io/posts/ebe68de0.html"/>
    <id>https://penge666.github.io/posts/ebe68de0.html</id>
    <published>2024-06-06T08:35:49.000Z</published>
    <updated>2024-06-06T08:39:03.307Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是MVCC">什么是MVCC</h2><p>首先和你聊聊什么是MVCC，从名字上理解，它是一个基于多版本技术实现的一种并发控制机制。那常见的并发机制有哪些？MVCC的优点在哪里呢？</p><p>提到并发控制机制你可能就没那么陌生了，比如数据库中的悲观锁，也就是通过锁机制确保同一时刻只能有一个事务对数据进行修改操作，常见的实现方案有读写锁、互斥锁、两阶段锁等。</p><p>悲观锁是一种事先预防机制，它悲观地认为多个并发事务可能会发生冲突，因此它要求事务必须先获得锁，才能进行修改数据操作。但是悲观锁粒度过大、高并发场景下大量事务会阻塞等，会导致服务性能较差。</p><p><strong>MVCC机制正是基于多版本技术实现的一种乐观锁机制</strong>，它乐观地认为数据不会发生冲突，但是当事务提交时，具备检测数据是否冲突的能力。</p><p>在MVCC数据库中，你更新一个key-value数据的时候，它并不会直接覆盖原数据，而是新增一个版本来存储新的数据，每个数据都有一个版本号。版本号它是一个逻辑时间，为了方便你深入理解版本号意义，在下面我给你画了一个etcd MVCC版本号时间序列图。</p><p>从图中你可以看到，随着时间增长，你每次修改操作，版本号都会递增。每修改一次，生成一条新的数据记录。<strong>当你指定版本号读取数据时，它实际上访问的是版本号生成那个时间点的快照数据</strong>。当你删除数据的时候，它实际也是新增一条带删除标识的数据记录。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163633150.png" alt="image-20240606163633150"></p><h2 id="MVCC特性初体验">MVCC特性初体验</h2><p>了解完什么是MVCC后，我先通过几个简单命令，带你初体验下MVCC特性，看看它是如何帮助你查询历史修改记录，以及找回不小心删除的key的。</p><p>启动一个空集群，更新两次key hello后，如何获取key hello的上一个版本值呢？ 删除key hello后，还能读到历史版本吗?</p><p>如下面的命令所示，第一次key hello更新完后，我们通过get命令获取下它的key-value详细信息。正如你所看到的，除了key、value信息，还有各类版本号，我后面会详细和你介绍它们的含义。这里我们重点关注mod_revision，它表示key最后一次修改时的etcd版本号。</p><p>当我们再次更新key hello为world2后，然后通过查询时指定key第一次更新后的版本号，你会发现我们查询到了第一次更新的值，甚至我们执行删除key hello后，依然可以获得到这个值。那么etcd是如何实现的呢?</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新key hello为world1</span></span><br><span class="line"><span class="variable">$ </span>etcdctl put hello world1</span><br><span class="line"><span class="variable constant_">OK</span></span><br><span class="line"><span class="comment"># 通过指定输出模式为json,查看key hello更新后的详细信息</span></span><br><span class="line"><span class="variable">$ </span>etcdctl get hello -w=json</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;kvs&quot;</span><span class="symbol">:</span>[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;key&quot;</span><span class="symbol">:<span class="string">&quot;aGVsbG8=&quot;</span></span>,</span><br><span class="line">            <span class="string">&quot;create_revision&quot;</span><span class="symbol">:</span><span class="number">2</span>,</span><br><span class="line">            <span class="string">&quot;mod_revision&quot;</span><span class="symbol">:</span><span class="number">2</span>,</span><br><span class="line">            <span class="string">&quot;version&quot;</span><span class="symbol">:</span><span class="number">1</span>,</span><br><span class="line">            <span class="string">&quot;value&quot;</span><span class="symbol">:<span class="string">&quot;d29ybGQx&quot;</span></span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;count&quot;</span><span class="symbol">:</span><span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 再次修改key hello为world2</span></span><br><span class="line"><span class="variable">$ </span>etcdctl put hello world2</span><br><span class="line"><span class="variable constant_">OK</span></span><br><span class="line"><span class="comment"># 确认修改成功,最新值为wolrd2</span></span><br><span class="line"><span class="variable">$ </span>etcdctl get hello</span><br><span class="line">hello</span><br><span class="line">world2</span><br><span class="line"><span class="comment"># 指定查询版本号,获得了hello上一次修改的值</span></span><br><span class="line"><span class="variable">$ </span>etcdctl get hello --rev=<span class="number">2</span></span><br><span class="line">hello</span><br><span class="line">world1</span><br><span class="line"><span class="comment"># 删除key hello</span></span><br><span class="line"><span class="variable">$ </span>etcdctl del  hello</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="comment"># 删除后指定查询版本号3,获得了hello删除前的值</span></span><br><span class="line"><span class="variable">$ </span>etcdctl get hello --rev=<span class="number">3</span></span><br><span class="line">hello</span><br><span class="line">world2</span><br></pre></td></tr></table></figure><h2 id="整体架构">整体架构</h2><p>在详细和你介绍etcd如何实现MVCC特性前，我先和你从整体上介绍下MVCC模块。下图是MVCC模块的一个整体架构图，整个MVCC特性由treeIndex、Backend/boltdb组成。</p><p>当你执行MVCC特性初体验中的put命令后，请求经过gRPC KV Server、Raft模块流转，对应的日志条目被提交后，Apply模块开始执行此日志内容。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163649219.png" alt="image-20240606163649219"></p><p>Apply模块通过MVCC模块来执行put请求，持久化key-value数据。MVCC模块将请求请划分成两个类别，分别是读事务（ReadTxn）和写事务（WriteTxn）。读事务负责处理range请求，写事务负责put/delete操作。读写事务基于treeIndex、Backend/boltdb提供的能力，实现对key-value的增删改查功能。</p><p>treeIndex模块基于内存版B-tree实现了key索引管理，它保存了用户key与版本号（revision）的映射关系等信息。</p><p>Backend模块负责etcd的key-value持久化存储，主要由ReadTx、BatchTx、Buffer组成，ReadTx定义了抽象的读事务接口，BatchTx在ReadTx之上定义了抽象的写事务接口，Buffer是数据缓存区。</p><p>etcd设计上支持多种Backend实现，目前实现的Backend是boltdb。boltdb是一个基于B+ tree实现的、支持事务的key-value嵌入式数据库。</p><p>treeIndex与boltdb关系你可参考下图。当你发起一个get hello命令时，从treeIndex中获取key的版本号，然后再通过这个版本号，从boltdb获取value信息。boltdb的value是包含用户key-value、各种版本号、lease信息的结构体。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163705986.png" alt="image-20240606163705986"></p><p>接下来我和你重点聊聊treeIndex模块的原理与核心数据结构。</p><h2 id="treeIndex原理">treeIndex原理</h2><p>为什么需要treeIndex模块呢?</p><p>对于etcd v2来说，当你通过etcdctl发起一个put hello操作时，etcd v2直接更新内存树，这就导致历史版本直接被覆盖，无法支持保存key的历史版本。在etcd v3中引入treeIndex模块正是为了解决这个问题，支持保存key的历史版本，提供稳定的Watch机制和事务隔离等能力。</p><p>那etcd v3又是如何基于treeIndex模块，实现保存key的历史版本的呢?</p><p>在02节课里，我们提到过etcd在每次修改key时会生成一个全局递增的版本号（revision），然后通过数据结构B-tree保存用户key与版本号之间的关系，再以版本号作为boltdb key，以用户的key-value等信息作为boltdb value，保存到boltdb。</p><p>下面我就为你介绍下，etcd保存用户key与版本号映射关系的数据结构B-tree，为什么etcd使用它而不使用哈希表、平衡二叉树？</p><p>从etcd的功能特性上分析， 因etcd支持范围查询，因此保存索引的数据结构也必须支持范围查询才行。所以哈希表不适合，而B-tree支持范围查询。</p><p>从性能上分析，平横二叉树每个节点只能容纳一个数据、导致树的高度较高，而B-tree每个节点可以容纳多个数据，树的高度更低，更扁平，涉及的查找次数更少，具有优越的增、删、改、查性能。</p><p>Google的开源项目btree，使用Go语言实现了一个内存版的B-tree，对外提供了简单易用的接口。etcd正是基于btree库实现了一个名为treeIndex的索引模块，通过它来查询、保存用户key与版本号之间的关系。</p><p>下图是个最大度（degree &gt; 1，简称d）为5的B-tree，度是B-tree中的一个核心参数，它决定了你每个节点上的数据量多少、节点的“胖”、“瘦”程度。</p><p>从图中你可以看到，节点越胖，意味着一个节点可以存储更多数据，树的高度越低。在一个度为d的B-tree中，节点保存的最大key数为2d - 1，否则需要进行平衡、分裂操作。这里你要注意的是在etcd treeIndex模块中，创建的是最大度32的B-tree，也就是一个叶子节点最多可以保存63个key。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163722544.png" alt="image-20240606163722544"></p><p>从图中你可以看到，你通过put/txn命令写入的一系列key，treeIndex模块基于B-tree将其组织起来，节点之间基于用户key比较大小。当你查找一个key k95时，通过B-tree的特性，你仅需通过图中流程1和2两次快速比较，就可快速找到k95所在的节点。</p><p>在treeIndex中，每个节点的key是一个keyIndex结构，etcd就是通过它保存了用户的key与版本号的映射关系。</p><p>那么keyIndex结构包含哪些信息呢？下面是字段说明，你可以参考一下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> keyIndex <span class="keyword">struct</span> &#123;</span><br><span class="line">   key         []<span class="type">byte</span> <span class="comment">//用户的key名称，比如我们案例中的&quot;hello&quot;</span></span><br><span class="line">   modified    revision <span class="comment">//最后一次修改key时的etcd版本号,比如我们案例中的刚写入hello为world1时的，版本号为2</span></span><br><span class="line">   generations []generation <span class="comment">//generation保存了一个key若干代版本号信息，每代中包含对key的多次修改的版本号列表</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>keyIndex中包含用户的key、最后一次修改key时的etcd版本号、key的若干代（generation）版本号信息，每代中包含对key的多次修改的版本号列表。那我们要如何理解generations？为什么它是个数组呢?</p><p>generations表示一个key从创建到删除的过程，每代对应key的一个生命周期的开始与结束。当你第一次创建一个key时，会生成第0代，后续的修改操作都是在往第0代中追加修改版本号。当你把key删除后，它就会生成新的第1代，一个key不断经历创建、删除的过程，它就会生成多个代。</p><p>generation结构详细信息如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> generation <span class="keyword">struct</span> &#123;</span><br><span class="line">   ver     <span class="type">int64</span>    <span class="comment">//表示此key的修改次数</span></span><br><span class="line">   created revision <span class="comment">//表示generation结构创建时的版本号</span></span><br><span class="line">   revs    []revision <span class="comment">//每次修改key时的revision追加到此数组</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>generation结构中包含此key的修改次数、generation创建时的版本号、对此key的修改版本号记录列表。</p><p>你需要注意的是版本号（revision）并不是一个简单的整数，而是一个结构体。revision结构及含义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> revision <span class="keyword">struct</span> &#123;</span><br><span class="line">   main <span class="type">int64</span>    <span class="comment">// 一个全局递增的主版本号，随put/txn/delete事务递增，一个事务内的key main版本号是一致的</span></span><br><span class="line">   sub <span class="type">int64</span>    <span class="comment">// 一个事务内的子版本号，从0开始随事务内put/delete操作递增</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>revision包含main和sub两个字段，main是全局递增的版本号，它是个etcd逻辑时钟，随着put/txn/delete等事务递增。sub是一个事务内的子版本号，从0开始随事务内的put/delete操作递增。</p><p>比如启动一个空集群，全局版本号默认为1，执行下面的txn事务，它包含两次put、一次get操作，那么按照我们上面介绍的原理，全局版本号随读写事务自增，因此是main为2，sub随事务内的put/delete操作递增，因此key hello的revison为{2,0}，key world的revision为{2,1}。</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl txn -i</span><br><span class="line">compares:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">success <span class="title">requests</span> (<span class="params"><span class="keyword">get</span>，put，del</span>):</span></span><br><span class="line"><span class="function">put hello 1</span></span><br><span class="line"><span class="function"><span class="keyword">get</span> hello</span></span><br><span class="line"><span class="function">put world 2</span></span><br></pre></td></tr></table></figure><p>介绍完treeIndex基本原理、核心数据结构后，我们再看看在MVCC特性初体验中的更新、查询、删除key案例里，treeIndex与boltdb是如何协作，完成以上key-value操作的?</p><h2 id="MVCC更新key原理">MVCC更新key原理</h2><p>当你通过etcdctl发起一个put hello操作时，如下面的put事务流程图流程一所示，在put写事务中，首先它需要从treeIndex模块中查询key的keyIndex索引信息，keyIndex中存储了key的创建版本号、修改的次数等信息，这些信息在事务中发挥着重要作用，因此会存储在boltdb的value中。</p><p>在我们的案例中，因为是第一次创建hello key，此时keyIndex索引为空。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163736154.png" alt="image-20240606163736154"></p><p>其次etcd会根据当前的全局版本号（空集群启动时默认为1）自增，生成put hello操作对应的版本号revision{2,0}，这就是boltdb的key。</p><p>boltdb的value是mvccpb.KeyValue结构体，它是由用户key、value、create_revision、mod_revision、version、lease组成。它们的含义分别如下：</p><ul><li>create_revision表示此key创建时的版本号。在我们的案例中，key hello是第一次创建，那么值就是2。当你再次修改key hello的时候，写事务会从treeIndex模块查询hello第一次创建的版本号，也就是keyIndex.generations[i].created字段，赋值给create_revision字段；</li><li>mod_revision表示key最后一次修改时的版本号，即put操作发生时的全局版本号加1；</li><li>version表示此key的修改次数。每次修改的时候，写事务会从treeIndex模块查询hello已经历过的修改次数，也就是keyIndex.generations[i].ver字段，将ver字段值加1后，赋值给version字段。</li></ul><p>填充好boltdb的KeyValue结构体后，这时就可以通过Backend的写事务batchTx接口将key{2,0},value为mvccpb.KeyValue保存到boltdb的缓存中，并同步更新buffer，如上图中的流程二所示。</p><p>此时存储到boltdb中的key、value数据如下：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163747347.png" alt="image-20240606163747347"></p><p>然后put事务需将本次修改的版本号与用户key的映射关系保存到treeIndex模块中，也就是上图中的流程三。</p><p>因为key hello是首次创建，treeIndex模块它会生成key hello对应的keyIndex对象，并填充相关数据结构。</p><p>keyIndex填充后的结果如下所示：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">key hello的keyIndex:</span><br><span class="line"><span class="section">key:     &quot;hello&quot;</span></span><br><span class="line"><span class="section">modified: &lt;2,0&gt;</span></span><br><span class="line"><span class="section">generations:</span></span><br><span class="line"><span class="section">[&#123;ver:1,created:&lt;2,0&gt;,revisions: [&lt;2,0&gt;]&#125; ]</span></span><br></pre></td></tr></table></figure><p>我们来简易分析一下上面的结果。</p><ul><li>key为hello，modified为最后一次修改版本号&lt;2,0&gt;，key hello是首次创建的，因此新增一个generation代跟踪它的生命周期、修改记录；</li><li>generation的ver表示修改次数，首次创建为1，后续随着修改操作递增；</li><li>generation.created表示创建generation时的版本号为&lt;2,0&gt;；</li><li>revision数组保存对此key修改的版本号列表，每次修改都会将将相应的版本号追加到revisions数组中。</li></ul><p>通过以上流程，一个put操作终于完成。</p><p>但是此时数据还并未持久化，为了提升etcd的写吞吐量、性能，一般情况下（默认堆积的写事务数大于1万才在写事务结束时同步持久化），数据持久化由Backend的异步goroutine完成，它通过事务批量提交，定时将boltdb页缓存中的脏数据提交到持久化存储磁盘中，也就是下图中的黑色虚线框住的流程四。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163759638.png" alt="image-20240606163759638"></p><h2 id="MVCC查询key原理">MVCC查询key原理</h2><p>完成put hello为world1操作后，这时你通过etcdctl发起一个get hello操作，MVCC模块首先会创建一个读事务对象（TxnRead），在etcd 3.4中Backend实现了ConcurrentReadTx， 也就是并发读特性。</p><p>并发读特性的核心原理是创建读事务对象时，它会全量拷贝当前写事务未提交的buffer数据，并发的读写事务不再阻塞在一个buffer资源锁上，实现了全并发读。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163812068.png" alt="image-20240606163812068"></p><p>如上图所示，在读事务中，它首先需要根据key从treeIndex模块获取版本号，因我们未带版本号读，默认是读取最新的数据。treeIndex模块从B-tree中，根据key查找到keyIndex对象后，匹配有效的generation，返回generation的revisions数组中最后一个版本号{2,0}给读事务对象。</p><p>读事务对象根据此版本号为key，通过Backend的并发读事务（ConcurrentReadTx）接口，优先从buffer中查询，命中则直接返回，否则从boltdb中查询此key的value信息。</p><p>那指定版本号读取历史记录又是怎么实现的呢？</p><p>当你再次发起一个put hello为world2修改操作时，key hello对应的keyIndex的结果如下面所示，keyIndex.modified字段更新为&lt;3,0&gt;，generation的revision数组追加最新的版本号&lt;3,0&gt;，ver修改为2。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">key hello的keyIndex:</span><br><span class="line"><span class="section">key:     &quot;hello&quot;</span></span><br><span class="line"><span class="section">modified: &lt;3,0&gt;</span></span><br><span class="line"><span class="section">generations:</span></span><br><span class="line"><span class="section">[&#123;ver:2,created:&lt;2,0&gt;,revisions: [&lt;2,0&gt;,&lt;3,0&gt;]&#125;]</span></span><br></pre></td></tr></table></figure><p>boltdb插入一个新的key revision{3,0}，此时存储到boltdb中的key-value数据如下：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163824235.png" alt="image-20240606163824235"></p><p>这时你再发起一个指定历史版本号为2的读请求时，实际是读版本号为2的时间点的快照数据。treeIndex模块会遍历generation内的历史版本号，返回小于等于2的最大历史版本号，在我们这个案例中，也就是revision{2,0}，以它作为boltdb的key，从boltdb中查询出value即可。</p><h2 id="MVCC删除key原理">MVCC删除key原理</h2><p>介绍完MVCC更新、查询key的原理后，我们接着往下看。当你执行etcdctl del hello命令时，etcd会立刻从treeIndex和boltdb中删除此数据吗？还是增加一个标记实现延迟删除（lazy delete）呢？</p><p>答案为etcd实现的是延期删除模式，原理与key更新类似。</p><p>与更新key不一样之处在于，一方面，生成的boltdb key版本号{4,0,t}追加了删除标识（tombstone,简写t），boltdb value变成只含用户key的KeyValue结构体。另一方面treeIndex模块也会给此key hello对应的keyIndex对象，追加一个空的generation对象，表示此索引对应的key被删除了。</p><p>当你再次查询hello的时候，treeIndex模块根据key hello查找到keyindex对象后，若发现其存在空的generation对象，并且查询的版本号大于等于被删除时的版本号，则会返回空。</p><p>etcdctl hello操作后的keyIndex的结果如下面所示：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">key hello的keyIndex:</span><br><span class="line"><span class="section">key:     &quot;hello&quot;</span></span><br><span class="line"><span class="section">modified: &lt;4,0&gt;</span></span><br><span class="line"><span class="section">generations:</span></span><br><span class="line">[</span><br><span class="line"><span class="section">&#123;ver:3,created:&lt;2,0&gt;,revisions: [&lt;2,0&gt;,&lt;3,0&gt;,&lt;4,0&gt;(t)]&#125;，             </span></span><br><span class="line">&#123;empty&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>boltdb此时会插入一个新的key revision{4,0,t}，此时存储到boltdb中的key-value数据如下：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240606163836986.png" alt="image-20240606163836986"></p><p>那么key打上删除标记后有哪些用途呢？什么时候会真正删除它呢？</p><p>一方面删除key时会生成events，Watch模块根据key的删除标识，会生成对应的Delete事件。</p><p>另一方面，当你重启etcd，遍历boltdb中的key构建treeIndex内存树时，你需要知道哪些key是已经被删除的，并为对应的key索引生成tombstone标识。而真正删除treeIndex中的索引对象、boltdb中的key是通过压缩(compactor)组件异步完成。</p><p>正因为etcd的删除key操作是基于以上延期删除原理实现的，因此只要压缩组件未回收历史版本，我们就能从etcd中找回误删的数据。</p><h2 id="小结">小结</h2><p>最后我们来小结下今天的内容，我通过MVCC特性初体验中的更新、查询、删除key案例，为你分析了MVCC整体架构、核心模块，它由treeIndex、boltdb组成。</p><p>treeIndex模块基于Google开源的btree库实现，它的核心数据结构keyIndex，保存了用户key与版本号关系。每次修改key都会生成新的版本号，生成新的boltdb key-value。boltdb的key为版本号，value包含用户key-value、各种版本号、lease的mvccpb.KeyValue结构体。</p><p>当你未带版本号查询key时，etcd返回的是key最新版本数据。当你指定版本号读取数据时，etcd实际上返回的是版本号生成那个时间点的快照数据。</p><p>删除一个数据时，etcd并未真正删除它，而是基于lazy delete实现的异步删除。删除原理本质上与更新操作类似，只不过boltdb的key会打上删除标记，keyIndex索引中追加空的generation。真正删除key是通过etcd的压缩组件去异步实现的，在后面的课程里我会继续和你深入介绍。</p><p>基于以上原理特性的实现，etcd实现了保存key历史版本的功能，是高可靠Watch机制的基础。基于key-value中的各种版本号信息，etcd可提供各种级别的简易事务隔离能力。基于Backend/boltdb提供的MVCC机制，etcd可实现读写不冲突。</p>]]></content>
    
    
    <summary type="html">etcd中的MVCC</summary>
    
    
    
    <category term="数据库" scheme="https://penge666.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="etcd" scheme="https://penge666.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/etcd/"/>
    
    
    <category term="数据库" scheme="https://penge666.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="etcd" scheme="https://penge666.github.io/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>Raft论文</title>
    <link href="https://penge666.github.io/posts/a5b7770b.html"/>
    <id>https://penge666.github.io/posts/a5b7770b.html</id>
    <published>2024-06-04T12:45:18.000Z</published>
    <updated>2024-06-04T13:00:39.328Z</updated>
    
    <content type="html"><![CDATA[<p>翻译自：<a href="https://github.com/maemual/raft-zh_cn">https://github.com/maemual/raft-zh_cn</a></p><p>raft经典论文.原汁原味理解raft</p><h1>寻找一种易于理解的一致性算法（扩展版）</h1><ul><li><a href="#%E5%AF%BB%E6%89%BE%E4%B8%80%E7%A7%8D%E6%98%93%E4%BA%8E%E7%90%86%E8%A7%A3%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E6%89%A9%E5%B1%95%E7%89%88">寻找一种易于理解的一致性算法（扩展版）</a><ul><li><a href="#%E6%91%98%E8%A6%81">摘要</a></li><li><a href="#1-%E4%BB%8B%E7%BB%8D">1 介绍</a></li><li><a href="#2-%E5%A4%8D%E5%88%B6%E7%8A%B6%E6%80%81%E6%9C%BA">2 复制状态机</a></li><li><a href="#3-paxos-%E7%AE%97%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98">3 Paxos 算法的问题</a></li><li><a href="#4-%E4%B8%BA%E4%BA%86%E5%8F%AF%E7%90%86%E8%A7%A3%E6%80%A7%E7%9A%84%E8%AE%BE%E8%AE%A1">4 为了可理解性的设计</a></li><li><a href="#5-raft-%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95">5 Raft 一致性算法</a><ul><li><a href="#51-raft-%E5%9F%BA%E7%A1%80">5.1 Raft 基础</a></li><li><a href="#52-%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE">5.2 领导人选举</a></li><li><a href="#53-%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">5.3 日志复制</a></li><li><a href="#54-%E5%AE%89%E5%85%A8%E6%80%A7">5.4 安全性</a><ul><li><a href="#541-%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6">5.4.1 选举限制</a></li><li><a href="#542-%E6%8F%90%E4%BA%A4%E4%B9%8B%E5%89%8D%E4%BB%BB%E6%9C%9F%E5%86%85%E7%9A%84%E6%97%A5%E5%BF%97%E6%9D%A1%E7%9B%AE">5.4.2 提交之前任期内的日志条目</a></li><li><a href="#543-%E5%AE%89%E5%85%A8%E6%80%A7%E8%AE%BA%E8%AF%81">5.4.3 安全性论证</a></li></ul></li><li><a href="#55-%E8%B7%9F%E9%9A%8F%E8%80%85%E5%92%8C%E5%80%99%E9%80%89%E4%BA%BA%E5%B4%A9%E6%BA%83">5.5 跟随者和候选人崩溃</a></li><li><a href="#56-%E6%97%B6%E9%97%B4%E5%92%8C%E5%8F%AF%E7%94%A8%E6%80%A7">5.6 时间和可用性</a></li></ul></li><li><a href="#6-%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E5%8F%98%E5%8C%96">6 集群成员变化</a></li><li><a href="#7-%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9">7 日志压缩</a></li><li><a href="#8-%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BA%A4%E4%BA%92">8 客户端交互</a></li><li><a href="#9-%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%92%8C%E8%AF%84%E4%BC%B0">9 算法实现和评估</a><ul><li><a href="#91-%E5%8F%AF%E7%90%86%E8%A7%A3%E6%80%A7">9.1 可理解性</a></li><li><a href="#92-%E6%AD%A3%E7%A1%AE%E6%80%A7">9.2 正确性</a></li><li><a href="#93-%E6%80%A7%E8%83%BD">9.3 性能</a></li></ul></li><li><a href="#10-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C">10 相关工作</a></li><li><a href="#11-%E7%BB%93%E8%AE%BA">11 结论</a></li><li><a href="#12-%E6%84%9F%E8%B0%A2">12 感谢</a></li><li><a href="#%E5%8F%82%E8%80%83">参考</a></li></ul></li></ul><h2 id="摘要">摘要</h2><p>Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。一项用户研究的结果表明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。</p><h2 id="1-介绍">1 介绍</h2><p>一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos 算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。</p><p>但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。因此工业界和学术界都对 Paxos 算法感到十分头疼。</p><p>努力研究过 Paxos 算法之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。与 Paxos 不同，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且比 Paxos 算法更容易学习。此外，我们希望该算法方便系统构建者的直觉的发展。重要的不仅仅是算法能够工作，更重要的是能够很清楚地知道它为什么能工作。</p><p>Raft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。</p><p>Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：</p><ul><li><strong>强领导人</strong>：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导人发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。</li><li><strong>领导选举</strong>：Raft 算法使用一个随机计时器来选举领导人。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。</li><li><strong>成员关系调整</strong>：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。</li></ul><p>我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全特性已经被正式定义和证明；它的效率和其他算法比起来也不相上下。</p><p>接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了可理解性而采取的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。</p><p>Q：<strong>共识和一致性</strong>的区别</p><p>A：</p><p>共识是分布式系统中多个节点之间对某个事情的看法。</p><p>一致性是多个副本对外呈现的状态。</p><p>因此，共识不一定一致。</p><h2 id="2-复制状态机">2 复制状态机</h2><p>一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导人，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604203908377.png" alt="image-20240604203908377"></p><blockquote><p>图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。</p></blockquote><p>复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。</p><p>一致性算法的任务是保证复制日志的一致性。服务器上的一致性模块接收客户端发送的指令然后添加到自己的日志中。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，即使有些服务器发生故障。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成了一个高可靠的状态机。</p><p>实际系统中使用的一致性算法通常含有以下特性：</p><ul><li>安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、重复和乱序等错误都可以保证正确。</li><li>可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。它们稍后可能会从可靠存储的状态中恢复并重新加入集群。</li><li>不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。</li><li>通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。</li></ul><h2 id="3-Paxos-算法的问题">3 Paxos 算法的问题</h2><p>在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。</p><p>不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。</p><p>我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。</p><p>Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。</p><p>而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立地选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。</p><p>因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的，并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：</p><blockquote><p>在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。</p></blockquote><p>由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft 算法就是这次实验的结果。</p><h2 id="4-为了可理解性的设计">4 为了可理解性的设计</h2><p>设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。</p><p>在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？</p><p>我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：我们尽可能地将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和成员变更几个部分。</p><p>我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化来简化 Raft 中领导人选举算法。</p><h2 id="5-Raft-一致性算法">5 Raft 一致性算法</h2><p>Raft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。</p><p>Raft 通过选举一个杰出的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目（log entries），把日志条目复制到其他服务器上，并告诉其他的服务器什么时候可以安全地将日志条目应用到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可能会发生故障，或者和其他服务器失去连接，在这种情况下一个新的领导人会被选举出来。</p><p>通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：</p><ul><li><strong>领导选举</strong>：当现存的领导人发生故障的时候, 一个新的领导人需要被选举出来（章节 5.2）</li><li><strong>日志复制</strong>：领导人必须从客户端接收日志条目（log entries）然后复制到集群中的其他节点，并强制要求其他节点的日志和自己保持一致。</li><li><strong>安全性</strong>：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到选举机制（5.2 节）上的一个额外限制。</li></ul><p>在展示一致性算法之后，这一章节会讨论一些可用性的问题和计时在系统中的作用。</p><p><strong>状态</strong>：</p><p>所有服务器上的持久性状态<br>(在响应 RPC 请求之前，已经更新到了稳定的存储设备)</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>currentTerm</td><td>服务器已知最新的任期（在服务器首次启动时初始化为0，单调递增）</td></tr><tr><td>votedFor</td><td>当前任期内收到选票的 candidateId，如果没有投给任何候选人 则为空</td></tr><tr><td>log[]</td><td>日志条目；每个条目包含了用于状态机的命令，以及领导人接收到该条目时的任期（初始索引为1）</td></tr></tbody></table><p>所有服务器上的易失性状态</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>commitIndex</td><td>已知已提交的最高的日志条目的索引（初始值为0，单调递增）</td></tr><tr><td>lastApplied</td><td>已经被应用到状态机的最高的日志条目的索引（初始值为0，单调递增）</td></tr></tbody></table><p>领导人（服务器）上的易失性状态<br>(选举后已经重新初始化)</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>nextIndex[]</td><td>对于每一台服务器，发送到该服务器的下一个日志条目的索引（初始值为领导人最后的日志条目的索引+1）</td></tr><tr><td>matchIndex[]</td><td>对于每一台服务器，已知的已经复制到该服务器的最高日志条目的索引（初始值为0，单调递增）</td></tr></tbody></table><p><strong>追加条目（AppendEntries）RPC</strong>：</p><p>由领导人调用，用于日志条目的复制，同时也被当做心跳使用</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>领导人的任期</td></tr><tr><td>leaderId</td><td>领导人 ID 因此跟随者可以对客户端进行重定向（译者注：跟随者根据领导人 ID 把客户端的请求重定向到领导人，比如有时客户端把请求发给了跟随者而不是领导人）</td></tr><tr><td>prevLogIndex</td><td>紧邻新日志条目之前的那个日志条目的索引</td></tr><tr><td>prevLogTerm</td><td>紧邻新日志条目之前的那个日志条目的任期</td></tr><tr><td>entries[]</td><td>需要被保存的日志条目（被当做心跳使用时，则日志条目内容为空；为了提高效率可能一次性发送多个）</td></tr><tr><td>leaderCommit</td><td>领导人的已知已提交的最高的日志条目的索引</td></tr></tbody></table><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期，对于领导人而言 它会更新自己的任期</td></tr><tr><td>success</td><td>如果跟随者所含有的条目和 prevLogIndex 以及 prevLogTerm 匹配上了，则为 true</td></tr></tbody></table><p>接收者的实现：</p><ol><li>返回假 如果领导人的任期小于接收者的当前任期（译者注：这里的接收者是指跟随者或者候选人）（5.1 节）</li><li>返回假 如果接收者日志中没有包含这样一个条目 即该条目的任期在 prevLogIndex 上能和 prevLogTerm 匹配上<br>（译者注：在接收者日志中 如果能找到一个和 prevLogIndex 以及 prevLogTerm 一样的索引和任期的日志条目 则继续执行下面的步骤 否则返回假）（5.3 节）</li><li>如果一个已经存在的条目和新条目（译者注：即刚刚接收到的日志条目）发生了冲突（因为索引相同，任期不同），那么就删除这个已经存在的条目以及它之后的所有条目 （5.3 节）</li><li>追加日志中尚未存在的任何新条目</li><li>如果领导人的已知已提交的最高日志条目的索引大于接收者的已知已提交最高日志条目的索引（<code>leaderCommit &gt; commitIndex</code>），则把接收者的已知已经提交的最高的日志条目的索引commitIndex 重置为 领导人的已知已经提交的最高的日志条目的索引 leaderCommit 或者是 上一个新条目的索引 取两者的最小值</li></ol><p><strong>请求投票（RequestVote）RPC</strong>：</p><p>由候选人负责调用用来征集选票（5.2 节）</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>候选人的任期号</td></tr><tr><td>candidateId</td><td>请求选票的候选人的 ID</td></tr><tr><td>lastLogIndex</td><td>候选人的最后日志条目的索引值</td></tr><tr><td>lastLogTerm</td><td>候选人最后日志条目的任期号</td></tr></tbody></table><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期号，以便于候选人去更新自己的任期号</td></tr><tr><td>voteGranted</td><td>候选人赢得了此张选票时为真</td></tr></tbody></table><p>接收者实现：</p><ol><li>如果<code>term &lt; currentTerm</code>返回 false （5.2 节）</li><li>如果 votedFor 为空或者为 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）</li></ol><p><strong>所有服务器需遵守的规则</strong>：</p><p>所有服务器：</p><ul><li>如果<code>commitIndex &gt; lastApplied</code>，则 lastApplied 递增，并将<code>log[lastApplied]</code>应用到状态机中（5.3 节）</li><li>如果接收到的 RPC 请求或响应中，任期号<code>T &gt; currentTerm</code>，则令 <code>currentTerm = T</code>，并切换为跟随者状态（5.1 节）</li></ul><p>跟随者（5.2 节）：</p><ul><li>响应来自候选人和领导人的请求</li><li>如果在超过选举超时时间的情况之前没有收到<strong>当前领导人</strong>（即该领导人的任期需与这个跟随者的当前任期相同）的心跳/附加日志，或者是给某个候选人投了票，就自己变成候选人</li></ul><p>候选人（5.2 节）：</p><ul><li>在转变成候选人后就立即开始选举过程<ul><li>自增当前的任期号（currentTerm）</li><li>给自己投票</li><li>重置选举超时计时器</li><li>发送请求投票的 RPC 给其他所有服务器</li></ul></li><li>如果接收到大多数服务器的选票，那么就变成领导人</li><li>如果接收到来自新的领导人的附加日志（AppendEntries）RPC，则转变成跟随者</li><li>如果选举过程超时，则再次发起一轮选举</li></ul><p>领导人：</p><ul><li>一旦成为领导人：发送空的附加日志（AppendEntries）RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以防止跟随者超时（5.2 节）</li><li>如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）</li><li>如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex（<code>lastLogIndex ≥ nextIndex</code>），则发送从 nextIndex 开始的所有日志条目：<ul><li>如果成功：更新相应跟随者的 nextIndex 和 matchIndex</li><li>如果因为日志不一致而失败，则 nextIndex 递减并重试</li></ul></li><li>假设存在 N 满足<code>N &gt; commitIndex</code>，使得大多数的 <code>matchIndex[i] ≥ N</code>以及<code>log[N].term == currentTerm</code> 成立，则令 <code>commitIndex = N</code>（5.3 和 5.4 节）</li></ul><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604203937594.png" alt="image-20240604203937594"></p><blockquote><p>图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。</p></blockquote><table><thead><tr><th>特性</th><th>解释</th></tr></thead><tbody><tr><td>选举安全特性</td><td>对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）</td></tr><tr><td>领导人只附加原则</td><td>领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）</td></tr><tr><td>日志匹配原则</td><td>如果两个日志在某一相同索引位置日志条目的任期号相同，那么我们就认为这两个日志从头到该索引位置之间的内容完全一致（5.3 节）</td></tr><tr><td>领导人完全特性</td><td>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）</td></tr><tr><td>状态机安全特性</td><td>如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用不同的日志条目（5.4.3 节）</td></tr></tbody></table><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604203944709.png" alt="image-20240604203944709"></p><blockquote><p>图 3：Raft 在任何时候都保证以上的各个特性。</p></blockquote><h3 id="5-1-Raft-基础">5.1 Raft 基础</h3><p>一个 Raft 集群包含若干个服务器节点；5 个服务器节点是一个典型的例子，这允许整个系统容忍 2 个节点失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导人或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604203949708.png" alt="image-20240604203949708"></p><blockquote><p>图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导人。在一个任期内，领导人一直都会是领导人，直到自己宕机了。</p></blockquote><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604203954762.png" alt="image-20240604203954762"></p><blockquote><p>图 5：时间被划分成一个个的任期，每个任期始于一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。</p></blockquote><p>Raft 把时间分割成任意长度的<strong>任期</strong>，如图 5。任期用连续的整数标记。每一段任期从一次<strong>选举</strong>开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导人。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导人。</p><p>不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，任期使得服务器可以检测一些过期的信息：比如过期的领导人。每个节点存储一个当前任期号，这一编号在整个时期内单调递增。每当服务器之间通信的时候都会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的任期号到较大的任期号值。如果一个候选人或者领导人发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。</p><p>Raft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节  5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。</p><h3 id="5-2-领导人选举">5.2 领导人选举</h3><p>Raft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选人处接收到有效的 RPCs。领导人周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加条目（AppendEntries） RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是<strong>选举超时</strong>，那么他就会认为系统中没有可用的领导人,并且发起选举以选出新的领导人。</p><p>要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行地向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导人，© 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。</p><p>当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止发起新的选举。</p><p>在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加条目（AppendEntries）RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。</p><p>第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。</p><p>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。</p><p>领导人选举这个例子，体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了，那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快，则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。</p><h3 id="5-3-日志复制">5.3 日志复制</h3><p>一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行地发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全地复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204000734.png" alt="image-20240604204000734"></p><blockquote><p>图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全地被应用到状态机中去的时候，就认为是可以提交了。</p></blockquote><p>日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。</p><p>领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为<strong>已提交</strong>。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。</p><p>我们设计了 Raft 的日志机制来维护不同服务器日志之间的高层次的一致性。这么做不仅简化了系统的行为也使其更具有可预测性，同时它也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些特性共同组成了图 3 中的<strong>日志匹配特性（Log Matching Property）</strong>：</p><ul><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。</li><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。</li></ul><p>第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目前紧挨着的条目的索引位置和任期号包含在日志内。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查在日志扩展的时候保护了日志匹配特性。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。</p><p>在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同。跟随者可能会丢失一些在新的领导人中存在的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204006613.png" alt="image-20240604204006613"></p><blockquote><p>图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。</p></blockquote><p>在 Raft 算法中，领导人是通过强制跟随者直接复制自己的日志来处理不一致问题的。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。</p><p>要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除跟随者从那个点之后的所有日志条目，并发送自己在那个点之后的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 <strong>nextIndex</strong>，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的 index 加 1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。</p><blockquote><p>如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以(返回)冲突条目的任期号和该任期号对应的最小索引地址。借助这些信息，领导人可以减小 nextIndex 一次性越过该冲突任期的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。</p></blockquote><p>通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。</p><p>日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。</p><h3 id="5-4-安全性">5.4 安全性</h3><p>前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。</p><p>这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于<strong>领导人完整特性（Leader Completeness Property）</strong> 的简要证明，并且说明该特性是如何引导复制状态机做出正确行为的。</p><h4 id="5-4-1-选举限制">5.4.1 选举限制</h4><p>在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导人。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证在选举的时候新的领导人拥有所有之前任期中已经提交的日志条目，而不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。</p><p>Raft 使用投票的方式来阻止一个候选人赢得选举，除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票（RequestVote） RPC 实现了这样的限制：RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。</p><p>Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。</p><h4 id="5-4-2-提交之前任期内的日志条目">5.4.2 提交之前任期内的日志条目</h4><p>如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204012637.png" alt="image-20240604204012637"></p><blockquote><p>图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中，S1 是领导人，部分的(跟随者)复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 ©，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。反之，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为 S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。</p></blockquote><p>为了消除图 8 里描述的情况，Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。</p><p>当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。</p><h4 id="5-4-3-安全性论证">5.4.3 安全性论证</h4><p>在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204018143.png" alt="image-20240604204018143"></p><blockquote><p>图 9：如果 S1 （任期 T 的领导人）在它的任期里提交了一条新的日志，然后 S5 在之后的任期 U 里被选举为领导人，那么至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。</p></blockquote><ol><li>在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。</li><li>领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人 U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人 T 的日志条目，并且给领导人 U 投票了，如图 9。这个投票者是产生这个矛盾的关键。</li><li>这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。</li><li>投票者在给领导人 U 投票时依然保存有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有在和领导人冲突的时候才会删除条目。</li><li>投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。</li><li>首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。</li><li>除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交的日志，这里产生矛盾。</li><li>这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。</li><li>日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (e) 中的索引 2。</li></ol><p>通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。</p><p>最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。</p><h3 id="5-5-跟随者和候选人崩溃">5.5 跟随者和候选人崩溃</h3><p>到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单地通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。</p><h3 id="5-6-时间和可用性">5.6 时间和可用性</h3><p>Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。</p><p>领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：</p><blockquote><p>广播时间（broadcastTime）  &lt;&lt;  选举超时时间（electionTimeout） &lt;&lt;  平均故障间隔时间（MTBF）</p></blockquote><p>在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。</p><p>广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。</p><h2 id="6-集群成员变化">6 集群成员变化</h2><p>到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。</p><p>为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人在同一个任期里同时被选举成功。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性原子地转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204024635.png" alt="image-20240604204024635"></p><blockquote><p>图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。</p></blockquote><p>为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致（<em>joint consensus</em>)；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：</p><ul><li>日志条目被复制给集群中新、老配置的所有服务器。</li><li>新、旧配置的服务器都可以成为领导人。</li><li>达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。</li></ul><p>共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程中依然响应客户端的请求。</p><p>集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用  C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。</p><p>一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，如果不经过另一个配置的允许都不能单独做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204030188.png" alt="image-20240604204030188"></p><blockquote><p>图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的配置日志条目，实线表示最后被提交的配置日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和  C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在  C-new 和 C-old 可以同时做出决定的时间点。</p></blockquote><p>在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新之前使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。</p><p>第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。</p><p>第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。</p><p>为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。确切地说，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。</p><h2 id="7-日志压缩">7 日志压缩</h2><p>Raft 的日志在正常操作中不断地增长，但是在实际的系统中，日志不能无限制地增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。</p><p>快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。</p><p>增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204036683.png" alt="image-20240604204036683"></p><blockquote><p>图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。</p></blockquote><p>图 12 展示了 Raft 中快照的基础思想。每个服务器独立地创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：<strong>最后被包含索引</strong>指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），<strong>最后被包含的任期</strong>指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查，因为这个条目需要前一日志条目的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。</p><p>尽管通常服务器都是独立地创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。</p><p><strong>安装快照 RPC</strong>：</p><p>由领导人调用以将快照的分块发送给跟随者。领导人总是按顺序发送分块。</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>领导人的任期号</td></tr><tr><td>leaderId</td><td>领导人的 ID，以便于跟随者重定向请求</td></tr><tr><td>lastIncludedIndex</td><td>快照中包含的最后日志条目的索引值</td></tr><tr><td>lastIncludedTerm</td><td>快照中包含的最后日志条目的任期号</td></tr><tr><td>offset</td><td>分块在快照中的字节偏移量</td></tr><tr><td>data[]</td><td>从偏移量开始的快照分块的原始字节</td></tr><tr><td>done</td><td>如果这是最后一个分块则为 true</td></tr></tbody></table><table><thead><tr><th>结果</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期号（currentTerm），便于领导人更新自己</td></tr></tbody></table><p><strong>接收者实现</strong>：</p><ol><li>如果<code>term &lt; currentTerm</code>就立即回复</li><li>如果是第一个分块（offset 为 0）就创建一个新的快照</li><li>在指定偏移量写入数据</li><li>如果 done 是 false，则继续等待更多的数据</li><li>保存快照文件，丢弃具有较小索引的任何现有或部分快照</li><li>如果现存的日志条目与快照中最后包含的日志条目具有相同的索引值和任期号，则保留其后的日志条目并进行回复</li><li>丢弃整个日志</li><li>使用快照重置状态机（并加载快照的集群配置）</li></ol><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204049784.png" alt="image-20240604204049784"></p><blockquote><p>图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。</p></blockquote><p>在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种  RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者丢弃其整个日志；它全部被快照取代，并且可能包含与快照冲突的未提交条目。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照后面的条目仍然有效，必须保留。</p><p>这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。</p><p>我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。</p><p>还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。</p><p>第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。</p><h2 id="8-客户端交互">8 客户端交互</h2><p>这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。</p><p>Raft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。</p><p>我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可能执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。</p><p>只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为响应客户端请求的领导人可能在他不知道的时候已经被新的领导人取代了。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道哪些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。</p><h2 id="9-算法实现和评估">9 算法实现和评估</h2><p>我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。</p><p>这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。</p><h3 id="9-1-可理解性">9.1 可理解性</h3><p>为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者从第一部分的算法学习中获得的表现和经验的差异。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。</p><p>我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些  Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。</p><table><thead><tr><th>关心</th><th>缓和偏见采取的手段</th><th>可供查看的材料</th></tr></thead><tbody><tr><td>相同的讲课质量</td><td>两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。</td><td>视频</td></tr><tr><td>相同的测验难度</td><td>问题以难度分组，在两个测验里成对出现。</td><td>小测验</td></tr><tr><td>公平评分</td><td>使用评价量规。随机顺序打分，两个测验交替进行。</td><td>评价量规（rubric）</td></tr></tbody></table><blockquote><p>表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。</p></blockquote><p>参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。配置t-检验（又称student‘s t-test）表明，在 95% 的可信度下，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204056165.png" alt="image-20240604204056165"></p><blockquote><p>图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。</p></blockquote><p>我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型预测，对小测验的选择会产生 12.5 分的差别。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于 Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进行 Paxos 小测验的人而言，Raft的得分低了6.3分; 虽然我们不知道为什么，这似乎在统计上是有意义的。</p><p>我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204101119.png" alt="image-20240604204101119"></p><blockquote><p>图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。</p></blockquote><p>关于 Raft 用户学习有一个更加详细的讨论。</p><h3 id="9-2-正确性">9.2 正确性</h3><p>在第 5 节，我们已经制定了正式的规范，和对一致性机制的安全性证明。这个正式规范使用 TLA+ 规范语言使图 2 中总结的信息非常清晰。它长约400行，并作为证明的主题。同时对于任何想实现 Raft 的人也是十分有用的。我们通过 TLA 证明系统非常机械的证明了日志完全特性。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明规范的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性是完备的，并且是相当清晰的（大约 3500 个词）。</p><h3 id="9-3-性能">9.3 性能</h3><p>Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。</p><p>我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240604204108409.png" alt="image-20240604204108409"></p><blockquote><p>图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小选举超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。</p></blockquote><p>为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。</p><p>图 16 中上面的图表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。</p><p>图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。</p><h2 id="10-相关工作">10 相关工作</h2><p>已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：</p><ul><li>Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。</li><li>关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。</li><li>实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。</li><li>Paxos 可以应用的性能优化。</li><li>Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。</li></ul><p>Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。</p><p>像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。</p><p>和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 种不同的消息类型，相对的，Raft 只有 4 种消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。</p><p>Raft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。</p><p>一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。</p><h2 id="11-结论">11 结论</h2><p>算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。</p><p>在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；随着设计的进展，我们发现自己重复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。</p><h2 id="12-感谢">12 感谢</h2><p>这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。</p><h2 id="参考">参考</h2><p>略</p>]]></content>
    
    
    <summary type="html">原汁原味理解raft</summary>
    
    
    
    <category term="分布式" scheme="https://penge666.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="论文阅读" scheme="https://penge666.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="分布式" scheme="https://penge666.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    <category term="论文阅读" scheme="https://penge666.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
  </entry>
  
  <entry>
    <title>Nginx网络工作原理</title>
    <link href="https://penge666.github.io/posts/ef701d36.html"/>
    <id>https://penge666.github.io/posts/ef701d36.html</id>
    <published>2024-06-03T12:19:08.000Z</published>
    <updated>2024-06-03T13:32:35.755Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>在单进程的网络编程模型中。所有的网络相关的动作都是在一个进程里完成的，如监听 socket 的创建， bind、listen。再比如 epoll 的创建、要监听事件的添加，以及 epoll_wait 等待时间发生。这些统统都是在一个进程里搞定。</p><p>一个客户端和使用了 epoll 的服务端的交互过程如下图所示。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202016660.png" alt="image-20240603202016660"></p><p>以下是其大概的代码示例（没耐心看的同学可以先）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line"> <span class="comment">//监听</span></span><br><span class="line"> lfd = <span class="built_in">socket</span>(AF_INET,SOCK_STREAM,<span class="number">0</span>);</span><br><span class="line"> <span class="built_in">bind</span>(lfd, ...)</span><br><span class="line"> <span class="built_in">listen</span>(lfd, ...);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//创建epoll对象，并把 listen socket的事件管理起来</span></span><br><span class="line"> efd = <span class="built_in">epoll_create</span>(...);</span><br><span class="line"> <span class="built_in">epoll_ctl</span>(efd, EPOLL_CTL_ADD, lfd, ...);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//事件循环</span></span><br><span class="line"> <span class="keyword">for</span> (;;)</span><br><span class="line"> &#123;</span><br><span class="line">  <span class="type">size_t</span> nready = <span class="built_in">epoll_wait</span>(efd, ep, ...);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nready; ++i)&#123;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span>(ep[i].data.fd == lfd)&#123;</span><br><span class="line">    <span class="comment">//lfd上发生事件表示都连接到达，accept接收它</span></span><br><span class="line">    fd = <span class="built_in">accept</span>(listenfd, ...);</span><br><span class="line">    <span class="built_in">epoll_ctl</span>(efd, EPOLL_CTL_ADD, fd, ...);</span><br><span class="line">   &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="comment">//其它socket发生的事件都是读写请求、或者关闭连接</span></span><br><span class="line">    ...</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在单进程模型中，不管有多少的连接，是几万还是几十万，服务器都是通过 epoll 来监控这些连接 socket 上的可读和可写事件。当某个 socket 上有数据发生的时候，再以非阻塞的方式对 socket 进行读写操作。</p><p>事实上，Redis 5.0 及以前的版本中，它的网络部分去掉对 handler 的封装，去掉时间事件以后，代码基本和上述 demo 非常接近。而且因为 Redis 的业务特点只需要内存 IO，且 CPU 计算少，所以可以达到数万的 QPS。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202045785.png" alt="image-20240603202045785"></p><p>但是单进程的问题也是显而易见的，没有办法充分发挥多核的优势。所以目前业界绝大部分的后端服务还都是需要基于多进程的方式来进行开发的。到了多进程的时候，更复杂的问题多进程之间的配合和协作问题就产生了。比如</p><ul><li>哪个进程执行监听 listen ，以及 accept 接收新连接？</li><li>哪个进程负责发现用户连接上的读写事件？</li><li>当有用户请求到达的时候，如何均匀地将请求分散到不同的进程中？</li><li>需不需要单独搞一部分进程执行计算工作</li><li>…</li></ul><p>事实上，以上这些问题并没有标准答案。各大应用或者网络框架都有自己不同的实现方式。为此业界还专门总结出了两类网络设计模式 - Reactor 和 Proactor。不过今天我不想讨论这种抽象模式，而是想带大家看一个具体的 Case - Nginx 是如何在多进程下使用 epoll 的。</p><h2 id="一、-Nginx-Master-进程初始化">一、 Nginx Master 进程初始化</h2><p>在 Nginx 中，将进程分成了两类。一类是 Master 进程，一类是 Worker 进程。</p><p>在 Master 进程中，主要的任务是负责启动整个程序、读取配置文件、监听和处理各种信号，并对 Worker 进程进行统筹管理。</p><p>不过今天我们要查看的重点问题是看网络。在 Master 进程中，和网络相关的操作非常简单就是创建了 socket 并对其进行 bind 和 监听。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202124833.png" alt="image-20240603202124833"></p><p>具体细节我们来看 Main 函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/core/nginx.c</span></span><br><span class="line"><span class="function"><span class="type">int</span> ngx_cdecl <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *<span class="type">const</span> *argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="type">ngx_cycle_t</span>      *cycle, init_cycle;</span><br><span class="line"></span><br><span class="line"> <span class="comment">//1.1 ngx_init_cycle 中开启监听</span></span><br><span class="line"> cycle = <span class="built_in">ngx_init_cycle</span>(&amp;init_cycle);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//1.2 启动主进程循环</span></span><br><span class="line"> <span class="built_in">ngx_master_process_cycle</span>(cycle);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 Nginx 中，ngx_cycle_t 是非常核心的一个结构体。这个结构体存储了很多东西，也贯穿了好多的函数。其中对端口的 bind 和 listen 就是在它执行时完成的。</p><p>ngx_master_process_cycle 是 Master 进程的主事件循环。它先是根据配置启动指定数量的 Worker 进程，然后就开始关注和处理重启、退出等信号。接下来我们分两个小节来更详细地看。</p><h3 id="1-1-Nginx-的服务端口监听">1.1 Nginx 的服务端口监听</h3><p>我们看下 ngx_init_cycle 中是如何执行 bind 和 listen 的。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/core/ngx_cycle.c</span></span><br><span class="line"><span class="function"><span class="type">ngx_cycle_t</span> *<span class="title">ngx_init_cycle</span><span class="params">(<span class="type">ngx_cycle_t</span> *old_cycle)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> ......</span><br><span class="line"> <span class="keyword">if</span> (<span class="built_in">ngx_open_listening_sockets</span>(cycle) != NGX_OK) &#123;</span><br><span class="line">  <span class="keyword">goto</span> failed;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>真正的监听还是在 ngx_open_listening_sockets 函数中，继续看它的源码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/core/ngx_connection.c</span></span><br><span class="line"><span class="function"><span class="type">ngx_int_t</span> <span class="title">ngx_open_listening_sockets</span><span class="params">(<span class="type">ngx_cycle_t</span> *cycle)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> ......</span><br><span class="line"></span><br><span class="line"> <span class="comment">//要监听的 socket 对象</span></span><br><span class="line"> ls = cycle-&gt;listening.elts;</span><br><span class="line"> <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; cycle-&gt;listening.nelts; i++) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取第i个socket</span></span><br><span class="line">  s = <span class="built_in">ngx_socket</span>(ls[i].sockaddr-&gt;sa_family, ls[i].type, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//绑定</span></span><br><span class="line">  <span class="built_in">bind</span>(s, ls[i].sockaddr, ls[i].socklen)</span><br><span class="line"></span><br><span class="line">  <span class="comment">//监听</span></span><br><span class="line">  <span class="built_in">listen</span>(s, ls[i].backlog)</span><br><span class="line">  ls[i].listen = <span class="number">1</span>;</span><br><span class="line">  ls[i].fd = s;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个函数中，遍历要监听的 socket。如果是启用了 REUSEPORT 配置，那先把 socket 设置上 SO_REUSEPORT 选项。然后接下来就是大家都熟悉的 bind 和 listen。<strong>所以，bind 和 listen 是在 Master 进程中完成的。</strong></p><h3 id="1-2-Master-进程的主循环">1.2 Master 进程的主循环</h3><p>在 ngx_master_process_cycle 中主要完成两件事。</p><ul><li>启动 Worker 进程</li><li>将 Master 进程推入事件循环</li></ul><p>在创建 Worker 进程的时候，是通过 fork 系统调用让 Worker 进程完全复制自己的资源，包括 listen 状态的 socket 句柄</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202234404.png" alt="image-20240603202234404"></p><p>我们接下来看详细的代码。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/os/unix/ngx_process_cycle.c</span></span><br><span class="line">void <span class="built_in">ngx_master_process_cycle</span>(ngx_cycle_t *cycle)</span><br><span class="line">&#123;</span><br><span class="line"> ......</span><br><span class="line"> <span class="built_in">ngx_start_worker_processes</span>(cycle, ccf-&gt;worker_processes,</span><br><span class="line">          NGX_PROCESS_RESPAWN);</span><br><span class="line"> <span class="comment">//进入主循环,等待接收各种信号</span></span><br><span class="line"> for ( ;; ) &#123;</span><br><span class="line">  <span class="comment">//ngx_quit</span></span><br><span class="line">  <span class="comment">//ngx_reconfigure</span></span><br><span class="line">  <span class="comment">//ngx_restart</span></span><br><span class="line">  ...</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主进程在配置中读取到了 Worker 进程的数量 ccf-&gt;worker_processes。通过 ngx_start_worker_processes 来启动指定数量的 Worker。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file:src/os/unix/ngx_process_cycle.c</span></span><br><span class="line">static void <span class="built_in">ngx_start_worker_processes</span>(...)</span><br><span class="line">&#123;</span><br><span class="line"> for (i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">  <span class="built_in">ngx_spawn_process</span>(cycle, ngx_worker_process_cycle,</span><br><span class="line">        (void *) (intptr_t) <span class="selector-tag">i</span>, &quot;worker process&quot;, type);</span><br><span class="line">  ...</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码中值得注意的是，在调用 ngx_spawn_process 时的几个参数</p><ul><li>cycle：nginx 的核心数据结构</li><li>cngx_worker_process_cycle：worker 进程的入口函数</li><li>ci: 当前 worker 的序号</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/os/unix/ngx_process.c</span></span><br><span class="line"><span class="function"><span class="type">ngx_pid_t</span> <span class="title">ngx_spawn_process</span><span class="params">(<span class="type">ngx_cycle_t</span> *cycle, ngx_spawn_proc_pt proc,...)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> pid = fork();</span><br><span class="line"> <span class="keyword">switch</span> (pid) &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="number">-1</span>: <span class="comment">//出错了</span></span><br><span class="line">   ... </span><br><span class="line">  <span class="keyword">case</span> <span class="number">0</span>: <span class="comment">//子进程创建成功</span></span><br><span class="line">   ngx_parent = ngx_pid;</span><br><span class="line">   ngx_pid = <span class="built_in">ngx_getpid</span>();</span><br><span class="line">   <span class="built_in">proc</span>(cycle, data);</span><br><span class="line">   <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">   <span class="keyword">break</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 ngx_spawn_process 中调用 fork 来创建进程，创建成功后 Worker 进程就将进入 ngx_worker_process_cycle 来进行处理了。</p><p>总结：在网络上，master 进程其实只是 listen 了一下。listen 过后的 socket 存到 cycle-&gt;listening 这里了。剩下的网络操作都是在 Worker 中完成的。</p><h2 id="二、Worker-进程处理">二、Worker 进程处理</h2><p>在上面小节中看到，Master 进程关于网络其实做的事情不多，只是 bind 和 listen 了一下。epoll 相关的函数调用一个也没见着，更别说 accept 接收连接，以及 read 、 write 函数处理了。那这些细节一定都是在 Worker 进程中完成的。</p><p>事实的确如此，epoll_create、epoll_ctl、epoll_wait 都是在 Worker 进程中执行的。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202329716.png" alt="image-20240603202329716"></p><p>在 Worker 进程中，创建了一个 epoll 内核对象，通过 epoll_ctl 将其想监听的事件注册上去，然后调用 epoll_wait 进入事件循环。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/os/unix/ngx_process_cycle.c</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">ngx_worker_process_cycle</span><span class="params">(<span class="type">ngx_cycle_t</span> *cycle, <span class="type">void</span> *data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="comment">//2.2 Worker进程初始化编译进来的各个模块</span></span><br><span class="line"> <span class="built_in">ngx_worker_process_init</span>(cycle, worker);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//进入事件循环</span></span><br><span class="line"> <span class="keyword">for</span> ( ;; ) &#123;</span><br><span class="line">  <span class="comment">//2.3 进入 epollwait</span></span><br><span class="line">  <span class="built_in">ngx_process_events_and_timers</span>(cycle);</span><br><span class="line">  ......</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-1-Nginx-的-网络相关-module">2.1 Nginx 的 网络相关 module</h3><p>撇开 Worker 的工作流程不提，咱们先来了解一个背景知识 - Nginx module。</p><p>Nginx 采用的是<strong>一种模块化的架构</strong>，<strong>它的模块包括核心模块、标准HTTP模块、可选HTTP模块、邮件服务模块和第三方模块等几大类</strong>。每一个模块都以一个 module 的形式存在，都对应一个 ngx_module_s 结构体。通过这种方式来实现软件可拔插，是一种非常优秀的软件架构。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202401129.png" alt="image-20240603202401129"></p><p>每个 module 根据自己的需求来实现各种 init_xxx, exit_xxx 方法来供 Nginx 在合适的时机调用。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/core/ngx_module.h</span></span><br><span class="line">struct ngx_module_s &#123;</span><br><span class="line"> ......</span><br><span class="line"></span><br><span class="line"> ngx_uint_t            version;</span><br><span class="line"></span><br><span class="line"> void                 *ctx;</span><br><span class="line"> ngx_command_t        *commands;</span><br><span class="line"> ngx_uint_t            type;</span><br><span class="line"></span><br><span class="line"> ngx_int_t           (*init_master)(ngx_log_t *log);</span><br><span class="line"> ngx_int_t           (*init_module)(ngx_cycle_t *cycle);</span><br><span class="line"> ngx_int_t           (*init_process)(ngx_cycle_t *cycle);</span><br><span class="line"> ngx_int_t           (*init_thread)(ngx_cycle_t *cycle);</span><br><span class="line"> void                (*exit_thread)(ngx_cycle_t *cycle);</span><br><span class="line"> void                (*exit_process)(ngx_cycle_t *cycle);</span><br><span class="line"> void                (*exit_master)(ngx_cycle_t *cycle);</span><br><span class="line"></span><br><span class="line"> ......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中和网络相关的 module 有 ngx_events_module 、ngx_event_core_module 和具体的网络底层模块 ngx_epoll_module、ngx_kqueue_module等。</p><p>对于 ngx_epoll_module 来说，它在其上下文 ngx_epoll_module_ctx 中定义了各种 actions 方法（添加事件、删除事件、添加连接等）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file:src/event/ngx_event.h</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line"> <span class="type">ngx_str_t</span>              *name;</span><br><span class="line"></span><br><span class="line"> <span class="type">void</span>                 *(*create_conf)(<span class="type">ngx_cycle_t</span> *cycle);</span><br><span class="line"> <span class="type">char</span>                 *(*init_conf)(<span class="type">ngx_cycle_t</span> *cycle, <span class="type">void</span> *conf);</span><br><span class="line"></span><br><span class="line"> <span class="type">ngx_event_actions_t</span>     actions;</span><br><span class="line">&#125; <span class="type">ngx_event_module_t</span>;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file:src/event/modules/ngx_epoll_module.c</span></span><br><span class="line"><span class="type">static</span> <span class="type">ngx_event_module_t</span>  ngx_epoll_module_ctx = &#123;</span><br><span class="line"> &amp;epoll_name,</span><br><span class="line"> ngx_epoll_create_conf,               <span class="comment">/* create configuration */</span></span><br><span class="line"> ngx_epoll_init_conf,                 <span class="comment">/* init configuration */</span></span><br><span class="line"></span><br><span class="line"> &#123;</span><br><span class="line">  ngx_epoll_add_event,             <span class="comment">/* add an event */</span></span><br><span class="line">  ngx_epoll_del_event,             <span class="comment">/* delete an event */</span></span><br><span class="line">  ngx_epoll_add_event,             <span class="comment">/* enable an event */</span></span><br><span class="line">  ngx_epoll_del_event,             <span class="comment">/* disable an event */</span></span><br><span class="line">  ngx_epoll_add_connection,        <span class="comment">/* add an connection */</span></span><br><span class="line">  ngx_epoll_del_connection,        <span class="comment">/* delete an connection */</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> (NGX_HAVE_EVENTFD)</span></span><br><span class="line">  ngx_epoll_notify,                <span class="comment">/* trigger a notify */</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">  <span class="literal">NULL</span>,                            <span class="comment">/* trigger a notify */</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  ngx_epoll_process_events,        <span class="comment">/* process the events */</span></span><br><span class="line">  ngx_epoll_init,                  <span class="comment">/* init the events */</span></span><br><span class="line">  ngx_epoll_done,                  <span class="comment">/* done the events */</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>其中有一个 init 方法是 ngx_epoll_init，在这个 init 中会进行 epoll 对象的创建，以及 ngx_event_actions 方法的设置。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file:src/event/modules/ngx_epoll_module.c</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">ngx_int_t</span></span></span><br><span class="line"><span class="function"><span class="title">ngx_epoll_init</span><span class="params">(<span class="type">ngx_cycle_t</span> *cycle, <span class="type">ngx_msec_t</span> timer)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="comment">//创建一个 epoll 句柄</span></span><br><span class="line"> ep = <span class="built_in">epoll_create</span>(cycle-&gt;connection_n / <span class="number">2</span>);</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line"> ngx_event_actions = ngx_epoll_module_ctx.actions;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-2-Worker-进程初始化各个模块">2.2 Worker 进程初始化各个模块</h3><p>Worker 进程初始化的时候，在 ngx_worker_process_init 中读取配置信息进行一些设置，然后调用所有模块的 init_process 方法。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202452066.png" alt="image-20240603202452066"></p><p>来看详细代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/os/unix/ngx_process_cycle.c</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">ngx_worker_process_init</span><span class="params">(<span class="type">ngx_cycle_t</span> *cycle, <span class="type">ngx_int_t</span> worker)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line"> <span class="comment">//获取配置</span></span><br><span class="line"> ccf = (<span class="type">ngx_core_conf_t</span> *) <span class="built_in">ngx_get_conf</span>(cycle-&gt;conf_ctx, ngx_core_module);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//设置优先级</span></span><br><span class="line"> <span class="built_in">setpriority</span>(PRIO_PROCESS, <span class="number">0</span>, ccf-&gt;priority)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//设置文件描述符限制</span></span><br><span class="line"> <span class="built_in">setrlimit</span>(RLIMIT_NOFILE, &amp;rlmt)</span><br><span class="line"> <span class="built_in">setrlimit</span>(RLIMIT_CORE, &amp;rlmt)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//group 和 uid 设置</span></span><br><span class="line"> <span class="built_in">initgroups</span>(ccf-&gt;username, ccf-&gt;group)</span><br><span class="line"> <span class="built_in">setuid</span>(ccf-&gt;user)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//CPU亲和性</span></span><br><span class="line"> cpu_affinity = <span class="built_in">ngx_get_cpu_affinity</span>(worker)</span><br><span class="line"> <span class="keyword">if</span> (cpu_affinity) &#123;</span><br><span class="line">  <span class="built_in">ngx_setaffinity</span>(cpu_affinity, cycle-&gt;log);</span><br><span class="line"> &#125;</span><br><span class="line"> ......</span><br><span class="line"></span><br><span class="line"> <span class="comment">//调用各个模块的init_process进行模块初始化</span></span><br><span class="line"> <span class="keyword">for</span> (i = <span class="number">0</span>; cycle-&gt;modules[i]; i++) &#123;</span><br><span class="line">  <span class="keyword">if</span> (cycle-&gt;modules[i]-&gt;init_process) &#123;</span><br><span class="line">   <span class="keyword">if</span> (cycle-&gt;modules[i]-&gt;<span class="built_in">init_process</span>(cycle) == NGX_ERROR) &#123;</span><br><span class="line">    <span class="comment">/* fatal */</span></span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">2</span>);</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>[✳]  ~ <a href="https://www.cnblogs.com/wenqiang/p/6049978.html">linux进程、线程与cpu的亲和性（affinity）</a></li></ul><p>前面我们说过 ngx_event_core_module ，它的 init_process 方法是 ngx_event_process_init。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/event/ngx_event.c</span></span><br><span class="line"><span class="type">ngx_module_t</span>  ngx_event_core_module = &#123;</span><br><span class="line"> ...</span><br><span class="line"> ngx_event_process_init,                <span class="comment">/* init process */</span></span><br><span class="line"> ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>在 ngx_event_core_module 的 ngx_event_process_init 中，我们将看到 <strong>Worker 进程使用 epoll_create 来创建 epoll 对象，使用epoll_ctl 来监听 listen socket 上的连接请求。</strong></p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202522699.png" alt="image-20240603202522699"></p><p>来详细看 ngx_event_process_init 的代码。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/event/ngx_event.c</span></span><br><span class="line">static ngx_int_t ngx_event_process_init(ngx_cycle_t *cycle)</span><br><span class="line">&#123;</span><br><span class="line"> <span class="comment">//调用模块的init，创建 epoll 对象</span></span><br><span class="line"> <span class="function"><span class="title">for</span> (m = 0; cycle-&gt;</span>modules[m]; m++) &#123;</span><br><span class="line">  <span class="function"><span class="title">if</span> (cycle-&gt;</span><span class="function"><span class="title">modules</span>[m]-&gt;</span>type != NGX_EVENT_MODULE) &#123;</span><br><span class="line">   continue;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="function"><span class="title">module</span>-&gt;</span>actions.init(cycle, ngx_timer_resolution)</span><br><span class="line">  break;</span><br><span class="line"> &#125;</span><br><span class="line"> ...</span><br><span class="line"></span><br><span class="line"> <span class="comment">//获取自己监听的sokcet，将它们都添加到 epoll 中</span></span><br><span class="line"> ngx_event_t         *rev</span><br><span class="line"> <span class="function"><span class="title">ls</span> = cycle-&gt;</span>listening.elts;</span><br><span class="line"> <span class="function"><span class="title">for</span> (i = 0; i &lt; cycle-&gt;</span>listening.nelts; i++) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取一个 ngx_connection_t</span></span><br><span class="line">  <span class="function"><span class="title">c</span> = ngx_get_connection(ls[i].fd, cycle-&gt;</span><span class="built_in">log</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//设置回调函数为 ngx_event_accept</span></span><br><span class="line">  <span class="function"><span class="title">rev</span>-&gt;</span>handler = ngx_event_accept </span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (ngx_add_event(rev, NGX_READ_EVENT, <span class="number">0</span>) == NGX_ERROR) &#123;</span><br><span class="line">   return NGX_ERROR;</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过 ngx_add_event 注册的 READ 事件的处理函数。ngx_add_event 就是一个抽象，对于 epoll 来说就是对 epoll_ctl 的封装而已。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/event/ngx_event.h</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ngx_add_event        ngx_event_actions.add</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//file: src/event/modules/ngx_epoll_module.c</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">ngx_int_t</span> <span class="title">ngx_epoll_add_event</span><span class="params">(...)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (<span class="built_in">epoll_ctl</span>(ep, op, c-&gt;fd, &amp;ee) == <span class="number">-1</span>) &#123;</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>TODO: epoll_create 还没解决呢。</p><h3 id="2-3-进入-epollwait">2.3 进入 epollwait</h3><p>在 ngx_worker_process_init 中， epoll_create 和 epoll_ctl 都已经完成了。接下来就是进入事件循环，执行 epoll_wait 来处理。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202554722.png" alt="image-20240603202554722"></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/event/ngx_event.c</span></span><br><span class="line"><span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">ngx_process_events_and_timers</span><span class="params">(<span class="type">ngx_cycle_t</span> *cycle)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> ...</span><br><span class="line"> <span class="comment">// 防accept惊群锁</span></span><br><span class="line"> <span class="keyword">if</span> (ngx_use_accept_mutex) &#123;</span><br><span class="line">  <span class="comment">//尝试获取锁，获取失败直接返回</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">ngx_trylock_accept_mutex</span>(cycle) == NGX_ERROR) &#123;</span><br><span class="line">   <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//获取锁成功，则设置 NGX_POST_EVENTS 标记。</span></span><br><span class="line">  <span class="keyword">if</span> (ngx_accept_mutex_held) &#123;</span><br><span class="line">   flags |= NGX_POST_EVENTS;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">   ...</span><br><span class="line">  &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">//处理各种事件</span></span><br><span class="line"> (<span class="type">void</span>) <span class="built_in">ngx_process_events</span>(cycle, timer, flags);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在 ngx_process_events_and_timers 开头处，判断是否使用 accpet_mutext 锁。这是一个防止惊群的解决办法。如果使用的话，先调用 ngx_trylock_accept_mutex 获取锁，获取失败则直接返回，过段时间再来尝试。获取成功是则设置 NGX_POST_EVENTS 的标志位。</p><p>接下来调用 ngx_process_events 来处理各种网络和 timer 事件。对于 epoll 来说，这个函数就是对 epoll_wait 的封装。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/event/ngx_event.h</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ngx_process_events   ngx_event_actions.process_events</span></span><br><span class="line"><span class="comment">//file: src/event/modules/ngx_epoll_module.c</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">ngx_int_t</span> <span class="title">ngx_epoll_process_events</span><span class="params">(<span class="type">ngx_cycle_t</span> *cycle, ...)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> events = <span class="built_in">epoll_wait</span>(ep, event_list, (<span class="type">int</span>) nevents, timer);</span><br><span class="line"> <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; events; i++) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (flags &amp; NGX_POST_EVENTS) &#123;</span><br><span class="line">   ...</span><br><span class="line">   <span class="built_in">ngx_post_event</span>(rev, queue);</span><br><span class="line">  &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">   <span class="comment">//调用回调函数</span></span><br><span class="line">   rev-&gt;<span class="built_in">handler</span>(rev);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可见，在 ngx_epoll_process_events 是调用 epoll_wait 等待各种事件的发生。如果没有 NGX_POST_EVENTS 标志，则直接回调 rev-&gt;handler 进行处理。使用了 accept_mutex 锁的话，先把这个事件保存起来，等后面合适的时机再去 accpet。</p><p>简单对本节内容汇总一下。在 Master 进程中只是做了 socket 的 bind 和 listen。而在 Worker 进程中所做的事情比较多，创建了 epoll，使用 epoll_ctl 将 listen 状态的 socket 的事件监控起来。最后调用 epoll_wait 进入了事件循环，开始处理各种网络和 timer 事件。本节流程总结如图。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202632527.png" alt="image-20240603202632527"></p><h2 id="三、用户连接来啦！">三、用户连接来啦！</h2><p>现在假设用户的连接请求已经到了，这时候 epoll_wait 返回后会执行其对应的 handler 函数 ngx_add_event。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202651350.png" alt="image-20240603202651350"></p><p>在该回调函数中被执行到的时候，表示 listen 状态的 socket 上面有连接到了。所以这个函数主要做了三件事。</p><ul><li>1.调用 accept 获取用户连接</li><li>2.获取 connection 对象，其回调函数为 ngx_http_init_connection</li><li>3.将新连接 socket 通过 epoll_ctl 添加到 epoll 中进行管理</li></ul><p>我们来看 ngx_event_accept 详细代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/event/ngx_event_accept.c</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ngx_event_accept</span><span class="params">(<span class="type">ngx_event_t</span> *ev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">do</span> &#123;</span><br><span class="line">  <span class="comment">//接收建立好的连接</span></span><br><span class="line">  s = <span class="built_in">accept</span>(lc-&gt;fd, &amp;sa.sockaddr, &amp;socklen);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> s &#123;</span><br><span class="line">   <span class="comment">//3.1 获取 connection</span></span><br><span class="line">   c = <span class="built_in">ngx_get_connection</span>(s, ev-&gt;log);</span><br><span class="line"></span><br><span class="line">   <span class="comment">//3.2 添加新连接</span></span><br><span class="line">   <span class="keyword">if</span> (<span class="built_in">ngx_add_conn</span>(c) == NGX_ERROR) &#123;</span><br><span class="line">    <span class="built_in">ngx_close_accepted_connection</span>(c);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">   &#125;</span><br><span class="line">  &#125; </span><br><span class="line"> &#125; <span class="keyword">while</span> (ev-&gt;available);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>listen socket 上的读事件发生的时候，就意味着有用户连接就绪了。所以可以直接通过 accept 将其取出来。取出连接以后，再获取一个空闲的 connection对象，通过 ngx_add_conn 将其添加到 epoll 中进行管理。</p><h3 id="3-1-获取-connection">3.1 获取 connection</h3><p>我们说一下 ngx_get_connection，这个函数本身倒是没有啥可说的。就是从 ngx_cycle 的 free_connections 中获取一个 connection 出来。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/core/ngx_connection.c</span></span><br><span class="line">ngx_connection_t *ngx_get_connection(ngx_socket_t s, ngx_log_t *<span class="built_in">log</span>)</span><br><span class="line">&#123;</span><br><span class="line"> <span class="function"><span class="title">c</span> = ngx_cycle-&gt;</span>free_connections;</span><br><span class="line"> <span class="function"><span class="title">c</span>-&gt;</span>read = rev;</span><br><span class="line"> <span class="function"><span class="title">c</span>-&gt;</span>write = wev;</span><br><span class="line"> <span class="function"><span class="title">c</span>-&gt;</span>fd = s;</span><br><span class="line"> <span class="function"><span class="title">c</span>-&gt;</span><span class="built_in">log</span> = <span class="built_in">log</span>;</span><br><span class="line"> return c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>值得说的是 free_connections 中的连接，对于 HTTP 服务来说，会经过 ngx_http_init_connection 的初始化处理。它会设置该连接读写事件的回调函数 c-&gt;read-&gt;handler 和 c-&gt;write-&gt;handler。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/http/ngx_http_request.c</span></span><br><span class="line">void ngx_http_init_connection(ngx_connection_t *c)</span><br><span class="line">&#123;</span><br><span class="line"> ...</span><br><span class="line"> <span class="function"><span class="title">rev</span> = c-&gt;</span>read;</span><br><span class="line"> <span class="function"><span class="title">rev</span>-&gt;</span>handler = ngx_http_wait_request_handler;</span><br><span class="line"> <span class="function"><span class="title">c</span>-&gt;</span><span class="function"><span class="title">write</span>-&gt;</span>handler = ngx_http_empty_handler;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-添加新连接">3.2 添加新连接</h3><p>我们再来看 ngx_add_conn，对于 epoll module 来说，它就是 ngx_epoll_add_connection 这个函数。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//file: src/event/ngx_event.h</span></span><br><span class="line">#define ngx_add_conn         ngx_event_actions.add_conn</span><br><span class="line"></span><br><span class="line"><span class="comment">//file: src/event/modules/ngx_epoll_module.c</span></span><br><span class="line">static ngx_int_t</span><br><span class="line">ngx_epoll_add_connection(ngx_connection_t *c)</span><br><span class="line">&#123;</span><br><span class="line"> struct epoll_event  ee;</span><br><span class="line"> ee.events = EPOLLIN|EPOLLOUT|EPOLLET|EPOLLRDHUP;</span><br><span class="line"> <span class="function"><span class="title">ee</span>.<span class="keyword">data</span>.ptr = (void *) ((uintptr_t) c | c-&gt;</span><span class="function"><span class="title">read</span>-&gt;</span>instance);</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="title">epoll_ctl</span>(ep, EPOLL_CTL_ADD, c-&gt;</span>fd, &amp;ee)</span><br><span class="line"> <span class="function"><span class="title">c</span>-&gt;</span><span class="function"><span class="title">read</span>-&gt;</span>active = <span class="number">1</span>;</span><br><span class="line"> <span class="function"><span class="title">c</span>-&gt;</span><span class="function"><span class="title">write</span>-&gt;</span>active = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"> return NGX_OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可见这只是 epoll_ctl 的一个封装而已。这里再补充说一下，如果这个客户端连接 socket 上有数据到达的时候，就会进入到上面 3.1 节中注册的 ngx_http_wait_request_handler 函数进行处理。后面就是 HTTP 的处理逻辑了。</p><h2 id="四、总结">四、总结</h2><p>Nginx 的 Master 中做的网络相关动作不多，仅仅只是创建了 socket、然后 bind 并 listen 了一下。接着就是用自己 fork 出来多个 Worker 进程来。由于每个进程都一样，所以每个 Worker 都有 Master 创建出来的 listen 状态的 socket 句柄。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202746092.png" alt="image-20240603202746092"></p><p>Worker 进程处理的网络相关工作就比较多了。epoll_create、epoll_ctl、epoll_wait 都是在 Worker 进程中执行的，也包括用户连接上的数据 read、处理 和 write。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202802393.png" alt="image-20240603202802393"></p><ul><li>1.先是使用 epoll_create 创建一个 epoll 对象出来</li><li>2.设置回调为 ngx_event_accept</li><li>3.通过 epoll_ctl 将所有 listen 状态的 socket 的事件都管理起来</li><li>4.执行 epoll_wait 等待 listen socket 上的连接到来</li><li>5.新连接到来是 epoll_wait 返回，进入 ngx_event_accept 回调</li><li>6.ngx_event_accept 回调中将新连接也添加到 epoll 中进行管理（其回调为ngx_http_init_connection）</li><li>7.继续进入 epoll_wait 等待事件</li><li>8.用户数据请求到达时进入 http 回调函数进行处理</li></ul><p>讲到这里，你可以觉得咱们已经讨论完了。实际上有一个点我们还没有考虑到。我们上面讨论的流程是一个 Worker 在工作的情况。那么在多 Worker 的情况下，Nginx 的全貌咱们还没展开说过。通过上文我们可以看到以下几个细节：</p><ul><li>1.每个 Worker 都会有一个属于自己的 epoll 对象</li><li>2.每个 Worker 会关注所有的 listen 状态上的新连接事件</li><li>3.对于用户连接，只有一个 Worker 会处理，其它 Worker 不会持有该用户连接的 socket。</li></ul><p>根据这三条结论，我们再画一个 Nginx 的全貌图。</p><p>【easy say:就是刚开始master进程创建socket与端口绑定，然后通过fork子进程的方式，让这些子进程也可以监听这些最为原始的socket，然后时间发生的时候，操作系统的内核会发生惊群效应，从这些子进程中选择·一个进程事件处理】</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240603202820951.png" alt="image-20240603202820951"></p>]]></content>
    
    
    <summary type="html">Nginx网络工作原理</summary>
    
    
    
    <category term="网络编程" scheme="https://penge666.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="网络编程" scheme="https://penge666.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper原理篇</title>
    <link href="https://penge666.github.io/posts/586aed37.html"/>
    <id>https://penge666.github.io/posts/586aed37.html</id>
    <published>2024-06-02T12:40:07.000Z</published>
    <updated>2024-06-02T12:57:39.241Z</updated>
    
    <content type="html"><![CDATA[<h2 id="28-彻底掌握二阶段提交三阶段提交算法原理">28 彻底掌握二阶段提交三阶段提交算法原理</h2><p>在本节课的开篇中，我们已经提到过 ZooKeeper 在分布式系统环境中主要解决的是分布式一致性问题。而为什么会发生数据不一致的问题呢？是因为当网络集群处理来自客户端的请求时，其中的事务性会导致服务器上数据状态的变更。</p><p>为了保证数据变更请求在整个分布式环境下正确地执行，不会发生异常中断，从而导致请求在某一台服务器执行失败而在集群中其他服务器上执行成功，在整个分布式系统处理数据变更请求的过程中，引入了分布式事务的概念。</p><h3 id="分布式事务">分布式事务</h3><p>对于事务操作我们并不陌生，最为熟悉的就是数据库事务操作。当多个线程对数据库中的同一个信息进行修改的时候，为保证数据的原子性、一致性、隔离性、持久性，需要进行本地事务性操作。而在分布式的网络环境下，也会面临多个客户端的数据请求服务。在处理数据变更的时候，需要保证在分布式环境下的数据的正确完整，因此在分布式环境下也引入了分布式事务。</p><h3 id="二阶段提交">二阶段提交</h3><p>二阶段提交（Two-phase Commit）简称 2PC ，它是一种实现分布式事务的算法。二阶段提交算法可以保证分布在不同网络节点上的程序或服务按照事务性的方式进行调用。</p><h4 id="底层实现">底层实现</h4><p>正如算法的名字一样，二阶段提交的底层实现主要分成两个阶段，分别是<strong>询问阶段</strong>和<strong>提交阶段</strong>。具体过程如下图所示：</p><p>整个集群服务器被分成一台协调服务器，集群中的其他服务器是被协调的服务器。在二阶段算法的询问阶段，分布式集群服务在接收到来自客户端的请求的时候，首先会通过协调者服务器，针对本次请求能否正常执行向集群中参与处理的服务器发起询问请求。集群服务器在接收到请求的时候，会在本地机器上执行会话操作，并记录执行的相关日志信息，最后将结果返回给协调服务器。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602194748445.png" alt="image-20240602194748445"></p><p>【简单来说，先搞懂这是分布式事务，本质还是事务，只不过在分布式环境中。就是先问你事务能不能执行，能执行就执行】</p><p>在协调服务器接收到来自集群中其他服务器的反馈信息后，会对信息进行统计。如果集群中的全部机器都能正确执行客户端发送的会话请求，那么协调者服务器就会再次向这些服务器发送提交命令。在集群服务器接收到协调服务器的提交指令后，会根据之前处理该条会话操作的日志记录在本地提交操作，并最终完成数据的修改。</p><p>虽然二阶段提交可以有效地保证客户端会话在分布式集群中的事务性，但是<strong>该算法自身也有很多问题</strong>，主要可以归纳为以下几点：效率问题、单点故障、异常中断。</p><h4 id="性能问题">性能问题</h4><p>首先，我们先来介绍一下性能问题。如我们上面介绍的二阶段算法，在数据提交的过程中，所有参与处理的服务器都处于阻塞状态，如果其他线程想访问临界区的资源，需要等待该条会话请求在本地执行完成后释放临界区资源。因此，采用二阶段提交算法也会降低程序并发执行的效率。</p><h4 id="单点问题">单点问题</h4><p>此外，还会发生单点问题。单点问题也叫作单点服务器故障问题，它指的是当作为分布式集群系统的调度服务器发生故障时，整个集群因为缺少协调者而无法进行二阶段提交算法。单点问题也是二阶段提交最大的缺点，因此使用二阶段提交算法的时候通常都会进行一些改良，以满足对系统稳定性的要求。</p><h4 id="异常中断">异常中断</h4><p>异常中断问题指的是当统计集群中的服务器可以进行事务操作时，协调服务器会向这些处理事务操作的服务器发送 commit 提交请求。如果在这个过程中，其中的一台或几台服务器发生网络故障，无法接收到来自协调服务器的提交请求，导致这些服务器无法完成最终的数据变更，就会造成整个分布式集群出现数据不一致的情况。</p><p>由于以上种种问题，在实际操作中，我更推荐使用另一种分布式事务的算法——三阶段提交算法。</p><h3 id="三阶段提交">三阶段提交</h3><p>三阶段提交（Three-phase commit）简称 3PC ， 其实是在二阶段算法的基础上进行了优化和改进。如下图所示，在整个三阶段提交的过程中，相比二阶段提交，<strong>增加了预提交阶段</strong>。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602194807863.png" alt="image-20240602194807863"></p><p>【简单来说，就是问你事务能不能执行，执行的结果如何，🆗的就提交吧！】</p><h4 id="底层实现-2">底层实现</h4><p><strong>预提交阶段</strong></p><p>为了保证事务性操作的稳定性，同时避免二阶段提交中因为网络原因造成数据不一致等问题，完成提交准备阶段后，集群中的服务器已经为请求操作做好了准备，协调服务器会向参与的服务器发送预提交请求。集群服务器在接收到预提交请求后，在本地执行事务操作，并将执行结果存储到本地事务日志中，并对该条事务日志进行锁定处理。</p><p><strong>提交阶段</strong></p><p>在处理完预提交阶段后，集群服务器会返回执行结果到协调服务器，最终，协调服务器会根据返回的结果来判断是否继续执行操作。如果所有参与者服务器返回的都是可以执行事务操作，协调者服务器就会再次发送提交请求到参与者服务器。参与者服务器在接收到来自协调者服务器的提交请求后，在本地正式提交该条事务操作，并在完成事务操作后关闭该条会话处理线程、释放系统资源。当参与者服务器执行完相关的操作时，会再次向协调服务器发送执行结果信息。</p><p>协调者服务器在接收到返回的状态信息后会进行处理，如果全部参与者服务器都正确执行，并返回 yes 等状态信息，整个事务性会话请求在服务端的操作就结束了。如果在接收到的信息中，有参与者服务器没有正确执行，则协调者服务器会再次向参与者服务器发送 rollback 回滚事务操作请求，整个集群就退回到之前的状态，这样就避免了数据不一致的问题。</p><h3 id="总结">总结</h3><p>本节课我们主要学习了分布式系统下的分布式事务问题。由于分布式系统架构的特点，组成整个系统的网络服务可能分布在不同的网络节点或服务器上，因此在调用这些网络服务的过程中，会面临网络异常中断等不确定的问题，最终导致集群中出现数据不一致的情况。</p><p>为了保证数据的有一致性，我们引入了二阶段提交和三阶段提交算法。这两种算法都会将整个事务处理过程分成<strong>准备、执行、确认</strong>提交这几个阶段。不同的是，二阶段提交会因为网络原因造成数据不一致的问题，而三阶段提交通过增加预加载阶段将执行的事务数据保存到本地，当整个网络中的参与者服务器都能进行事务操作后，协调服务器会发送最终提交请求给参与者服务器，并最终完成事务操作的数据的修改。</p><h2 id="29-ZAB-协议算法：崩溃恢复和消息广播">29 ZAB 协议算法：崩溃恢复和消息广播</h2><p>之前谈到当 Leader 节点发生崩溃的时候，在 ZooKeeper 集群中会重新选举出新的 Leader 节点服务器，以保证 ZooKeeper 集群的可用性。那么从 Leader 节点发生崩溃到重新恢复中间经历了哪些过程，又是采用什么算法恢复集群服务的？</p><h3 id="ZAB-协议算法">ZAB 协议算法</h3><p>ZooKeeper 最核心的作用就是保证分布式系统的数据一致性，而无论是处理来自客户端的会话请求时，还是集群 Leader 节点发生重新选举时，都会产生数据不一致的情况。为了解决这个问题，ZooKeeper 采用了 ZAB 协议算法。</p><p><strong>ZAB 协议算法</strong>（Zookeeper Atomic Broadcast ，Zookeeper 原子广播协议）是 ZooKeeper 专门设计用来解决集群最终一致性问题的算法，它的两个核心功能点是<strong>崩溃恢复</strong>和<strong>原子广播协议</strong>。</p><p>在整个 ZAB 协议的底层实现中，ZooKeeper 集群主要采用<strong>主从模式</strong>的系统架构方式来保证 ZooKeeper 集群系统的一致性。整个实现过程如下图所示，当接收到来自客户端的事务性会话请求后，系统集群采用主服务器来处理该条会话请求，经过主服务器处理的结果会通过网络发送给集群中其他从节点服务器进行数据同步操作。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602195634863.png" alt="image-20240602195634863"></p><p>以 ZooKeeper 集群为例，这个操作过程可以概括为：当 ZooKeeper 集群接收到来自客户端的事务性的会话请求后，集群中的其他 Follow 角色服务器会将该请求转发给 Leader 角色服务器进行处理。当 Leader 节点服务器在处理完该条会话请求后，会将结果通过操作日志的方式同步给集群中的 Follow 角色服务器。然后 Follow 角色服务器根据接收到的操作日志，在本地执行相关的数据处理操作，最终完成整个 ZooKeeper 集群对客户端会话的处理工作。</p><h4 id="崩溃恢复">崩溃恢复</h4><p>【简单来说，就是主节点泵了选一个出来继续当头】</p><p>在介绍完 ZAB 协议在架构层面的实现逻辑后，我们不难看出整个 ZooKeeper 集群处理客户端会话的核心点<strong>在一台 Leader 服务器上</strong>。所有的业务处理和数据同步操作都要靠 Leader 服务器完成。结合我们在“ 28 | 彻底掌握二阶段提交/三阶段提交算法原理” 中学习到的二阶段提交知识，会发现就目前介绍的 ZooKeeper 架构方式而言，<strong>极易产生单点问题</strong>，即当集群中的 Leader 发生故障的时候，整个集群就会因为缺少 Leader 服务器而无法处理来自客户端的事务性的会话请求。因此，为了解决这个问题。在 ZAB 协议中也设置了处理该问题的崩溃恢复机制。</p><p>崩溃恢复机制是保证 ZooKeeper 集群服务高可用的关键。触发 ZooKeeper 集群执行崩溃恢复的事件是集群中的 Leader 节点服务器发生了异常而无法工作，于是 Follow 服务器会通过投票来决定是否选出新的 Leader 节点服务器。</p><p><strong>投票过程如下</strong>：当崩溃恢复机制开始的时候，整个 ZooKeeper 集群的每台 Follow 服务器会发起投票，并同步给集群中的其他 Follow 服务器。在接收到来自集群中的其他 Follow 服务器的投票信息后，集群中的每个 Follow 服务器都会与自身的投票信息进行对比，如果判断新的投票信息更合适，则采用新的投票信息作为自己的投票信息。在集群中的投票信息还没有达到超过半数原则的情况下，再进行新一轮的投票，最终当整个 ZooKeeper 集群中的 Follow 服务器超过半数投出的结果相同的时候，就会产生新的 Leader 服务器。</p><p><strong>举个生活的例子：</strong></p><p>举个例子，假设我们有一个小镇，镇长突然离职了，我们需要选出一个新的镇长来。每个居民（对应于Follow服务器）都可以提名一个候选人，然后将这个提名给其他居民看。每个居民在收到其他居民的提名后，会将自己的提名和新的提名进行比较，如果认为新的提名更合适，那么就会采用新的提名作为自己的提名。</p><p>这个过程就像是一轮轮的投票，每一轮投票结束后，如果还没有超过半数的居民提名同一个人，那么就需要进行新一轮的投票。最终，当超过半数的居民提名同一个人时，这个人就被选为新的镇长。</p><h4 id="选票结构">选票结构</h4><p>介绍完整个选举 Leader 节点的过程后，我们来看一下整个投票阶段中的投票信息具有怎样的结构。以 Fast Leader Election 选举的实现方式来讲，如下图所示，一个选票的整体结果可以分为一下六个部分：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602195729126.png" alt="image-20240602195729126"></p><ul><li><strong>ogicClock</strong>：用来记录服务器的投票轮次。logicClock 会从 1 开始计数，每当该台服务经过一轮投票后，logicClock 的数值就会加 1 。</li><li><strong>state</strong>：用来标记当前服务器的状态。在 ZooKeeper 集群中一台服务器具有 LOOKING、FOLLOWING、LEADERING、OBSERVING 这四种状态。</li><li><strong>self_id</strong>：用来表示当前服务器的 ID 信息，该字段在 ZooKeeper 集群中主要用来作为服务器的身份标识符。</li><li><strong>self_zxid</strong>： 当前服务器上所保存的数据的最大事务 ID ，从 0 开始计数。</li><li><strong>vote_id</strong>：投票要被推举的服务器的唯一 ID 。</li><li><strong>vote_zxid</strong>：被推举的服务器上所保存的数据的最大事务 ID ，从 0 开始计数。</li></ul><p>当 ZooKeeper 集群需要重新选举出新的 Leader 服务器的时候，就会根据上面介绍的投票信息内容进行对比，以找出最适合的服务器。</p><h4 id="选票筛选">选票筛选</h4><p>接下来我们再来看一下，当一台 Follow 服务器接收到网络中的其他 Follow 服务器的投票信息后，是如何进行对比来更新自己的投票信息的。Follow 服务器进行选票对比的过程，如下图所示。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602195829997.png" alt="image-20240602195829997"></p><p>首先，会对比 logicClock 服务器的投票轮次，当 logicClock 相同时，表明两张选票处于相同的投票阶段，并进入下一阶段，否则跳过。接下来再对比 vote_zxid 被选举的服务器 ID 信息，若接收到的外部投票信息中的 vote_zxid 字段较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid ，并广播出去。要是对比的结果相同，则继续对比 vote_myid 被选举服务器上所保存的最大事务 ID ，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 。 经过这些对比和替换后，最终该台 Follow 服务器会产生新的投票信息，并在下一轮的投票中发送到 ZooKeeper 集群中。</p><p><strong>举例说明</strong></p><p>ZooKeeper集群的选举过程可以比作一个民主投票过程。</p><p>假设我们在一个小镇上，需要选出新的镇长。每个居民（对应于ZooKeeper的服务器）都会在一张选票上写下他心目中理想的候选人，并写下他们的理由（这可以看作是服务器的vote_zxid和vote_myid）。</p><p>然后，每个人都会拿着自己的选票和其他人的票进行比较。首先，他们会看选票的轮次（logicClock），如果轮次是一样的，那么就说明这两张票是在同一轮投票中产生的，可以进行下一步比较。如果轮次不同，那么就会跳过这张票。</p><p>接下来，他们会看票上的理由（vote_zxid），如果别人的理由更有说服力（即vote_zxid更大），那么他就会改变自己的心意，将自己的票改为别人的候选人和理由，并将这个改变告诉其他人。如果理由相同，那么他们会继续看候选人（vote_myid），如果别人的候选人更优秀（即vote_myid更大），那么他也会改变自己的票。</p><p>通过这样的比较和替换，每个人都可能产生新的投票信息。然后，在下一轮投票中，他们会将自己的新票发送给其他人。最终，当超过半数的人选出了同一个人，这个人就会被选为新的镇长。</p><p>在ZooKeeper集群中，这个过程确保了即使在Leader服务器崩溃后，整个集群也能通过投票选出新的Leader服务器，保证系统的正常运行。</p><h4 id="消息广播">消息广播</h4><p><strong>在 Leader 节点服务器处理请求后，需要通知集群中的其他角色服务器进行数据同步</strong>。ZooKeeper 集群采用消息广播的方式发送通知。</p><p>ZooKeeper 集群使用原子广播协议进行消息发送，该协议的底层实现过程与我们在“ 28 | 彻底掌握二阶段提交/三阶段提交算法原理” 的二阶段提交过程非常相似，如下图所示。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602200426527.png" alt="image-20240602200426527"></p><p>当要在集群中的其他角色服务器进行数据同步的时候，Leader 服务器将该操作过程封装成一个 Proposal 提交事务，并将其发送给集群中其他需要进行数据同步的服务器。当这些服务器接收到 Leader 服务器的数据同步事务后，会将该条事务能否在本地正常执行的结果反馈给 Leader 服务器，Leader 服务器在接收到其他 Follow 服务器的反馈信息后进行统计，判断是否在集群中执行本次事务操作。</p><p>这里请大家注意 ，与我们“ 28 | 彻底掌握二阶段提交/三阶段提交算法原理” 中提到的二阶段提交过程不同（即需要集群中所有服务器都反馈可以执行事务操作后，主服务器再次发送 commit 提交请求执行数据变更） ，ZAB 协议算法省去了中断的逻辑，当 ZooKeeper 集群中有超过一般的 Follow 服务器能够正常执行事务操作后，整个 ZooKeeper 集群就可以提交 Proposal 事务了。</p><h3 id="总结-2">总结</h3><p>本节课我们主要介绍了 ZooKeeper 中的 ZAB 协议算法。 ZAB 协议算法能够保证 ZooKeeper 集群服务在处理事务性请求后的数据一致性 ，当集群中的 Leader 服务器发生崩溃的时候，ZAB 协议算法可以在 ZooKeeper 集群中重新选举 Leader 并进行数据的同步恢复。其中值得注意的是消息广播的底层实现过程虽然与二阶段提交非常相似，但是与二阶段提交相比，<strong>并没有事务丢弃的过程</strong>。在 ZooKeeper 集群的消息广播中，只要满足整个集群中超过半数的 Follow 服务器可以执行本次事务操作，Leader 就可以向集群中发送提交事务操作，最终完成数据的变更。</p><h2 id="30-ZAB-与-Paxos-算法的联系与区别">30 ZAB 与 Paxos 算法的联系与区别</h2><p>在掌握 ZAB 协议的情况下，我们再进一步学习另一种算法： Paxos 算法。我们会通过研究 Paxos 算法的实现原理，来分析它与 ZAB 协议有什么不同，及它们各自的优缺点。</p><h3 id="Paxos-算法">Paxos 算法</h3><p>在分布式一致性问题的解决方案中，Paxos 算法可以说是<strong>目前最为优秀</strong>的。很多方案，包括我们学习的 ZooKeeper 的 ZAB 协议算法都是在其基础上改进和演变过来的。</p><p>Paxos 算法是基于消息传递的分布式一致性算法，很多大型的网络技术公司和开源框架都采用 Paxos 算法作为其各自的底层解决方案，比如 Chubby 、 Megastore 以及 MySQL Group Replication 。 Paxos 算法运行在服务器发生宕机故障的时候，能够保证数据的完整性，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复，保证服务的高可用性。</p><h3 id="底层实现-3">底层实现</h3><p>介绍完 Paxos 算法能够解决哪些问题后，接下来我们继续学习 Paxos 算法的底层实现过程。保证分布式系统下数据的一致性操作，本质是协调运行在不同的网络服务器上的线程服务，使这些服务就某一个特定的数据执行一致性的变更操作。在整个 Paxos 算法的实现过程中，将参与算法的集群中的全部服务器，分成三种角色：提议者（Proposer）、决策者（Acceptor）、决策学习者（Learner）。</p><h4 id="三种角色">三种角色</h4><p>先来看看三种角色的具体分工。</p><ul><li><strong>提议者（Proposer）</strong>：提出提案（Proposal）。Proposal 信息包括提案编号（Proposal ID）和提议的值（Value）。</li><li><strong>决策者（Acceptor）</strong>：参与决策，回应 Proposers 的提案。收到 Proposal 后可以接受提案，若 Proposal 获得超过半数 Acceptors 的许可，则称该 Proposal 被批准。</li><li><strong>决策学习者</strong>：不参与决策，从 Proposers/Acceptors 学习最新达成一致的提案（Value）。</li></ul><p>经过我们之前对 ZooKeeper 的学习，相信对 Paxos 算法的集群角色划分并不陌生。而与 ZAB 协议算法<strong>不同的是</strong>，<strong>在 Paxos 算法中，当处理来自客户端的事务性会话请求的过程时，首先会触发一个或多个服务器进程，就本次会话的处理发起提案。当该提案通过网络发送到集群中的其他角色服务器后，这些服务器会就该会话在本地的执行情况反馈给发起提案的服务器。发起提案的服务器会在接收到这些反馈信息后进行统计，当集群中超过半数的服务器认可该条事务性的客户端会话操作后，认为该客户端会话可以在本地执行操作</strong>。</p><p>上面介绍的 Paxos 算法针对事务性会话的处理投票过程与 ZAB 协议十分相似，但不同的是，对于采用 ZAB 协议的 ZooKeeper 集群中发起投票的机器，所采用的是在集群中运行的一台 Leader 角色服务器。而 Paxos 算法则采用多副本的处理方式，即存在多个副本，每个副本分别包含提案者、决策者以及学习者。下图演示了三种角色的服务器之间的关系。</p><p><strong>举例说明</strong></p><p>将Paxos算法中的参与者比作一个议会的三个角色可能会更好理解：</p><ol><li><strong>提议者（Proposer）</strong>：就像是议会的议员，他们有权提出新的法案（Proposal）。每个法案都有一个唯一的编号（Proposal ID）和一个具体的内容（Value）。</li><li><strong>决策者（Acceptor）</strong>：就像是参议院的成员，他们的职责是对提出的法案进行投票。他们可以选择赞成或反对法案，如果一个法案得到了超过半数的赞成票，那么这个法案就被认为是通过了。</li><li><strong>决策学习者（Learner）</strong>：就像是公众，他们不参与决策，但是可以从议员和参议员那里了解最新通过的法案（Value）。</li></ol><p>当处理来自客户端的请求时，Paxos算法会触发一个或多个服务器进程，这些服务器就像是提出新法案的议员。他们会将法案发送给其他的服务器，其他的服务器就像是参议院的成员，他们会根据自己的情况对法案进行投票，并将投票结果反馈给发起法案的服务器。发起法案的服务器收到反馈后，会进行统计，如果超过半数的服务器赞成这个法案，那么就认为这个请求可以在本地执行。</p><h4 id="事务处理过程">事务处理过程</h4><p>介绍完 Paxos 算法中的服务器角色和投票的处理过程后，接下来我们再来看一下 Paxos 针对一次提案是如何处理的。如下图所示，整个提案的处理过程可以分为三个阶段，分别是提案准备阶段、事务处理阶段、数据同步阶段。我们分别介绍一下这三个阶段的底层处理逻辑。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602201705558.png" alt="image-20240602201705558"></p><ul><li><strong>提案准备阶段</strong>：该阶段是整个 Paxos 算法的最初阶段，所有接收到的来自客户端的事务性会话在执行之前，整个集群中的 Proposer 角色服务器或者节点，需要将会话发送给 Acceptor 决策者服务器。在 Acceptor 服务器接收到该条询问信息后，需要返回 Promise ，承诺可以执行操作信息给 Proposer 角色服务器。</li><li><strong>事务处理阶段</strong>：在经过提案准备阶段，确认该条事务性的会话操作可以在集群中正常执行后，Proposer 提案服务器会再次向 Acceptor 决策者服务器发送 propose 提交请求。Acceptor 决策者服务器在接收到该 propose 请求后，在本地执行该条事务性的会话操作。</li><li><strong>数据同步阶段</strong>：在完成了事务处理阶段的操作后，整个集群中对该条事务性会话的数据变更已经在 Acceptor 决策者服务器上执行完成，当整个集群中有超过半数的 Acceptor 决策者服务器都成功执行后，Paxos 算法将针对本次执行结果形成一个决议，并发送给 Learner 服务器。当 Learner 服务器接收到该条决议信息后，会同步 Acceptor 决策者服务器上的数据信息，最终完成该条事务性会话在整个集群中的处理。</li></ul><p><strong>举例说明</strong></p><p>Paxos算法的处理流程就像一个公司的决策过程。</p><p>首先是<strong>提案准备阶段</strong>，这就像是公司的某个部门（Proposer角色服务器）有一个新的项目想法，他们会将这个想法提交给公司的领导团队（Acceptor决策者服务器）。领导团队在接收到这个想法后，会评估这个项目是否值得进行，并给出他们的承诺（Promise），也就是是否同意进行这个项目。</p><p>接下来是<strong>事务处理阶段</strong>，这个阶段就像是公司开始执行这个项目。部门会再次向领导团队发送项目的详细计划（propose提交请求），领导团队在接收到这个计划后，会开始在本地执行这个项目，也就是开始分配资源，调配人员等。</p><p>最后是<strong>数据同步阶段</strong>，这就像是项目执行完成后，公司开始进行项目的总结和反馈。当超过半数的领导团队成员都同意这个项目的执行结果后，公司会形成一个最终的决议，并将这个决议发送给其他的部门（Learner服务器）。其他的部门在接收到这个决议后，会同步领导团队的决策，也就是根据这个项目的结果进行相应的调整和改进。</p><p>这就是Paxos算法的整个处理流程。通过这个流程，Paxos算法能够在分布式环境中实现数据的一致性，保证系统的正常运行。</p><h3 id="Paxos-PK-ZAB">Paxos PK ZAB</h3><p>经过上面的介绍我们对 Paxos 算法所能解决的问题，以及底层的实现原理都有了一个详细的了解。现在结合我们之前学习的 ZooKeeper 相关知识，来看看 Paxos 算法与 ZAB 算法的相同及不同之处。</p><p><strong>相同之处是</strong>，在执行事务行会话的处理中，两种算法最开始都需要一台服务器或者线程针对该会话，在集群中发起提案或是投票。只有当集群中的过半数服务器对该提案投票通过后，才能执行接下来的处理。</p><p>而 Paxos 算法与 ZAB 协议<strong>不同的是</strong>，Paxos 算法的发起者可以是一个或多个。当集群中的 Acceptor 服务器中的大多数可以执行会话请求后，提议者服务器只负责发送提交指令，事务的执行实际发生在 Acceptor 服务器。这与 ZooKeeper 服务器上事务的执行发生在 Leader 服务器上不同。Paxos 算法在数据同步阶段，是多台 Acceptor 服务器作为数据源同步给集群中的多台 Learner 服务器，而 ZooKeeper 则是单台 Leader 服务器作为数据源同步给集群中的其他角色服务器。</p><p><strong>举例说明</strong></p><p>Paxos算法和ZAB协议都是用于处理分布式系统中数据一致性问题的算法，它们有一些相同之处，也有一些不同之处。</p><p>相同之处在于，两种算法在处理事务性会话时，都需要有一个服务器或线程在集群中发起提案或投票，只有当集群中的过半数服务器对这个提案投票通过，才能执行接下来的操作。这就像是一个公司在做重大决策时，需要有一个部门提出建议，然后全公司进行投票，<strong>只有当半数以上的员工同意这个建议时，才会执行这个决策。</strong></p><p>不同之处在于，Paxos算法的发起者可以是一个或者多个，这就像是公司中的多个部门都可以提出建议。而在ZAB协议中，只有一个Leader服务器可以发起提案，这就像是公司中只有CEO可以提出建议。另外，Paxos算法中，事务的执行实际发生在Acceptor（决策者）服务器，这就像是公司的各个部门根据CEO的决策进行执行。而在ZooKeeper中，事务的执行实际上发生在Leader服务器，这就像是CEO直接负责执行决策。</p><p>此外，在数据同步阶段，Paxos算法是由多台Acceptor服务器同步数据给集群中的Learner服务器，就像是公司的各个部门都会将执行结果报告给所有员工。而在ZooKeeper中，只有Leader服务器会同步数据给其他服务器，这就像是只有CEO会将执行结果公布给全公司。</p><p>通过这些例子，我们可以更好地理解Paxos算法和ZAB协议的相同之处和不同之处。</p><h3 id="总结-3">总结</h3><p>本节课我们主要介绍了 Paxos 算法，该算法在解决分布式一致性问题上被广泛采用。Paxos 算法将集群中的服务器或网络节点分为提议者（Proposer）、决策者（Acceptor）、决策学习者（Learner），在处理事务性会话请求的时候，会针对该会话操作在集群中通过提议者（Proposer）服务器发起询问操作，之后由决策者（Acceptor）服务器决定是否执行。在集群中多数服务器都正确执行会话操作后，决策学习者（Learner）会同步（Acceptor）服务器上的数据，并完成最终的操作。</p><h2 id="31-ZooKeeper-中二阶段提交算法的实现分析">31 ZooKeeper 中二阶段提交算法的实现分析</h2><p>我们一直围绕在分布式系统环境下，如何解决一致性问题来进行讨论，并分别介绍了在分布式环境中比较常见的二阶段提交、三阶段提交算法，之后又对比介绍了 ZooKeeper 所采用的 ZAB 协议算法和 Paxos 算法的优缺点。</p><p>在学习 ZAB 协议和 Paxos 算法的过程中，我们曾提到在处理来自客户端的事务性请求时，为了保证整个集群的数据一致性，其各自的底层实现与二阶段算法都有相似之处。但我们知道，二阶段提交算法自身有一些缺点，比如容易发生单点故障，比如在并发性能上有一些瓶颈，那么今天就深入 ZooKeeper 的底层，来看一下 ZooKeeper 是如何克服这些问题，并实现自己特有的二阶段提交算法的。希望通过本节课的学习，帮助你进一步提高解决分布式一致性问题的能力。</p><h3 id="提交请求">提交请求</h3><p>前面我们学到，二阶段提交的本质是协调和处理 ZooKeeper 集群中的服务器，使它们在处理事务性会话请求的过程中能保证数据一致性。如果把执行在 ZooKeeper 集群中各个服务器上的事务会话处理操作分别看作不同的函数，那么整个一致性的处理逻辑就相当于包裹这些函数的事务。而在单机环境中处理事务的逻辑是，包含在事务中的所有函数要么全部成功执行，要么全部都不执行。</p><p>其中，事务性会话，简单来说，就是一系列的操作，这些操作被视为一个整体，要么全部成功，要么全部失败。这就像是一个链条，只有当所有的环节都成功，链条才能完整，只要有一个环节失败，整个链条就会断开。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602203300990.png" alt="image-20240602203300990"></p><p>不同的是，在分布式环境中，处理事务请求的各个函数是分布在不同的网络服务器上的线程，无法像在单机环境下一样，做到当事务中的某一个环节发生异常的时候，回滚包裹在整个事务中的操作。因此，分布式环境中处理事务操作的时候，一般的算法不会要求全部集群中的机器都成功执行操作，如果有其中一个函数执行异常，那么整个事务就会把所有函数的执行结果回滚到执行前的状态，也就是无论是正确执行的函数，还是执行异常的函数，各自所做的对数据和程序状态的变更都将被删除。</p><h3 id="执行请求">执行请求</h3><p>看完提交请求的处理过程后，我们再来看一下在执行请求时 ZooKeeper 的底层实现过程。</p><p>ZooKeeper 集群中的 Leader 服务器对该条事务性会话操作是否能够在 Follow 服务器上执行，向集群中的 Follow 服务器发起 Proposal 请求。</p><p>这里请你注意，与我们之前介绍的二阶段提交不同的是，在 ZooKeeper 的实现中并没有中断提交的逻辑。集群中的 Follow 服务器在接收到上述 Proposal 请求后，只有两种处理情况：</p><p>第一种情况：ZooKeeper 集群中的 Follow 服务器能够正确执行操作，并向 ZooKeeper 集群中的 Leader 反馈执行结果。</p><p>第二种情况：无法正确执行该条 Proposal 操作，直接抛弃该条请求。</p><p>ZooKeeper 集群的这种执行逻辑，最终导致无须等 待所有服务器都执行完成并反馈，集群中的 Leader 服务器只需要接收到集群中过半数的 Follow 服务器成功执行的反馈信息， ZooKeeper 集群中的 Leader 服务器最终会统计 Follow 服务器反馈的信息，当超过半数以上服务器可以正确执行操作后，整个 ZooKeeper 集群就可以进入执行事务提交操作。</p><h3 id="底层实现-4">底层实现</h3><p>介绍完 ZooKeeper 实现二阶段提交算法的原理后，接下来我们深入代码层面看看 ZooKeeper 是如何设计架构的。</p><p>从源码层面来讲，ZooKeeper 在实现整个二阶段提交算法的过程中，可以分为 Leader 服务器端的发起 Proposal 操作和 Follow 服务器端的执行反馈操作。</p><p>我们先来看看，在 ZooKeeper 集群中的 Leader 是如何向其他 Follow 服务器发送 Proposal 请求的呢？</p><p>如下面的代码所示， ZooKeeper 通过 SendAckRequestProcessor 类发送 Proposal 来提交请求。这个类首先继承了 RequestProcessor 类，但是它不是处理来自客户端的请求信息，而是用来处理向 Follow 服务器发送的 Proposal 请求信息。它在内部通过 processRequest 函数来判断，责任链中传递请求操作是否是数据同步操作：如果判断是 OpCode.sync 操作（也就是数据同步操作），就通过 learner.writePacket 方法把 Proposal 请求向集群中的所有 Follow 服务器进行发送。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SendAckRequestProcessor</span> <span class="keyword">implements</span> <span class="title class_">RequestProcessor</span>, Flushable &#123; </span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processRequest</span><span class="params">(Request si)</span> &#123; </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(si.type != OpCode.sync)&#123; </span><br><span class="line"></span><br><span class="line">        <span class="type">QuorumPacket</span> <span class="variable">qp</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">QuorumPacket</span>(Leader.ACK, si.getHdr().getZxid(), <span class="literal">null</span>, </span><br><span class="line"></span><br><span class="line">            <span class="literal">null</span>); </span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123; </span><br><span class="line"></span><br><span class="line">            learner.writePacket(qp, <span class="literal">false</span>); </span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123; </span><br><span class="line"></span><br><span class="line">            LOG.warn(<span class="string">&quot;Closing connection to leader, exception during packet send&quot;</span>, e); </span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123; </span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (!learner.sock.isClosed()) &#123; </span><br><span class="line"></span><br><span class="line">                    learner.sock.close(); </span><br><span class="line"></span><br><span class="line">                &#125; </span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123; </span><br><span class="line"></span><br><span class="line">                <span class="comment">// Nothing to do, we are shutting things down, so an exception here is irrelevant </span></span><br><span class="line"></span><br><span class="line">                LOG.debug(<span class="string">&quot;Ignoring error closing the connection&quot;</span>, e1); </span><br><span class="line"></span><br><span class="line">            &#125; </span><br><span class="line"></span><br><span class="line">        &#125; </span><br><span class="line"></span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">&#125; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>在介绍完 ZooKeeper 集群中的 Leader 服务器发送 Proposal 的底层实现过程后，接下来我们再来学习一下 Follow 服务端在接收到 Leader 服务器发送的 Proposal 后的整个处理逻辑。</p><p>如下面的代码所示，这在 Follow 服务器端是通过 ProposalRequestProcessor 来完成处理的。ProposalRequestProcessor 构造函数中首先初始化了 Leader 服务器、下一个请求处理器，以及负责反馈执行结果给 Leader 服务器的 AckRequestProcessor 处理器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">ProposalRequestProcessor</span><span class="params">(LeaderZooKeeperServer zks, </span></span><br><span class="line"><span class="params"></span></span><br><span class="line"><span class="params">        RequestProcessor nextProcessor)</span> &#123; </span><br><span class="line"></span><br><span class="line">    <span class="built_in">this</span>.zks = zks; </span><br><span class="line"></span><br><span class="line">    <span class="built_in">this</span>.nextProcessor = nextProcessor; </span><br><span class="line"></span><br><span class="line">    <span class="type">AckRequestProcessor</span> <span class="variable">ackProcessor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AckRequestProcessor</span>(zks.getLeader()); </span><br><span class="line"></span><br><span class="line">    syncProcessor = <span class="keyword">new</span> <span class="title class_">SyncRequestProcessor</span>(zks, ackProcessor); </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>接下来，我们进入到 AckRequestProcessor 函数的内部，来看一下 Follow 服务器是如何反馈处理结果给 Leader 服务器的。</p><p>如下面的代码所示， AckRequestProcessor 类同样也继承了 RequestProcessor，从中可以看出在 ZooKeeper 中处理 Leader 服务器的 Proposal 时，是将该 Proposal 请求当作网络中的一条会话请求来处理的。整个处理的逻辑实现也是按照处理链模式设计实现的，在 AckRequestProcessor 类的内部通过 processRequest 函数，来向集群中的 Leader 服务器发送 ack 反馈信息。</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AckRequestProcessor</span> <span class="keyword">implements</span> <span class="title">RequestProcessor</span> </span>&#123; </span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_ invoke__">processRequest</span>(Request request) &#123; </span><br><span class="line"></span><br><span class="line">    QuorumPeer <span class="built_in">self</span> = leader.<span class="built_in">self</span>; </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">self</span> != <span class="literal">null</span>) </span><br><span class="line">        leader.<span class="title function_ invoke__">processAck</span>(<span class="built_in">self</span>.<span class="title function_ invoke__">getId</span>(), request.zxid, <span class="literal">null</span>); </span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        LOG.<span class="title function_ invoke__">error</span>(<span class="string">&quot;Null QuorumPeer&quot;</span>); </span><br><span class="line"></span><br><span class="line">&#125;&#125; </span><br></pre></td></tr></table></figure><h3 id="总结-4">总结</h3><p>本节课我们主要介绍了，二阶段提交算法在 ZooKeeper 中的应用，并深入底层分析了 ZooKeeper 实现二阶段提交的具体过程。虽然二阶段提交自身有一些问题，不过还是一个比较好的解决分布式环境下一致性问题的算法，因此 ZooKeeper 在实现的过程中也借鉴了它，并通过自身的崩溃恢复机制来解决二阶段提交算法中的单点故障等问题。</p><h2 id="32-ZooKeeper-数据存储底层实现解析">32 ZooKeeper 数据存储底层实现解析</h2><h3 id="文件系统布局">文件系统布局</h3><p>无论是 ZooKeeper 服务在运行时候产生的数据日志，还是在集群中进行数据同步的时候所用到的数据快照，都可以被看作一种文件系统。而文件系统的两个功能就是对文件的存储和对不同文件格式的解析。ZooKeeper 中的数据存储，可以分为两种类型：数据日志文件和快照文件，接下来我们就分别介绍这两种文件的结构信息和底层实现。</p><h3 id="数据日志">数据日志</h3><p>在 ZooKeeper 服务运行的过程中，数据日志是用来记录 ZooKeeper 服务运行状态的数据文件。通过这个文件我们不但能统计 ZooKeeper 服务的运行情况，更可以在 ZooKeeper 服务发生异常的情况下，根据日志文件记录的内容来进行分析，定位问题产生的原因并找到解决异常错误的方法。</p><p>如何找到日志文件呢？在 ZooKeeper 的 zoo.cfg 配置文件中的 dataLogDir 属性字段，所指定的文件地址就是当前 ZooKeeper 服务的日志文件的存储地址。</p><p>在了解了 ZooKeeper 服务在运行的过程中所产生的日志文件的存放位置，以及日志文件的格式结构后，接下来我们就深入到 ZooKeeper 服务的底层，来看一下它是如何实现日志的搜集以及存储的。</p><h4 id="搜集日志">搜集日志</h4><p>我们先来看一下 ，ZooKeeper 是如何搜集程序的运行信息的。在统计操作情况的日志信息中，ZooKeeper 通过第三方开源日志服务框架 SLF4J 来实现的。</p><p>SLF4J 是一个<strong>采用门面设计模式（Facade）</strong> 的日志框架。如下图所示，门面模式也叫作外观模式，采用这种设计模式的主要作用是，对外隐藏系统内部的复杂性，并向外部调用的客户端或程序提供统一的接口。门面模式通常以接口的方式实现，可以被程序中的方法引用。</p><p>在下图中，我们用门面模式创建了一个绘制几何图形的小功能。首先，定义了一个 Shape 接口类，并分别创建了三个类 Circle、Square、Rectangle ，以继承 Shape 接口。其次，我们再来创建一个画笔类 ShapeMaker ，在该类中我定义了 shape 形状字段以及绘画函数 drawCircle等。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602203726254.png" alt="image-20240602203726254"></p><p>之后，当我们在本地项目中需要调用实现的会话功能时，直接调用 ShapeMaker 类，并传入我们要绘制的图形信息，就可以实现图形的绘制功能了。它使用起来非常简单，不必关心其底层是如何实现绘制操作的，只要将我们需要绘制的图形信息传入到接口函数中即可。</p><p>而在 ZooKeeper 中使用 SLF4J 日志框架也同样简单，如下面的代码所示，首先在类中通过工厂函数创建日志工具类 LOG，然后在需要搜集的操作流程处引入日志搜集函数 <a href="http://LOG.info">LOG.info</a> 即可。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="type">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.<span class="built_in">getLogger</span>(Learner.<span class="keyword">class</span>);</span><br><span class="line"></span><br><span class="line">LOG.<span class="built_in">info</span>(<span class="string">&quot;Revalidating client: 0x&quot;</span> + Long.<span class="built_in">toHexString</span>(clientId));</span><br><span class="line"></span><br><span class="line">LOG.<span class="built_in">warn</span>(<span class="string">&quot;Couldn&#x27;t find the leader with id = &quot;</span></span><br><span class="line"></span><br><span class="line">        + current.<span class="built_in">getId</span>());</span><br></pre></td></tr></table></figure><h4 id="存储日志">存储日志</h4><p>接下来我们看一下搜集完的日志是什么样子的。在开头我们已经说过，系统日志的存放位置，在 zoo.cfg 文件中。假设我们的日志路径为dataDir=/var/lib/zookeeper，打开系统命令行，进入到该文件夹，就会看到如下图所示的样子，所有系统日志文件都放在了该文件夹下。</p><h3 id="快照文件">快照文件</h3><p>除了上面介绍的记录系统操作日志的文件外，ZooKeeper 中另一种十分重要的文件数据是快照日志文件。快照日志文件主要用来存储 ZooKeeper 服务中的事务性操作日志，并通过数据快照文件实现集群之间服务器的数据同步功能。</p><h4 id="快照创建">快照创建</h4><p>接下来我们来介绍，在 ZooKeeper 的底层实现中，一个快照文件是如何创建的。</p><p>如下面的代码所示，在 ZooKeeper 的源码中定义了一个 SnapShot 接口类，在该接口中描述了 ZooKeeper 服务的相关属性和方法。其中 serialize 函数是用来将内存中的快照文件转存到本地磁盘中时的序列化操作。而 deserialize 的作用正好与其相反，是把快照文件从本地磁盘中加载到内存中时的反序列化操作。无论是序列化还是反序列化，整个快照所操作的数据对象是 ZooKeeper 数据模型，也就是由 Znode 组成的结构树。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">SnapShot</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">long</span> <span class="title function_">deserialize</span><span class="params">(DataTree dt, Map&lt;Long, Integer&gt; sessions)</span> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">serialize</span><span class="params">(DataTree dt, Map&lt;Long, Integer&gt; sessions,</span></span><br><span class="line"><span class="params"></span></span><br><span class="line"><span class="params">               File name, <span class="type">boolean</span> fsync)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line">    File <span class="title function_">findMostRecentSnapshot</span><span class="params">()</span> <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="快照存储">快照存储</h4><p>创建完 ZooKeeper 服务的数据快照文件后，接下来就要对数据文件进行持久化的存储操作了。其实在整个 ZooKeeper 中，随着服务的不同阶段变化，数据快照存放文件的位置也随之变化。存储位置的变化，主要是内存和本地磁盘之间的转变。当 ZooKeeper 集群处理来自客户端的事务性的会话请求的时候，会首先在服务器内存中针对本次会话生成数据快照。当整个集群可以执行该条事务会话请求后，提交该请求操作，就会将数据快照持久化到本地磁盘中，如下图所示。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602203745904.png" alt="image-20240602203745904"></p><p>存储到本地磁盘中的数据快照文件，是经过 ZooKeeper 序列化后的二进制格式文件，通常我们无法直接查看，但如果想要查看，也可以通过 ZooKeeper 自带的 SnapshotFormatter 类来实现。如下图所示，在 SnapshotFormatter 类的内部用来查看快照文件的几种函数分别是： printDetails 函数，用来打印日志中的数据节点和 Session 会话信息；printZnodeDetails 函数，用来查看日志文件中节点的详细信息，包括节点 id 编码、state 状态信息、version 节点版本信息等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SnapshotFormatter</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printDetails</span><span class="params">(DataTree dataTree, Map&lt;Long, Integer&gt; sessions)</span> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printZnodeDetails</span><span class="params">(DataTree dataTree)</span> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printZnode</span><span class="params">(DataTree dataTree, String name)</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printSessionDetails</span><span class="params">(DataTree dataTree, Map&lt;Long, Integer&gt; sessions)</span> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printStat</span><span class="params">(StatPersisted stat)</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printHex</span><span class="params">(String prefix, <span class="type">long</span> value)</span> </span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然 ZooKeeper 提供了 SnapshotFormatter 类，但其实现的查询功能比较单一，我们可以通过本节课的学习，按照自己的业务需求，编写自己的快照文件查看器。</p><p>到目前位置，我们对 ZooKeeper 服务相关的数据文件都做了讲解。无论是数据日志文件，还是数据快照文件，最终都会存储在本地磁盘中。而从文件的生成方式来看，两种日志文件的不同是：数据日志文件实施性更高，相对的产生的日志文件也不断变化，只要 ZooKeeper 服务一直运行，就会产生新的操作日志数据；而数据快照并非实时产生，它是当集群中数据发生变化后，先在内存中生成数据快照文件，经过序列化后再存储到本地磁盘中。</p><h3 id="总结-5">总结</h3><p>本节课我们讲解了在 ZooKeeper 服务运行过程中所产生的两种主要数据文件：数据日志文件和数据快照文件的结构信息和底层实现，以便加强你对它们的理解。</p>]]></content>
    
    
    <summary type="html">Zookeeper原理篇</summary>
    
    
    
    <category term="分布式" scheme="https://penge666.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://penge666.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>MongoDB基础笔记</title>
    <link href="https://penge666.github.io/posts/b79fdeab.html"/>
    <id>https://penge666.github.io/posts/b79fdeab.html</id>
    <published>2024-06-02T08:07:40.000Z</published>
    <updated>2024-06-02T09:44:59.002Z</updated>
    
    <content type="html"><![CDATA[<h2 id="MongoDB-基础">MongoDB 基础</h2><h3 id="MongoDB-是什么？">MongoDB 是什么？</h3><p>MongoDB 是一个基于 <strong>分布式文件存储</strong> 的开源 NoSQL 数据库系统，由 <strong>C++</strong> 编写的。MongoDB 提供了 面向文档 的存储方式，操作起来比较简单和容易，支持“无模式”的数据建模，可以存储比较复杂的数据类型，是一款非常流行的 <strong>文档类型数据库</strong> 。</p><p>在高负载的情况下，MongoDB 天然支持水平扩展和高可用，可以很方便地添加更多的节点/实例，以保证服务性能和可用性。在许多场景下，MongoDB 可以用于代替传统的关系型数据库或键/值存储方式，皆在为 Web 应用提供可扩展的高可用高性能数据存储解决方案。</p><p>适用于<strong>OLTP</strong>。</p><h3 id="MongoDB-的存储结构是什么？">MongoDB 的存储结构是什么？</h3><p>MongoDB 的存储结构区别于传统的关系型数据库，主要由如下三个单元组成：</p><ul><li>文档（Document） ：MongoDB 中最基本的单元，由 BSON 键值对（key-value）组成，类似于关系型数据库中的行（Row）。</li><li>集合（Collection） ：一个集合可以包含多个文档，类似于关系型数据库中的表（Table）。</li><li>数据库（Database） ：一个数据库中可以包含多个集合，可以在 MongoDB 中创建多个数据库，类似于关系型数据库中的数据库（Database）。</li></ul><p>也就是说，MongoDB 将数据记录存储为文档 （更具体来说是BSON 文档），这些文档在集合中聚集在一起，数据库中存储一个或多个文档集合。</p><p>SQL 与 MongoDB 常见术语对比 ：</p><table><thead><tr><th>SQL</th><th>MongoDB</th></tr></thead><tbody><tr><td>表（Table）</td><td>集合（Collection）</td></tr><tr><td>行（Row）</td><td>文档（Document）</td></tr><tr><td>列（Col）</td><td>字段（Field）</td></tr><tr><td>主键（Primary Key）</td><td>对象 ID（Objectid）</td></tr><tr><td>索引（Index）</td><td>索引（Index）</td></tr><tr><td>嵌套表（Embeded Table）</td><td>嵌入式文档（Embeded Document）</td></tr><tr><td>数组（Array）</td><td>数组（Array）</td></tr></tbody></table><h3 id="文档">文档</h3><p>MongoDB 中的记录就是一个 BSON 文档，它是由键值对组成的数据结构，类似于 JSON 对象，是 MongoDB 中的基本数据单元。字段的值可能包括其他文档、数组和文档数组。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602163330369.png" alt="image-20240602163330369"></p><p>文档的键是字符串。除了少数例外情况，键可以使用任意 UTF-8 字符。</p><ul><li>键不能含有 <code>\0</code>(空字符）。这个字符用来表示键的结尾。</li><li><code>.</code> 和 <code>$</code> 有特别的意义，只有在特定环境下才能使用。</li><li>以下划线<code>_</code>开头的键是保留的(不是严格要求的)。</li></ul><p>BSON [bee·sahn] 是 Binary JSON的简称，是 JSON 文档的二进制表示，支持将文档和数组嵌入到其他文档和数组中，还包含允许表示不属于 JSON 规范的数据类型的扩展。有关 BSON 规范的内容，可以参考 <a href="http://bsonspec.org">bsonspec.org</a>，另见BSON 类型。</p><p>根据维基百科对 BJSON 的介绍，BJSON 的遍历速度优于 JSON，这也是 MongoDB 选择 BSON 的主要原因，但 BJSON 需要更多的存储空间。</p><blockquote><p>与 JSON 相比，BSON 着眼于提高存储和扫描效率。BSON 文档中的大型元素以长度字段为前缀以便于扫描。在某些情况下，由于长度前缀和显式数组索引的存在，BSON 使用的空间会多于 JSON。</p></blockquote><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602163349917.png" alt="image-20240602163349917"></p><h3 id="集合">集合</h3><p>MongoDB 集合存在于数据库中，没有固定的结构，也就是 无模式 的，这意味着可以往集合插入不同格式和类型的数据。不过，通常情况相爱插入集合中的数据都会有一定的关联性。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602163406051.png" alt="image-20240602163406051"></p><p>集合不需要事先创建，当第一个文档插入或者第一个索引创建时，如果该集合不存在，则会创建一个新的集合。</p><p>集合名可以是满足下列条件的任意 UTF-8 字符串：</p><ul><li>集合名不能是空字符串<code>&quot;&quot;</code>。</li><li>集合名不能含有 <code>\0</code> （空字符)，这个字符表示集合名的结尾。</li><li>集合名不能以&quot;system.&quot;开头，这是为系统集合保留的前缀。例如 <code>system.users</code> 这个集合保存着数据库的用户信息，<code>system.namespaces</code> 集合保存着所有数据库集合的信息。</li><li>集合名必须以下划线或者字母符号开始，并且不能包含 <code>$</code>。</li></ul><h3 id="数据库">数据库</h3><p>数据库用于存储所有集合，而集合又用于存储所有文档。一个 MongoDB 中可以创建多个数据库，每一个数据库都有自己的集合和权限。</p><p>MongoDB 预留了几个特殊的数据库。</p><ul><li>admin : admin 数据库主要是保存 root 用户和角色。例如，system.users 表存储用户，system.roles 表存储角色。一般不建议用户直接操作这个数据库。将一个用户添加到这个数据库，且使它拥有 admin 库上的名为 dbAdminAnyDatabase 的角色权限，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如关闭服务器。</li><li>local : local 数据库是不会被复制到其他分片的，因此可以用来存储本地单台服务器的任意 collection。一般不建议用户直接使用 local 库存储任何数据，也不建议进行 CRUD 操作，因为数据无法被正常备份与恢复。</li><li>config : 当 MongoDB 使用分片设置时，config 数据库可用来保存分片的相关信息。</li><li>test : 默认创建的测试库，连接 mongod 服务时，如果不指定连接的具体数据库，默认就会连接到 test 数据库。</li></ul><p>数据库名可以是满足以下条件的任意 UTF-8 字符串：</p><ul><li>不能是空字符串<code>&quot;&quot;</code>。</li><li>不得含有<code>' '</code>（空格)、<code>.</code>、<code>$</code>、<code>/</code>、<code>\</code>和 <code>\0</code> (空字符)。</li><li>应全部小写。</li><li>最多 64 字节。</li></ul><p>数据库名最终会变成文件系统里的文件，这也就是有如此多限制的原因。</p><h3 id="MongoDB-有什么特点？">MongoDB 有什么特点？</h3><ul><li><strong>数据记录被存储为文档</strong> ：MongoDB 中的记录就是一个 BSON 文档，它是由键值对组成的数据结构，类似于 JSON 对象，是 MongoDB 中的基本数据单元。</li><li><strong>模式自由</strong> ：集合的概念类似 MySQL 里的表，但它不需要定义任何模式，能够用更少的数据对象表现复杂的领域模型对象。</li><li><strong>支持多种查询方式</strong> ：MongoDB 查询 API 支持读写操作 (CRUD)以及数据聚合、文本搜索和地理空间查询。</li><li><strong>支持 ACID 事务</strong> ：NoSQL 数据库通常不支持事务，为了可扩展和高性能进行了权衡。不过，也有例外，MongoDB 就支持事务。与关系型数据库一样，MongoDB 事务同样具有 ACID 特性。MongoDB 单文档原生支持原子性，也具备事务的特性。MongoDB 4.0 加入了对多文档事务的支持，但只支持复制集部署模式下的事务，也就是说事务的作用域限制为一个副本集内。MongoDB 4.2 引入了分布式事务，增加了对分片集群上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。</li><li><strong>高效的二进制存储</strong> ：存储在集合中的文档，是以键值对的形式存在的。键用于唯一标识一个文档，一般是 ObjectId 类型，值是以 BSON 形式存在的。BSON = Binary JSON， 是在 JSON 基础上加了一些类型及元数据描述的格式。</li><li><strong>自带数据压缩功能</strong> ：存储同样的数据所需的资源更少。</li><li><strong>支持 mapreduce</strong> ：通过分治的方式完成复杂的聚合任务。不过，从 MongoDB 5.0 开始，map-reduce 已经不被官方推荐使用了，替代方案是 聚合管道。聚合管道提供比 map-reduce 更好的性能和可用性。</li><li><strong>支持多种类型的索引</strong> ：MongoDB 支持多种类型的索引，包括单字段索引、复合索引、多键索引、哈希索引、文本索引、 地理位置索引等，每种类型的索引有不同的使用场合。</li><li><strong>支持 failover</strong> ：提供自动故障恢复的功能，主节点发生故障时，自动从从节点中选举出一个新的主节点，确保集群的正常使用，这对于客户端来说是无感知的。</li><li><strong>支持分片集群</strong> ：MongoDB 支持集群自动切分数据，让集群存储更多的数据，具备更强的性能。在数据插入和更新时，能够自动路由和存储。</li><li><strong>支持存储大文件</strong> ：MongoDB 的单文档存储空间要求不超过 16MB。对于超过 16MB 的大文件，MongoDB 提供了 GridFS 来进行存储，通过 GridFS，可以将大型数据进行分块处理，然后将这些切分后的小文档保存在数据库中。</li></ul><h3 id="MongoDB-适合什么应用场景？">MongoDB 适合什么应用场景？</h3><p>MongoDB 的优势在于其数据模型和存储引擎的灵活性、架构的可扩展性以及对强大的索引支持。</p><p>选用 MongoDB 应该充分考虑 MongoDB 的优势，结合实际项目的需求来决定：</p><ul><li>随着项目的发展，使用类 JSON 格式（BSON）保存数据是否满足项目需求？MongoDB 中的记录就是一个 BSON 文档，它是由键值对组成的数据结构，类似于 JSON 对象，是 MongoDB 中的基本数据单元。</li><li>是否需要大数据量的存储？是否需要快速水平扩展？MongoDB 支持分片集群，可以很方便地添加更多的节点（实例），让集群存储更多的数据，具备更强的性能。</li><li>是否需要更多类型索引来满足更多应用场景？MongoDB 支持多种类型的索引，包括单字段索引、复合索引、多键索引、哈希索引、文本索引、 地理位置索引等，每种类型的索引有不同的使用场合。</li><li>…</li></ul><h2 id="MongoDB-存储引擎">MongoDB 存储引擎</h2><h3 id="MongoDB-支持哪些存储引擎？">MongoDB 支持哪些存储引擎？</h3><p>存储引擎（Storage Engine）是数据库的核心组件，负责管理数据在内存和磁盘中的存储方式。</p><p>与 MySQL 一样，MongoDB 采用的也是 插件式的存储引擎架构 ，支持不同类型的存储引擎，不同的存储引擎解决不同场景的问题。在创建数据库或集合时，可以指定存储引擎。</p><blockquote><p>插件式的存储引擎架构可以实现 Server 层和存储引擎层的解耦，可以支持多种存储引擎，如MySQL既可以支持B-Tree结构的InnoDB存储引擎，还可以支持LSM结构的RocksDB存储引擎。</p></blockquote><p>在存储引擎刚出来的时候，默认是使用 MMAPV1 存储引擎，MongoDB4.x 版本不再支持 MMAPv1 存储引擎。</p><p>现在主要有下面这两种存储引擎：</p><ul><li>WiredTiger 存储引擎 ：自 MongoDB 3.2 以后，默认的存储引擎为 WiredTiger 存储引擎 。非常适合大多数工作负载，建议用于新部署。WiredTiger 提供文档级并发模型、检查点和数据压缩（后文会介绍到）等功能。</li><li>In-Memory 存储引擎 ：In-Memory 存储引擎在 MongoDB Enterprise 中可用。它不是将文档存储在磁盘上，而是将它们保留在内存中以获得更可预测的数据延迟。</li></ul><p>此外，MongoDB 3.0 提供了 可插拔的存储引擎 API ，允许第三方为 MongoDB 开发存储引擎，这点和 MySQL 也比较类似。</p><h3 id="WiredTiger-基于-LSM-Tree-还是-B-Tree？">WiredTiger 基于 LSM Tree 还是 B+ Tree？</h3><p>目前绝大部分流行的数据库存储引擎都是基于 B/B+ Tree 或者 LSM(Log Structured Merge) Tree 来实现的。对于 NoSQL 数据库来说，绝大部分（比如 HBase、Cassandra、RocksDB）都是基于 LSM 树，MongoDB 不太一样。</p><p>上面也说了，自 MongoDB 3.2 以后，默认的存储引擎为WiredTiger 存储引擎。在 WiredTiger 引擎官网上，我们发现 WiredTiger 使用的是 B+ 树作为其存储结构：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WiredTiger maintains a table<span class="comment">&#x27;s data in memory using a data structure called a B-Tree ( B+ Tree to be specific), referring to the nodes of a B-Tree as pages. Internal pages carry only keys. The leaf pages store both keys and values.</span></span><br></pre></td></tr></table></figure><p>此外，WiredTiger 还支持 LSM(Log Structured Merge) 树作为存储结构，MongoDB 在使用WiredTiger 作为存储引擎时，默认使用的是 B+ 树。</p><p>如果想要了解 MongoDB 使用 B 树的原因，可以看看这篇文章：为什么 MongoDB 使用 B 树？。</p><blockquote><p>为什么这么设计（Why’s THE Design）是一系列关于计算机领域中程序设计决策的文章，我们在这个系列的每一篇文章中都会提出一个具体的问题并从不同的角度讨论这种设计的优缺点、对具体实现造成的影响。如果你有想要了解的问题，可以在文章下面留言。</p></blockquote><p>我们在这一系列前面的文章曾经分析过 为什么 MySQL 使用 B+ 树，有读者在文章下面留言，希望能出一个为什么 MongoDB 使用 B 树的对比文章，这是一个比较好的问题，MySQL 和 MongoDB 两种不同类型的数据库使用了相似却不同的数据结构，为什么 MySQL 选择使用 B+ 树而 MongoDB 使用 B 树呢？</p><p><strong>概述</strong></p><p>MongoDB 是一个通用的、面向文档的分布式数据库[^1]，这是官方对 MongoDB 介绍。区别于传统的关系型数据库 MySQL、Oracle 和 SQL Server，MongoDB 最重要的一个特点就是**『面向文档』**，由于数据存储方式的不同，对外提供的接口不再是被大家熟知的 SQL，所以被划分成了 NoSQL，NoSQL 是相对 SQL 而言的，很多我们耳熟能详的存储系统都被划分成了 NoSQL，例如：Redis、DynamoDB[^2] 和 Elasticsearch 等。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602163456995.png" alt="image-20240602163456995"></p><p>NoSQL 经常被理解成没有 SQL（Non-SQL）或者非关系型（Non-Relational）[^3]，不过也有人将其理解成不只是 SQL（Not Only SQL）[^4]，深挖这个词的含义和起源可能没有太多意义，这种二次解读很多时候都是为营销服务的，我们只需要知道 MongoDB 对数据的存储方式与传统的关系型数据库完全不同。</p><p>MongoDB 的架构与 MySQL 非常类似，它们底层都使用了可插拔的存储引擎以满足用户的不同需求，用户可以根据数据特征选择不同的存储引擎，最新版本的 MongoDB 使用了 WiredTiger 作为默认的存储引擎[^5]。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602163510771.png" alt="image-20240602163510771"></p><p>作为 MongoDB 默认的存储引擎，WiredTiger 使用 B 树作为索引底层的数据结构，但是除了 B 树之外，它还支持 LSM 树作为可选的底层存储结构，LSM 树的全称是 Log-structured merge-tree，你可以在 MongoDB 中使用如下所示的命令创建一个基于 LSM 树的集合（Collection）[^6]:</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.<span class="title function_ invoke__">createCollection</span>(    <span class="string">&quot;posts&quot;</span>,    &#123; <span class="attr">storageEngine</span>: &#123; <span class="attr">wiredTiger</span>: &#123;<span class="attr">configString</span>: <span class="string">&quot;type=lsm&quot;</span>&#125;&#125;&#125;)</span><br></pre></td></tr></table></figure><p>我们在这篇文章中不仅会介绍 MongoDB 的默认存储引擎 WiredTiger 为什么选择使用 B 树而不是 B+ 树，还会对 B 树和 LSM 树之间的性能和应用场景进行比较，帮助各位读者更全面地理解今天的问题。</p><p><strong>设计</strong></p><p>既然要比较两个不同数据结构与 B 树的差别，那么在这里我们将分两个小节分别介绍 B+ 树和 LSM 树为什么没有成为 WiredTiger 默认的数据结构：</p><ul><li>作为非关系型的数据库，MongoDB 对于遍历数据的需求没有关系型数据库那么强，它追求的是读写单个记录的性能；</li><li>大多数 OLTP 的数据库面对的都是读多写少的场景，B 树与 LSM 树在该场景下有更大的优势；</li></ul><p>上述的两个场景都是 MongoDB 需要面对和解决的，所以我们会在这两个常见场景下对不同的数据结构进行比较。</p><p><strong>非关系型</strong></p><p>我们在上面其实已经多次提到了 MongoDB 是非关系型的文档数据库，它完全抛弃了关系型数据库那一套体系之后，在设计和实现上就非常自由，它不再需要遵循 SQL 和关系型数据库的体系，可以更自由对特定场景进行优化，而在 MongoDB 假设的场景中遍历数据并不是常见的需求。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602163545596.png" alt="image-20240602163545596"></p><p>MySQL 中使用 B+ 树是因为 B+ 树只有叶节点会存储数据，将树中的每一个叶节点通过指针连接起来就能实现顺序遍历，而遍历数据在关系型数据库中非常常见，所以这么选择是完全没有问题的[^7]。</p><p>MongoDB 和 MySQL 在多个不同数据结构之间选择的最终目的就是减少查询需要的随机 IO 次数，MySQL 认为遍历数据的查询是常见的，所以它选择 B+ 树作为底层数据结构，而舍弃了通过<strong>非叶节点存储数据</strong>这一特性，但是 MongoDB 面对的问题就不太一样了：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602163600570.png" alt="image-20240602163600570"></p><p>虽然遍历数据的查询是相对常见的，但是【关键】<strong>MongoDB 认为查询单个数据记录远比遍历数据更加常见，由于 B 树的非叶结点也可以存储数据</strong>，所以<strong>查询一条数据所需要的平均随机 IO 次数会比 B+ 树少</strong>，使用 B 树的 MongoDB 在类似场景中的查询速度就会比 MySQL 快。这里并不是说 MongoDB 并不能对数据进行遍历，我们在 MongoDB 中也可以使用范围来查询一批满足对应条件的记录，只是需要的时间会比 MySQL 长一些。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM comments WHERE created_at &gt; <span class="string">&#x27;2019-01-01&#x27;</span></span><br></pre></td></tr></table></figure><p>很多人看到遍历数据的查询想到的可能都是如上所示的范围查询，然而在关系型数据库中更常见的其实是如下所示的 SQL —— 查询外键或者某字段等于某一个值的全部记录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM comments WHERE post_id = 1</span><br></pre></td></tr></table></figure><p>上述查询其实并不是范围查询，它没有使用 <code>&gt;</code>、<code>&lt;</code> 等表达式，但是它却会在 <code>comments</code> 表中查询一系列的记录，如果 <code>comments</code> 表上有索引 <code>post_id</code>，那么这个查询可能就会在索引中遍历相应索引，找到满足条件的 <code>comment</code>，这种查询也会受益于 MySQL B+ 树相互连接的叶节点，因为它能减少磁盘的随机 IO 次数。</p><p>MongoDB 作为非关系型的数据库，它从集合的设计上就使用了完全不同的方法，如果我们仍然使用传统的关系型数据库的表设计思路来思考 MongoDB 中集合的设计，写出类似如上所示的查询会带来相对比较差的性能：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.comments.<span class="built_in">find</span>( &#123; post_id: 1 &#125; )</span><br></pre></td></tr></table></figure><p>因为 B 树的所有节点都能存储数据，各个连续的节点之间没有很好的办法通过指针相连，所以上述查询在 B 树中性能会比 B+ 树差很多，但是这并不是一个 MongoDB 中推荐的设计方法，更合适的做法其实是使用嵌入文档，将 <code>post</code> 和属于它的所有 <code>comments</code> 都存储到一起：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;...&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;为什么 MongoDB 使用 B 树&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;draven&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;comments&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;...&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你这写的不行&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;...&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;一楼说的对&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>使用上述方式对数据进行存储时就不会遇到 <code>db.comments.find( &#123; post_id: 1 &#125; )</code> 这样的查询了，我们只需要将 <code>post</code> 取出来就会获得相关的全部评论，这种区别于传统关系型数据库的设计方式是需要所有使用 MongoDB 的开发者重新思考的，这也是很多人使用 MongoDB 后却发现性能不如 MySQL 的最大原因 —— 使用的姿势不对。</p><p><strong>进一步说明：</strong></p><p>在传统的关系型数据库中，你可能会将帖子（post）和评论（comments）存储在两个不同的表中，并通过post_id将他们关联起来。当你想要获取一个帖子和它的所有评论时，你就需要执行一个类似于<code>db.comments.find( &#123; post_id: 1 &#125; )</code>的查询。然而，因为MongoDB使用的是B树，这种查询在性能上可能不如使用B+树的关系型数据库。</p><p>在MongoDB中，一种更好的设计方式是使用嵌入式文档（embedded documents）。你可以将一个帖子和它的所有评论都存储在一起，像这样：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;_id&quot;</span>: <span class="string">&quot;...&quot;</span>,</span><br><span class="line">    <span class="string">&quot;title&quot;</span>: <span class="string">&quot;为什么 MongoDB 使用 B 树&quot;</span>,</span><br><span class="line">    <span class="string">&quot;author&quot;</span>: <span class="string">&quot;draven&quot;</span>,</span><br><span class="line">    <span class="string">&quot;comments&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;_id&quot;</span>: <span class="string">&quot;...&quot;</span>,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你这写的不行&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;_id&quot;</span>: <span class="string">&quot;...&quot;</span>,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: <span class="string">&quot;一楼说的对&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这种情况下，你只需要取出帖子就能同时获取所有的评论，而不需要像在关系型数据库中那样进行额外的查询。这样就大大提高了查询效率，因此这是一种更推荐的设计方法。</p><hr><p>有些读者到这里可能会有疑问了，既然 MongoDB 认为查询单个数据记录远比遍历数据的查询更加常见，那为什么不使用哈希作为底层的数据结构呢？</p><p>回答：如果我们使用哈希，那么对于所有单条记录查询的复杂度都会是 <code>O(1)</code>，但是遍历数据的复杂度就是 <code>O(n)</code>；如果使用 B+ 树，那么单条记录查询的复杂度是 <code>O(log n)</code>，遍历数据的复杂度就是 <code>O(log n) + X</code>，这两种不同的数据结构一种提供了最好的单记录查询性能，一种提供了最好的遍历数据的性能，但是这都不能满足 MongoDB 面对的场景 —— 单记录查询非常常见，但是对于遍历数据也需要有相对较好的性能支持，哈希这种性能表现较为极端的数据结构往往只能在简单、极端的场景下使用。</p><h3 id="读多写少">读多写少</h3><p>LSM 树是一个基于磁盘的数据结构，它设计的主要目的是为长期需要高频率写入操作的文件提供低成本的索引机制[^8]。无论是 B 树还是 B+ 树，向这些数据结构组成的索引文件中写入记录都需要执行的磁盘随机写，LSM 树的优化逻辑就是牺牲部分的读性能，将随机写转换成顺序写以优化数据的写入。</p><p>我们在这篇文章不会详细介绍为什么 LSM 树有着较好的写入性能，我们只是来分析为什么 WiredTiger 使用 B 树作为默认的数据结构。WiredTiger 对 LSM 树和 B 树的性能进行了读写吞吐量的基准测试[^9]，通过基准测试得到了如下图所示的结果，从图中的结果我们能发现：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602164301739.png" alt="image-20240602164301739"></p><ol><li><p>在不限制写入的情况下；</p></li><li><ol><li>LSM 树的写入性能是 B 树的 1.5 ~ 2 倍；</li><li>LSM 树的读取性能是 B 树的 1/6 ~ 1/3；</li></ol></li><li><p>在限制写入的情况下；</p></li><li><ol><li>LSM 树的写入性能与 B 树的性能基本持平；</li><li>LSM 树的读取性能是 B 树的 1/4 ~ 1/2；</li></ol></li></ol><p>在限制写入的情况下，每秒会写入 30,000 条数据，从这里的分析结果来看，无论那种情况下 B 树的读取性能是远好于 LSM 树的。对于大多数的 OLTP 系统来说，系统的查询会是写的很多倍，所以 LSM 树在写入方面的优异表现也没有办法让它成为 MongoDB 默认的数据格式。</p><p><strong>解释</strong>：在&quot;无限制写&quot;的情况下，数据可以随时写入，没有任何限制。这种方式下，如果有大量的写入请求，那么写入性能会成为系统的瓶颈。在这种情况下，LSM树的写入性能通常会优于B树。</p><p>而&quot;限制写&quot;是指对数据写入进行一定的限制，这可能是通过限制写入速度或者限制同时写入的数据量等方式来实现的。在这种情况下，因为写入被限制，所以读取性能会变得更重要。在这种情况下，B树的读取性能通常会优于LSM树。</p><p><strong>总结</strong></p><p>应用场景永远都是系统设计时首先需要考虑的问题，作为 NoSQL 的 MongoDB，其目标场景就与更早的数据库就有着比较大的差异，我们来简单总结一下 MongoDB 最终选择使用 B 树的两个原因：</p><ul><li>MySQL 使用 B+ 树是因为数据的遍历在关系型数据库中非常常见，它经常需要处理各个表之间的关系并通过范围查询一些数据；但是 MongoDB 作为面向文档的数据库，与数据之间的关系相比，它更看重以文档为中心的组织方式，所以选择了查询单个文档性能较好的 B 树，这个选择对遍历数据的查询也可以保证可以接受的时延；</li><li>LSM 树是一种专门用来优化写入的数据结构，它将随机写变成了顺序写显著地提高了写入性能，但是却牺牲了读的效率，这与大多数场景需要的特点是不匹配的，所以 MongoDB 最终还是选择读取性能更好的 B 树作为默认的数据结构；</li></ul><h2 id="MongoDB-聚合">MongoDB 聚合</h2><h3 id="MongoDB-聚合有什么用？">MongoDB 聚合有什么用？</h3><p>实际项目中，我们经常需要将多个文档甚至是多个集合汇总到一起计算分析（比如求和、取最大值）并返回计算后的结果，这个过程被称为 <strong>聚合操作</strong> 。</p><p>根据官方文档介绍，我们可以使用聚合操作来：</p><ul><li>将来自多个文档的值组合在一起。</li><li>对集合中的数据进行的一系列运算。</li><li>分析数据随时间的变化。</li></ul><h3 id="MongoDB-提供了哪几种执行聚合的方法？">MongoDB 提供了哪几种执行聚合的方法？</h3><p>MongoDB 提供了两种执行聚合的方法：</p><ul><li><strong>聚合管道（Aggregation Pipeline）</strong> ：执行聚合操作的首选方法。</li><li><strong>单一目的聚合方法（Single purpose aggregation methods）</strong> ：也就是单一作用的聚合函数比如 <code>count()</code>、<code>distinct()</code>、<code>estimatedDocumentCount()</code>。</li></ul><p>绝大部分文章中还提到了 <strong>map-reduce 这种聚合方法</strong>。不过，从 <strong>MongoDB 5.0</strong> 开始，map-reduce 已经不被官方推荐使用了，替代方案是 聚合管道。聚合管道提供比 map-reduce 更好的性能和可用性。</p><p>MongoDB 聚合管道由多个阶段组成，每个阶段在文档通过管道时转换文档。每个阶段接收前一个阶段的输出，进一步处理数据，并将其作为输入数据发送到下一个阶段。</p><p>每个管道的工作流程是：</p><ol><li>接受一系列原始数据文档</li><li>对这些文档进行一系列运算</li><li>结果文档输出给下一个阶段</li></ol><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602165207382.png" alt="image-20240602165207382"></p><p>常用阶段操作符 ：</p><table><thead><tr><th>操作符</th><th>简述</th></tr></thead><tbody><tr><td>$match</td><td>匹配操作符，用于对文档集合进行筛选</td></tr><tr><td>$project</td><td>投射操作符，用于重构每一个文档的字段，可以提取字段，重命名字段，甚至可以对原有字段进行操作后新增字段</td></tr><tr><td>$sort</td><td>排序操作符，用于根据一个或多个字段对文档进行排序</td></tr><tr><td>$limit</td><td>限制操作符，用于限制返回文档的数量</td></tr><tr><td>$skip</td><td>跳过操作符，用于跳过指定数量的文档</td></tr><tr><td>$count</td><td>统计操作符，用于统计文档的数量</td></tr><tr><td>$group</td><td>分组操作符，用于对文档集合进行分组</td></tr><tr><td>$unwind</td><td>拆分操作符，用于将数组中的每一个值拆分为单独的文档</td></tr><tr><td>$lookup</td><td>连接操作符，用于连接同一个数据库中另一个集合，并获取指定的文档，类似于 populate</td></tr></tbody></table><p>更多操作符介绍详见官方文档：<a href="https://docs.mongodb.com/manual/reference/operator/aggregation/">https://docs.mongodb.com/manual/reference/operator/aggregation/</a></p><p>阶段操作符用于 <code>db.collection.aggregate</code> 方法里面，数组参数中的第一层。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.collection.aggregate( [ &#123; 阶段操作符：表述 &#125;, &#123; 阶段操作符：表述 &#125;, ... ] )</span><br></pre></td></tr></table></figure><p>下面是 MongoDB 官方文档中的一个例子：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">db.orders.<span class="title function_ invoke__">aggregate</span>([</span><br><span class="line">   # 第一阶段：<span class="variable">$match</span>阶段按status字段过滤文档，并将status等于<span class="string">&quot;A&quot;</span>的文档传递到下一阶段。</span><br><span class="line">    &#123; <span class="variable">$match</span>: &#123; <span class="attr">status</span>: <span class="string">&quot;A&quot;</span> &#125; &#125;,</span><br><span class="line">  # 第二阶段：<span class="variable">$group</span>阶段按cust_id字段将文档分组，以计算每个cust_id唯一值的金额总和。</span><br><span class="line">    &#123; <span class="variable">$group</span>: &#123; <span class="attr">_id</span>: <span class="string">&quot;<span class="subst">$cust_id</span>&quot;</span>, <span class="attr">total</span>: &#123; <span class="variable">$sum</span>: <span class="string">&quot;<span class="subst">$amount</span>&quot;</span> &#125; &#125; &#125;</span><br><span class="line">])</span><br></pre></td></tr></table></figure><h2 id="MongoDB-事务">MongoDB 事务</h2><ul><li><a href="https://mongoing.com/archives/82187">技术干货| MongoDB 事务原理</a></li><li><a href="https://developer.aliyun.com/article/782494">MongoDB 一致性模型设计与实现</a></li><li><a href="https://www.mongodb.com/docs/upcoming/core/transactions/">MongoDB 官方文档对事务的介绍</a></li></ul><p>我们在介绍 NoSQL 数据的时候也说过，NoSQL 数据库通常不支持事务，为了可扩展和高性能进行了权衡。不过，也有例外，MongoDB 就支持事务。</p><p>与关系型数据库一样，MongoDB 事务同样具有 ACID 特性：</p><ul><li>原子性（<code>Atomicity</code>） ：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li><li>一致性（<code>Consistency</code>）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；</li><li>隔离性（<code>Isolation</code>）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的。WiredTiger 存储引擎支持读未提交（ read-uncommitted ）、读已提交（ read-committed ）和快照（ snapshot ）隔离，MongoDB 启动时默认选快照隔离。在不同隔离级别下，一个事务的生命周期内，可能出现脏读、不可重复读、幻读等现象。</li><li>持久性（<code>Durability</code>）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li></ul><p>MongoDB 单文档原生支持原子性，也具备事务的特性。当谈论 MongoDB 事务的时候，通常指的是 多文档 。MongoDB 4.0 加入了对多文档 ACID 事务的支持，但只支持复制集部署模式下的 ACID 事务，也就是说事务的作用域限制为一个副本集内。MongoDB 4.2 引入了 分布式事务 ，增加了对分片集群上多文档事务的支持，并合并了对副本集上多文档事务的现有支持。</p><p>根据官方文档介绍：</p><blockquote><p>从 MongoDB 4.2 开始，分布式事务和多文档事务在 MongoDB 中是一个意思。分布式事务是指分片集群和副本集上的多文档事务。从 MongoDB 4.2 开始，多文档事务（无论是在分片集群还是副本集上）也称为分布式事务。</p></blockquote><p>在大多数情况下，多文档事务比单文档写入会产生更大的性能成本。对于大部分场景来说， 非规范化数据模型（嵌入式文档和数组） 依然是最佳选择。也就是说，适当地对数据进行建模可以最大限度地减少对多文档事务的需求。</p><p>注意 ：</p><ul><li>从MongoDB 4.2开始，多文档事务支持副本集和分片集群，其中：主节点使用WiredTiger存储引擎，同时从节点使用WiredTiger存储引擎或In-Memory存储引擎。在MongoDB 4.0中，只有使用WiredTiger存储引擎的副本集支持事务。</li><li>在MongoDB 4.2及更早版本中，你无法在事务中创建集合。从 MongoDB 4.4 开始，您可以在事务中创建集合和索引。有关详细信息，请参阅 在事务中创建集合和索引。</li></ul><h2 id="MongoDB-数据压缩">MongoDB 数据压缩</h2><p>借助 WiredTiger 存储引擎（ MongoDB 3.2 后的默认存储引擎），MongoDB 支持对所有集合和索引进行压缩。压缩以额外的 CPU 为代价最大限度地减少存储使用。</p><p>默认情况下，WiredTiger 使用 Snappy 压缩算法（谷歌开源，旨在实现非常高的速度和合理的压缩，压缩比 3 ～ 5 倍）对所有集合使用块压缩，对所有索引使用前缀压缩。</p><p>除了 Snappy 之外，对于集合还有下面这些压缩算法：</p><ul><li>zlib：高度压缩算法，压缩比 5 ～ 7 倍</li><li>Zstandard（简称 zstd）：Facebook 开源的一种快速无损压缩算法，针对 zlib 级别的实时压缩场景和更好的压缩比，提供更高的压缩率和更低的 CPU 使用率，MongoDB 4.2 开始可用。</li></ul><p>WiredTiger 日志也会被压缩，默认使用的也是 Snappy 压缩算法。如果日志记录小于或等于 128 字节，WiredTiger 不会压缩该记录。</p><h2 id="MongoDB-索引">MongoDB 索引</h2><h3 id="MongoDB-索引有什么用">MongoDB 索引有什么用?</h3><p>和关系型数据库类似，MongoDB 中也有索引。索引的目的主要是用来提高查询效率，如果没有索引的话，MongoDB 必须执行 <strong>集合扫描</strong> ，即扫描集合中的每个文档，以选择与查询语句匹配的文档。如果查询存在合适的索引，MongoDB 可以使用该索引来限制它必须检查的文档数量。并且，MongoDB 可以使用索引中的排序返回排序后的结果。</p><p>虽然索引可以显著缩短查询时间，但是使用索引、维护索引是有代价的。在执行写入操作时，除了要更新文档之外，还必须更新索引，这必然会影响写入的性能。因此，当有大量写操作而读操作少时，或者不考虑读操作的性能时，都不推荐建立索引。</p><h3 id="MongoDB-支持哪些类型的索引？">MongoDB 支持哪些类型的索引？</h3><p><strong>MongoDB 支持多种类型的索引，包括单字段索引、复合索引、多键索引、哈希索引、文本索引、 地理位置索引等，每种类型的索引有不同的使用场合。</strong></p><ul><li><strong>单字段索引</strong>： 建立在单个字段上的索引，索引创建的排序顺序无所谓，MongoDB 可以头/尾开始遍历。</li><li><strong>复合索引</strong>： 建立在多个字段上的索引，也可以称之为组合索引、联合索引。</li><li><strong>多键索引</strong> ：MongoDB 的一个字段可能是数组，在对这种字段创建索引时，就是多键索引。MongoDB 会为数组的每个值创建索引。就是说你可以按照数组里面的值做条件来查询，这个时候依然会走索引。</li><li><strong>哈希索引</strong> ：按数据的哈希值索引，用在哈希分片集群上。</li><li><strong>文本索引</strong>： 支持对字符串内容的文本搜索查询。文本索引可以包含任何值为字符串或字符串元素数组的字段。一个集合只能有一个文本搜索索引，但该索引可以覆盖多个字段。MongoDB 虽然支持全文索引，但是性能低下，暂时不建议使用。</li><li><strong>地理位置索引</strong>： 基于经纬度的索引，适合 2D 和 3D 的位置查询。</li><li><strong>唯一索引</strong> ：确保索引字段不会存储重复值。如果集合已经存在了违反索引的唯一约束的文档，则后台创建唯一索引会失败。</li><li><strong>TTL 索引</strong> ：TTL 索引提供了一个过期机制，允许为每一个文档设置一个过期时间，当一个文档达到预设的过期时间之后就会被删除。</li><li>…</li></ul><h3 id="复合索引中字段的顺序有影响吗？">复合索引中字段的顺序有影响吗？</h3><p>复合索引中字段的顺序非常重要，例如下图中的复合索引由<code>&#123;userid:1, score:-1&#125;</code>组成，则该复合索引首先按照<code>userid</code>升序排序；然后再每个<code>userid</code>的值内，再按照<code>score</code>降序排序。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602170041591.png" alt="image-20240602170041591"></p><p>在复合索引中，按照何种方式排序，决定了该索引在查询中是否能被应用到。</p><p>走复合索引的排序：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;userid&quot;</span>: <span class="number">1</span>, <span class="string">&quot;score&quot;</span>: -<span class="number">1</span>&#125;)</span><br><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;userid&quot;</span>: -<span class="number">1</span>, <span class="string">&quot;score&quot;</span>: <span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure><p>不走复合索引的排序：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;userid&quot;</span>: <span class="number">1</span>, <span class="string">&quot;score&quot;</span>: <span class="number">1</span>&#125;)</span><br><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;userid&quot;</span>: -<span class="number">1</span>, <span class="string">&quot;score&quot;</span>: -<span class="number">1</span>&#125;)</span><br><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;score&quot;</span>: <span class="number">1</span>, <span class="string">&quot;userid&quot;</span>: -<span class="number">1</span>&#125;)</span><br><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;score&quot;</span>: <span class="number">1</span>, <span class="string">&quot;userid&quot;</span>: <span class="number">1</span>&#125;)</span><br><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;score&quot;</span>: -<span class="number">1</span>, <span class="string">&quot;userid&quot;</span>: -<span class="number">1</span>&#125;)</span><br><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;score&quot;</span>: -<span class="number">1</span>, <span class="string">&quot;userid&quot;</span>: <span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure><p>我们可以通过 explain 进行分析：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db<span class="selector-class">.s2</span><span class="selector-class">.find</span>()<span class="selector-class">.sort</span>(&#123;<span class="string">&quot;score&quot;</span>: -<span class="number">1</span>, <span class="string">&quot;userid&quot;</span>: <span class="number">1</span>&#125;)<span class="selector-class">.explain</span>()</span><br></pre></td></tr></table></figure><h3 id="复合索引遵循左前缀原则吗？">复合索引遵循左前缀原则吗？</h3><p>MongoDB 的复合索引遵循左前缀原则 ：拥有多个键的索引，可以同时得到所有这些键的前缀组成的索引，但不包括除左前缀之外的其他子集。比如说，有一个类似 <code>&#123;a: 1, b: 1, c: 1, ..., z: 1&#125;</code> 这样的索引，那么实际上也等于有了 <code>&#123;a: 1&#125;</code>、<code>&#123;a: 1, b: 1&#125;</code>、<code>&#123;a: 1, b: 1, c: 1&#125;</code> 等一系列索引，但是不会有 <code>&#123;b: 1&#125;</code> 这样的非左前缀的索引。</p><h3 id="什么是-TTL-索引？">什么是 TTL 索引？</h3><p>TTL 索引提供了一个过期机制，<strong>允许为每一个文档设置一个过期时间</strong> <code>expireAfterSeconds</code> ，当一个文档达到预设的过期时间之后就会被删除。TTL 索引除了有 <code>expireAfterSeconds</code> 属性外，和普通索引一样。</p><p>数据过期对于某些类型的信息很有用，比如<strong>机器生成的事件数据、日志和会话信息，这些信息只需要在数据库中保存有限的时间。</strong></p><p><strong>TTL 索引运行原理</strong>：</p><ul><li>MongoDB 会开启一个后台线程读取该 TTL 索引的值来判断文档是否过期，但不会保证已过期的数据会立马被删除，因后台线程每 60 秒触发一次删除任务，且如果删除的数据量较大，会存在上一次的删除未完成，而下一次的任务已经开启的情况，导致过期的数据也会出现超过了数据保留时间 60 秒以上的现象。</li><li>对于副本集而言，TTL 索引的后台进程只会在 Primary 节点开启，在从节点会始终处于空闲状态，从节点的数据删除是由主库删除后产生的 oplog 来做同步。</li></ul><p><strong>TTL 索引限制</strong> ：</p><ul><li>TTL 索引是单字段索引。复合索引不支持 TTL。</li><li><code>_id</code>字段不支持 TTL 索引。</li><li>无法在上限集合(Capped Collection)上创建 TTL 索引，因为 MongoDB 无法从上限集合中删除文档。</li><li>如果某个字段已经存在非 TTL 索引，那么在该字段上无法再创建 TTL 索引。</li></ul><h3 id="什么是覆盖索引查询？">什么是覆盖索引查询？</h3><p>根据官方文档介绍，覆盖查询是以下的查询：</p><ul><li>所有的查询字段是索引的一部分。</li><li>结果中返回的所有字段都在同一索引中。</li><li>查询中没有字段等于<code>null</code>。</li></ul><p>由于所有出现在查询中的字段是索引的一部分， MongoDB 无需在整个数据文档中检索匹配查询条件和返回使用相同索引的查询结果。因为索引存在于内存中，从索引中获取数据比通过扫描文档读取数据要快得多。</p><p>举个例子：我们有如下 <code>users</code> 集合:</p><figure class="highlight clojure"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   <span class="string">&quot;_id&quot;</span>: ObjectId(<span class="string">&quot;53402597d852426020000002&quot;</span>)<span class="punctuation">,</span></span><br><span class="line">   <span class="string">&quot;contact&quot;</span>: <span class="string">&quot;987654321&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="string">&quot;dob&quot;</span>: <span class="string">&quot;01-01-1991&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="string">&quot;gender&quot;</span>: <span class="string">&quot;M&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Tom Benzamin&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="string">&quot;user_name&quot;</span>: <span class="string">&quot;tombenzamin&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们在 <code>users</code> 集合中创建联合索引，字段为 <code>gender</code> 和 <code>user_name</code> :</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">db</span>.users.ensureIndex(&#123;gender:<span class="number">1</span>,user_name:<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure><p>现在，该索引会覆盖以下查询：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">db.users.<span class="title function_ invoke__">find</span>(&#123;<span class="attr">gender</span>:<span class="string">&quot;M&quot;</span>&#125;,&#123;<span class="attr">user_name</span>:<span class="number">1</span>,<span class="attr">_id</span>:<span class="number">0</span>&#125;)</span><br></pre></td></tr></table></figure><p>为了让指定的索引覆盖查询，必须显式地指定 <code>_id: 0</code> 来从结果中排除 <code>_id</code> 字段，因为索引不包括 <code>_id</code> 字段。</p><h2 id="MongoDB-高可用">MongoDB 高可用</h2><h3 id="复制集群">复制集群</h3><h4 id="什么是复制集群？">什么是复制集群？</h4><p>MongoDB 的复制集群又称为<strong>副本集群</strong>，<strong>是一组维护相同数据集合的 mongod 进程</strong>。</p><p><strong>客户端连接到整个 Mongodb 复制集群，主节点机负责整个复制集群的写，从节点可以进行读操作，但默认还是主节点负责整个复制集群的读</strong>。主节点发生故障时，自动从从节点中选举出一个新的主节点，确保集群的正常使用，这对于客户端来说是无感知的。</p><p>通常来说，<strong>一个复制集群包含 1 个主节点（Primary），多个从节点（Secondary）以及零个或 1 个仲裁节点（Arbiter）。</strong></p><ul><li>主节点 ：整个集群的写操作入口，接收所有的写操作，并将集合所有的变化记录到操作日志中，即 oplog。主节点挂掉之后会自动选出新的主节点。</li><li>从节点 ：从主节点同步数据，在主节点挂掉之后选举新节点。不过，从节点可以配置成 0 优先级，阻止它在选举中成为主节点。</li><li>仲裁节点 ：这个是为了节约资源或者多机房容灾用，只负责主节点选举时投票不存数据，保证能有节点获得多数赞成票。</li></ul><p>下图是一个典型的三成员副本集群：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602170958257.png" alt="image-20240602170958257"></p><p>主节点与备节点之间是通过 oplog（操作日志） 来同步数据的。oplog 是 local 库下的一个特殊的 上限集合(Capped Collection) ，用来保存写操作所产生的增量日志，类似于 MySQL 中 的 Binlog。</p><blockquote><p>上限集合类似于定长的循环队列，数据顺序追加到集合的尾部，当集合空间达到上限时，它会覆盖集合中最旧的文档。上限集合的数据将会被顺序写入到磁盘的固定空间内，所以，I/O 速度非常快，如果不建立索引，性能更好。</p></blockquote><p><strong>当主节点上的一个写操作完成后，会向 oplog 集合写入一条对应的日志，而从节点则通过这个 oplog 不断拉取到新的日志，在本地进行回放以达到数据同步的目的。</strong></p><p>副本集最多有一个主节点。如果当前主节点不可用，一个选举会抉择出新的主节点。MongoDB 的节点选举规则能够保证在 Primary 挂掉之后选取的新节点一定是集群中数据最全的一个。</p><h4 id="为什么要用复制集群？">为什么要用复制集群？</h4><ul><li>实现 failover ：提供自动故障恢复的功能，主节点发生故障时，自动从从节点中选举出一个新的主节点，确保集群的正常使用，这对于客户端来说是无感知的。</li><li>实现读写分离 ：我们可以设置从节点上可以读取数据，主节点负责写入数据，这样的话就实现了读写分离，减轻了主节点读写压力过大的问题。MongoDB 4.0 之前版本如果主库压力不大,不建议读写分离，因为写会阻塞读，除非业务对响应时间不是非常关注以及读取历史数据接受一定时间延迟。</li></ul><h3 id="分片集群">分片集群</h3><h4 id="什么是分片集群？">什么是分片集群？</h4><p>分片集群是 MongoDB 的分布式版本，相较副本集，分片集群数据被均衡的分布在不同分片中， 不仅大幅提升了整个集群的数据容量上限，也将读写的压力分散到不同分片，以解决副本集性能瓶颈的难题。</p><p>MongoDB 的分片集群由如下三个部分组成</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602171729227.png" alt="image-20240602171729227"></p><ul><li>Config Servers：配置服务器，本质上是一个 MongoDB 的副本集，负责存储集群的各种元数据和配置，如分片地址、Chunks 等</li><li>Mongos：路由服务，不存具体数据，从 Config 获取集群配置讲请求转发到特定的分片，并且整合分片结果返回给客户端。</li><li>Shard：每个分片是整体数据的一部分子集，从MongoDB3.6版本开始，每个Shard必须部署为副本集（replica set）架构</li></ul><p><strong>解释：</strong></p><p>首先，分片集群主要由三个部分组成：Config Servers，Mongos和Shard。</p><ol><li>Config Servers：它们是配置服务器，负责存储集群的元数据和配置信息。比如说，你的数据库里有哪些数据，这些数据该如何分布在不同的Shard上，这些信息都是由Config Servers来保存的。可以把它们看作是一本详尽的目录，帮助我们知道去哪里查找或者存储数据。</li><li>Mongos：它是路由服务，它的主要职能就是把客户端的请求转发到对应的Shard上。比如说，<strong>你想要查询某个数据，这个请求首先会被发送到Mongos，Mongos会查阅Config Servers的信息，找到这个数据存储在哪个Shard上，然后把请求转发到那个Shard</strong>。Mongos本身不存储数据，它只是起到一个信息中转站的作用。</li><li>Shard：它们是真正存储数据的地方。每个Shard存储数据库的一部分数据。这样，当数据量非常大的时候，我们可以把数据分布在多个Shard上，这样不仅可以提高数据的读写速度，还能有效地利用多台服务器的存储空间。</li></ol><p>举个例子，假设你正在管理一个图书馆，那么Config Servers就像是图书馆的图书目录，记录了每本书在哪个书架上；Mongos就像是图书馆的管理员，当读者想要找一本书的时候，管理员会查阅目录，然后告诉读者这本书在哪个书架上；而Shard就像是图书馆的书架，真正存储了这些书。</p><h4 id="为什么要用分片集群？">为什么要用分片集群？</h4><p>随着系统数据量以及吞吐量的增长，常见的解决办法有两种：垂直扩展和水平扩展。</p><p>垂直扩展通过增加单个服务器的能力来实现，比如磁盘空间、内存容量、CPU 数量等；水平扩展则通过将数据存储到多个服务器上来实现，根据需要添加额外的服务器以增加容量。</p><p>类似于 Redis Cluster，MongoDB 也可以通过分片实现 水平扩展 。水平扩展这种方式更灵活，可以满足更大数据量的存储需求，支持更高吞吐量。并且，水平扩展所需的整体成本更低，仅仅需要相对较低配置的单机服务器即可，代价是增加了部署的基础设施和维护的复杂性。</p><p>也就是说当你遇到如下问题时，可以使用分片集群解决：</p><ul><li>存储容量受单机限制，即磁盘资源遭遇瓶颈。</li><li>读写能力受单机限制，可能是 CPU、内存或者网卡等资源遭遇瓶颈，导致读写能力无法扩展。</li></ul><p><strong>举例：</strong></p><p>垂直扩展和水平扩展是处理大数据的两种常见解决方案。我来通俗易懂地解释一下这两种扩展方式。</p><ol><li>垂直扩展：这就好比是把一台车加装更大的引擎、更宽敞的储物空间，或者更舒适的座椅来提高它的性能。在计算机世界里，垂直扩展就是通过提升单台服务器的硬件性能来处理更多的数据，比如增加更大的硬盘、更多的内存、或者更强大的CPU。这种方式的优点是操作相对简单，只需要购买更好的硬件就行，但缺点是硬件的提升总是有上限的，比如CPU的速度或者硬盘的大小总是有个上限。</li><li>水平扩展：这就像是买更多的车来承载更多的人。在计算机世界里，水平扩展就是通过增加更多的服务器来共同处理数据。比如一个大型的网站，可以将用户的请求分发到多台服务器上处理，这样就可以处理更多的用户请求。水平扩展的优点是理论上可以无限扩展，只要有足够的资源，就可以一直添加服务器。但是，这种方式需要有合理的数据分片和负载均衡策略，否则可能会导致数据不一致或者某些服务器过载。</li></ol><p>举个例子，假设我们开一家快餐店。如果我们要提高服务能力，垂直扩展就好比是购买更快的炉子、更大的冰箱、更多的食材，这样我们可以更快地做出更多的食物。而水平扩展就好比是开更多的分店，每家分店都可以为客户提供服务，这样我们就可以服务更多的客户。</p><h4 id="什么是分片键？">什么是分片键？</h4><p>分片键（Shard Key） 是数据分区的前提， 从而实现数据分发到不同服务器上，减轻服务器的负担。也就是说，分片键决定了集合内的文档如何在集群的多个分片间的分布状况。</p><p>分片键就是文档里面的一个字段，但是这个字段不是普通的字段，有一定的要求：</p><ul><li>它必须在所有文档中都出现。</li><li>它必须是集合的一个索引，可以是单索引或复合索引的前缀索引，不能是多索引、文本索引或地理空间位置索引。</li><li>MongoDB 4.2 之前的版本，文档的分片键字段值不可变。MongoDB 4.2 版本开始，除非分片键字段是不可变的 <code>_id</code> 字段，否则您可以更新文档的分片键值。MongoDB 5.0 版本开始，实现了实时重新分片（live resharding），可以实现分片键的完全重新选择。</li><li>它的大小不能超过 512 字节。</li></ul><p><strong>解释</strong>：</p><p>分片键在MongoDB中起到了非常重要的作用。它是决定数据如何在分布式数据库系统中进行分布的关键。<strong>简单来说，就好比是一本厚厚的字典，我们是按照字母顺序来决定每个单词在哪一页的，那么这个“字母顺序”就相当于是分片键。</strong></p><p>以一个学生管理系统为例，如果我们把学生的学号设置为分片键，那么系统在存储学生信息的时候，就会根据学号的大小将数据分布到不同的服务器上。<strong>比如学号1-1000的学生信息存储在服务器A，学号1001-2000的学生信息存储在服务器B</strong>，以此类推。这样做的好处是，当我们想要查找某个学生的信息时，系统可以直接去对应的服务器上查找，大大提高了查询效率。</p><p>但是，分片键需要满足一些条件：</p><ol><li>它必须在所有文档中都出现。这是因为分片键是用来决定数据如何分布的，如果有的文档没有这个字段，那系统就无法决定把这个文档存储到哪里。</li><li>它必须是集合的一个索引，可以是单索引或复合索引的前缀索引。</li><li>分片键的大小不能超过512字节。</li></ol><p>这就是分片键的基本概念，希望对你有所帮助。</p><h4 id="如何选择分片键？">如何选择分片键？</h4><p>选择合适的片键对 sharding 效率影响很大，主要基于如下四个因素（摘自分片集群使用注意事项 - - 腾讯云文档）：</p><ul><li>取值基数 取值基数建议尽可能大，如果用小基数的片键，因为备选值有限，那么块的总数量就有限，随着数据增多，块的大小会越来越大，导致水平扩展时移动块会非常困难。例如：选择年龄做一个基数，范围最多只有100个，随着数据量增多，同一个值分布过多时，导致 chunck 的增长超出 chuncksize 的范围，引起 jumbo chunk，从而无法迁移，导致数据分布不均匀，性能瓶颈。</li><li>取值分布 取值分布建议尽量均匀，分布不均匀的片键会造成某些块的数据量非常大，同样有上面数据分布不均匀，性能瓶颈的问题。</li><li>查询带分片 查询时建议带上分片，使用分片键进行条件查询时，mongos 可以直接定位到具体分片，否则 mongos 需要将查询分发到所有分片，再等待响应返回。</li><li>避免单调递增或递减 单调递增的 sharding key，数据文件挪动小，但写入会集中，导致最后一篇的数据量持续增大，不断发生迁移，递减同理。</li></ul><p>综上，在选择片键时要考虑以上4个条件，尽可能满足更多的条件，才能降低 MoveChuncks 对性能的影响，从而获得最优的性能体验。</p><h4 id="分片策略有哪些？">分片策略有哪些？</h4><p>MongoDB 支持两种分片算法来满足不同的查询需求（摘自MongoDB 分片集群介绍 - 阿里云文档）：</p><p>1、<strong>基于范围的分片</strong> ：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602172751440.png" alt="image-20240602172751440"></p><p>MongoDB 按照分片键（Shard Key）的值的范围将数据拆分为不同的块（Chunk），每个块包含了一段范围内的数据。当分片键的基数大、频率低且值非单调变更时，范围分片更高效。</p><ul><li>优点：Mongos 可以快速定位请求需要的数据，并将请求转发到相应的 Shard 节点中。</li><li>缺点：可能导致数据在 Shard 节点上分布不均衡，容易造成读写热点，且不具备写分散性。</li><li>适用场景：分片键的值不是单调递增或单调递减、分片键的值基数大且重复的频率低、需要范围查询等业务场景。</li></ul><p>2、<strong>基于 Hash 值的分片</strong></p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602172837739.png" alt="image-20240602172837739"></p><p>MongoDB 计算单个字段的哈希值作为索引值，并以哈希值的范围将数据拆分为不同的块（Chunk）。</p><ul><li>优点：可以将数据更加均衡地分布在各 Shard 节点中，具备写分散性。</li><li>缺点：不适合进行范围查询，进行范围查询时，需要将读请求分发到所有的 Shard 节点。</li><li>适用场景：分片键的值存在单调递增或递减、片键的值基数大且重复的频率低、需要写入的数据随机分发、数据读取随机性较大等业务场景。</li></ul><p>除了上述两种分片策略，您还可以配置 复合片键 ，例如由一个低基数的键和一个单调递增的键组成。</p><h4 id="分片数据如何存储？">分片数据如何存储？</h4><p>Chunk（块） 是 MongoDB 分片集群的一个核心概念，其本质上就是由一组 Document 组成的逻辑数据单元。每个 Chunk 包含一定范围片键的数据，互不相交且并集为全部数据，即离散数学中划分的概念。</p><p>分片集群不会记录每条数据在哪个分片上，而是记录 Chunk 在哪个分片上一级这个 Chunk 包含哪些数据。</p><p>默认情况下，一个 Chunk 的最大值默认为 64MB（可调整，取值范围为 1~1024 MB。如无特殊需求，建议保持默认值），进行数据插入、更新、删除时，如果此时 Mongos 感知到了目标 Chunk 的大小或者其中的数据量超过上限，则会触发 Chunk 分裂。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602172927951.png" alt="image-20240602172927951"></p><p>数据的增长会让 Chunk 分裂得越来越多。这个时候，各个分片上的 Chunk 数量可能会不平衡。Mongos 中的 均衡器(Balancer) 组件就会执行自动平衡，尝试使各个 Shard 上 Chunk 的数量保持均衡，这个过程就是 再平衡（Rebalance）。默认情况下，数据库和集合的 Rebalance 是开启的。</p><p>如下图所示，随着数据插入，导致 Chunk 分裂，让 AB 两个分片有 3 个 Chunk，C 分片只有一个，这个时候就会把 B 分配的迁移一个到 C 分片实现集群数据均衡。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602172941546.png" alt="image-20240602172941546"></p><blockquote><p>Balancer 是 MongoDB 的一个运行在 Config Server 的 Primary 节点上(自 MongoDB 3.4 版本起)的后台进程，它监控每个分片上 Chunk 数量，并在某个分片上 Chunk 数量达到阈值进行迁移。</p></blockquote><p>Chunk 只会分裂，不会合并，即使 chunkSize 的值变大。</p><p>Rebalance 操作是比较耗费系统资源的，我们可以通过在业务低峰期执行、预分片或者设置 Rebalance 时间窗等方式来减少其对 MongoDB 正常使用所带来的影响。</p><p>Chunk 只会分裂，不会合并，即使 chunkSize 的值变大。</p><p>Rebalance 操作是比较耗费系统资源的，我们可以通过在业务低峰期执行、预分片或者设置 Rebalance 时间窗等方式来减少其对 MongoDB 正常使用所带来的影响。</p><h4 id="Chunk-迁移原理是什么？">Chunk 迁移原理是什么？</h4><p><strong>一、chunk简介</strong></p><p><strong>1.1 chunk是什么</strong></p><p>MongoDB在Sharding模式下（对于Sharding不了解的可以参考shard介绍），通过Mongos向开启了shard分片的集合写入文档，这些文档会根据其shardKey分散到MongoDB的不同shard上。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602174141898.png" alt="image-20240602174141898"></p><p>如上图，假设集合的shardKey x（以范围分片为例，哈希分片类似），写入该集合的文档根据其x的取值范围，会被分散到chunk1到chunk4中，每个chunk只包含特定范围的数据（比如chunk2就只包含x的取值在[-75, 25)范围内的文档），同一chunk的文档只会存储在一个shard上，一个shard可能包含多个chunk，chunk具体存储在哪个shard，由记录在config server中的路由信息决定。</p><p><strong>1.2 chunk分裂</strong></p><p>默认情况下，一个chunk的最大值默认为64MB（可调整），进行数据插入、更新、删除时，如果此时mongos感知到了目标chunk的大小超过上限，则会触发chunk分裂。chunk分裂动作为逻辑上的概念，它会对需要分裂的chunk进行分段，指定split point标记切割的位置</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602174158563.png" alt="image-20240602174158563"></p><p><strong>解释：</strong></p><p>例如，假设我们的分片键是学号，一个Chunk中存储了学号1-1000的学生信息，但是这个Chunk已经满了。这时，如果我们要插入更多的学生信息，系统就会选择一个分裂点，例如500，然后将学号501-1000的学生信息移动到新的Chunk，原来的Chunk就只存储学号1-500的学生信息了。</p><p>这样，我们就可以继续向数据库插入新的数据，而不需要担心存储空间不足的问题。同时，通过合理的分裂点选择，我们也可以保证数据在Chunk之间的均衡分布，提高查询效率。</p><p><strong>1.3 chunk的迁移</strong></p><p>MongoDB默认情况下会开启一个balancer模块用于定期检测各个shard上的chunk数量分布，当检测到各个shard上的chunk数量存在分布不均匀的情况时，就会触发chunk迁移。如下图，三个shard的chunk数量分别为3、3、1，此时balancer认为chunk数量分布不均，于是会将shard B上的chunk迁移一个到shard C上，这样三个shard的chunk数量分布最终就会变为3、2、2，分布更为均匀。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602174214629.png" alt="image-20240602174214629"></p><p>上文提到的balancer通过特定规则来筛选出来需要进行迁移的chunk，这些规则具体是什么呢？当前，mongoDB会对以下三种类型的chunk进行迁移（优先级由高到底）：</p><ul><li>chunk属于正在进行排水（即draining，一般出现在shard删除，move primary等情况下，表示该chunk需要尽快被删除）的shard</li><li>chunk是否违反了zones的约束（zones的定义见此）</li><li>如果不属于以上两种情况，则通过计算各个shard之间的chunks数量进行负载均衡，原则上balancer会让各个shard在满足zones约束的条件下尽可能均衡</li></ul><p>选定了需要迁移的chunk后，balancer会选择当前shards中chunks数最少的一个作为迁移的目标。</p><p><strong>chunk迁移原理</strong></p><p>chunk迁移操作通过moveChunk命令发起，moveChunk命令即可以被balancer自动调用（balancer每隔10s扫描哪些chunk需要被迁移），也支持用户主动发起。迁移chunk的整个过程实际上就是一次两个shard进行数据交换的过程，发送chunk的一方称为发送方（donorShard），接收chunk的一方称为接收方（recipientShard）。发送方和接收方通过一系列精心设计的步骤来实现chunk的迁移。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602174250750.png" alt="image-20240602174250750"></p><p>完成一次chunk迁移需要进行以下7个步骤：1）发送方发起迁移: configsvr向发送方请求进行指定chunk的迁移任务（同一时刻只能执行一个chunk迁移）。如果此时发现已有一个相同的chunk的迁移任务，跳过此次迁移，否则会新发起一个迁移任务。</p><p>2）接收方发起chunk拷贝: 发送方进行迁移参数的校验，校验通过后，向接收方发送recvChunkStart命令，接收方进行一些传送文档数据的初始化工作后，会不断重复地向发送方发送migrateClone命令批量拉取chunk中的文档并将拉取的文档进行批量插入，即进行文档的全量拷贝。</p><p>3）接收方拉取增量修改: 文档全量拷贝完成后，接收方通过不断重复发送transferMods命令拉取chunk的增量修改（包括插入、更新、删除），并将其应用到自身。</p><p>4）发送方等待接收方chunk拷贝完成: 发送方不断向接收方发送recvChunkStatus命令查询文档增量同步是否完成或超时，当增量同步完成时，表示此时接受方已进入“steady”状态，可以进行接下来的流程。</p><p>5）发送方进入临界区: 一旦当接收方的文档数据同步完成，发送方就会进入临界区(critical section)，此时发送方接下来的操作不可被打断，并且所有发送方的写操作将被挂起，直到发送方退出临界区。</p><p>6）接收方执行commit: 发送方进入临界区后，接下来会同步地调用recvChunkCommit命令给接收方，接收方再一次进行chunk文档的增量同步，同步完成后，向接收方返回同步完成的结果，接收方退出临界区。</p><p>7）configsvr执行commit: 接收方收到同步完成的结果后，向configsvr发送configsvrCommitChunkMigration命令，表示迁移完成。（configsvrCommitChunkMigration命令返回前，发送方的读操作会被挂起）</p><p>以上便为MongoDB进行chunk迁移的基本步骤，在下一节我们将会从源码层面对迁移流程的每一阶段代码做详细解读。</p><p>想看源码的点击下面网址详细查看！</p><p>转载自：<a href="https://mp.weixin.qq.com/s/JCbkayq07H34RMs8sUmKEA">万字详解，吃透 MongoDB！</a></p>]]></content>
    
    
    <summary type="html">万字详解，吃透 MongoDB！</summary>
    
    
    
    <category term="数据库" scheme="https://penge666.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="数据库" scheme="https://penge666.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>聊聊MVCC</title>
    <link href="https://penge666.github.io/posts/5f51f1dd.html"/>
    <id>https://penge666.github.io/posts/5f51f1dd.html</id>
    <published>2024-06-02T07:28:05.000Z</published>
    <updated>2024-06-02T08:04:51.198Z</updated>
    
    <content type="html"><![CDATA[<p>推荐2篇经典论文：</p><ul><li>MVCC：<a href="https://www.vldb.org/pvldb/vol10/p781-Wu.pdf">An Empirical Evaluation of InMemory Multi-Version Concurrency Control</a></li><li>GC：<a href="http://www.vldb.org/pvldb/vol13/p128-bottcher.pdf">Scalable Garbage Collection for In-Memory MVCC Systems</a></li></ul><p>先聊聊第一篇的趣事，论文最初投稿时使用的并不是这个标题，而是《This is the Best Paper Ever on In-Memory Multi-Version Concurrency Control》。据Andrew Pavlo（论文作者之一，CMU Associate Professor）称他们给VLDB投稿时得到的Review反馈非常正面，要求他们更换题目。哈哈哈哈哈哈，大佬总是那么自信~</p><h2 id="MVCC简介">MVCC简介</h2><ul><li><p>MVCC（Multi-Version Concurrency Control）字面包含了两个方面的内容：</p><ul><li>Multi-Versioning：产生多版本的数据内容，使得读写可以不互相阻塞。</li><li>Concurrency Control：并发控制，使得并行执行的内容能保持串行化结果。</li></ul><p>例如，对于SQL：<code>SELECT a FROM tab_1 where id = 1;</code>，事务T1和T3可以访问到不同版本的数据结果：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="operator">|</span> T1                                <span class="operator">|</span> T2                                   <span class="operator">|</span> T3                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span><span class="comment">---|-----------------------------------|--------------------------------------|-----------------------------------|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span> <span class="operator">|</span> <span class="keyword">BEGIN</span>;                            <span class="operator">|</span>                                      <span class="operator">|</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span> <span class="operator">|</span>                                   <span class="operator">|</span> <span class="keyword">BEGIN</span>;                               <span class="operator">|</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span> <span class="operator">|</span>                                   <span class="operator">|</span> <span class="keyword">UPDATE</span> tab_1 <span class="keyword">SET</span> a <span class="operator">=</span> <span class="number">2</span> <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="operator">|</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span> <span class="operator">|</span>                                   <span class="operator">|</span> <span class="keyword">COMMIT</span>;                              <span class="operator">|</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span> <span class="operator">|</span>                                   <span class="operator">|</span>                                      <span class="operator">|</span> <span class="keyword">BEGIN</span>;                            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">6</span> <span class="operator">|</span> <span class="keyword">SELECT</span> a <span class="keyword">FROM</span> tab_1 <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="operator">|</span>                                      <span class="operator">|</span> <span class="keyword">SELECT</span> a <span class="keyword">FROM</span> tab_1 <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="number">1</span>; <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------------------------------------------------------------------------+</span></span><br></pre></td></tr></table></figure><p>T1在T2前开启，T3在T2修改记录后开启，因此T1读到的是修改前的版本，T3读到的是commit后的版本。</p><p>MVCC的目的是<strong>让不同的事务都能运行在各自的快照版本数据下而不互相阻塞</strong>：写操作写操作可以生成新版本数据，而读操作仍能够读到旧的版本。目前很多主流的DBMS都支持MVCC，如：MySQL、Microsoft SQL Server、Oracle、Hekaton等。</p><p>虽然诞生已久，也有很多数据库支持，但是MVCC并没有一个“标准”的实现。不同的数据库在MVCC的设计上都有自己的权衡和取舍，不同的设计在不同场景下也有性能上的差异。</p><p>MVCC的实现主要可以分为四个关键模块设计：</p><ul><li>并发控制协议</li><li>版本数据存储</li><li>垃圾清理机制</li><li>索引管理</li></ul><p>我们后面将会逐一介绍不同模块的多种设计与实现。不过首先，让我们来认识一下为了支持MVCC，DMBS中需要补充什么样的元数据。</p></li></ul><h2 id="版本数据形式">版本数据形式</h2><p>从<strong>事务</strong>（transaction）维度和<strong>数据行</strong>（tuple）维度而言，为了支持MVCC，都需要引入特定的Metadata。</p><p>对于<strong>事务</strong>，DBMS需要提供一个唯一的标识符区分不同事务。这个标识符通常是单调递增的时间戳（可以是0、1、2的序号，也可以是真实时间），我们把它称作事务的ID。有了<code>TID</code>，DMBS可以用他们来标记数据行的版本。</p><p>对于<strong>数据行</strong>，DBMS需要以下4个字段来在并发事务中进行定位：</p><ul><li><code>txn-id</code>：事务ID，并可用作写锁</li><li><code>begin-ts</code>与<code>end-ts</code>：代表版本数据的生命周期</li><li><code>pointer</code>：指向同一行数据相邻（新/旧）版的指针，依靠指针，版本数据可以形成一个<strong>单向</strong>链表</li></ul><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153258896.png" alt="image-20240602153258896"></p><p>MVCC中的MV是通过版本数据行的这些Metadata实现的，如果我们把模型稍微简化一下，只要记录有<code>begin-ts</code>和<code>end-ts</code>，我们就可以通过对比他们与当前事务的<code>TID</code>判断出哪个版本行才是事务可见的。而CC的实现，实际上也可以独立于MV存在，例如通过Timestamp Ordering或Two-phase Locking保持事务的串行性。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153307531.png" alt="image-20240602153307531"></p><h2 id="并发控制协议">并发控制协议</h2><p>每个DBMS系统都需要有一套并发控制协议，这套协议需要做的事情有两个：</p><ul><li>判定特定事务是否可以访问或修改特定版本的数据</li><li>判定特定事务是否可以提交它的改动</li></ul><p>注意通过这套协议，MVCC解决的是不同事务间执行顺序和结果的问题（而不是多版本数据），也就是通过<strong>锁</strong>或者<strong>时间顺序</strong>保持串行性。本节中将介绍两种协议：MVTO和MV2PL，MVOCC与Serialization Certifier可以在论文中进一步了解。</p><h3 id="Timestamp-Ordering-MVTO">Timestamp Ordering (MVTO)</h3><p>MVTO的设计思路是依赖时间顺序保证事务的串行性执行结果：</p><ul><li>写锁依然通过<code>txn-id</code>来实现，只要<code>txn-id</code>不为0或者不为事务自己的<code>TID</code>，说明有其他事务进行了改动，第二个想进行改动的事务将会终止</li><li>读锁通过时间先后顺序保证，并发读的场景中互不阻塞，但是会将读取这个版本数据行的最大<code>TID</code>进行记录，如果有未来事务进行了读取（尽管它已经发生，也就是发生在过去），那么当前事务将不能修改这行数据（不能新增版本数据行）</li></ul><p>MVTO的实现关键在于借助事务的唯一标识符（<code>TID</code>，即时间戳）来计算不同事务的先后顺序。</p><p>在这个实现中，版本数据行除了上面提到的Metadata字段外，还引入了一个<code>read-ts</code>字段，它记录的是上一个读取它的事务<code>TID</code>。</p><p>当事务T对逻辑数据行A进行读操作时，DBMS需要根据当前的<code>TID</code>搜寻A合适的版本数据，使得<code>TID</code>落在begin-ts和end-ts之间。同时，事务T能读到的数据必须是<code>txn-id</code>为0或<code>TID</code>的，意味着数据行没有被其他事务加上写锁，因为MVTO不允许事务读取到未提交的改动。在读取A的版本数据Ax时，如果Ax的<code>read-ts</code>小于<code>TID</code>，则将该字段修改为<code>TID</code>。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153402967.png" alt="image-20240602153402967"></p><p>在MVTO中，事务更新数据行的结果总是生成一个该数据行的最新版本。事务T在满足如下条件的时候，可以对版本<code>Bx</code>进行更新：</p><ul><li><code>Bx</code>版本数据没有被其他事务加上写锁</li><li><code>TID</code>必须大于等于<code>Bx</code>的<code>read-ts</code>，代表没有在<code>TID</code>之后的事务读了这行数据</li></ul><p>更新时事务T会新增一个版本数据<code>Bx+1</code>，它的<code>txn-id</code>等于<code>TID</code>。在事务T提交的时候，<code>Bx+1</code>的<code>begin-ts</code>设为<code>TID</code>，<code>end-ts</code>设为<code>INF</code>，并且将上一个版本数据<code>Bx</code>的<code>end-ts</code>设为<code>TID</code>。</p><h3 id="Optimistic-Concurrency-Control-OCC">Optimistic Concurrency Control (OCC)</h3><p>OCC 是 H.T. KUNG 在 CMU 任教时提出的并发控制算法。在 OCC 中，数据库为每个事务都创建一个私有空间：</p><ul><li>所有被读取的数据都复制到私有空间中</li><li>所有修改都在私有空间中执行</li></ul><p>OCC 分为 3 个阶段：</p><ol><li>Read Phase：追踪、记录每个事务的读、写集合，并存储到私有空间中</li><li>Validation Phase：当事务提交时，检查冲突</li><li>Write Phase：如果校验成功，则合并数据；否则中止并重启事务</li></ol><p>DBMS 需要维持所有活跃事务的全局视角，并将 Validation Phase 和 Write Phase 的逻辑放入一个 critical section 中。</p><p><strong>OCC - Example</strong></p><p>事务 𝑇1 读取 A 时，将 A 复制到自己的 workspace 中，可以看到，与 Basic T/O 相比，OCC 只需要记录一个时间戳，W-TS。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153459749.png" alt="image-20240602153459749"></p><p>事务 𝑇2 读取 A 时，同样将 A 复制到自己的 workspace 中：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153527180.png" alt="image-20240602153527180"></p><p>事务 𝑇2 完成数据操作，在 Validation Phase 中获得事务时间戳 1，由于没有数据写入，跳过 Write Phase</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153545234.png" alt="image-20240602153545234"></p><p>事务 𝑇1 修改 A 的值为 456，由于尚不知道自己的事务时间戳，将 W-TS(A) 设置为无穷大：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153603371.png" alt="image-20240602153603371"></p><p>事务 𝑇1 在 Validation Phase 获得事务时间戳 2，并通过校验，将 W-TS(A) 修改为 2，并合并到数据库中</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153618764.png" alt="image-20240602153618764"></p><h4 id="OCC-Read-Phase">OCC - Read Phase</h4><p>追踪事务的读写集合 (read/write sets)，将 read set 存放在 private workspace 中用来保证 repeatable read，将 write set 存放在 private workspace 中用来作冲突检测。</p><h4 id="OCC-Validation-Phase">OCC - Validation Phase</h4><p>在进入 Validation Phase 后，每个事务都会被赋予一个时间戳，然后与其它正在运行的事务执行 Timestamp Ordering 检查，检查的方式有两种：</p><ol><li>Backward Validation</li><li>Forward Validation</li></ol><p>如下图所示，在 Backward Validation 中，需要检查待提交的事务 (txn #2) 的读写集合是否与已经提交的事务的读写集合存在交集：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153635989.png" alt="image-20240602153635989"></p><p>与此类似，在 Forward Validation 中，需要检查待提交的事务 (txn #2) 的读写集合是否与尚未提交的事务的读写集合存在交集：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153648206.png" alt="image-20240602153648206"></p><p>如果 𝑇𝑆(𝑇𝑖)&lt;𝑇𝑆(𝑇𝑗)，那么以下 3 个条件之一必须成立：</p><blockquote><p>Condition 1: 𝑇𝑖Tcompletes all three phases before 𝑇𝑗 begins</p></blockquote><p>如果事务 𝑇𝑖在事务 𝑇𝑗 开始之前已经完成 OCC 的所有 3 个阶段，那么二者之间不存在任何冲突。</p><blockquote><p>Condition 2: 𝑇𝑖 completes before 𝑇𝑗starts its <strong>Write Phase</strong>, and 𝑇𝑖does not write to any object read by 𝑇𝑗</p></blockquote><p>如果 𝑇𝑖在 𝑇𝑗 的 Write Phase 开始前就已提交，同时 𝑇𝑖 没有修改任意 𝑇𝑗 读取的数据，即 𝑊𝑟𝑖𝑡𝑒𝑆𝑒𝑡(𝑇𝑖)∩𝑅𝑒𝑎𝑑𝑆𝑒𝑡(𝑇𝑗)=∅ ，则二者之间不存在冲突。</p><blockquote><p>Condition 3: 𝑇𝑖 completes its <strong>Read Phase</strong> before 𝑇𝑗 completes its Read Phase, and 𝑇𝑖 does not write to any object that is either read or written by 𝑇𝑗</p></blockquote><p>如果 𝑇𝑖在 𝑇𝑗结束自己的 Read Phase 前结束 Read Phase，同时 𝑇𝑖 没有修改任何 𝑇𝑗读取或修改的数据，即满足：</p><p>𝑊𝑟𝑖𝑡𝑒𝑆𝑒𝑡(𝑇𝑖)∩𝑅𝑒𝑎𝑑𝑆𝑒𝑡(𝑇𝑗)=∅ , 𝑊𝑟𝑖𝑡𝑒𝑆𝑒𝑡(𝑇𝑖)∩𝑊𝑟𝑖𝑡𝑒𝑆𝑒𝑡(𝑇𝑗)=∅</p><p>时，二者之间不存在冲突。</p><p>OCC 与 Basic T/O 的思路类似，都是在检查事务之间的 WW、WR 冲突。当冲突发生的频率很低时，即：</p><ul><li>大部分事务都是读事务</li><li>大部分事务之间访问的数据间没有交集</li></ul><p>OCC 的表现很好，如在数据库体量较大，workload 比较均衡的场景下。2PC 的性能瓶颈在于锁管理，尽管 OCC 没有加锁的成本，但它也存在性能问题:</p><ul><li>在 private workspace 与 global database 之间移动、合并数据开销大</li><li>Validation/Write Phase 需要在一个全局的 critical section 中完成，可能造成瓶颈</li><li>在 Validation Phase 中，待提交事务需要和其它事务做冲突检查，即便实际上并没有冲突，这里也有很多获取 latch 的成本 (锁住其它事务的 private workspace，对比是否有冲突，再释放锁)</li><li>事务中止的成本比 2PL 高，因为 OCC 在事务执行快结束时才检查数据冲突</li></ul><h3 id="Two-phase-Locking-MV2PL">Two-phase Locking (MV2PL)</h3><p>MV2PL仍然使用<code>begin-ts</code>和<code>end-ts</code>来决定版本记录是否可见。是否可读、可写，由读写锁来控制。</p><p>MV2PL使用<code>read-cnt</code>作为读锁，当寻找到对应版本行数据时，通过<code>read-cnt</code>加1可以给版本数据加读锁。同时，在版本数据持有写锁时，<code>read-cnt</code>不能进行递增。</p><p><strong>2PL，顾名思义，有两个阶段：growing 和 shrinking：</strong></p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602153911817.png" alt="image-20240602153911817"></p><p>但是2PL会有脏读问题，会导致级联终止！</p><p>事实上 2PL 还有一个增强版变种，Rigorous 2PL，后者<strong>每个事务在结束之前，其写过的数据不能被其它事务读取或者重写</strong>，如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602154001534.png" alt="image-20240602154001534"></p><p>Rigorous 2PL 可以避免级联中止，而且回滚操作很简单。</p><h2 id="版本数据存储">版本数据存储</h2><p>在MVCC中，每次的更新都会创建一个新的版本数据。版本数据行中的指针负责指向前一个版本的数据或后一个版本的数据，以此形成一个单向的版本链。版本链不能是双向链表，因为双向链表的修改操作需要加锁，不能借助原子指令完成。</p><p>主流的版本数据的存储Schema有多种，不过可以提前透露的是，Delta存储是最优的方案，InnoDB使用的就是Delta存储，Postgres使用了Append-only存储，而极少数的DBMS在使用Time-travel存储。我们将逐一介绍。</p><h3 id="Append-only">Append-only</h3><p>Append-only将所有数据行的不同版本（包括master版本）都存放在同一块空间中（例如同一张表）。每当有逻辑数据更新时，DMBS在表中先请求一个数据行的空间，然后将最新版本的数据复制一份到新数据行空间中，最后将变更内容应用到这一行上。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602154026377.png" alt="image-20240602154026377"></p><p>前面说过，因为锁的关系，没有办法维护一个双向链表的版本数据，那么版本数据的方向就变得非常重要：</p><ul><li>如果版本数据是从老到新（O2N）排列的，那么每次获取较新的版本数据（大部分场景都是如此）都需要遍历整个链表</li><li>如果版本数据是从新到老（N2O）排列的，那么每次插入新的版本数据时，链表的起点都要发生变更</li></ul><p>在O2N的方案中，由于无用版本遍历的存在，这种方案的性能高度依赖于版本数据的垃圾回收机制，如果垃圾回收能够将单链表维持在较短的长度，那么查询的性能是可以有提升的，否则就会很耗费时间。</p><p>而在N2O的方案中，也有方法可以减少变更起点的次数，就是采用一个映射entry代表链表的起点，这样当新版本数据产生时，只有entry指向的地址需要改变，而指向entry的索引则可以不发生变更。这种优化在辅助索引非常多的表上有很好的提升，但是会需要额外的存储空间。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602154038670.png" alt="image-20240602154038670"></p><p>由于Append-only存储的是完整的数据行，即使数据行中只有少量字段发生了变更。这种行为在表中带有非内联数据（即数据不记录在tuple内，如BLOB、TEXT）时会导致引入大量的重复且大体积数据。其中一个优化方式是允许不同的版本数据行指向同一个BLOB、TEXT对象，并且增加<code>cnt</code>元数据来记录引用次数，便于GC处理。</p><h3 id="Time-Travel">Time-Travel</h3><p>Time-Travel和Append-only的存储很相似，版本数据都是链表记录数据行，但是历史的版本数据与最新版本数据的存储空间分离开。在主表上，只有最新的master版本数据，而历史数据的链表存放在一张“Time-Travel”表中。</p><p>在更新逻辑行时，DBMS将master版本的数据复制进“Time-Travel”表中，然后原地更新主表中的数据行，形成新的版本数据。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602154055859.png" alt="image-20240602154055859"></p><p>Time-Travel的设计可以避免索引上的指针频繁更新，因为他们始终指向主表上的master版本数据，并且数据原地更新，地址也没有发生变更。</p><p>但是因为版本数据存储的是完整tuple，因此也会有非内联数据的问题，同样，可以使用共享对象的方式进行优化。</p><h3 id="Delta">Delta</h3><p>最后介绍的Delta存储同样在主表上只维护master版本的数据，然后将版本数据存放在额外的“Delta”空间中。“Delta”空间在MySQL InnoDB和Oracle中指的就是用于rollback的数据段，例如InnoDB中的undo log。</p><p>在更新逻辑数据行时，DMBS同样先申请“delta”空间的位置，然后将被改动的属性的老版本数据写入其中，而不是完整的tuple行。最后DMBS在主表上原地更新master版本的数据。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602154111711.png" alt="image-20240602154111711"></p><p>Delta存储在记录版本数据时表现非常优秀，当UPDATE只操作了数据行的子集时，减少了内存的分配占用，也没有外联数据版本体积过大的问题。然而，在重度读的场景中，为了获得对应的版本数据，DMBS必须从各个字段的版本数据链中获取到对应版本的字段值，再进行拼凑，这就带来了一定的额外开销。</p><p><strong>总结</strong></p><p>由此可见，不同的版本数据存储方案都有各自适应的场景。例如Append-only存储在一些数据分析场景下更佳，因为版本数据存储在连续的空间中，当进行大范围的扫描时可以提高缓存的命中率，而且还可以配合硬件预读进行优化。另外，存储完整数据行的方案（Append-only、Time-Travel）可以暴露物理的版本数据给索引管理系统，为索引管理提供了更多可选的方案，而Delta存储中就没有物理的版本数据行，在以上方面的对比处于劣势。</p><h2 id="垃圾清理机制">垃圾清理机制</h2><p>不断创建版本数据的好处在于，如果一直不进行清理的话，DBMS可以借助它们实现“Time Travel”，意味着可以访问任意时刻的数据快照。Postgre在之前的版本曾经这样做过，但是当他们意识到没有什么场景需要这种功能之后，在新版本就放弃支持了。</p><p>版本数据积累的坏处有很多，包括巨大的存储开销，极高的版本链遍历开销（也取决于版本链的方向和使用场景）。所以自然而然就需要有GC操作去释放这部分的空间。</p><p>GC可以分作3个步骤：</p><ul><li>检测过时版本</li><li>在链表中将它们断开连接（移除链表元素）</li><li>释放空间</li></ul><p>检测过时版本数据有很多方法，例如检测版本行是否由异常的事务创建，或者检查版本行是否对所有活跃事务都不可见。对于后者，可以通过比较版本行的<code>end-ts</code>和活跃事务的<code>TID</code>来实现。DBMS通常可以把事务信息集中存储，但在多核系统上这会是扩展性的一个瓶颈。</p><p>有了检测方法之后，DMBS可以从不同的维度去寻找这些过时版本，比如从版本数据行出发，以及从事务出发。</p><h3 id="Tuple-level">Tuple-level</h3><p>论文中介绍了两种数据行维度的GC方法，VAC和COOP。</p><p>Background Vacuuming（VAC）使用一个后台线程，周期性地扫描数据库以寻找过时的版本。这种方案最简单的实现就是遍历版本数据链表，但是这样做的GC性能很难在数据量增长时同步提升，我们需要减少无目的的遍历，或者让遍历范围能缩小下来。一种优化的方案是让DBMS维护一个bitmap，映射包含改动过数据的block，这样后台的vacuum线程就可以跳过上一次GC以来没有发生数据变更的block。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602154258084.png" alt="image-20240602154258084"></p><p>Cooperative Cleaning（COOP）的思路是改用worker线程进行GC。寻找版本数据时，worker线程也需要跟着版本链表进行遍历，在遍历过程中，如果发现过时版本数据，就直接进行清理。这种方案会存在两个问题：</p><ul><li>只支持O2N的版本数据记录方式，否则worker线程每次遍历的都是靠前的活跃版本数据，找到目标后就停止，不能发现过时数据</li><li>存在“dusty corners”问题，GC与查询任务关联在一起，因此如果逻辑数据创建有多个版本数据后，就没有发生过任何查询，那么这些版本数据就一直没办法得到清理。一般DBMS会通过结合VAC来处理这部分的数据</li></ul><h3 id="Transaction-level">Transaction-level</h3><p>事务维度的GC一般通过事务记录它读写数据行的集合，DBMS需要监控集合中的版本数据是否都过时了。当某个事务的版本数据集合对所有的活跃事务都不可见时，就可以将这个集合中的版本数据都进行GC清理。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602154321693.png" alt="image-20240602154321693"></p><p>简单说：让每个事务都保存着它的读写数据集合 (read/write set)，当 DBMS 决定什么时候这个事务创建的各版本数据可以被回收时，就按照集合内部的数据处理即可。</p><p><strong>总结</strong></p><p>Tuple-level的VAC是最常用的版本数据清理方案，通过增加GC线程的数量可以提升它的性能。但是对比Transaction-level GC，这种方案在出现长事务的时候会对性能有较大的影响，因为长事务意味着它开始之后的所有版本数据都得不到清理，这时候版本数据链就会变得很长，直到长事务提交或者中止。</p><p>解释：</p><p>在数据库系统中，垃圾回收（GC）是一个重要的过程，其目标是清理不再需要的数据版本，释放存储空间。在使用MVCC（多版本并发控制）的数据库中，由于每个事务都可能创建新的数据版本，因此需要一个有效的机制来清理旧的数据版本。这就是版本数据清理方案，通常有Tuple-level GC和Transaction-level GC两种。</p><p><strong>Tuple-level GC</strong>：这种方案中，GC线程会检查每个数据版本，看它是否还被任何事务引用。如果没有，就将其清理掉。这种方案的优点是可以增加GC线程的数量来提升性能，因为每个线程可以独立地检查和清理数据版本。</p><p>但是，Tuple-level GC的问题在于，如果存在长事务，在这个长事务运行期间，它引用的所有数据版本都不能被清理。这可能会导致大量的旧数据版本堆积，占用大量的存储空间，因此对性能有较大的影响。</p><p>举个例子，假设我们有一个大的数据库，里面存储了一个在线商店的所有交易记录。每一次交易都会创建新的数据版本。如果我们有一个长事务正在运行，比如统计过去一年的所有交易，那么这个事务运行期间，所有的交易记录都不能被清理，即使有些交易记录已经很旧了。</p><p><strong>Transaction-level GC</strong>：这种方案中，GC线程会检查每个事务，看它是否还在运行。如果一个事务已经完成，那么这个事务创建的所有数据版本都可以被清理。这种方案的优点是可以更有效地清理旧的数据版本，因为一次可以清理很多的数据版本。但是，这种方案的性能取决于事务的数量和大小，如果有很多大的事务，那么清理的工作可能会很重。</p><p>以上就是Tuple-level GC和Transaction-level GC在面对长事务时对性能影响的原因。在实际的数据库系统中，可能会根据具体的需求和性能考虑，选择合适的版本数据清理方案。</p><h2 id="索引管理">索引管理</h2><p>所有支持MVCC的DBMSs都将版本数据和索引数据分开存储。我们可以将索引看作KV键值对，键是被索引的数据行中的字段值（例如ID），值是索引对应的数据行的指针。</p><p>主键索引的情况比较简单，因为主键（同时也是索引的Key）是保持不变的，索引的Value总是指向版本数据链的起点，比如在InnoDB中，主键索引的数据行就是指向主表的。在主键索引中，索引的键值对指针会发生什么样的变更，取决于DBMS使用了哪种的数据存储方式。</p><p>对于Delta存储，我们上面讨论过，主表永远都是存的master版本数据，它是原地更新的，因此在更新数据时，主表中的数据行位置不发生改变，因此索引Value的指针也没有发生改变。</p><p>对于Append-only的存储，版本数据链有两种不同的方向：</p><ul><li>O2N，新的版本数据Append在版本链的末端，因此索引的Value指针始终指向链表的起点不变；只有在发生GC的时候才会调整指针地址</li><li>N2O，每当产生新版本时，都需要调整索引值的指针，此时DBMS一般会在索引上进行DELETE &amp; INSERT的操作完成调整</li></ul><p>对于辅助索引，被索引的字段值（同时也是索引中的Key）可能改变，索引的Value指向的版本数据也有可能改变。因此有不同的方案对索引中的指针进行管理。</p><h3 id="Logical-Pointers">Logical Pointers</h3><p>最常用的方案是建立一层中间表，让索引的Value能够一直不变，例如指向主键。这种方案也是InnoDB在使用的，所以我们通常说辅助索引会包含被索引值以及主键值。通过主键值将索引中的指针固定下来，这样每当版本数据链表起点发生改变时，只需要同时更新主键值对应的指针。虽然只有一个辅助索引时，听起来改动的复杂度是相同的，都是改变了1处指针，但是当有许多辅助索引时，就会是O(1) vs. O(n)的差异了。</p><p>借助主键的坏处是辅助索引的体积会随着主键体积发生变化，另一个方案是为逻辑tuple提供64-bit的唯一ID。实际上思路并没有区别，都是在物理版本链和索引之间增加了一层映射，只是看映射的内容如何选取一个唯一固定、节约空间的值。</p><h3 id="Physical-Pointers">Physical Pointers</h3><p>Uber曾经发过一篇文章：<a href="https://eng.uber.com/postgres-to-mysql-migration/">《Why Uber Engineering Switched from Postgres to MySQL》</a>，实际上他们并不是一开始就在用Postgres。Uber最早使用的也是MySQL，中途招了一些热衷于Postgres的工程师，所以他们就从MySQL切到了Postgres。他们在表中加了非常多的辅助索引，在使用过程中发现，Postgres的辅助索引是指向磁盘中的版本链起点的，在版本链起点发生变动时，多个辅助索引的指针就要发生修改。在Append-only的存储方式下，这种设计的好处是没有通过中间层映射（例如主键ID）回表查询，坏处也非常明显，当辅助索引非常多的时候，版本数据链起点的变更将会导致所有辅助索引的指针都需要更新。</p><p>目前还有一些DBMS使用了这种方案，例如MemSQL、Hekaton。如果Uber的工程师有读过这篇论文，他们可能可以节约不少的迁移成本。</p><p><strong>解释</strong>：</p><p>在数据库系统中，索引是一种数据结构，它可以帮助我们快速地查找到数据。索引中的每一个条目都是一个键值对，其中键通常是一些列的值，值是这些列值对应的行的位置信息。在使用MVCC（多版本并发控制）的数据库中，每一行数据可能有多个版本，因此索引的值实际上是指向一个版本链的。</p><p>理解逻辑指针和物理指针的关键在于理解，它们在索引中作为值，实际上指向了什么。</p><ol><li><strong>逻辑指针</strong>：逻辑指针实际上存储的是主键的值。当我们需要查找数据时，首先会通过索引找到对应的主键值，然后再通过主键值找到数据。这种方式的好处是，即使数据的位置发生了变化，只要主键值没有变，我们就能找到数据。比如，我们可以把图书的ISBN号视为主键，即使图书在书架上的位置变了，只要我们知道ISBN号，就能找到这本书。</li><li><strong>物理指针</strong>：物理指针则是直接存储了数据的物理位置信息。这意味着我们可以通过物理指针直接找到数据，无需经过主键。这种方式的好处是查找效率高，因为减少了一次查找。但是缺点是，一旦数据的位置发生了变化，物理指针就会失效。比如，我们把图书在书架上的位置作为物理指针，如果图书被移动了，那么我们就无法通过原来的位置找到这本书。</li></ol><p>在实际的数据库系统中，通常会根据具体的需求和性能考虑，选择适合的索引管理策略。</p><p><strong>总结</strong></p><p>同样，不同的管理方式也有各自适合的场景。对于Logical Pointer，在写入频繁的场景下表现更好，因为辅助索引只需要在索引字段值发生改变时才会改变，在读取场景下，它还需要对不同的版本链进行对比，因为同一个逻辑值有可能对应不同的物理值，例如DELETE后再INSERT同一个值；对于Physical Pointers，缺点之前已经提到过，频繁的更新场景会导致写入性能变差，但是在检索时就会有它的优势。</p><p>另外，在支持MVCC的DBMS中，所谓的“覆盖索引”其实并不能通过扫描单个索引得到Query结果，因为索引里面并没有版本数据。对于Append-only的设计，回到主表进行检索是必须的；而对于Delta存储，至少也需要在Delta空间（例如undo log）中查找对应版本。</p><h2 id="总结">总结</h2><p>论文对MVCC的4个要点进行了分类总结：</p><ul><li>并发控制协议：MVTO、MVOCC、MV2PL和Serialization Certifier</li><li>版本数据存储：Append-only、Time-Travel和Delta</li><li>垃圾清理机制：Tuple-level和Transaction-level</li><li>索引管理：Logical Pointers和Physical Pointers</li></ul><p>意在说明MVCC并没有一套标准的实现，不同的实现之间针对具体场景Workload的不同也有着不同的表现。在Paper Reading中我们并没有展示论文中不同Approaches的测试结果，关心的同学可以在文末的链接找到原文查看。</p><p>另外，尽管可以从不同的DBMS中总结出一些共用的实现方案，但是它们各自都有进一步地做不同的优化，例如InnoDB中的undo log管理与GC就比原文的概述复杂得多。</p><p>Q：MySQL中的版本链保存在哪里？</p><p>A：MySQL中的版本链是存储在InnoDB引擎的undo日志中的。在InnoDB中，当一个事务开始时，会生成一个新的读视图。读视图中保留了所有当前未提交的事务的事务ID，而每个事务在开始时都会生成一个唯一的事务ID。</p><p>当我们需要访问一个行记录时，InnoDB会先检查该行记录的事务ID是否在当前读视图的事务ID列表中，如果在，说明该行记录在当前事务开始后有过修改，这时候就需要去undo日志中找到对应的版本来读取；如果不在，说明该行记录在当前事务开始后没有修改，可以直接读取该行记录。</p><p>版本链就是通过undo日志来实现的，每次对行记录的修改都会在undo日志中生成一个新的版本，这些版本通过回滚指针链接起来，形成一个版本链。undo日志分为insert undo和update undo，insert undo用于存储新插入的记录的版本，update undo用于存储更新和删除的记录的版本。</p><p>这就是MySQL中的版本链保存的位置以及它的工作原理。</p><p>补充：</p><p>MySQL中的版本链是对每个数据库表的行进行链式存储的。当一个行记录被更新时，MySQL会保留该行的旧版本，并将新版本和旧版本通过链接形成一个版本链。这样，MySQL可以同时保留和访问同一行的多个版本，这对于实现多版本并发控制（MVCC）是非常有用的。这使得每个事务都可以看到一个一致的快照，而不会被其他正在进行的事务所影响。</p><p>Q：MySQL中的版本链上有索引吗</p><p>A：MySQL中的版本链本身并没有索引。版本链是由每个数据行在进行更新操作时产生的不同版本所形成的链表，这些版本通过UNDO日志中的回滚指针链接起来。当进行查询操作时，通过查找主键索引或二级索引可以找到数据行，然后如果需要读取的版本不是最新版本，就会沿着版本链向后查找，直到找到对应的版本为止。这个查找过程是顺序进行的，没有索引来加速。这也是为什么在MySQL中，长时间运行的事务可能会影响性能的原因之一，因为版本链可能会变得很长，导致查找特定版本的时间变长。</p><p>学习自：<a href="https://jiekun.dev/posts/mvcc/#transaction-level">Paper Reading：聊一聊MVCC</a></p><p>好文推荐：<a href="https://www.cnblogs.com/jelly12345/p/14889331.html">https://www.cnblogs.com/jelly12345/p/14889331.html</a></p>]]></content>
    
    
    <summary type="html">聊聊Multi-Version Concurrency Control</summary>
    
    
    
    <category term="数据库" scheme="https://penge666.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="数据库" scheme="https://penge666.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper基础篇</title>
    <link href="https://penge666.github.io/posts/ccd40453.html"/>
    <id>https://penge666.github.io/posts/ccd40453.html</id>
    <published>2024-06-01T13:42:49.000Z</published>
    <updated>2024-06-02T13:42:45.335Z</updated>
    
    <content type="html"><![CDATA[<h2 id="01-ZooKeeper-数据模型：节点的特性与应用">01 ZooKeeper 数据模型：节点的特性与应用</h2><p>ZooKeeper 基础知识基本分为三大模块：</p><ul><li>数据模型</li><li>ACL 权限控制</li><li>Watch 监控</li></ul><p>其中，数据模型是最重要的，很多 ZooKeeper 中典型的应用场景都是利用这些基础模块实现的。比如我们可以利用数据模型中的临时节点和 Watch 监控机制来实现一个发布订阅的功能。</p><h3 id="数据模型">数据模型</h3><p>计算机最根本的作用其实就是处理和存储数据，作为一款分布式一致性框架，ZooKeeper 也是如此。数据模型就是 ZooKeeper 用来存储和处理数据的一种逻辑结构。就像我们用 MySQL 数据库一样，要想处理复杂业务。前提是先学会如何往里边新增数据。ZooKeeper 数据模型最根本的功能就像一个数据库。</p><p>现在，数据模型对我们来说还是一个比较抽象的概念，接下来我们开始部署一个开发测试环境，并在上面做一些简单的操作。来看看 ZooKeeper 的数据模型究竟是什么样的：</p><ol><li>配置文件</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tickTime=<span class="number">2000</span></span><br><span class="line"></span><br><span class="line">dataDir=/<span class="keyword">var</span>/lib/zookeeper</span><br><span class="line"></span><br><span class="line">clientPort=<span class="number">2181</span></span><br></pre></td></tr></table></figure><ol><li>服务启动</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh start</span><br></pre></td></tr></table></figure><ol><li>使用客户端连接服务器</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkCli.sh -server <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">2181</span></span><br></pre></td></tr></table></figure><ol><li>这样单机版的开发环境就已经构建完成了，接下来我们通过 ZooKeeper 提供的 create 命令来创建几个节点，分别是：“/locks”“/servers”“/works”：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create /locks</span><br><span class="line"></span><br><span class="line">create /servers</span><br><span class="line"></span><br><span class="line">create /works</span><br></pre></td></tr></table></figure><p>最终在 ZooKeeper 服务器上会得到一个具有层级关系的数据结构，如下图所示，这个数据结构就是 ZooKeeper 中的数据模型。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214357114.png" alt="image-20240601214357114"></p><p>ZooKeeper 中的数据模型是一种树形结构，非常像电脑中的文件系统，有一个根文件夹，下面还有很多子文件夹。ZooKeeper 的数据模型也具有一个固定的根节点（/），我们可以在根节点下创建子节点，并在子节点下继续创建下一级节点。ZooKeeper 树中的每一层级用斜杠（/）分隔开，且只能用绝对路径（如“get /work/task1”）的方式查询 ZooKeeper 节点，而不能使用相对路径。具体的结构你可以看看下面这张图：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214410026.png" alt="image-20240601214410026"></p><h3 id="znode-节点类型与特性">znode 节点类型与特性</h3><p>知道了 ZooKeeper 的数据模型是一种树形结构，就像在 MySQL 中数据是存在于数据表中，ZooKeeper 中的数据是由多个数据节点最终构成的一个层级的树状结构，和我们在创建 MySOL 数据表时会定义不同类型的数据列字段，ZooKeeper 中的数据节点也分为持久节点、临时节点和有序节点三种类型：</p><h4 id="1、持久节点">1、持久节点</h4><p>我们第一个介绍的是持久节点，这种节点也是在 ZooKeeper 最为常用的，几乎所有业务场景中都会包含持久节点的创建。之所以叫作持久节点是因为一旦将节点创建为持久节点，该数据节点会一直存储在 ZooKeeper 服务器上，即使创建该节点的客户端与服务端的会话关闭了，该节点依然不会被删除。如果我们想删除持久节点，就要显式调用 delete 函数进行删除操作。</p><h4 id="2、临时节点">2、临时节点</h4><p>接下来我们来介绍临时节点。从名称上我们可以看出该节点的一个最重要的特性就是临时性。所谓临时性是指，如果将节点创建为临时节点，那么该节点数据不会一直存储在 ZooKeeper 服务器上。当创建该临时节点的客户端会话因超时或发生异常而关闭时，该节点也相应在 ZooKeeper 服务器上被删除。同样，我们可以像删除持久节点一样主动删除临时节点。</p><p>在平时的开发中，我们可以利用临时节点的这一特性来做服务器集群内机器运行情况的统计，将集群设置为“/servers”节点，并为集群下的每台服务器创建一个临时节点“/servers/host”，当服务器下线时该节点自动被删除，最后统计临时节点个数就可以知道集群中的运行情况。如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214425685.png" alt="image-20240601214425685"></p><h4 id="3、有序节点">3、有序节点</h4><p>最后我们再说一下有序节点，其实有序节点并不算是一种单独种类的节点，而是在之前提到的持久节点和临时节点特性的基础上，增加了一个节点有序的性质。所谓节点有序是说在我们创建有序节点的时候，ZooKeeper 服务器会自动使用一个单调递增的数字作为后缀，追加到我们创建节点的后边。例如一个客户端创建了一个路径为 works/task- 的有序节点，那么 ZooKeeper 将会生成一个序号并追加到该节点的路径后，最后该节点的路径为 works/task-1。通过这种方式我们可以直观的查看到节点的创建顺序。</p><p>到目前为止我们知道在 ZooKeeper 服务器上存储数据的基本信息，知道了 ZooKeeper 中的数据节点种类有持久节点和临时节点等。上述这几种数据节点虽然类型不同，但 ZooKeeper 中的每个节点都维护有这些内容：一个二进制数组（byte data[]），用来存储节点的数据、ACL 访问控制信息、子节点数据（因为临时节点不允许有子节点，所以其子节点字段为 null），除此之外每个数据节点还有一个记录自身状态信息的字段 stat。</p><p>下面我们详细说明节点的状态信息。</p><h3 id="节点的状态结构">节点的状态结构</h3><p>每个节点都有属于自己的状态信息，这就很像我们每个人的身份信息一样，我们打开之前的客户端，执行 stat /zk_test，可以看到控制台输出了一些信息，这些就是节点状态信息。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214440092.png" alt="image-20240601214440092"></p><p>每一个节点都有一个自己的状态属性，记录了节点本身的一些信息，这些属性包括的内容我列在了下面这个表格里：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214456572.png" alt="image-20240601214456572"></p><h3 id="数据节点的版本">数据节点的版本</h3><p>这里我们重点讲解一下版本相关的属性，在 ZooKeeper 中为数据节点引入了版本的概念，每个数据节点有 3 种类型的版本信息，对数据节点的任何更新操作都会引起版本号的变化。ZooKeeper 的版本信息表示的是对节点数据内容、子节点信息或者是 ACL 信息的修改次数。</p><h4 id="使用-ZooKeeper-实现锁">使用 ZooKeeper 实现锁</h4><p>学习了 ZooKeeper 的数据模型和数据节点的相关知识，下面我们通过实际的应用进一步加深理解。</p><p>设想这样一个情景：一个购物网站，某个商品库存只剩一件，客户 A 搜索到这件商品并准备下单，但在这期间客户 B 也查询到了该件商品并提交了购买，于此同时，客户 A 也下单购买了此商品，这样就出现了只有一件库存的商品实际上卖出了两件的情况。为了解决这个问题，我们可以在客户 A 对商品进行操作的时候对这件商品进行锁定从而避免这种超卖的情况发生。</p><p>实现锁的方式有很多中，这里我们主要介绍两种：悲观锁、乐观锁。</p><p><strong>悲观锁</strong> 悲观锁认为进程对临界区的竞争总是会出现，为了保证进程在操作数据时，该条数据不被其他进程修改。数据会一直处于被锁定的状态。</p><p>我们假设一个具有 n 个进程的应用，同时访问临界区资源，我们通过进程创建 ZooKeeper 节点 /locks 的方式获取锁。</p><p>线程 a 通过成功创建 ZooKeeper 节点“/locks”的方式获取锁后继续执行，如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214512591.png" alt="image-20240601214512591"></p><p>这时进程 b 也要访问临界区资源，于是进程 b 也尝试创建“/locks”节点来获取锁，因为之前进程 a 已经创建该节点，所以进程 b 创建节点失败无法获得锁。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214529182.png" alt="image-20240601214529182"></p><p>这样就实现了一个简单的悲观锁，不过这也有一个隐含的问题，就是当进程 a 因为异常中断导致 /locks 节点始终存在，其他线程因为无法再次创建节点而无法获取锁，这就产生了一个死锁问题。针对这种情况我们可以通过将节点设置为临时节点的方式避免。并通过在服务器端添加监听事件来通知其他进程重新获取锁。</p><p><strong>乐观锁</strong> 乐观锁认为，进程对临界区资源的竞争不会总是出现，所以相对悲观锁而言。加锁方式没有那么激烈，不会全程的锁定资源，而是在数据进行提交更新的时候，对数据的冲突与否进行检测，如果发现冲突了，则拒绝操作。</p><p>**乐观锁基本可以分为读取、校验、写入三个步骤。**CAS（Compare-And-Swap），即比较并替换，就是一个乐观锁的实现。CAS 有 3 个操作数，内存值 V，旧的预期值 A，要修改的新值 B。当且仅当预期值 A 和内存值 V 相同时，将内存值 V 修改为 B，否则什么都不做。</p><p>在 ZooKeeper 中的 version 属性就是用来实现乐观锁机制中的“校验”的，ZooKeeper 每个节点都有数据版本的概念，在调用更新操作的时候，假如有一个客户端试图进行更新操作，它会携带上次获取到的 version 值进行更新。而如果在这段时间内，ZooKeeper 服务器上该节点的数值恰好已经被其他客户端更新了，那么其数据版本一定也会发生变化，因此肯定与客户端携带的 version 无法匹配，便无法成功更新，因此可以有效地避免一些分布式更新的并发问题。</p><p>在 ZooKeeper 的底层实现中，当服务端处理 setDataRequest 请求时，首先会调用 checkAndIncVersion 方法进行数据版本校验。ZooKeeper 会从 setDataRequest 请求中获取当前请求的版本 version，同时通过 getRecordForPath 方法获取服务器数据记录 nodeRecord， 从中得到当前服务器上的版本信息 currentversion。如果 version 为 -1，表示该请求操作不使用乐观锁，可以忽略版本对比；如果 version 不是 -1，那么就对比 version 和 currentversion，如果相等，则进行更新操作，否则就会抛出 BadVersionException 异常中断操作。</p><h3 id="总结">总结</h3><p>主要介绍了ZooKeeper的基础知识点——<strong>数据模型。并深入介绍了节点类型、stat 状态属性等知识，并利用目前学到的知识解决了集群中服务器运行情况统计、悲观锁、乐观锁等问题</strong>。</p><p><strong>为什么 ZooKeeper 不能采用相对路径查找节点呢？</strong></p><p>这是因为 ZooKeeper 大多是应用场景是定位数据模型上的节点，并在相关节点上进行操作。像这种查找与给定值相等的记录问题最适合用散列来解决。因此 ZooKeeper 在底层实现的时候，使用了一个 hashtable，即 hashtableConcurrentHashMap nodes ，用节点的完整路径来作为 key 存储节点数据。这样就大大提高了 ZooKeeper 的性能。</p><h2 id="02-发布订阅模式：如何使用-Watch-机制实现分布式通知">02 发布订阅模式：如何使用 Watch 机制实现分布式通知</h2><p>我们来学习 ZooKeeper 又一关键技术——Watch 监控机制，并用它实现一个发布订阅功能。</p><p>在日常生活中也有很多订阅发布的场景。比如我们喜欢观看某一个剧集，视频网站会有一个订阅按钮，用户可以订阅自己喜欢的电视剧，当有新的剧集发布时，网站会通知该用户第一时间观看。或者我们在网站上看到一件心仪的商品，但是当前没有库存，网站会提供到货通知的功能，我们开启这个商品的到货通知功能后，商品补货的时候会通知我们，之后就可以进行购买了。ZooKeeper 中的 Watch 机制很像这些日常的应用场景，其中的客户端就是用户，而服务端的数据节点就好像是我们订阅的商品或剧集。</p><p>现在我们可以从技术实现的角度分析一下上边提到的这些场景，无论是订阅一集电视剧还是订购一件商品。都有几个核心节点，即用户端注册服务、服务端处理请求、客户端收到回调后执行相应的操作。接下来我们也带着这个观点来看一下 ZooKeeper 中的 Watch 机制是如何实现的。</p><h3 id="Watch-机制是如何实现的">Watch 机制是如何实现的</h3><p>正如我们可以通过点击视频网站上的”收藏“按钮来订阅我们喜欢的内容，ZooKeeper 的客户端也可以通过 Watch 机制来订阅当服务器上某一节点的数据或状态发生变化时收到相应的通知，我们可以通过向 ZooKeeper 客户端的构造方法中传递 Watcher 参数的方式实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="title class_">ZooKeeper</span>(String connectString, <span class="type">int</span> sessionTimeout, Watcher watcher)</span><br></pre></td></tr></table></figure><p>上面代码的意思是定义了一个了 ZooKeeper 客户端对象实例，并传入三个参数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">connectString 服务端地址</span><br><span class="line"></span><br><span class="line">sessionTimeout：超时时间</span><br><span class="line"></span><br><span class="line">Watcher：监控事件</span><br></pre></td></tr></table></figure><p>这个 Watcher 将作为整个 ZooKeeper 会话期间的上下文 ，一直被保存在客户端 ZKWatchManager 的 defaultWatcher 中。</p><p>除此之外，ZooKeeper 客户端也可以通过 getData、exists 和 getChildren 三个接口来向 ZooKeeper 服务器注册 Watcher，从而方便地在不同的情况下添加 Watch 事件：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">getData</span>(<span class="title class_">String</span> path, <span class="title class_">Watcher</span> watcher, <span class="title class_">Stat</span> stat)</span><br></pre></td></tr></table></figure><p>知道了 ZooKeeper 添加服务器监控事件的方式，下面我们来讲解一下触发通知的条件。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214646207.png" alt="image-20240601214646207"></p><p>上图中列出了客户端在不同会话状态下，相应的在服务器节点所能支持的事件类型。例如在客户端连接服务端的时候，可以对数据节点的创建、删除、数据变更、子节点的更新等操作进行监控。</p><p>现在我们已经从应用层的角度了解了 ZooKeeper 中的 Watch 机制，而学习 ZooKeeper 过程中一个大问题就是入门容易精通难，像上边我们通过几个简单的 API 调用就可以对服务器的节点状态变更进行监控，但是在实际生产环境中我们会遇到很多意想不到的问题，要想解决好这些问题就要深入理解 Watch 的底层实现机制。</p><h3 id="Watch-机制的底层原理">Watch 机制的底层原理</h3><p>现在我们就深入底层了解其背后的实现原理。与上个课时直接通过底层代码的调用过程来分析不同，在 Watch 底层实现的分析阶段，由于 Watch 机制涉及了客户端和服务端的多个函数和操作节点，单单按照程序执行流程分析跳跃性对整体实现机制的理解难度大，这也是我在学习 Watch 这部分底层实现遇到的问题。为了更好地阐述 Watch 机制，我们另辟蹊径，从设计模式角度出发来分析其底层实现：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214659082.png" alt="image-20240601214659082"></p><p>【简单说，思考整个过程，就是网络发送，回调处理】</p><p>最初我在开始学习 Watch 机制的时候，它给我的第一印象是，其结构很像设计模式中的”观察者模式“，一个对象或者数据节点可能会被多个客户端监控，当对应事件被触发时，会通知这些对象或客户端。我们可以将 Watch 机制理解为是分布式环境下的观察者模式。所以接下来我们就以观察者模式的角度点来看看 ZooKeeper 底层 Watch 是如何实现的。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214711961.png" alt="image-20240601214711961"></p><p>通常我们在实现观察者模式时，最核心或者说关键的代码就是创建一个列表来存放观察者。 而在 ZooKeeper 中则是在客户端和服务器端分别实现两个存放观察者列表，即：ZKWatchManager 和 WatchManager。其核心操作就是围绕着这两个展开的。</p><h4 id="客户端-Watch-注册实现过程">客户端 Watch 注册实现过程</h4><p>我们先看一下客户端的实现过程，在发送一个 Watch 监控事件的会话请求时，ZooKeeper 客户端主要做了两个工作：</p><ul><li>标记该会话是一个带有 Watch 事件的请求</li><li>将 Watch 事件存储到 ZKWatchManager</li></ul><p>我们以 getData 接口为例。当发送一个带有 Watch 事件的请求时，客户端首先会把该会话标记为带有 Watch 监控的事件请求，之后通过 DataWatchRegistration 类来保存 watcher 事件和节点的对应关系：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">byte</span>[] getData(<span class="keyword">final</span> String path, Watcher watcher, Stat stat)&#123;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="type">WatchRegistration</span> <span class="variable">wcb</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (watcher != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">    wcb = <span class="keyword">new</span> <span class="title class_">DataWatchRegistration</span>(watcher, clientPath);</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">RequestHeader</span> <span class="variable">h</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RequestHeader</span>();</span><br><span class="line"></span><br><span class="line">  request.setWatch(watcher != <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="type">GetDataResponse</span> <span class="variable">response</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GetDataResponse</span>();</span><br><span class="line"></span><br><span class="line">  <span class="type">ReplyHeader</span> <span class="variable">r</span> <span class="operator">=</span> cnxn.submitRequest(h, request, response, wcb);</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>之后客户端向服务器发送请求时，是将请求封装成一个 Packet 对象，并添加到一个等待发送队列 outgoingQueue 中：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Packet <span class="title function_">queuePacket</span><span class="params">(RequestHeader h, ReplyHeader r，...)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">Packet</span> <span class="variable">packet</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    packet = <span class="keyword">new</span> <span class="title class_">Packet</span>(h, r, request, response, watchRegistration);</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    outgoingQueue.add(packet); </span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> packet;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后，ZooKeeper 客户端就会向服务器端发送这个请求，完成请求发送后。调用负责处理服务器响应的 SendThread 线程类中的 readResponse 方法接收服务端的回调，并在最后执行 finishPacket（）方法将 Watch 注册到 ZKWatchManager 中：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">finishPacket</span><span class="params">(Packet p)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">err</span> <span class="operator">=</span> p.replyHeader.getErr();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (p.watchRegistration != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">            p.watchRegistration.register(err);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">       ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="服务端-Watch-注册实现过程">服务端 Watch 注册实现过程</h4><p>介绍完客户端对 Watch 请求的发送过程，下面我们来看一下服务端是如何处理一个 Watch 事件。</p><p>Zookeeper 服务端处理 Watch 事件基本有 2 个过程：</p><ul><li>解析收到的请求是否带有 Watch 注册事件</li><li>将对应的 Watch 事件存储到 WatchManager</li></ul><p>下面我们分别对这 2 个步骤进行分析：</p><p>当 ZooKeeper 服务器接收到一个客户端请求后，首先会对请求进行解析，判断该请求是否包含 Watch 事件。这在 ZooKeeper 底层是通过 FinalRequestProcessor 类中的 processRequest 函数实现的。当 getDataRequest.getWatch() 值为 True 时，表明该请求需要进行 Watch 监控注册。并通过 zks.getZKDatabase().getData 函数将 Watch 事件注册到服务端的 WatchManager 中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processRequest</span><span class="params">(Request request)</span> &#123;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="type">byte</span> b[] =                zks.getZKDatabase().getData(getDataRequest.getPath(), stat,</span><br><span class="line"></span><br><span class="line">        getDataRequest.getWatch() ? cnxn : <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">rsp = <span class="keyword">new</span> <span class="title class_">GetDataResponse</span>(b, stat);</span><br><span class="line"></span><br><span class="line">..</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="服务端-Watch-事件的触发过程">服务端 Watch 事件的触发过程</h4><p>在客户端和服务端都对 watch 注册完成后，我们接下来看一下在 ZooKeeper 中触发一个 Watch 事件的底层实现过程：</p><p>我们以 setData 接口即“节点数据内容发生变更”事件为例。在 setData 方法内部执行完对节点数据的变更后，会调用 WatchManager.triggerWatch 方法触发数据变更事件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Stat <span class="title function_">setData</span><span class="params">(String path, <span class="type">byte</span> data[], ...)</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">Stat</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Stat</span>();</span><br><span class="line"></span><br><span class="line">        <span class="type">DataNode</span> <span class="variable">n</span> <span class="operator">=</span> nodes.get(path);</span><br><span class="line"></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">        dataWatches.triggerWatch(path, EventType.NodeDataChanged);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> s;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>下面我们进入 triggerWatch 函数内部来看看他究竟做了哪些工作。首先，封装了一个具有会话状态、事件类型、数据节点 3 种属性的 WatchedEvent 对象。之后查询该节点注册的 Watch 事件，如果为空说明该节点没有注册过 Watch 事件。如果存在 Watch 事件则添加到定义的 Wathcers 集合中，并在 WatchManager 管理中删除。最后，通过调用 process 方法向客户端发送通知。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">Set&lt;Watcher&gt; <span class="title function_">triggerWatch</span><span class="params">(String path, EventType type...)</span> &#123;</span><br><span class="line"></span><br><span class="line">       <span class="type">WatchedEvent</span> <span class="variable">e</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WatchedEvent</span>(type,</span><br><span class="line"></span><br><span class="line">               KeeperState.SyncConnected, path);</span><br><span class="line"></span><br><span class="line">       Set&lt;Watcher&gt; watchers;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123;</span><br><span class="line"></span><br><span class="line">           watchers = watchTable.remove(path);</span><br><span class="line"></span><br><span class="line">           ...</span><br><span class="line"></span><br><span class="line">           <span class="keyword">for</span> (Watcher w : watchers) &#123;</span><br><span class="line"></span><br><span class="line">               Set&lt;String&gt; paths = watch2Paths.get(w);</span><br><span class="line"></span><br><span class="line">               <span class="keyword">if</span> (paths != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">                   paths.remove(path);</span><br><span class="line"></span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> (Watcher w : watchers) &#123;</span><br><span class="line"></span><br><span class="line">           <span class="keyword">if</span> (supress != <span class="literal">null</span> &amp;&amp; supress.contains(w)) &#123;</span><br><span class="line"></span><br><span class="line">               <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">           w.process(e);</span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> watchers;</span><br><span class="line"></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h4 id="客户端回调的处理过程">客户端回调的处理过程</h4><p>知道了服务器端 Watch 事件的触发过程后，我们来看一下客户端接收到通知后如何进行操作的。</p><p>客户端使用 SendThread.readResponse() 方法来统一处理服务端的相应。首先反序列化服务器发送请求头信息 replyHdr.deserialize(bbia, “header”)，并判断相属性字段 xid 的值为 -1，表示该请求响应为通知类型。在处理通知类型时，首先将己收到的字节流反序列化转换成 WatcherEvent 对象。接着判断客户端是否配置了 chrootPath 属性，如果为 True 说明客户端配置了 chrootPath 属性。需要对接收到的节点路径进行 chrootPath 处理。最后调用 eventThread.queueEvent( ）方法将接收到的事件交给 EventThread 线程进行处理</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (replyHdr.getXid() == -<span class="number">1</span>) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="type">WatcherEvent</span> <span class="variable">event</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WatcherEvent</span>();</span><br><span class="line"></span><br><span class="line">    event.deserialize(bbia, <span class="string">&quot;response&quot;</span>);</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (chrootPath != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">serverPath</span> <span class="operator">=</span> event.getPath();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(serverPath.compareTo(chrootPath)==<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            event.setPath(<span class="string">&quot;/&quot;</span>);</span><br><span class="line"></span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">            event.setPath(serverPath.substring(chrootPath.length()));</span><br><span class="line"></span><br><span class="line">            ...</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">WatchedEvent</span> <span class="variable">we</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">WatchedEvent</span>(event);</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    eventThread.queueEvent( we );</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来我们来看一下 EventThread.queueEvent() 方法内部的执行逻辑。其主要工作分为 2 点： 第 1 步按照通知的事件类型，从 ZKWatchManager 中查询注册过的客户端 Watch 信息。客户端在查询到对应的 Watch 信息后，会将其从 ZKWatchManager 的管理中删除。因此这里也请你多注意，客户端的 Watcher 机制是一次性的，触发后就会被删除。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Set&lt;Watcher&gt; <span class="title function_">materialize</span><span class="params">(...)</span></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">Set&lt;Watcher&gt; result = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;Watcher&gt;();</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> (type) &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> NodeDataChanged:</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> NodeCreated:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">synchronized</span> (dataWatches) &#123;</span><br><span class="line"></span><br><span class="line">        addTo(dataWatches.remove(clientPath), result);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">synchronized</span> (existWatches) &#123;</span><br><span class="line"></span><br><span class="line">        addTo(existWatches.remove(clientPath), result);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">    ....</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成了第 1 步工作获取到对应的 Watcher 信息后，将查询到的 Watcher 存储到 waitingEvents 队列中，调用 EventThread 类中的 run 方法会循环取出在 waitingEvents 队列中等待的 Watcher 事件进行处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">  isRunning = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line"></span><br><span class="line">     <span class="type">Object</span> <span class="variable">event</span> <span class="operator">=</span> waitingEvents.take();</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span> (event == eventOfDeath) &#123;</span><br><span class="line"></span><br><span class="line">        wasKilled = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">        processEvent(event);</span><br><span class="line"></span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">if</span> (wasKilled)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">synchronized</span> (waitingEvents) &#123;</span><br><span class="line"></span><br><span class="line">           <span class="keyword">if</span> (waitingEvents.isEmpty()) &#123;</span><br><span class="line"></span><br><span class="line">              isRunning = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">              <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">     ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后调用 processEvent(event) 方法来最终执行实现了 Watcher 接口的 process（）方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">processEvent</span><span class="params">(Object event)</span> &#123;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (event <span class="keyword">instanceof</span> WatcherSetEventPair) &#123;</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line"></span><br><span class="line">      <span class="type">WatcherSetEventPair</span> <span class="variable">pair</span> <span class="operator">=</span> (WatcherSetEventPair) event;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (Watcher watcher : pair.watchers) &#123;</span><br><span class="line"></span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">              watcher.process(pair.event);</span><br><span class="line"></span><br><span class="line">          &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line"></span><br><span class="line">              LOG.error(<span class="string">&quot;Error while calling watcher &quot;</span>, t);</span><br><span class="line"></span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到目前为止我们将 ZooKeeper 中 Watch 机制的处理过程全部学习了一遍，大体上讲 ZooKeeper 实现的方式是通过客服端和服务端分别创建有观察者的信息列表。客户端调用 getData、exist 等接口时，首先将对应的 Watch 事件放到本地的 ZKWatchManager 中进行管理。服务端在接收到客户端的请求后根据请求类型判断是否含有 Watch 事件，并将对应事件放到 WatchManager 中进行管理。</p><p>在事件触发的时候服务端通过节点的路径信息查询相应的 Watch 事件通知给客户端，客户端在接收到通知后，首先查询本地的 ZKWatchManager 获得对应的 Watch 信息处理回调操作。这种设计不但实现了一个分布式环境下的观察者模式，而且通过将客户端和服务端各自处理 Watch 事件所需要的额外信息分别保存在两端，减少彼此通信的内容。大大提升了服务的处理性能。</p><h3 id="订阅发布场景实现">订阅发布场景实现</h3><p>现在我们已经知道 Watch 事件在 ZooKeeper 中的完整处理过程，接下来我们通过一个实际应用来加深我们对 ZooKeeper 中 Watch 机制的理解。</p><p>提到 ZooKeeper 的应用场景，你可能第一时间会想到最为典型的发布订阅功能。发布订阅功能可以看作是一个一对多的关系，即一个服务或数据的发布者可以被多个不同的消费者调用。一般一个发布订阅模式的数据交互可以分为消费者主动请求生产者信息的拉取模式，和生产者数据变更时主动推送给消费者的推送模式。ZooKeeper 采用了两种模式结合的方式实现订阅发布功能。下面我们来分析一个具体案例：</p><p>在系统开发的过程中会用到各种各样的配置信息，如数据库配置项、第三方接口、服务地址等，这些配置操作在我们开发过程中很容易完成，但是放到一个大规模的集群中配置起来就比较麻烦了。通常这种集群中，我们可以用配置管理功能自动完成服务器配置信息的维护，利用ZooKeeper 的发布订阅功能就能解决这个问题。</p><p>我们可以把诸如数据库配置项这样的信息存储在 ZooKeeper 数据节点中。如图中的 /confs/data_item1。服务器集群客户端对该节点添加 Watch 事件监控，当集群中的服务启动时，会读取该节点数据获取数据配置信息。而当该节点数据发生变化时，ZooKeeper 服务器会发送 Watch 事件给各个客户端，集群中的客户端在接收到该通知后，重新读取节点的数据库配置信息。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214733308.png" alt="image-20240601214733308"></p><p>我们使用 Watch 机制实现了一个分布式环境下的配置管理功能，通过对 ZooKeeper 服务器节点添加数据变更事件，实现当数据库配置项信息变更后，集群中的各个客户端能接收到该变更事件的通知，并获取最新的配置信息。<strong>要注意一点是，我们提到 Watch 具有一次性，所以当我们获得服务器通知后要再次添加 Watch 事件。</strong></p><h3 id="总结-2">总结</h3><p>学习了 ZooKeeper 中非常重要的基础知识——Watch 监控机制。详细分析了 ZooKeeper 在处理 Watch 事件的底层实现，并通过我们掌握的知识实现了一个集群环境下的配置管理功能。</p><p>现在我有一个思考题留给你：“当服务端某一节点发生数据变更操作时，所有曾经设置了该节点监控事件的客户端都会收到服务器的通知吗？答案是否定的，通过本课时对 ZooKeeper 内部实现机制的解析可以知道，Watch 事件的触发机制取决于会话的连接状态和客户端注册事件的类型，所以当客户端会话状态或数据节点发生改变时，都会触发对应的 Watch 事件。</p><h2 id="03-ACL-权限控制：如何避免未经授权的访问？">03 ACL 权限控制：如何避免未经授权的访问？</h2><p>之前，我们学习了数据模型节点、Watch 监控机制等知识。并利用这些知识实现了在分布式环境中经常用到的诸如分布式锁、配置管理等功能。这些功能的本质都在于操作数据节点，而如果作为分布式锁或配置项的数据节点被错误删除或修改，那么对整个分布式系统有很大的影响，甚至会造成严重的生产事故。而作为在分布式领域应用最为广泛的一致性解决框架，ZooKeeper 提供一个很好的解决方案那就是 ACL 权限控制。</p><p>说到 ACL 可能你会觉得陌生，但是提到权限控制相信你一定很熟悉。比如 Linux 系统将对文件的使用者分为三种身份，即 User、Group、Others。使用者对文件拥有读（read） 写（write）以及执行（execute）3 种方式的控制权。这种权限控制方式相对比较粗糙，在复杂的授权场景下往往并不适用。比如下边一个应用场景。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214908300.png" alt="image-20240601214908300"></p><p>上图给出了某个技术开发公司的一个工作项目 /object 。项目中的每个开发人员都可以读取和修改该项目中的文件，作为开发组长也对这个项目文件具有读取和修改的权限。其他技术开发组的员工则不能访问这个项目。如果我们用之前说到的 Linux 权限应该怎么设计呢？</p><p>首先作为技术组长使用 User 身份，具有读、写、执行权限。项目组其他成员使用 Group 身份，具有读写权限，其他项目组的人员则没有任何权限。这样就实现了满足要求的权限设定了。</p><p>但是，如果技术组新加入一个实习人员，为了能让他熟悉项目，必须具有该项目的读取的权限。但是目前他不具备修改项目的能力，所以并没给他赋予写入的权限。而如果使用现有的权限设置，显然将其分配给 User 用户或者 Group 用户都并不合适。而如果修改 Others 用户的权限，其他项目组的成员也能访问该项目文件。显然普通的三种身份的权限划分是无法满足要求的。而 ZooKeeper 中的 ACl 就能应对这种复杂的权限应用场景。</p><h3 id="ACL-的使用">ACL 的使用</h3><p>下面我们来讲解一下如何使用 ZooKeeper 的 ACL 机制来实现客户端对数据节点的访问控制。</p><p>一个 ACL 权限设置通常可以分为 3 部分，分别是：权限模式（Scheme）、授权对象（ID）、权限信息（Permission）。最终组成一条例如“scheme:id:permission”格式的 ACL 请求信息。下面我们具体看一下这 3 部分代表什么意思：</p><h4 id="权限模式：Scheme">权限模式：Scheme</h4><p>权限模式就是用来设置 ZooKeeper 服务器进行权限验证的方式。ZooKeeper 的权限验证方式大体分为两种类型，一种是范围验证，另外一种是口令验证。所谓的范围验证就是说 ZooKeeper 可以针对一个 IP 或者一段 IP 地址授予某种权限。比如我们可以让一个 IP 地址为“ip：192.168.0.11”的机器对服务器上的某个数据节点具有写入的权限。或者也可以通过“ip:192.168.0.11/22”给一段 IP 地址的机器赋权。</p><p>另一种权限模式就是口令验证，也可以理解为用户名密码的方式，这是我们最熟悉也是日常生活中经常使用的模式，比如我们打开自己的电脑或者去银行取钱都需要提供相应的密码。在 ZooKeeper 中这种验证方式是 Digest 认证，我们知道通过网络传输相对来说并不安全，所以“绝不通过明文在网络发送密码”也是程序设计中很重要的原则之一，而 Digest 这种认证方式首先在客户端传送“username:password”这种形式的权限表示符后，ZooKeeper 服务端会对密码 部分使用 SHA-1 和 BASE64 算法进行加密，以保证安全性。另一种权限模式 Super 可以认为是一种特殊的 Digest 认证。具有 Super 权限的客户端可以对 ZooKeeper 上的任意数据节点进行任意操作。下面这段代码给出了 Digest 模式下客户端的调用方式。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建节点</span></span><br><span class="line"></span><br><span class="line">create /digest_node1</span><br><span class="line"></span><br><span class="line"><span class="comment">//设置digest权限验证</span></span><br><span class="line"></span><br><span class="line">setAcl /digest_node1 digest:用户名:base64格式密码:rwadc </span><br><span class="line"></span><br><span class="line"><span class="comment">//查询节点Acl权限</span></span><br><span class="line"></span><br><span class="line">getAcl /digest_node1 </span><br><span class="line"></span><br><span class="line"><span class="comment">//授权操作</span></span><br><span class="line"></span><br><span class="line">addauth digest user:passwd</span><br></pre></td></tr></table></figure><p>最后一种授权模式是 world 模式，其实这种授权模式对应于系统中的所有用户，本质上起不到任何作用。设置了 world 权限模式系统中的所有用户操作都可以不进行权限验证。</p><h4 id="授权对象（ID）">授权对象（ID）</h4><p>接下来我们再看一下授权对象部分，其实这个很好理解，所谓的授权对象就是说我们要把权限赋予谁，而对应于 4 种不同的权限模式来说，如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段；而如果使用 Digest 或 Super 方式，则对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。</p><h4 id="权限信息（Permission）">权限信息（Permission）</h4><p>介绍完授权方式以及授权对象，下面我们学习 ACL 请求信息中的最后一项：权限（Permission）。权限就是指我们可以在数据节点上执行的操作种类，如下图所示：在 ZooKeeper 中已经定义好的权限有 5 种：</p><ul><li>数据节点（create）创建权限，授予权限的对象可以在数据节点下创建子节点；</li><li>数据节点（wirte）更新权限，授予权限的对象可以更新该数据节点；</li><li>数据节点（read）读取权限，授予权限的对象可以读取该节点的内容以及子节点的信息；</li><li>数据节点（delete）删除权限，授予权限的对象可以删除该数据节点的子节点；</li><li>数据节点（admin）管理者权限，授予权限的对象可以对该数据节点体进行 ACL 权限设置。</li></ul><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214925230.png" alt="image-20240601214925230"></p><p>需要注意的一点是，<strong>每个节点都有维护自身的 ACL 权限数据，即使是该节点的子节点也是有自己的 ACL 权限而不是直接继承其父节点的权限</strong>。如下中“172.168.11.1”服务器有“/Config”节点的读取权限，但是没有其子节点的“/Config/dataBase_Config1”权限。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214939192.png" alt="image-20240601214939192"></p><h4 id="实现自己的权限口控制">实现自己的权限口控制</h4><p>通过上边的介绍我们了解了 ZooKeeper 中的权限相关知识，虽然 ZooKeeper 自身的权限控制机制已经做得很细，但是它还是提供了一种权限扩展机制来让用户实现自己的权限控制方式。官方文档中对这种机制的定义是 “Pluggable ZooKeeper Authenication”，意思是可插拔的授权机制，从名称上我们可以看出它的灵活性。那么这种机制是如何实现的呢？</p><p>首先，要想实现自定义的权限控制机制，最核心的一点是实现 ZooKeeper 提供的权限控制器接口 AuthenticationProvider。下面这张图片展示了接口的内部结构，用户通过该接口实现自定义的权限控制。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601214950210.png" alt="image-20240601214950210"></p><p>实现了自定义权限后，如何才能让 ZooKeeper 服务端使用自定义的权限验证方式呢？接下来就需要将自定义的权限控制注册到 ZooKeeper 服务器中，而注册的方式通常有两种。</p><p>第一种是通过设置系统属性来注册自定义的权限控制器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Dzookeeper.authProvider.x=CustomAuthenticationProvider</span><br></pre></td></tr></table></figure><p>另一种是在配置文件 zoo.cfg 中进行配置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">authProvider.x=CustomAuthenticationProvider</span><br></pre></td></tr></table></figure><h3 id="ACL-内部实现原理">ACL 内部实现原理</h3><p>到目前为止我们学习了 ACL 权限控制机制应用层方面的相关知识，下面就深入到底层学习一下 ZooKeeper 是如何实现的。</p><h4 id="客户端处理过程">客户端处理过程</h4><p>我们先看一下客户端是如何操作的，我们以节点授权 addAuth 接口为例，首先客户端通过 ClientCnxn 类中的 addAuthInfo 方法向服务端发送 ACL 权限信息变更请求，该方法首先将 scheme 和 auth 封装成 AuthPacket 类，并通过 RequestHeader 方法表示该请求是权限操作请求，最后将这些数据统一封装到 packet 中，并添加到 outgoingQueue 队列中发送给服务端。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addAuthInfo</span><span class="params">(String scheme, <span class="type">byte</span> auth[])</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!state.isAlive()) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    authInfo.add(<span class="keyword">new</span> <span class="title class_">AuthData</span>(scheme, auth));</span><br><span class="line"></span><br><span class="line">    queuePacket(<span class="keyword">new</span> <span class="title class_">RequestHeader</span>(-<span class="number">4</span>, OpCode.auth), <span class="literal">null</span>,</span><br><span class="line"></span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">AuthPacket</span>(<span class="number">0</span>, scheme, auth), <span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>, <span class="literal">null</span>,</span><br><span class="line"></span><br><span class="line">            <span class="literal">null</span>, <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ACL 权限控制机制的客户端实现相对简单，只是封装请求类型为权限请求，方便服务器识别处理，而发送到服务器的信息包括我们之前提到的权限校验信息。</p><h4 id="服务端实现过程">服务端实现过程</h4><p>相比于客户端的处理过程，服务器端对 ACL 内部实现就比较复杂，当节点授权请求发送到服务端后，在服务器的处理中首先调用 readRequest（）方法作为服务器处理的入口，其内部只是调用 processPacket 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">readRequest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">    zkServer.processPacket(<span class="built_in">this</span>, incomingBuffer);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而在 processPacket 方法的内部，首先反序列化客户端的请求信息并封装到 AuthPacket 对象中。之后通过 getServerProvider 方法根据不同的 scheme 判断具体的实现类，这里我们使用 Digest 模式为例，因此该实现类是 DigestAuthenticationProvider 。之后调用其 handleAuthentication() 方法进行权限验证。如果返 KeeperException.Code.OK 则表示该请求已经通过了权限验证，如果返回的状态是其他或者抛出异常则表示权限验证失败。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processPacket</span><span class="params">(ServerCnxn cnxn, ByteBuffer incomingBuffer)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">       ...</span><br><span class="line"></span><br><span class="line"> ServerAuthenticationProvider         ap=ProviderRegistry.getServerProvider(scheme);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(ap != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">authReturn = ap.handleAuthentication(<span class="keyword">new</span>                          <span class="title class_">ServerAuthenticationProvider</span>.ServerObjs(<span class="built_in">this</span>, cnxn), authPacket.getAuth());</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">       ...</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>现在我们知道了权限认证的最终实现函数是 handleAuthentication 函数，而这个函数内部实现的逻辑就很清晰简单了，主要的工作就是解析客户端传递的权限验证类型，并通过 addAuthInfo 函数将权限信息添加到 authInfo 集合属性中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> KeeperException.Code </span><br><span class="line"></span><br><span class="line">        <span class="title function_">handleAuthentication</span><span class="params">(ServerCnxn cnxn, <span class="type">byte</span>[] authData)</span></span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">String</span>(authData);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">            <span class="type">String</span> <span class="variable">digest</span> <span class="operator">=</span> generateDigest(id);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (digest.equals(superDigest)) &#123;</span><br><span class="line"></span><br><span class="line">                cnxn.addAuthInfo(<span class="keyword">new</span> <span class="title class_">Id</span>(<span class="string">&quot;super&quot;</span>, <span class="string">&quot;&quot;</span>));</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            cnxn.addAuthInfo(<span class="keyword">new</span> <span class="title class_">Id</span>(getScheme(), digest));</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> KeeperException.Code.OK;</span><br><span class="line"></span><br><span class="line">       ...</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里我们重点讲解一下 addAuthInfo 函数，其作用是将解析到的权限信息存储到 ZooKeeper 服务器的内存中，该信息在整个会话存活期间一直会保存在服务器上，如果会话关闭，该信息则会被删，这个特性很像我们之前学过的数据节点中的临时节点。</p><p>经过上面的步骤，服务器已经将客户端 ACL 请求解析并将对应的会话权限信息存储在服务器上，下面我们再看一下服务器是如何进行权限验证的。首先，在处理一次权限请求时，先通过 PrepRequestProcessor 中的 checkAcl 函数检查对应的请求权限，如果该节点没有任何权限设置则直接返回，如果该节点有权限设置则循环遍历节点信息进行检查，如果具有相应的权限则直接返回表明权限认证成功，否则最后抛出 NoAuthException 异常中断操作表明权限认证失败。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">checkACL</span><span class="params">(...)</span>&#123;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (ACL a : acl) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(authId.getScheme().equals(id.getScheme()..)&#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">KeeperException</span>.NoAuthException();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到目前为止我们对 ACL 权限在 ZooKeeper 服务器客户端和服务端的底层实现过程进行了深度的分析。总体来说，客户端在 ACL 权限请求发送过程的步骤比较简单：首先是封装该请求的类型，之后将权限信息封装到 request 中并发送给服务端。而服务器的实现比较复杂，首先分析请求类型是否是权限相关操作，之后根据不同的权限模式（scheme）调用不同的实现类验证权限最后存储权限信息。本课时的例子采用了授权接口 addAuth 而没有采用权限设置接口 setAcl，是因为权限设置接口相对简单，其核心功能点已经包括在授权接口实现中。而在授权接口中，值得注意的是会话的授权信息存储在 ZooKeeper 服务端的内存中，如果客户端会话关闭，授权信息会被删除。下次连接服务器后，需要重新调用授权接口进行授权。</p><h3 id="总结-3">总结</h3><p>ZooKeeper 作为分布式系统协调框架，往往在一个分布式系统下起到关键的作用。尤其是在分布式锁、配置管理等应用场景中。如果因为错误操作对重要数据节点进行变更或删除，对整个分布式系统影响很大，甚至会导致整个分布式服务不可用。所以当你在设计使用 ZooKeeper 的时候一定要考虑对关键节点添加权限控制。</p><h2 id="04-ZooKeeper-如何进行序列化？">04 ZooKeeper 如何进行序列化？</h2><p>我们大概清楚了使用 ZooKeeper 实现一些功能的主要方式，也就是通过客户端与服务端之间的相互通信。那么首先要解决的问题就是通过网络传输数据，而要想通过网络传输我们定义好的 Java 对象数据，必须要先对其进行序列化。例如，我们通过 ZooKeeper 客户端发送 ACL 权限控制请求时，需要把请求信息封装成 packet 类型，经过序列化后才能通过网络将 ACL 信息发送给 ZooKeeper 服务端进行处理。</p><h4 id="什么是序列化，为什么要进行序列化操作">什么是序列化，为什么要进行序列化操作</h4><p>序列化是指将我们定义好的 Java 类型转化成数据流的形式。之所以这么做是因为在网络传输过程中，TCP 协议采用“流通信”的方式，提供了可以读写的字节流。而这种设计的好处在于避免了在网络传输过程中经常出现的问题：比如消息丢失、消息重复和排序等问题。那么什么时候需要序列化呢？如果我们需要通过网络传递对象或将对象信息进行持久化的时候，就需要将该对象进行序列化。</p><p>我们较为熟悉的序列化操作是在 Java中，当我们要序列化一个对象的时候，首先要实现一个 Serializable 接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> Long ids;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现了 Serializable 接口后其实没有做什么实际的工作，它是一个没有任何内容的空接口，起到的作用就是标识该类是需要进行序列化的，这个就与我们后边要重点讲解的 ZooKeeper 序列化实现方法有很大的不同，这里请你先记住当前的写法，后边我们会展开讲解。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义好序列化接口后，我们再看一下如何进行序列化和反序列化的操作。Java 中进行序列化和反序列化的过程中，主要用到了 ObjectInputStream 和 ObjectOutputStream 两个 IO 类。</p><p>ObjectOutputStream 负责将对象进行序列化并存储到本地。而 ObjectInputStream 从本地存储中读取对象信息反序列化对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//序列化</span></span><br><span class="line"></span><br><span class="line"><span class="type">ObjectOutputStream</span> <span class="variable">oo</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectOutputStream</span>()</span><br><span class="line"></span><br><span class="line">oo.writeObject(user);</span><br><span class="line"></span><br><span class="line"><span class="comment">//反序列化</span></span><br><span class="line"></span><br><span class="line"><span class="type">ObjectInputStream</span> <span class="variable">ois</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectInputStream</span>();</span><br><span class="line"></span><br><span class="line"><span class="type">User</span> <span class="variable">user</span> <span class="operator">=</span> (User) ois.readObject();</span><br></pre></td></tr></table></figure><p>到目前为止我们了解了什么是序列化，以及为什么要进行序列化，并通过我们熟悉的 Java 编程语言中的序列化实现，进一步对序列化操作有更加具体的了解。我们知道，当我们要把对象进行本地存储或网络传输时是需要进行序列化操作的，而在 ZooKeeper 中需要频繁的网络传输工作，那么在 ZooKeeper 中是如何进行序列化的呢，我们带着这个问题继续下面的学习。</p><h4 id="ZooKeeper-中的序列化方案">ZooKeeper 中的序列化方案</h4><p>在 ZooKeeper 中并没有采用和 Java 一样的序列化方式，而是采用了一个 Jute 的序列解决方案作为 ZooKeeper 框架自身的序列化方式，说到 Jute 框架，它最早作为 Hadoop 中的序列化组件。之后 Jute 从 Hadoop 中独立出来，成为一个独立的序列化解决方案。ZooKeeper 从最开始就采用 Jute 作为其序列化解决方案，直到其最新的版本依然没有更改。</p><p>虽然 ZooKeeper 一直将 Jute 框架作为序列化解决方案，但这并不意味着 Jute 相对其他框架性能更好，反倒是 Apache Avro、Thrift 等框架在性能上优于前者。之所以 ZooKeeper 一直采用 Jute 作为序列化解决方案，主要是新老版本的兼容等问题，这里也请你注意，也许在之后的版本中，ZooKeeper 会选择更加高效的序列化解决方案。</p><h4 id="使用-Jute-实现序列化">使用 Jute 实现序列化</h4><p>简单介绍了 Jute 框架的发展过程，下面我们来看一下如何使用 Jute 在 ZooKeeper 中实现序列化。如果我们要想将某个定义的类进行序列化，首先需要该类实现 Record 接口的 serilize 和 deserialize 方法，这两个方法分别是序列化和反序列化方法。下边这段代码给出了我们一般在 ZooKeeper 中进行序列化的具体实现：首先，我们定义了一个 test_jute 类，为了能够对它进行序列化，需要该 test_jute 类实现 Record 接口，并在对应的 serialize 序列化方法和 deserialize 反序列化方法中编辑具体的实现逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">test_jute</span> <span class="keyword">implements</span> <span class="title class_">Record</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> ids；</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">serialize</span><span class="params">(OutpurArchive a_,String tag)</span>&#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deserialize</span><span class="params">(INputArchive a_,String tag)</span>&#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而在序列化方法 serialize 中，我们要实现的逻辑是，首先通过字符类型参数 tag 传递标记序列化标识符，之后使用 writeLong 和 writeString 等方法分别将对象属性字段进行序列化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">serialize</span><span class="params">(OutpurArchive a_,String tag)</span> <span class="keyword">throws</span> ...&#123;</span><br><span class="line"></span><br><span class="line">  a_.startRecord(<span class="built_in">this</span>.tag);</span><br><span class="line"></span><br><span class="line">  a_.writeLong(ids,<span class="string">&quot;ids&quot;</span>);</span><br><span class="line"></span><br><span class="line">  a_.writeString(type,<span class="string">&quot;name&quot;</span>);</span><br><span class="line"></span><br><span class="line">  a_.endRecord(<span class="built_in">this</span>,tag);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而调用 derseralize 在实现反序列化的过程则与我们上边说的序列化过程正好相反。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deserialize</span><span class="params">(INputArchive a_,String tag)</span> <span class="keyword">throws</span> &#123;</span><br><span class="line"></span><br><span class="line">  a_.startRecord(tag);</span><br><span class="line"></span><br><span class="line">  ids = a_.readLong(<span class="string">&quot;ids&quot;</span>);</span><br><span class="line"></span><br><span class="line">  name = a_.readString(<span class="string">&quot;name&quot;</span>);</span><br><span class="line"></span><br><span class="line">  a_.endRecord(tag);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里我们就介绍完了如何在 ZooKeeper 中使用 Jute 实现序列化，需要注意的是，<strong>在实现了Record 接口后，具体的序列化和反序列化逻辑要我们自己在 serialize 和 deserialize 函数中完成</strong>。</p><p>序列化和反序列化的实现逻辑编码方式相对固定，首先通过 startRecord 开启一段序列化操作，之后通过 writeLong、writeString 或 readLong、 readString 等方法执行序列化或反序列化。本例中只是实现了长整型和字符型的序列化和反序列化操作，除此之外 ZooKeeper 中的 Jute 框架还支持 整数类型（Int）、布尔类型（Bool）、双精度类型（Double）以及 Byte/Buffer 类型。</p><h4 id="Jute-在-ZooKeeper-中的底层实现">Jute 在 ZooKeeper 中的底层实现</h4><p>正因为 ZooKeeper 的设计目的是将复杂的底层操作封装成简单易用的接口，从而方便用户调用，也使得我们在使用 ZooKeeper 实现序列化的时候能够更加容易。</p><p>学会了利用 Jute 实现序列化和反序列化后，我们深入底层，看一下 ZooKeeper 框架具体是如何实现序列化操作的。正如上边我们提到的，通过简单的实现 Record 接口就可以实现序列化，那么我们接下来就以这个接口作为入口，详细分析其底层原理。</p><p>Record 接口可以理解为 ZooKeeper 中专门用来进行网络传输或本地存储时使用的数据类型。因此所有我们实现的类要想传输或者存储到本地都要实现该 Record 接口。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Record</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">serialize</span><span class="params">(OutputArchive archive, String tag)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">deserialize</span><span class="params">(InputArchive archive, String tag)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Record 接口的内部实现逻辑非常简单，只是定义了一个 序列化方法 serialize 和一个反序列化方法 deserialize 。而在 Record 起到关键作用的则是两个重要的类：OutputArchive 和 InputArchive ，其实这两个类才是真正的序列化和反序列化工具类。</p><p>在 OutputArchive 中定义了可进行序列化的参数类型，根据不同的序列化方式调用不同的实现类进行序列化操作。如下图所示，Jute 可以通过 Binary 、 Csv 、Xml 等方式进行序列化操作。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601215044427.png" alt="image-20240601215044427"></p><p>而对应于序列化操作，在反序列化时也会相应调用不同的实现类，来进行反序列化操作。 如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240601215058769.png" alt="image-20240601215058769"></p><p>注意：无论是序列化还是反序列化，都可以对多个对象进行操作，所以当我们在定义序列化和反序列化方法时，需要字符类型参数 tag 表示要序列化或反序列化哪个对象。</p><h4 id="总结-4">总结</h4><p>为什么需要序列化</p><p>在计算机网络中，数据通常会在不同的系统和设备之间进行传输。这些系统和设备可能有不同的架构和数据表示方式。序列化是将复杂的数据结构转换为字节流的过程，这使得数据能够在网络中进行传输，或者被存储到磁盘上。</p><p>以下是序列化的几个主要原因：</p><ol><li><strong>跨平台通信</strong>：不同的系统或语言有自己的内存管理和数据表示方式。序列化可以将数据转换为通用的格式，使得不同的系统和语言能够理解和使用。</li><li><strong>网络传输</strong>：网络传输的基本单位是字节，复杂的数据结构（如对象、数组等）无法直接在网络中传输。序列化可以将这些数据结构转换为字节流，从而可以在网络中进行传输。</li><li><strong>持久化存储</strong>：序列化也可以用于将数据持久化存储到磁盘中。序列化的数据可以在后续的程序运行中重新加载和使用，实现了数据的持久化。</li></ol><p>因此，无论是为了实现跨平台通信，还是为了网络传输，或者是为了持久化存储，序列化都是必不可少的过程。</p><h2 id="05-深入分析-Jute-的底层实现原理">05 深入分析 Jute 的底层实现原理</h2><p>上个课时我们讲解了 ZooKeeper 中采用 Jute 作为序列化解决的方案，并介绍了其应用层的使用技巧。本课时我们就深入 Jute 框架的内部核心，来看一看其内部的实现原理和算法。而通过研究 Jute 序列化框架的内部的实现原理，能够让我们在日常工作中更加高效安全地使用 Jute 序列化框架。</p><h3 id="简述-Jute-序列化">简述 Jute 序列化</h3><p>通过前面的课时我们知道了序列化就是将 Java 对象转化成字节码的形式，从而方便进行网络传输和本地化存储，那么具体的序列化方法都有哪些呢？这里我们结合 ZooKeeper 中使用到的序列化解决方案 Jute 来进行介绍，Jute 框架给出了 3 种序列化方式，分别是 Binary 方式、Csv 方式、XML 方式。序列化方式可以通俗地理解成我们将 Java 对象通过转化成特定的格式，从而更加方便在网络中传输和本地化存储。之所以采用这 3 种方式的格式化文件，也是因为这 3 种方式具有跨平台和普遍的规约特性，后面我将会对这三种方法的特性进行具体讲解。接下来我将深入 Jute 的底层，看一下这 3 种实现方式的底层实现过程。</p><h3 id="Jute-内部核心算法">Jute 内部核心算法</h3><p>上个课时中我们提到过，ZooKeeper 在实现序列化的时候要实现 Record 接口，而在 Record 接口的内部，真正起作用的是两个工具类，分别是 OutPutArchive 和 InputArchive。下边我们分别来看一下它们在 Jute 内部是如何实现的。</p><p>OutPutArchive 是一个接口，规定了一系列序列化相关的操作。而要实现具体的相关操作，Jute 是通过三个具体实现类分别实现了 Binary、Csv、XML 三种方式的序列化操作。而这三种方式有什么不同，我们在日常工作中应该如何选择呢？带着这些问题我们来深入到 Jute 的内部实现来找寻答案</p><h4 id="Binary-方式的序列化">Binary 方式的序列化</h4><p>首先我们来看一下 Jute 中的第 1 种序列化方式：Binary 序列化方式，即二进制的序列化方式。正如我们前边所提到的，采用这种方式的序列化就是将 Java 对象信息转化成二进制的文件格式。</p><p>在 Jute 中实现 Binary 序列化方式的类是 BinaryOutputArchive。该 BinaryOutputArchive 类通过实现 OutPutArchive 接口，在 Jute 框架采用二进制的方式实现序列化的时候，采用其作为具体的实现类。</p><p>在这里我们通过调用 Record 接口中的 writeString 方法为例，该方法是将 Java 对象的 String 字符类型进行序列化。当调用 writeString 方法后，首先判断所要进行序列化的字符串是否为空。如果是空字符串则采用 writeInt 方法，将空字符串当作值为 -1 的数字类型进行序列化；如果不为空，则调用 stringtoByteBuffer 方法对字符串进行序列化操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">writeString</span> <span class="params">(String s, Sring tag)</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(s==<span class="literal">null</span>)&#123;</span><br><span class="line"></span><br><span class="line">    writeInt(-<span class="number">1</span>,<span class="string">&quot;len&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">ByteBuffer</span> <span class="variable">bb</span> <span class="operator">=</span> stringtoByteBuffer(s);</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而 stringToByteBuffer 方法也是 BinaryOutputArchive 类的内部核心方法，除了 writeString 序列化方法外，其他的比如 writeInt、wirteDoule 等序列化方法则是调用 DataOutPut 接口中的相关方法来实现具体的序列化操作。</p><p>在调用 BinaryOutputArchive 类的 stringToByteBuffer 方法时，在将字符串转化成二进制字节流的过程中，首选将字符串转化成字符数组 CharSequence 对象，并根据 ascii 编码判断字符类型，如果是字母等则使用1个 byte 进行存储。如果是诸如 “¥” 等符号则采用两个 byte 进程存储。如果是汉字则采用3个 byte 进行存储。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">ByteBuffer</span> <span class="variable">bb</span> <span class="operator">=</span> ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">ByteBuffer <span class="title function_">stringToByteBuffer</span><span class="params">(CharSeuquece s)</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (c &lt; <span class="number">0x80</span>) &#123;</span><br><span class="line"></span><br><span class="line">                bb.put((<span class="type">byte</span>) c);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (c &lt; <span class="number">0x800</span>) &#123;</span><br><span class="line"></span><br><span class="line">      bb.put((<span class="type">byte</span>) (<span class="number">0xc0</span> | (c &gt;&gt; <span class="number">6</span>)));</span><br><span class="line"></span><br><span class="line">      bb.put((<span class="type">byte</span>) (<span class="number">0x80</span> | (c &amp; <span class="number">0x3f</span>)));</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">      bb.put((<span class="type">byte</span>) (<span class="number">0xe0</span> | (c &gt;&gt; <span class="number">12</span>)));</span><br><span class="line"></span><br><span class="line">      bb.put((<span class="type">byte</span>) (<span class="number">0x80</span> | ((c &gt;&gt; <span class="number">6</span>) &amp; <span class="number">0x3f</span>)));</span><br><span class="line"></span><br><span class="line">      bb.put((<span class="type">byte</span>) (<span class="number">0x80</span> | (c &amp; <span class="number">0x3f</span>)));</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>Binary 二进制序列化方式的底层实现相对简单，只是采用将对应的 Java 对象转化成二进制字节流的方式。Binary 方式序列化的优点有很多：无论是 Windows 操作系统、还是 Linux 操作系统或者是苹果的 macOS 操作系统，其底层都是对二进制文件进行操作，而且所有的系统对二进制文件的编译与解析也是一样的，所有操作系统都能对二进制文件进行操作，跨平台的支持性更好。而缺点则是会存在不同操作系统下，产生大端小端的问题。</p><h4 id="XML-方式的序列化">XML 方式的序列化</h4><p>说完了 Binary 的序列化方式，我们再来看看 Jute 中的另一种序列化方式 XML 方式。XML 是一种可扩展的标记语言。当初设计的目的就是用来传输和存储数据，很像我们都很熟悉的 HTML 语言，而与 HTML 语言不同的是我们需要自己定义标签。在 XML 文件中每个标签都是我们自己定义的，而每个标签就对应一项内容。一个简单的 XML 的格式如下面这段代码所示：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">note</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">to</span>&gt;</span>学生<span class="tag">&lt;/<span class="name">to</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">from</span>&gt;</span>老师<span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">heading</span>&gt;</span>上课提醒<span class="tag">&lt;/<span class="name">heading</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span>记得9:00来上课<span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">note</span>&gt;</span></span><br></pre></td></tr></table></figure><p>大概了解了 XML 文件，接下来我们看一下 Jute 框架中是如何采用 XML 方式进行序列化操作的。在 Jute 中使用 XmlOutPutArchive 类作用 XML 方式序列化的具体实现类。与上面讲解二进制的序列化实现一样 ，这里我们还是以 writeString 方法的 XML 序列化方式的实现为例。 首先，当采用XML 方式进行序列化时，调用 writeString 方法将 Java 中的 String 字符串对象进行序列化时，在 writeString 内部首先调用 printBeginEnvelope 方法并传入 tag 参数，标记我们要序列化的字段名称。之后采用“”和“”作用自定义标签，封装好传入的 Java 字符串。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void <span class="built_in">writeString</span>(String s, String tag)&#123;</span><br><span class="line"></span><br><span class="line">   <span class="built_in">printBeginEnvelope</span>(tag);</span><br><span class="line"></span><br><span class="line">   stream<span class="selector-class">.print</span>(&quot;&lt;string&gt;&quot;);</span><br><span class="line"></span><br><span class="line">   stream<span class="selector-class">.print</span>(Utils.toXMLString(s));</span><br><span class="line"></span><br><span class="line">   stream<span class="selector-class">.print</span>(&quot;&lt;/string&gt;&quot;);</span><br><span class="line"></span><br><span class="line">   <span class="built_in">printEndEnvelope</span>(tag);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而在 printBeginEnvelope 方法中，其主要作用就是添加该字段的名称、字段值等信息，用于之后反序列化的过程中。</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_ invoke__">printBeginEnvelope</span> (String tag)&#123;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="string">&quot;struct&quot;</span>.<span class="title function_ invoke__">equals</span>(s)) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">putIndent</span>();</span><br><span class="line"></span><br><span class="line">        stream.<span class="keyword">print</span>(<span class="string">&quot;&lt;member&gt;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">addIndent</span>();</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">putIndent</span>();</span><br><span class="line"></span><br><span class="line">        stream.<span class="keyword">print</span>(<span class="string">&quot;&lt;name&gt;&quot;</span>+tag+<span class="string">&quot;&lt;/name&gt;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">putIndent</span>();</span><br><span class="line"></span><br><span class="line">        stream.<span class="keyword">print</span>(<span class="string">&quot;&lt;value&gt;&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;vector&quot;</span>.<span class="title function_ invoke__">equals</span>(s)) &#123;</span><br><span class="line"></span><br><span class="line">        stream.<span class="keyword">print</span>(<span class="string">&quot;&lt;value&gt;&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;map&quot;</span>.<span class="title function_ invoke__">equals</span>(s)) &#123;</span><br><span class="line"></span><br><span class="line">        stream.<span class="keyword">print</span>(<span class="string">&quot;&lt;value&gt;&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">    stream.<span class="keyword">print</span>(<span class="string">&quot;&lt;value&gt;&quot;</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上面在 Jute 框架中，对采用 XML 方式序列化的实现类：XmlOutPutArchive 中的底层实现过程分析，我们可以了解到其实现的基本原理，也就是根据 XML 格式的要求，解析传入的序列化参数，并将参数按照 Jute 定义好的格式，采用设定好的默认标签封装成对应的序列化文件。</p><p>而采用 XML 方式进行序列化的优点则是，通过可扩展标记协议，不同平台或操作系统对序列化和反序列化的方式都是一样的，不存在因为平台不同而产生的差异性，也不会出现如 Binary 二进制序列化方法中产生的大小端的问题。而缺点则是序列化和反序列化的性能不如二进制方式。在序列化后产生的文件相比与二进制方式，同样的信息所产生的文件更大。</p><h4 id="Csv-方式的序列化">Csv 方式的序列化</h4><p>最后我们来学习一下 Jute 序列化框架的最后一种序列化方式：Csv，它和 XML 方式很像，只是所采用的转化格式不同，Csv 格式采用逗号将文本进行分割，我们日常使用中最常用的 Csv 格式文件就是 Excel 文件。</p><p>在 Jute 框架中实现 Csv 序列化的类是 CsvOutputArchive，我们还是以 String 字符对象序列化为例，在调用 CsvOutputArchive 的 writeString 方法时，writeString 方法首先调用 printCommaUnlessFirst 方法生成一个逗号分隔符，之后将要序列化的字符串值转换成 CSV 编码格式追加到字节数组中。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">void <span class="built_in">writeString</span>(String s, String tag)&#123;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">printCommaUnlessFirst</span>();</span><br><span class="line"></span><br><span class="line">  stream<span class="selector-class">.print</span>(Utils.toCSVString(s));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">throwExceptionOnError</span>(tag);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里我们已经对 Jute 框架的 3 种序列化方式的底层实现有了一个整体了解，这 3 种方式相比，二进制底层的实现方式最为简单，性能也最好。而 XML 作为可扩展的标记语言跨平台性更强。而 CSV 方式介于两者之间实现起来也相比 XML 格式更加简单。</p><h3 id="总结-5">总结</h3><p><strong>在 ZooKeeper 中默认的序列化实现方式是 Binary 二进制方式</strong>。这是因为二进制具有更好的性能，以及大多数平台对二进制的实现都不尽相同。</p><h2 id="06-ZooKeeper-的网络通信协议详解">06 ZooKeeper 的网络通信协议详解</h2><p>课我们将学习 ZooKeeper 的网络通信协议。同时，本节课也是基础篇中的最后一节课。在 ZooKeeper 中无论是客户端和服务器之间的通信，还是集群之间服务器的内部协同工作都是基于网络进行通信的。而网络通信协议则是影响 ZooKeeper 性能和稳定性的核心点。</p><h3 id="ZooKeeper-协议简述">ZooKeeper 协议简述</h3><p>说到网络通信协议我们最为熟悉的应该就是 TCP/IP 协议。而 ZooKeeper 则是在 TCP/IP 协议的基础上实现了自己特有的通信协议格式。在 ZooKeeper 中一次客户端的请求协议由请求头、请求体组成。而在一次服务端的响应协议中由响应头和响应体组成。</p><h3 id="ZooKeeper-协议的底层实现">ZooKeeper 协议的底层实现</h3><p>我们大概了解了 ZooKeeper 中的网络通信协议的结构后。接下来我们看一下在 ZooKeeper 中的内部对于网络通信协议的底层是怎么样实现的。</p><h4 id="请求协议">请求协议</h4><p>请求协议就是客户端向服务端发送的协议。比如我们经常用到的会话创建、数据节点查询等操作。都是客户端通过网络向 ZooKeeper 服务端发送请求协议完成的。</p><h4 id="客户端请求头底层解析">客户端请求头底层解析</h4><p>首先，我们先看一下请求头的内部的实现原理。在 ZooKeeper 中请求头是通过 RequestHeader 类实现的。首先 RequestHeader 类实现了 Record 接口，用于之后在网络传输中进行序列化操作。</p><p>我们可以看到 RequestHeader 类中只有两个属性字段分别是 xid 和 type。这两个字段在我们第一节课 ZooKeeper 的数据模型中介绍过，分别代表客户端序号用于记录客户端请求的发起顺序以及请求操作的类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RequestHeader</span> <span class="keyword">implements</span> <span class="title class_">Record</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> xid;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> type;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="客户端请求体底层解析">客户端请求体底层解析</h4><p>我们接下来再看一下客户端请求协议的请求体，协议的请求体包括了协议处理逻辑的全部内容，一次会话请求的所有操作内容都涵盖在请求体中。在 ZooKeeper 的内部实现中，根据不同的请求操作类型，会采用不同的结构封装请求体。接下来我们就以最常用的创建一次会话和数据节点的查询和更新这三种操作来介绍，深入底层看看 ZooKeeper 在内部是如何实现的。</p><p><strong>会话创建</strong></p><p>前面的课程我们已经介绍了 ZooKeeper 中的会话创建以及会话管理等相关知识。通过之前的学习我们知道了在 ZooKeeper 客户端发起会话时，会向服务端发送一个会话创建请求，该请求的作用就是通知 ZooKeeper 服务端需要处理一个来自客户端的访问链接。</p><p>而服务端处理会话创建请求时所需要的所有信息都包括在请求体内。在 ZooKeeper 中该请求体是通过 ConnectRequest 类实现的，其内部一共包括了五种属性字段。分别是 protocolVersion 表示该请求协议的版本信息、lastZxidSeen 最后一次接收到的服务器的 zxid 序号、timeOut 会话的超时时间、会话标识符 sessionId 以及会话的密码 password。有了这些信息 ZooKeeper 服务端在接收一个请求时，就可以根据请求体的信息进行相关的操作了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ConnectRequest <span class="keyword">implements</span> <span class="title class_">Record</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> protocolVersion;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> lastZxidSeen;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> timeOut;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> sessionId;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">byte</span>[] passwd;</span><br><span class="line"></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p><strong>节点查询</strong></p><p>在我们通过客户端 API 查询 ZooKeeper 服务器上的数据节点时，客户端会向服务端发送 GetDataRequest 会话请求。与上面介绍的会话请求不同。ZooKeeper 在处理获取数据节点会话请求时，选择了另一种结构作为该协议的请求体。而具体的实现类则是 GetDataRequest 。在 GetDataRequest 类中首先实现了 Record 接口用于序列化操作。其具有两个属性分别是字符类型 path 表示要请求的数据节点路径以及布尔类型 watch 表示该节点是否注册了 Watch 监控。</p><p>节点路径如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GetDataRequest</span> <span class="keyword">implements</span> <span class="title class_">Record</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String path;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">boolean</span> watch;</span><br></pre></td></tr></table></figure><p><strong>节点更新</strong></p><p>最后，我们来看一下最后一种会话操作类型即节点的更新操作，同样的在客户端向服务端发送一个数据节点更新操作时，其在网络上实际发送的是更新操作的请求协议。而在 ZooKeeper 中对于协议内部的请求体，ZooKeeper 通过 SetDataRequest 类进行了封装。在 SetDataRequest 内部也包含了三种属性，分别是 path 表示节点的路径、data 表示节点数据信息以及 version 表示节点期望的版本号用于锁的验证。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SetDataRequest</span> <span class="keyword">implements</span> <span class="title class_">Record</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> String path;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">byte</span>[] data;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> version;</span><br><span class="line"></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>到目前为止我们就对 ZooKeeper 客户端在一次网络会话请求中所发送的请求协议的内部结构和底层实现都做了介绍，然而这些都是客户端向服务器端的请求协议，接下来我们就继续分析 ZooKeeper 服务端向客户端发送的响应协议是如何实现的。</p><h4 id="响应协议">响应协议</h4><p>响应协议可以理解为服务端在处理客户端的请求后，返回相关信息给客户端。而服务端所采用的响应协议类型则要根据客户端的请求协议类型来选择。</p><h4 id="服务端请求头解析">服务端请求头解析</h4><p>在服务端接收到客户端的请求后，执行相关操作将结果通知给客户端。而在 ZooKeeper 服务端向客户单发送的响应协议中，也是包括了请求头和请求体。而与客户端的请求头不同的是在 ZooKeeper 服务端的请求头多了一个错误状态字段。具体的实现类是 ReplyHeader。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ReplyHeader</span> <span class="keyword">implements</span> <span class="title class_">Record</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> xid;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> zxid;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> err;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h4 id="服务端请求体解析">服务端请求体解析</h4><p>下面我们再看一下响应协议的请求体部分，服务端的请求体可以理解为对客户端所请求内容的封装，一个服务端的请求体包含了客户端所要查询的数据而对于不同的请求类型，在 ZooKeeper 的服务端也是采用了不同的结构进行处理的。与上面我们讲解客户端请求体的方法一样，我们还是通过会话的创建、数据节点的查询和修改这三种请求操作来介绍，看看 ZooKeeper 服务端是如何响应客户端请求的。</p><p><strong>响应会话创建</strong></p><p>对于客户端发起的一次会话连接操作，ZooKeeper 服务端在处理后，会返回给客户端一个 Response 响应。而在底层代码中 ZooKeeper 是通过 ConnectRespose 类来实现的。在该类中有四个属性，分别是 protocolVersion 请求协议的版本信息、timeOut 会话超时时间、sessionId 会话标识符以及 passwd 会话密码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConnectResponse</span> <span class="keyword">implements</span> <span class="title class_">Record</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> protocolVersion;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> timeOut;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">long</span> sessionId;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">byte</span>[] passwd;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><strong>响应节点查询</strong></p><p>在客户端发起查询节点数据的请求时，服务端根据客户端发送的节点路径，并验证客户端具有相应的权限后，会将节点数据返回给客户端。而 ZooKeeper 服务端通过 GetDataResponse 类来封装查询到的节点相关信息到响应协议的请求体中。在 GetDataResponse 内部有两种属性字段分别是 data 属性表示节点数据的内容和 stat 属性表示节点的状态信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GetDataResponse</span> <span class="keyword">implements</span> <span class="title class_">Record</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="type">byte</span>[] data;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> org.apache.zookeeper.data.Stat stat;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><strong>响应节点更新</strong></p><p>在客户端发送一个节点变更操作后， ZooKeeper 服务端在处理完相关逻辑后，会发送一个响应给客户端。而在 ZooKeeper 中更新完节点后会将操作结果返回给客户端，节点更新操作的响应协议请求体通过 SetDataResponse 类来实现。而在该类的内部只有一个属性就是 stat 字段，表示该节点数据更新后的最新状态信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SetDataResponse</span> <span class="keyword">implements</span> <span class="title class_">Record</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> org.apache.zookeeper.data.Stat stat;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="总结-6">总结</h3><p>Zookeeper为什么需要自定义协议？</p><p>ooKeeper选择使用自定义协议的主要原因是为了提高性能和灵活性。</p><ol><li><strong>性能</strong>：自定义协议允许ZooKeeper精确地定义和优化网络通信，以满足其特定的需求。例如，ZooKeeper的自定义协议可以更有效地处理大量的小数据包，这是ZooKeeper常见的使用场景。</li><li><strong>灵活性</strong>：使用自定义协议，ZooKeeper可以更灵活地调整和改进其网络通信。例如，它可以添加新的消息类型或者调整消息格式来支持新的功能。</li><li><strong>适应性</strong>：ZooKeeper的自定义协议可以更好地适应其特定的应用场景。例如，ZooKeeper需要在分布式环境中维护和同步状态，这需要一种能够有效处理这种需求的协议。</li></ol><p>总的来说，虽然使用自定义协议可能需要更多的开发工作，但是它可以带来更好的性能和更高的灵活性，使得ZooKeeper能够更好地满足其特定的需求。</p><h2 id="21-ZooKeeper-分布式锁：实现和原理解析">21 ZooKeeper 分布式锁：实现和原理解析</h2><h3 id="什么是分布式锁">什么是分布式锁</h3><p>在开始着手开发商业级的分布式锁之前，我们首先要弄清楚什么是分布式锁，以及分布式锁在日常工作的使用场景。明确了这些，我们才能设计出一个安全稳定的分布式锁。</p><p>在日常开发中，我们最熟悉也常用的分布式锁场景是在开发多线程的时候。为了协调本地应用上多个线程对某一资源的访问，就要对该资源或数值变量进行加锁，以保证在多线程环境下系统能够正确地运行。在一台服务器上的程序内部，线程可以通过系统进行线程之间的通信，实现加锁等操作。而<strong>在分布式环境下，执行事务的线程存在于不同的网络服务器中，要想实现在分布式网络下的线程协同操作，就要用到分布式锁</strong>。</p><h3 id="分布式死锁">分布式死锁</h3><p>在单机环境下，多线程之间会产生死锁问题。同样，在分布式系统环境下，也会产生分布式死锁的问题。</p><p>当死锁发生时，系统资源会一直被某一个线程占用，从而导致其他线程无法访问到该资源，最终使整个系统的业务处理或运行性能受到影响，严重的甚至可能导致服务器无法对外提供服务。</p><p>所以当我们在设计开发分布式系统的时候，要准备一些方案来面对可能会出现的死锁问题，当问题发生时，系统会根据我们预先设计的方案，避免死锁对整个系统的影响。<strong>常用的解决死锁问题的方法有超时方法和死锁检测</strong>。</p><ul><li><strong>超时方法</strong>：在解决死锁问题时，超时方法可能是最简单的处理方式了。<strong>超时方式是在创建分布式线程的时候，对每个线程都设置一个超时时间</strong>。当该线程的超时时间到期后，无论该线程是否执行完毕，都要关闭该线程并释放该线程所占用的系统资源。之后其他线程就可以访问该线程释放的资源，这样就不会造成分布式死锁问题。但是这种设置超时时间的方法也有很多缺点，最主要的就是很难设置一个合适的超时时间。如果时间设置过短，可能造成线程未执行完相关的处理逻辑，就因为超时时间到期就被迫关闭，最终导致程序执行出错。</li><li><strong>死锁检测</strong>：死锁检测是处理死锁问题的另一种方法，它解决了超时方法的缺陷。与超时方法相比，死锁检测方法主动检测发现线程死锁，在控制死锁问题上更加灵活准确。<strong>你可以把死锁检测理解为一个运行在各个服务器系统上的线程或方法，该方法专门用来探索发现应用服务上的线程是否发生了死锁</strong>。如果发生死锁，就会触发相应的预设处理方案。</li></ul><h3 id="锁的实现">锁的实现</h3><p>在介绍完分布式锁的基本性质和潜在问题后，接下来我们就通过 ZooKeeper 来实现两种比较常用的分布式锁。</p><h4 id="排他锁">排他锁</h4><p>排他锁也叫作独占锁，从名字上就可以看出它的实现原理。当我们给某一个数据对象设置了排他锁后，<strong>只有具有该锁的事务线程可以访问该条数据对象，直到该条事务主动释放锁</strong>。否则，在这期间其他事务不能对该数据对象进行任何操作。在第二课时我们已经学习了利用 ZooKeeper 实现排他锁，这里不再赘述。</p><h4 id="共享锁">共享锁</h4><p>另一种分布式锁的类型是共享锁。它在性能上要优于排他锁，这是因为在共享锁的实现中，只对数据对象的写操作加锁，而不为对象的读操作进行加锁。这样既保证了数据对象的完整性，也兼顾了多事务情况下的读取操作。可以说，共享锁是写入排他，而读取操作则没有限制。</p><p>接下来我就通过 ZooKeeper 来实现一个排他锁。</p><h4 id="创建锁">创建锁</h4><p>首先，我们通过在 ZooKeeper 服务器上创建数据节点的方式来创建一个共享锁。其实无论是共享锁还是排他锁，在锁的实现方式上都是一样的。唯一的区别在于，<strong>共享锁为一个数据事务创建两个数据节点，来区分是写入操作还是读取操作</strong>。如下图所示，在 ZooKeeper 数据模型上的 Locks_shared 节点下创建临时顺序节点，临时顺序节点的名称中带有请求的操作类型分别是 R 读取操作、W 写入操作。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602214101116.png" alt="image-20240602214101116"></p><h4 id="获取锁">获取锁</h4><p>当某一个事务在访问共享数据时，首先需要获取锁。ZooKeeper 中的所有客户端会在 Locks_shared 节点下创建一个临时顺序节点。根据对数据对象的操作类型创建不同的数据节点，如果是读操作，就创建名称中带有 R 标志的顺序节点，如果是写入操作就创建带有 W 标志的顺序节点。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602214114736.png" alt="image-20240602214114736"></p><h4 id="释放锁">释放锁</h4><p>事务逻辑执行完毕后，需要对事物线程占有的共享锁进行释放。我们可以利用 ZooKeeper 中数据节点的性质来实现主动释放锁和被动释放锁两种方式。</p><p>主动释放锁是当客户端的逻辑执行完毕，主动调用 delete 函数删除ZooKeeper 服务上的数据节点。而被动释放锁则利用临时节点的性质，在客户端因异常而退出时，ZooKeeper 服务端会直接删除该临时节点，即释放该共享锁。</p><p>这种实现方式正好和上面介绍的死锁的两种处理方式相对应。到目前为止，我们就利用 ZooKeeper 实现了一个比较完整的共享锁。如下图所示，在这个实现逻辑中，首先通过创建数据临时数据节点的方式实现获取锁的操作。创建数据节点分为两种，分别是读操作的数据节点和写操作的数据节点。当锁节点删除时，注册了该 Watch 监控的其他客户端也会收到通知，重新发起创建临时节点尝试获取锁。当事务逻辑执行完成，客户端会主动删除该临时节点释放锁。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602214127208.png" alt="image-20240602214127208"></p><p>总结</p><p>1、客户端调用 create 方法创建类似定义锁方式的临时顺序节点。</p><p>2、客户端调用 getChildren 接口来获取所有已创建的子节点列表。</p><p>3、判断是否获得锁，对于读请求如果所有比自己小的子节点都是读请求或者没有比自己序号小的子节点，表明已经成功获取共享锁，同时开始执行度逻辑。对于写请求，如果自己不是序号最小的子节点，那么就进入等待。</p><p>4、如果没有获取到共享锁，读请求向比自己序号小的最后一个写请求节点注册 watcher 监听，写请求向比自己序号小的最后一个节点注册watcher 监听。</p><p><strong>理解</strong></p><p>ZooKeeper中的锁机制可以通过一种称为“子节点列表”的方式来实现。这个过程可以类比为在一个电影院购买电影票。</p><ol><li>首先，客户端（也就是观众）通过调用getChildren接口（也就是询问售票员），来获取所有已创建的子节点列表（也就是看看有哪些座位已经被预订）。</li><li>然后，客户端会判断是否获得了锁。对于读请求（也就是想要查看电影信息），如果所有比自己小的子节点都是读请求（也就是其他的观众都只是在查看电影信息）或者没有比自己序号小的子节点（也就是没有其他的观众），那么就表明已经成功获取了共享锁，可以开始执行读取逻辑（也就是查看电影信息）。对于写请求（也就是想要预订座位），如果自己不是序号最小的子节点（也就是有其他的观众先预订了座位），那么就需要等待。</li><li>如果没有获取到共享锁，那么读请求会向比自己序号小的最后一个写请求节点（也就是最后一个预订座位的观众）注册watcher监听（也就是询问售票员何时有座位可用），写请求会向比自己序号小的最后一个节点（也就是最后一个操作的观众）注册watcher监听。</li></ol><p>这就是ZooKeeper中获取共享锁的过程</p><h2 id="实操">实操</h2><p><a href="https://www.runoob.com/w3cnote/zookeeper-tutorial.html">https://www.runoob.com/w3cnote/zookeeper-tutorial.html</a></p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-<span class="number">3.4</span>.<span class="number">14</span>.tar.gz</span><br><span class="line"><span class="variable constant_">CHANGES</span>.txt  dist-maven  ivy.xml          <span class="variable constant_">NOTICE</span>.txt   src         zookeeper-<span class="number">3.3</span>.<span class="number">4</span>.jar.md5</span><br><span class="line">(base) sv<span class="variable">@sv</span>-<span class="variable constant_">NF5280M5</span><span class="symbol">:/home/sv/pengeHome/mprpc/package/zookeeper-</span><span class="number">3.3</span>.<span class="number">4</span><span class="variable">$ </span>cd conf/</span><br><span class="line">(base) sv<span class="variable">@sv</span>-<span class="variable constant_">NF5280M5</span><span class="symbol">:/home/sv/pengeHome/mprpc/package/zookeeper-</span><span class="number">3.3</span>.<span class="number">4</span>/conf<span class="variable">$ </span> cp zoo_sample.cfg zoo.cfg</span><br><span class="line">(base) sv<span class="variable">@sv</span>-<span class="variable constant_">NF5280M5</span><span class="symbol">:/home/sv/pengeHome/mprpc/package/zookeeper-</span><span class="number">3.3</span>.<span class="number">4</span>/conf<span class="variable">$ </span>cd ..</span><br><span class="line">(base) sv<span class="variable">@sv</span>-<span class="variable constant_">NF5280M5</span><span class="symbol">:/home/sv/pengeHome/mprpc/package/zookeeper-</span><span class="number">3.3</span>.<span class="number">4</span><span class="variable">$ </span>cd bin/</span><br><span class="line">(base) sv<span class="variable">@sv</span>-<span class="variable constant_">NF5280M5</span><span class="symbol">:/home/sv/pengeHome/mprpc/package/zookeeper-</span><span class="number">3.3</span>.<span class="number">4</span>/bin<span class="variable">$ </span>sudo sh zkServer.sh start</span><br><span class="line"><span class="variable constant_">JMX</span> enabled by default</span><br><span class="line"><span class="title class_">Using</span> <span class="symbol">config:</span> /home/sv/pengeHome/mprpc/package/zookeeper-<span class="number">3.3</span>.<span class="number">4</span>/bin/../conf/zoo.cfg</span><br><span class="line"><span class="title class_">Starting</span> zookeeper ... zkServer.<span class="symbol">sh:</span> <span class="number">103</span>: cannot create /tmp/zookeeper/zookeeper_server.<span class="symbol">pid:</span> <span class="title class_">Directory</span> nonexistent</span><br><span class="line"><span class="variable constant_">FAILED</span> <span class="variable constant_">TO</span> <span class="variable constant_">WRITE</span> <span class="variable constant_">PID</span></span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/white_mvlog/article/details/112878757">ZooKeeper JMX enabled by default Using config…完美解决</a></p><p>上述问题解决：通过修改里面的路径解决的！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv/pengeHome/mprpc/package/zookeeper-3.3.4/conf$ sudo vim zoo.cfg</span><br></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">sudo</span> apt install openjdk-<span class="number">8</span>-jdk</span><br></pre></td></tr></table></figure><p><strong>数据模型</strong></p><p>查看信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] <span class="built_in">ls</span> /</span><br><span class="line">[zookeeper]</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 4] get /zookeeper</span><br><span class="line"></span><br><span class="line">cZxid = 0x0</span><br><span class="line">ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">mZxid = 0x0</span><br><span class="line">mtime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">pZxid = 0x0</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 0</span><br><span class="line">numChildren = 1</span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">Zxid</th><th style="text-align:left">创建节点时的事务ID</th></tr></thead><tbody><tr><td style="text-align:left">ctime</td><td style="text-align:left">创建节点时的时间</td></tr><tr><td style="text-align:left">mZxid</td><td style="text-align:left">最后修改节点时的事务ID</td></tr><tr><td style="text-align:left">mtime</td><td style="text-align:left">最后修改节点时的时间</td></tr><tr><td style="text-align:left">pZxid</td><td style="text-align:left">表示该节点的子节点列表最后一次修改的事务ID，添加子节点或删除子节点就会影响子节点列表，但是修改子节点的数据内容则不影响该ID**（注意，只有子节点列表变更了才会变更pzxid，子节点内容变更不会影响pzxid）**</td></tr><tr><td style="text-align:left">cversion</td><td style="text-align:left">子节点版本号，子节点每次修改版本号加1</td></tr><tr><td style="text-align:left">dataversion</td><td style="text-align:left">数据版本号，数据每次修改该版本号加1</td></tr><tr><td style="text-align:left">aclversion</td><td style="text-align:left">权限版本号，权限每次修改该版本号加1</td></tr><tr><td style="text-align:left">ephemeralOwner</td><td style="text-align:left">创建该临时节点的会话的sessionID。**（**<strong>如果该节点是持久节点，那么这个属性值为0）</strong></td></tr><tr><td style="text-align:left">dataLength</td><td style="text-align:left">该节点的数据长度</td></tr><tr><td style="text-align:left">numChildren</td><td style="text-align:left">该节点拥有子节点的数量**（只统计直接子节点的数量）**</td></tr></tbody></table><p>修改节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 4] get /zookeeper</span><br><span class="line"></span><br><span class="line">cZxid = 0x0</span><br><span class="line">ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">mZxid = 0x0</span><br><span class="line">mtime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">pZxid = 0x0</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 0</span><br><span class="line">numChildren = 1</span><br><span class="line">[zk: localhost:2181(CONNECTED) 5] <span class="built_in">set</span> /zookeeper 1</span><br><span class="line">cZxid = 0x0</span><br><span class="line">ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">mZxid = 0x2</span><br><span class="line">mtime = Sun Jun 02 21:31:29 CST 2024</span><br><span class="line">pZxid = 0x0</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 1</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 1</span><br><span class="line">numChildren = 1</span><br></pre></td></tr></table></figure><p>创建节点</p><p><strong>create 命令</strong></p><p>create 命令用于创建节点并赋值。</p><p>格式：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> [-s] [-<span class="built_in">e</span>] <span class="keyword">path</span> data acl</span><br></pre></td></tr></table></figure><ul><li><strong>[-s] [-e]</strong>：-s 和 -e 都是可选的，-s 代表顺序节点， -e 代表临时节点，注意其中 -s 和 -e 可以同时使用的，并且临时节点不能再创建子节点。</li><li><strong>path</strong>：指定要创建节点的路径，比如 <strong>/runoob</strong>。</li><li><strong>data</strong>：要在此节点存储的数据。</li><li><strong>acl</strong>：访问权限相关，默认是 world，相当于全世界都能访问。</li></ul><p>create 命令用于创建节点并赋值。</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[zk: localhost:2181(CONNECTED) 6] create -e /zookeeper/child 0</span></span><br><span class="line">Created /zookeeper/child</span><br><span class="line"><span class="section">[zk: localhost:2181(CONNECTED) 7] get /zookeeper</span></span><br><span class="line">1</span><br><span class="line">cZxid = 0x0</span><br><span class="line">ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">mZxid = 0x2</span><br><span class="line">mtime = Sun Jun 02 21:31:29 CST 2024</span><br><span class="line">pZxid = 0x3</span><br><span class="line">cversion = 1</span><br><span class="line">dataVersion = 1</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 1</span><br><span class="line">numChildren = 2</span><br><span class="line"><span class="section">[zk: localhost:2181(CONNECTED) 8] ls /zookeeper</span></span><br><span class="line">[quota, child]</span><br></pre></td></tr></table></figure><p>详细查看信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 9] ls2 /zookeeper</span><br><span class="line">[quota, child]</span><br><span class="line">cZxid = 0x0</span><br><span class="line">ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">mZxid = 0x2</span><br><span class="line">mtime = Sun Jun 02 21:31:29 CST 2024</span><br><span class="line">pZxid = 0x3</span><br><span class="line">cversion = 1</span><br><span class="line">dataVersion = 1</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 1</span><br><span class="line">numChildren = 2</span><br></pre></td></tr></table></figure><p>watch机制</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 10] get /zookeeper/child watch</span><br><span class="line">0</span><br><span class="line">cZxid = 0x3</span><br><span class="line">ctime = Sun Jun 02 21:32:29 CST 2024</span><br><span class="line">mZxid = 0x3</span><br><span class="line">mtime = Sun Jun 02 21:32:29 CST 2024</span><br><span class="line">pZxid = 0x3</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0xff8fd92315090000</span><br><span class="line">dataLength = 1</span><br><span class="line">numChildren = 0</span><br><span class="line">[zk: localhost:2181(CONNECTED) 11] <span class="built_in">set</span> /zookeeper/child 1</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected <span class="built_in">type</span>:NodeDataChanged path:/zookeeper/child</span><br><span class="line">cZxid = 0x3</span><br><span class="line">ctime = Sun Jun 02 21:32:29 CST 2024</span><br><span class="line">mZxid = 0x4</span><br><span class="line">mtime = Sun Jun 02 21:35:17 CST 2024</span><br><span class="line">pZxid = 0x3</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 1</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0xff8fd92315090000</span><br><span class="line">dataLength = 1</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure><p>参考:<a href="https://www.cnblogs.com/leesf456/p/6091208.html">https://www.cnblogs.com/leesf456/p/6091208.html</a></p>]]></content>
    
    
    <summary type="html">Zookeeper基础篇</summary>
    
    
    
    <category term="分布式" scheme="https://penge666.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://penge666.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>SEDA异步事件框架</title>
    <link href="https://penge666.github.io/posts/b1577ae3.html"/>
    <id>https://penge666.github.io/posts/b1577ae3.html</id>
    <published>2024-05-30T14:23:30.000Z</published>
    <updated>2024-05-30T14:43:33.302Z</updated>
    
    <content type="html"><![CDATA[<p>SEDA: An Architecture for Well-Conditioned, Scalable Internet Services</p><p>Matt Welsh, David Culler, and Eric Brewer 加州大学伯克利分校</p><p>论文地址：<a href="https://people.eecs.berkeley.edu/~brewer/papers/SEDA-sosp.pdf">https://people.eecs.berkeley.edu/~brewer/papers/SEDA-sosp.pdf</a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>​    我们为高度并发的Internet服务提出了一种新设计，我们将其称为<strong>分阶段事件驱动架构（SEDA）</strong>。SEDA旨在支持大规模并发需求并简化良好服务的构建。在SEDA中，应用程序由通过显式队列连接的阶段事件驱动网络组成。这种架构使服务具有良好的负载，在需求超过服务容量时防止资源过度使用。尽管负载波动很大，但SEDA利用一组动态资源控制器将各阶段保持在其运行状态。我们描述了几种用于自动调整和负载调节的控制机制，包括线程池大小调整，事件批处理和自适应负载消减。我们介绍了SEDA设计以及基于该架构的互联网服务平台的实现。我们通过两个应用程序评估SEDA的使用：用于Gnutella（无结构的P2P网络代表软件）对等文件共享网络的高性能HTTP服务器和数据包路由器。这些结果表明，SEDA应用程序表现出比传统服务设计更高的性能，并且对于负载的巨大变化具有稳健性。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>​      互联网呈现出前所未有的计算机系统问题：要求支持数百万用户的访问，服务必须是相应的、稳健的、始终可用的。Internet站点每天的并发会话数和点击次数转化为更多的I/O和网络请求，对底层资源提出了巨大的要求。雅虎每天收到超过12亿的页面浏览量，AOL的网络缓存每天提供超过100亿次点击。此外，互联网服务在服务负载方面经历巨大变化，突发与服务具有最大价值的时间一致。详细记录的“Slashdot效应”表明，当网站变得流行时，需求增长超过100倍并不罕见。随着对互联网服务的需求的增长，必须使用新的系统设计技术来管理这种负载。</p><p>​      这种系统挑战被三种趋势放大，这些趋势增加了服务的普遍性。首先，服务本身变得越来越复杂，静态内容被涉及大量计算和I/O的动态内容所取代。其次，服务逻辑趋于快速变化，这增加了工程和部署的复杂性。第三，服务越来越多地托管在通用设施上，而不是在为特定服务精心设计的平台上。随着这些趋势的继续，我们设想将创建一系列丰富的新颖服务并将其推入基础设施，在这些基础设施中，它们可能会成功扩展到数百万用户。一些研究正在解决服务的高级方面，包括命名，查找，组合和版本控制。我们将重点放在问题的性能方面：在负载变化很大的情况下，在广泛的服务上实现强大的性能，同时保持其易用性。复制是服务可伸缩性的关键方面。给定一个可以维持一定性能水平的服务实例，必须复制它以维持负载的多倍增加，可扩展的集群现在被广泛用于在服务站点内获得复制，并且广泛的复制越来越多地用于特定服务，例如内容分发网络。但是，因为峰值负载可能比平均值大几个数量级，所以它不实用。复制大多数服务以处理最大的潜在需求。 因此，我们预计每个节点所承受的负载会出现大幅峰值。我们的目标是开发一个通用框架，用于创建高度并发且运行良好的服务实例，以便优雅地处理负载。</p><p>​      遗憾的是，传统的操作系统设计和广泛推广的并发模型并不能提供这种优雅的负载管理。商品操作系统专注于通过为每个进程提供独有的CPU，内存，磁盘和网络的虚拟机的抽象来提供最大的透明度。 这个目标与互联网服务的需求有些不一致，互联网服务需要大量的并发性和对资源使用的广泛控制。进程和线程是良好支持的并发编程模型，但在上下文切换时间和内存占用方面往往需要很高的开销，这限制了并发性。 透明的资源虚拟化阻止了应用程序做出明智的决策，这对于管理过多的负载至关重要。大多说工作都侧重于特定服务的性能和稳健性。然而，随着服务变得越来越动态和灵活，这种工程负担变得过度。很少有工具可以帮助开发高度并发，运行良好的服务; 我们的目标是通过提供帮助软件开发人员获取这些属性的通用机制来降低这种复杂性。</p><p>​      我们为高度并发的服务器应用程序提出了一个新的设计框架，我们将其称为分阶段事件驱动架构（SEDA）。SEDA结合了线程和基于事件的编程模型的各个方面来管理Internet服务的并发性，I/O，调度和资源管理需求。在SEDA中，应用程序被构建为阶段网络，每个阶段都具有关联的传入事件队列。每个阶段可以通过单独调节负载阈值或过滤其事件队列来构建一个健壮的模块。此外，使事件队列显式化允许应用程序进行合适的调度和资源管理决策，例如重新排序，过滤或聚合请求。SEDA利用动态资源限制来控制应用程序组件的资源分配和调度，使系统能够适应过载状态。</p><p>​      本文描述了基于SEDA的Internet服务平台的设计，体系结构和实现。该平台提供高效，可扩展的I/O接口以及多种资源控制机制，包括线程池大小调整和动态事件调度。我们通过两个应用程序评估框架 - 一个高性能HTTP服务器和一个用于Gnutella对等文件共享网络的数据包路由器。我们为这些应用提供了性能和可扩展性结果，证明了SEDA在负载的巨大变化上实现了稳健性，并且优于其他服务设计。我们基于Java的SEDA HTTP服务器优于基于C实现的两个流行的Web服务器，如第5.1节所述。我们认为使用SEDA，高度并发的应用程序更容易构建，更高效，更强大的负载。通过正确的接口，应用程序设计人员可以专注于特定于应用程序的逻辑，而不是并发和资源管理的细节。</p><h2 id="背景和相关工作"><a href="#背景和相关工作" class="headerlink" title="背景和相关工作"></a>背景和相关工作</h2><p>​      SEDA汇集了两个重要的研究领域：<strong>使用基于线程的并发模型来简化编程，使用基于事件的模型来实现大规模的并发</strong>。本节通过概述主导SEDA设计的步骤中的关键贡献和问题来阐明开发这种方法的谱系。</p><p>​      直观地说，如果服务的行为类似于简单的管道，那么服务就是运行良好的，管道的深度由通过网络的路径和服务本身内的处理阶段决定。随着提供的负载增加，交付的吞吐量按比例增加，直到管道充满并且吞吐量饱和; 额外的负载不应该降低吞吐量。类似地，服务所呈现的响应时间在轻负载时大致恒定，因为它由管道的深度支配。当负载接近饱和时，排队延迟占主导地位。在许多服务典型的闭环场景中，每个客户端在提交下一个请求之前等待响应，响应时间应随客户端数量线性增加。</p><p>​      良好的服务的关键属性是优雅降级：当提供的负载超过容量时，服务保持高吞吐量，线性响应时间损失同等地影响所有客户端，或者至少根据某些特定于服务的策略可预测影响。请注意，这不是典型的Web体验; 相反，随着负载的增加，吞吐量会降低，响应时间也会大幅增加，从而产生服务崩溃的印象。</p><h3 id="基于线程的并发"><a href="#基于线程的并发" class="headerlink" title="基于线程的并发"></a>基于线程的并发</h3><p>​      服务器应用程序最常用的设计是thread-per-request线程模型，如RPC包，Java远程方法调用和DCOM中所体现的。 当前的语言和编程环境很好地支持这个模型。 在此模型中，如图1所示，每个接受的请求都使用一个线程来处理它，同步操作受保护的共享资源。操作系统通过在线程之间透明切换来交叉计算和I/O.</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530222909219.png" alt="image-20240530222909219"></p><p>图1：线程服务器设计：将每个传入请求分派到一个单独的线程，该线程处理请求并将结果返回给客户端。边表示分支之间的控制流。请注意，此处未显示其他I/O操作（如磁盘访问），但会将其合并到每个线程的请求处理中。</p><p>尽管编程相对容易，但与线程相关的开销（包括缓存和TLB未命中，调度开销和锁争用）当线程数量变大时，会导致严重的性能下降。作为一个具体示例，图2显示了随着线程数量的增加，简单线程服务器的性能。尽管有效的线程限制对于通用分时来说会很大，但它不足以满足Internet服务的巨大并发要求。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530222949971.png" alt="image-20240530222949971"></p><p>图2：线程服务器吞吐量降低</p><p>纵坐标表示吞吐量（每秒任务数） 横坐标表示线程数</p><p>红线代表吞吐量 蓝线代表实际延迟走势 紫线代表理想状态下线性延迟走势</p><p>​    此基准测试用于测量一个简单的线程服务器，该服务器为管道中的每个任务创建单个线收到任务后，每个线程从磁盘文件执行8 KB读取; 所有线程都从同一个文件读取，因此数据总是在缓冲区缓存中。线程在服务器中预先分配，以消除测量中的线程启动开销，并在内部生成任务以消除网络效应。该服务器采用C语言实现，运行在Linux 2.2.14下的4路500 MHz Pentium III和2 GB内存上。 随着并发任务数量的增加，吞吐量会增加，直到线程数量增大，之后吞吐量会大幅下降。 随着任务队列长度的增加，响应时间变得无限制; 为了比较，我们已经显示了理想的线性响应时间曲线（注意x轴上的对数刻度）。</p><p>​      线程和进程主要用于支持多道程序设计，现有的OS力求以对应用程序透明的方式虚拟化硬件资源。应用程序很少有机会参与系统范围的资源管理决策，或者给出资源可用性的指示，以使其行为适应不断变化的条件。虚拟化从根本上隐藏了资源有限和共享的事实。</p><p>​      许多系统试图通过向应用程序公开更多控制来解决这个问题。调度程序激活[5]，应用程序特定处理程序[59]和操作系统（如SPIN [11]，Exokernel [28]和Nemesis [34]）都试图通过为应用程序提供特化内核做出的决策的能力来增强有限的操作系统接口。然而，这些系统的设计仍然基于多道程序设计，因为重点仍然放在安全和有效的资源虚拟化上，而不是优雅的管理和高并发性。</p><h3 id="有界线程池"><a href="#有界线程池" class="headerlink" title="有界线程池"></a>有界线程池</h3><p>​      为了避免过度使用线程，许多系统采用粗略形式的负载调节，用于绑定与服务关联的线程池的大小。 当服务器中的请求数超过某个固定限制时，不接受其他连接。 Web服务器（如Apache [6]，IIS [38]和Netscape Enterprise Server [42]）以及应用程序服务器（如BEA Weblogic [10]和IBM WebSphere [25]）使用此方法。 通过限制并发线程的数量，服务器可以避免吞吐量降低，并且整体性能比无约束的每任务线程模型更强大。但是，这种方法会给客户端带来很多不公平：当所有服务器线程忙或被阻塞时，客户端请求在网络中排队等待服务。正如我们将在5.1节中所示，这可能导致客户端经历任意大的等待时间。</p><p>​      当每个请求由单个线程处理时，很难识别内部性能瓶颈以执行调整和负载调节。 考虑一个简单的线程Web服务器，其中一些请求处理起来成本低廉（例如，缓存的静态页面）而其他请求则很昂贵（例如，不在缓存中的大页面）。 对于许多并发请求，昂贵的请求可能是性能瓶颈的来源，因此需要执行减载。 但是，服务器无法检查内部请求流以实现此类策略; 它所知道的是线程池已经饱和，并且一定是在不知道瓶颈来源的情况下随意拒绝工作。</p><p>​      资源容器[7]和来自Scout操作系统[41,49]的路径概念是两种可用于限制服务器中任务的资源使用的技术。这些机制将垂直资源管理应用于一组软件模块，允许整个数据流通过系统的资源作为一个单元进行管理。 在上述瓶颈的情况下，限制给定请求的资源使用，将避免由于高速缓存未命中而导致的降级，但允许高速缓存命中继续进行。</p><h3 id="事件驱动的并发"><a href="#事件驱动的并发" class="headerlink" title="事件驱动的并发"></a>事件驱动的并发</h3><p>​      线程的可伸缩性限制导致许多开发人员几乎完全避开它们，并采用事件驱动的方法来管理并发。在这种方法中，如图3所示，服务器由少量线程（通常每个CPU一个）组成，它们不断循环，处理队列中不同类型的事件。事件可以由操作系统生成，也可以由应用程序在内部生成，通常对应于网络和磁盘I/O就绪和完成通知，定时器或其他特定于应用程序的事件。事件驱动方法将每个任务的处理实现为有限状态机，其中FSM（finite state machine）中的状态之间的转换由事件触发。通过这种方式，服务器为每个任务维护自己的连续状态，而不是依赖于线程上下文。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223052896.png" alt="image-20240530223052896"></p><p>图3：事件驱动的服务器设计：此图显示了通过事件驱动的服务器的事件流。 主线程处理来自网络，磁盘和其他来源的传入事件，并使用它们来驱动许多有限状态机的执行。 每个FSM代表通过系统的单个请求或执行流程。 此设计的复杂性的关键来源是事件调度程序，它必须控制每个FSM的执行。</p><pre><code> 事件驱动设计被许多系统使用，包括Flash [44]，thttpd [4]，Zeus [63]和JAWS [24] Web服务器以及Harvest [12] Web缓存。在Flash中，服务器的每个组件都响应特定类型的事件，例如套接字连接或文件系统访问。主服务器进程负责不断地将事件分派给每个组件，这些组件实现为库调用。因为某些I/O操作（在这种情况下，文件系统访问）没有异步接口，所以主服务器进程通过IPC将它们分派给辅助进程来处理这些事件。帮助程序处理发出（阻塞）I/O请求并在完成时将事件返回到主进程。Harvest的结构非常相似：它是单线程和事件驱动的，但FTP协议除外，它由一个单独的进程实现。(Harvest:google搜索到是一款面向自由职业者和小型企业的时间跟踪和在线发票应用程序。</code></pre><p>​      线程和事件驱动的并发模型之间的权衡已经在JAWS Web服务器中进行了广泛的研究[23,24]。JAWS(一个高性能的web服务器架构，jaws设计论文)为Web服务器构建提供了一个框架，允许自定义并发模型，协议处理代码，缓存文件系统和其他组件。与SEDA一样，JAWS强调服务设计中适应性的重要性，通过促进服务框架中的静态和动态适应性。据我们所知，JAWS仅在轻载（少于50个并发客户端）下进行了评估，并未解决在高负荷下使用适应性进行调节的问题。</p><p>​      事件驱动系统往往对负载具有稳定性，随着提供的负载增加超出饱和度，吞吐量几乎没有降低。 图4显示了使用图2中的服务的事件驱动版本实现的吞吐量。随着任务数量的增加，服务器吞吐量会增加，直到管道填满并且瓶颈（在这种情况下为CPU）变得饱和。 如果管道中的任务数量进一步增加，则多余的任务将被吸收在服务器的事件队列中。 吞吐量在很大的负载范围内保持不变，每个任务的延迟线性增加。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223140377.png" alt="image-20240530223140377"></p><p>图4：事件驱动的服务器吞吐量：该基准测试用于测量图2中服务器的事件驱动版本。</p><p>在这种情况下，服务器使用单个线程来处理任务，其中每个任务从单个磁盘文件读取8 KB。尽管此处使用的操作系统（Linux 2.2.14）提供的文件系统接口是阻塞的，但由于磁盘数据始终位于缓存中，因此此基准测试可估算非阻塞磁盘I/O层的最佳性能。如图所示，当负载增加到非常大量的任务时，吞吐量保持不变（注意图2中水平轴刻度的变化），响应时间是线性的（注意x轴上的对数刻度）。</p><p>​      此模型的一个重要限制是它假定事件处理线程不会阻塞，因此必须使用非阻塞I/O机制。虽然许多先前的工作已经研究了可伸缩的I/O原语[8,9,33,46,48]，但由于中断，页面错误或垃圾收集，事件处理线程会造成阻塞而不管所使用的I/O机制如何。</p><p>​      事件驱动的设计为应用程序开发人员带来了许多额外的挑战。 事件的调度和排序可能是最重要的问题：应用程序负责决定何时处理每个传入事件以及处理多个流的FSM的顺序。 为了平衡公平性和低响应时间，应用程序必须仔细地复用多个FSM的执行。事件调度算法的选择通常是针对特定应用而定制的，并且新功能的引入可能需要重新设计算法。此外，模块化很难实现，因为必须信任实现每个状态的代码，以阻止或消耗大量可能使事件处理线程停滞的资源。</p><h3 id="结构化事件队列"><a href="#结构化事件队列" class="headerlink" title="结构化事件队列"></a>结构化事件队列</h3><p>   已经提出了关于标准事件驱动设计的若干变体来解决上述问题。 这些设计的一个共同方面是使用一组事件队列构建事件驱动的应用程序，以提高代码模块性并简化应用程序设计。</p><p>   Click模块化分组路由器(Click路由器论文)[40]就是这样一个例子。在Click中，数据包处理阶段由具有自己的私有状态的单独代码模块实现。Click经过优化，可通过路由器改善每个数据包的延迟，允许单个线程直接通过多个数据包处理阶段进行调用。 此设计针对特定应用程序（路由），单个线程为所有事件队列提供服务。Click假设模块具有有限的处理时间，从而导致相对静态的资源管理策略。Qie(Qie路由器论文)等。[47]还描述了在基于软件的路由器中调度和负载调节的技术; 与SEDA一样，他们的设计利用控制器根据负载动态调整运行时参数。</p><p>   Gribble的分布式数据结构（DDS）[20]层也使用了结构化的事件处理框架。在DDS中，存储服务器通过使用固定大小的线程池来模拟异步网络和磁盘I/O接口，并且使用显式事件队列或隐式上行调用来组成软件组件。Work Crews [56]和TSS/360队列扫描程序[35]是利用结构化事件队列和有限数量的线程来管理并发性的系统的其他示例。在这些系统的每一个中，事件队列的使用解耦了两个组件的执行，这提高了模块性和稳定性。</p><p>   StagedServer [31]是另一个利用显式事件队列进行通信的系统。 在这种情况下，目标是通过仔细调度每个模块中的线程和事件来最大化处理器缓存局部性。 通过聚合队列中多个类似事件的执行，增强了局部性，从而提高了性能。（译者注：线程跳转越少，局部性就会更好）</p><p>   Lauer和Needham的经典论文[32]讨论了通过消息进行通信的过程的优点，并将这种方法与“procedures”的方法进行了对比，这与上述线程模型密切相关。 SEDA可以看作是那里讨论的面向消息的模型的一个实例。 作者声称基于消息和基于过程的模型是彼此的双重性，并且在一个模型中实现的任何程序都可以在另一个模型中有效地实现。 虽然我们同意这种基本情绪，但这一论点忽略了构建可扩展通用多线程的复杂性，以及在没有显示请求队列的情况下在基于线程的模型中调整负载的固有困难。</p><h3 id="分阶段事件驱动架构"><a href="#分阶段事件驱动架构" class="headerlink" title="分阶段事件驱动架构"></a>分阶段事件驱动架构</h3><p>​      在本节中，我们提出了一种新的软件架构，即分阶段事件驱动架构（SEDA），旨在实现Internet服务的高并发性，负载调节和易于设计。SEDA将应用程序分解为由事件队列分隔的阶段网络，并引入动态资源控制器的概念，以允许应用程序动态调整以适应不断变化的负载。SEDA服务设计方法概述如图5所示。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223255205.png" alt="image-20240530223255205"></p><p><strong>目标</strong></p><p>SEDA的主要目标如下：</p><p>支持大规模并发：为避免因为线程导致性能下降，SEDA尽可能使用事件驱动的执行。 这还要求系统提供高效且可扩展的I/O原语。</p><p>简化良好条件服务的构建：为了降低构建Internet服务的复杂性，SEDA保护应用程序开发者免受许多调度和资源管理的细节。该设计还支持这些应用程序的模块化构造，并为调试和性能分析提供支持。</p><p>启用自我检查：应用程序应该能够分析请求流，以使行为适应不断变化的负载条件。 例如，系统应该能够确定优先级并过滤请求，以支持在高负载下降级服务。</p><p>支持自我调优资源管理：系统应该动态调整其资源管理参数以满足性能目标，而不是强制要求应用程序资源需求和客户端负载特性的先验知识。例如，分配给阶段的线程数可以根据感知的并发需求自动确定，而不是由程序员或管理员硬编码。</p><p><strong>作为健壮构建块的阶段</strong></p><p>​      SEDA内的基本处理单位是stage。stage是一个独立的应用程序组件，由事件处理程序，传入事件队列和线程池组成，如图6所示。每个阶段由影响调度和线程分配的控制器管理，如下所述。阶段线程通过从传入事件队列中拉出一批事件并调用应用程序提供的事件处理程序来进行操作。事件处理程序处理每批事件，并通过将它们排入其他阶段的事件队列来调度零个或多个事件。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223336442.png" alt="image-20240530223336442"></p><p>图6：SEDA阶段：阶段由传入事件队列，线程池和应用程序提供的事件处理程序组成。 阶段的操作由控制器管理，控制器动态调整资源分配和调度。</p><p>​      线程是SEDA中的基本并发机制，但它们的使用仅限于每个阶段的少量线程，而不是系统中每个任务一个线程。此外，动态控制的使用（参见3.4节）可以根据需求自动调整分配给每个阶段的线程数。此设计允许阶段按顺序或并行运行，或两者的组合，取决于线程系统和调度程序的特性 在本文中，我们假设在SMP环境中的操作系统支持抢占式线程，尽管这种选择不是SEDA设计的基础。例如，可以设计一个线程系统，它认识到应用程序的分阶段结构并相应地调度线程。 我们在3.4节回到这个问题。</p><p>​      每个阶段的核心逻辑由事件处理程序提供，其输入是一批多个事件。 事件处理程序无法直接控制队列操作或线程。通过将核心应用程序逻辑与线程管理和调度分离，该阶段能够控制事件处理程序的执行以实现各种资源管理策略。例如，传递给事件处理程序的事件的数量和顺序可以由运行时环境在外部控制。但是，应用程序还可以通过过滤或重新排序传递给它的事件批来实现自己的调度策略。</p><p><strong>作为阶段网络的应用</strong></p><p>​      SEDA应用程序构建为阶段网络，由事件队列连接。事件处理程序可以通过首先获取该阶段的传入事件队列的句柄（通过系统提供的查找例程），然后在该队列上调用入队操作，将事件排入另一个阶段。<br>SEDA中事件队列的一个重要方面是它们可能是有限的：也就是说，如果队列希望拒绝新条目（例如，因为它已达到阈值），则入队操作可能会失败。当排队操作失败时，应用程序可以使用背压（通过阻塞整个队列）或减载（通过丢弃事件）。或者，应用程序可能希望采取某些特定于服务的操作，例如向用户发送错误，或执行替代功能，例如提供降级服务。</p><p>​      图5说明了基于SEDA的应用程序的结构，在本例中是5.1节中描述的Haboob Web服务器。该应用程序包含许多特定于应用程序的阶段，用于处理HTTP请求，实现页面缓存等，以及运行时提供的几个通用阶段，以支持异步I/O. 这些接口在第4节中进一步描述。</p><p>​      阶段之间引入队列通过采用显式控制边界来解耦其执行。此模型将线程的执行约束到给定阶段，因为线程可能只通过将事件排入队列来跨控制边界传递数据。一个基本问题是两个代码模块是应该通过队列进行通信，还是直接通过子程序调用进行通信。在两个模块之间引入队列可提供隔离，模块化和独立负载管理，但可能会增加延迟。例如，第三方代码模块可以在其自己的阶段中隔离，允许其他阶段通过其事件队列与之通信，而不是直接调用它。</p><p>​      SEDA设计有助于服务的调试和性能分析，这对于复杂的多线程服务器来说一直是一个挑战。 将应用程序代码分解为阶段和显式事件传递机制有助于检查; 例如，调试工具可以跟踪通过系统的事件流，并可视化阶段之间的交互。 由于各阶段通过事件调度协议而不是传统API进行交互，因此可以直接在组件之间插入代理阶段以进行调试和性能分析。 使用这种机制，我们的SEDA原型能够生成描绘应用程序阶段及其关系的图表。 原型还可以生成事件队列长度，内存使用和其他系统属性的时间视图，这些属性对于理解性能很有价值。</p><h3 id="动态资源控制器"><a href="#动态资源控制器" class="headerlink" title="动态资源控制器"></a>动态资源控制器</h3><p>​      实现易于服务工程的关键目标是保护程序员免受性能调优的复杂性。 为了使每个阶段保持在其运行状态内，SEDA利用一组资源控制器，根据观察到的性能和需求自动调整阶段的资源使用。 抽象地，控制器观察阶段的运行时特性并调整分配和调度参数以满足性能目标。 控制器既可以完全掌握关于特定阶段的本地知识，也可以基于全局状态协同工作。</p><p>​      我们在SEDA中实现了几个资源控制器，其中两个如图7所示。第一个是线程池控制器，它调整每个阶段内执行的线程数。 目标是避免分配太多线程，但仍有足够的线程来满足阶段的并发需求。 控制器定期对输入队列进行采样，并在队列长度超过某个阈值时添加一个线程，最多为每个阶段的最大线程数。 当线程空闲一段指定的时间后，线程将从一个阶段中删除。 图8显示了在5.1节中描述的Web服务器中运行的线程池控制器的影响; 控制器操作将在4.2节中详细讨论。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223433294.png" alt="image-20240530223433294"></p><p>图7：SEDA资源控制器：每个阶段都有一个关联的控制器，可以调整其资源分配和行为，以使应用程序保持在其运行状态。 线程池控制器调整在阶段内执行的线程数，批处理控制器调整事件处理程序的每次迭代处理的事件数。<br>      第二个是批处理控制器，它调整每个阶段内事件处理程序调用处理的事件数（批处理因子）。 已经观察到[31]一次处理许多事件会增加吞吐量，因为可以执行缓存局部性和任务聚合。 但是，较大的批处理因子也会增加响应时间。 控制器试图通过搜索维持高吞吐量的最小批处理因子来权衡这些影响。 它通过观察来自一个阶段的事件的输出速率（通过维持许多样本的移动平均值）来操作，并降低批处理因子直到吞吐量开始降低。 如果吞吐量略有下降，则批处理因子会少量增加。 控制器通过将批处理因子重置为其最大值来响应负载的突然下降。 图9显示了工作中的批处理控制器。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223454494.png" alt="image-20240530223454494"></p><p>图8：SEDA线程池控制器：此图显示了在运行Haboob Web服务器期间线程池控制器的操作，如第5.1节中所述。 控制器根据相应事件队列的长度调整每个阶段的线程池的大小。 在此运行中，队列长度每2秒采样一次，如果队列超过100个条目，则会将一个线程添加到池中（每个阶段的最大限制为20个线程）。当线程空闲超过5秒时，它们将从池中删除。 异步文件阶段使用10个队列条目的控制器阈值来夸大控制器的行为。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223512168.png" alt="image-20240530223512168"></p><p>图9：SEDA批处理控制器：该图显示了批处理控制器对简单基准测试的操作，该基准测试包括以振荡速率生成事件的单个阶段。 这导致测量的输出速率变化，如图的顶部所示。当输出速率增加时，控制器会降低批处理因子。当输出速率降低时，控制器会增加批处理因子。在输出速率突然下降之后，批处理因子被重置为其最大值。<br>      这些机制代表了SEDA中动态控制的两个简单例子。可以将更复杂的控制器引入系统中; 例如，控制器可能会根据阶段优先级的全局概念调整线程池大小，或者将整个系统中的线程数保持在某个阈值以下。另一种选择是根据阶段的进展调整线程调度参数，如Steere等人提出的。[51]。 SEDA异步套接字库（将在下一节中介绍）包含一个可选控制器，用于限制从网络读取数据包的速率 在5.1节中，我们描述了一个特定于应用程序的控制器，它可以自适应地减少负载以满足响应时间目标。SEDA的结构有助于检查和控制底层应用，并且该模型可以实现一系列控制策略。<br>      SEDA中动态控制的一个重要方面是它允许应用程序适应不断变化的条件，尽管底层操作系统使用了特定的算法。从某种意义上说，SEDA的控制器对操作系统的资源管理策略很天真。例如，SEDA批处理控制器不知道OS线程调度策略; 相反，它会影响基于应用程序性能的外部观察的线程调度。 虽然在某些情况下可能需要对底层操作系统施加更多控制 - 例如，为特定阶段或线程提供服务质量保证 - 我们认为商用操作系统提供的基本资源管理机制，取决于应用级别控制，足以满足互联网服务的需求。</p><h3 id="Sandstorm：SEDA原型"><a href="#Sandstorm：SEDA原型" class="headerlink" title="Sandstorm：SEDA原型"></a>Sandstorm：SEDA原型</h3><p>​      我们已经实施了一个名为Sandstorm的基于SEDA的互联网服务平台。Sandstorm完全用Java实现，并使用一组native库来实现非阻塞套接字I/O（如第4节所述）。使用最新的Java实现，加上正确地使用Java的语言功能，我们发现使用Java的软件工程的稳定性优势远远超过了性能权衡。例如，我们依靠Java的自动内存管理来在系统内对“过期”事件进行垃圾收集; 这大大简化了代码，因为组件不负责跟踪事件的生命周期。Java和静态编译语言之间的性能差距也在缩小; 事实上，我们基于Java的SEDA Web服务器优于在C中实现的两个流行的Web服务器，如第5.1节所述。</p><p>​      在Sandstorm中，每个应用程序模块都使用单个方法调用handleEvents()实现一个简单的事件处理程序接口，该方法处理从阶段的传入事件队列中提取的一批事件。应用程序不创建或管理线程; 这是运行时系统和相关控制器的责任。Sandstorm提供了一个线程管理器接口，可以对其进行定制以实现各种线程分配和调度策略; 此处描述的版本管理每个阶段的线程池，并依赖于底层操作系统进行调度。 Sandstorm提供用于命名，创建和销毁阶段，执行队列操作，控制队列阈值以及分析和调试的API。下一节中描述的套接字和文件I/O机制被提供为标准接口。</p><p>​      Sandstorm运行时由19934行代码和7871非注释源语句（NCSS）组成。其中，3023 NCSS专用于核心运行时，2566专用于I/O设施。</p><h2 id="异步I-O原语"><a href="#异步I-O原语" class="headerlink" title="异步I/O原语"></a>异步I/O原语</h2><p>​      要满足SEDA支持高并发性的目标，需要高效，强大的I/O接口。本节描述如何使用SEDA概念使用现有OS原语实现这些接口。我们描述了一个异步网络套接字层，它利用操作系统提供的非阻塞I/O，以及使用阻塞OS调用和线程池来暴露非阻塞行为的异步文件I/O层。这两个层都实现为一组SEDA阶段，应用程序可以使用它们来提供快速的异步I/O.</p><h3 id="异步套接字I-O"><a href="#异步套接字I-O" class="headerlink" title="异步套接字I / O."></a>异步套接字I / O.</h3><p>​      Sandstorm异步套接字（asyncSocket）层为服务提供了易于使用的非阻塞套接字接口。 应用程序创建类asyncClientSocket和asyncServerSocket的实例以启动传出和传入套接字连接。建立连接时，会将asyncConnection对象推送到用户提供的事件队列（通常是与请求阶段关联的队列）。传入的数据包被排入用户的事件队列，asyncConnection实现了一个可以放置传出数据包的队列接口。每个输出包还可以具有相关联的事件队列，当包被传输时，一个完成事件被推到这个队列上。错误和其他通知事件以类似的方式传递给用户。<br>​      在内部，asyncSocket层使用三个阶段实现，这三个阶段在所有套接字之间共享，如图10所示.readStage读取网络数据包并响应用户请求以在新套接字上启动数据包读取。writeStage将数据包写入网络并建立新的传出连接。 listenStage接受新的TCP连接并响应用户监听新端口的请求。asyncConnection，asyncClientSocket或async-ServerSocket上的每个操作都将转换为请求并放置到相应阶段的请求队列中。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223637885.png" alt="image-20240530223637885"></p><p>图10：基于SEDA的异步套接字层：Sandstorm套接字接口包括三个阶段：读取，写入和监听。读取阶段响应网络I/O就绪事件并从套接字读取数据，将新数据包推送到应用程序阶段。写入阶段接受传出数据包并调度它们以写入适当的套接字。它还建立新的传出套接字连接。listen阶段接受新的TCP连接并将连接事件推送到应用程序。<br>      每个asyncSocket阶段都为两个独立的事件队列提供服务：来自用户的请求队列，以及来自操作系统的I/O 就绪/完成事件队列。 每个阶段中的线程交替地为每个队列服务，使用简单的超时机制在两者之间切换。I/O事件队列实现为库，该库导致出队操作调用适当的OS调用以检索I/O事件。我们当前的实现支持标准的UNIX poll（2）系统调用以及用于事件传递的/dev/poll [46]接口。 native库用于在Java [60]中提供非阻塞套接字调用。为了提高套接字的公平性，每个阶段随机化处理操作系统提供的I/O事件的顺序。这是必要的，因为OS通常以固定顺序（例如，按文件描述符的递增顺序）返回套接字事件。<br>      只要I/O就绪事件指示套接字具有可用数据，readStage就会通过执行套接字读取来进行操作。它最多将16 KB读入预先分配的缓冲区，并将生成的数据包排入用户提供的事件队列中。在I/O错误的情况下（例如，因为对等方已关闭连接），该阶段关闭套接字并将适当的通知事件推送给用户。每个套接字读取都需要分配新的数据包缓冲区;虽然这可能会导致大量的垃圾收集开销，但我们并未发现这是一个性能问题。请注意，由于此系统是用Java实现的，因此不需要显式释放过期的数据包。readStage还提供了一个可选的速率控制器，可以限制从网络读取数据包的速率;该控制器可用于在过载条件下执行减载。通过计算输入包速率的移动平均值并将人工延迟引入事件处理循环以实现特定速率目标来实现控制器。<br>      writeStage接收来自用户的数据包写入请求，并将它们排入与特定套接字关联的内部队列。当操作系统指示套接字已准备好写入时，它会尝试在该套接字的传出队列上写入下一个数据包。如第5.2节所述，可以对套接字队列进行阈值处理，以防止“慢”套接字在服务器中占用过多资源。<br>      为了评估asyncSocket的性能，我们实现了一个简单的服务器应用程序，它接受来自多个客户端的8KB突发数据包，每1000个突发数据包响应一个32字节的ACK。这种有点人为的应用程序旨在强调网络层，并随着客户端数量的增加来衡量其可扩展性。图11显示了服务器的总吞吐量，期间客户端数量从1增加到8192.服务器和客户端计算机都是使用运行Linux 2.2.14和IBM JDK 1.3的千兆以太网互连的4路500 MHz Pentium III系统。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240530223652100.png" alt="image-20240530223652100"></p><p>图11：异步套接字层性能：此图显示了基于SEDA异步套接字层作为并发连接数量的函数的性能。每个客户端打开与服务器的连接并发出8KB突发数据包; 服务器对每个1000个数据包的突发，响应一个32字节的单独ACK。所有机器都通过交换式千兆以太网连接，并运行Linux 2.2.14。基于SEDA的服务器使用操作系统提供的非阻塞I/O原语。将性能与使用阻塞套接字和多个线程来模拟异步I/O的兼容性层进行比较。基于线程的层无法接受超过400个并发连接，因为所需的线程数将超过Linux中的每用户线程限制。<br>      套接字层的两种实现方式。 基于SEDA的层使用OS提供的非阻塞I/O和/dev/poll事件传递机制[46]。 将其与使用阻塞套接字的兼容性层和用于模拟异步I/O的线程池进行比较。该层为每个连接创建一个线程来处理套接字读取事件和一个固定大小的120个线程池来处理套接字写入。此兼容层最初是为了在Java下提供异步I / O而开发的，它不直接提供此功能。<br>      非阻塞实现明显优于线程版本，随着连接数量的增加，线程版本迅速降级。实际上，当接收超过400个连接时，线程实现会崩溃，因为所需的线程数超过了Linux中的每用户线程限制。非阻塞层的轻微吞吐量降低部分是由于Linux网络堆栈缺乏可扩展性。即使使用高度优化的/dev/poll机制[46]进行套接字I/O事件通知，随着套接字数量的增加，来自操作系统的轮询准备事件所涉及的开销也会显着增加[29]。</p><h3 id="异步文件I-O"><a href="#异步文件I-O" class="headerlink" title="异步文件I/O."></a>异步文件I/O.</h3><p>​      Sandstorm文件I/O（asyncFile）层展示与asyncSocket非常不同的设计点。由于底层操作系统不提供非阻塞文件I/O原语，因此我们不得不利用阻塞I/O和有界线程池来实现该层.3用户通过asyncFile对象执行文件I/O，该对象支持熟悉的接口读，写，寻找，统计和关闭。这些操作中的每一个都转换为asyncFile阶段的事件队列中的请求。asyncFile线程将每个请求出列并对文件执行相应的（阻塞）I/O操作。 为确保对同一文件上的多个I/O请求进行串行执行，一次只有一个线程可以处理特定文件的事件。当I/O请求完成时，相应的完成事件将排入用户的事件队列。<br>​      asyncFile阶段在其线程池中使用单个线程进行初始化。 SEDA线程池控制器负责根据观察到的并发需求动态调整线程池的大小。图8显示了在运行第5.1节中描述的基于SEDA的Web服务器期间工作的线程池控制器。运行分为三个阶段，每个阶段对应越来越多的客户;请注意，客户端负载是非常突发的。随着文件访问的突发到来，控制器将线程添加到每个阶段的线程池，直到最多20个线程饱和。在这之间，不需要I / O，并且线程池缩小。虽然PageCache和CacheMiss阶段需要更多线程且客户端负载增加，但服务文件I / O所需的线程数实际上会减少。这是因为底层文件系统缓冲区缓存正在预热，并且能够更快地为磁盘请求提供服务。线程池控制器推断出需要更少的线程来管理磁盘并发，并避免创建不需要的线程。</p><h2 id="应用和评估"><a href="#应用和评估" class="headerlink" title="应用和评估"></a>应用和评估</h2><p>​      在本节中，我们将介绍两个应用程序的性能和负载调节评估：Haboob，一个高性能的HTTP服务器; 和Gnutella对等文件共享网络的数据包路由器。 Haboob代表客户端发出请求并等待响应的“闭环”服务器，而Gnutella数据包路由器是一个“开环”服务器的例子，其中服务器性能不会成为提供负载的限制因素。</p><h3 id="Haboob：高性能HTTP服务器"><a href="#Haboob：高性能HTTP服务器" class="headerlink" title="Haboob：高性能HTTP服务器"></a>Haboob：高性能HTTP服务器</h3><p>​      Web服务器构成了可扩展的Internet服务的原型组件。许多先前的工作已经研究了构建高性能HTTP服务器的工程方面，但很少有关于负载调节，稳健性和易于构造的说法。研究HTTP服务器的一个好处是，存在各种行业标准的基准来衡量它们的性能。我们选择了SPECweb99基准套件[50]中的负载模型作为我们测量的基础，并进行了两项重要修改。首先，我们仅测量静态网页访问的性能（构成SPECweb99负载混合的70％）。其次，我们将网页文件集固定为3.31 GB的磁盘文件，对应于SPECweb99目标负载1000个连接。文件大小从102到921600字节，可以使用SPECweb99规定的基于Zipf的请求分发进行访问。更多细节可以在[50]中找到。</p><p> <strong>Haboob架构</strong></p><p>​      Haboob的整体结构如图5所示。服务器包含10个阶段，其中4个阶段专门用于异步套接字和磁盘I/O，如上一节所述。HttpParse阶段负责接受新的客户端连接和传入数据包的HTTP协议处理。 HttpRecv阶段接受HTTP连接并请求事件并将它们传递到PageCache阶段（如果它们代表磁盘文件）或直接生成响应（对于为收集服务器统计信息而生成的动态页面）。 PageCache实现了使用哈希表实现的内存中网页缓存。<br>​      Haboob的整体结构如图5所示。服务器包含10个阶段，其中4个阶段专门用于异步套接字和磁盘I/O，如上一节所述。HttpParse阶段负责接受新的客户端连接和传入数据包的HTTP协议处理。HttpRecv阶段接受HTTP连接并请求事件并将它们传递到PageCache阶段（如果它们代表磁盘文件）或直接生成响应（对于为收集服务器统计信息而生成的动态页面）。PageCache实现了一个使用由URL索引的哈希表实现的内存网页缓存，其中每个条目包含一个由HTTP头和Web页面有效负载组成的响应数据包。CacheMiss阶段负责处理页面缓存未命中，使用异步文件I/O层从磁盘读取所请求页面的内容。最后，HttpSend向客户端发送响应并处理连接管理和统计信息收集的某些方面。另一个阶段（图中未显示）从HTML模板生成动态Web页面，嵌入的代码用Python脚本语言编写[36]。此功能提供了通用的服务器端脚本，类似于Java Server Pages [26]。<br>​      页面缓存尝试将缓存大小保持在给定阈值以下（对于下面提供的测量，设置为204800 KB）。它积极地回收容量未命中的缓冲区，而不是允许旧的缓冲区被Java运行时垃圾收集; 我们发现这种方法可以产生明显的性能优势。缓存阶段使用特定于应用程序的事件调度来提高性能。特别是，它实现了最短连接优先（SCF）[15]调度，它重新排序请求流以在较长的缓存条目之前发送短缓存条目，并优先考虑缓存命中而不是未命中。由于SCF仅应用于批处理控制器提供的每组事件，因此跨请求的饥饿不是问题。<br>​      将Haboob构建为一组阶段极大地提高了设计的模块性，因为每个阶段都体现了一个强大的，可重复使用的软件组件，可以单独调节负载。 我们能够测试页面缓存的不同实现，而无需对其余代码进行任何修改; 运行时只是实例化一个不同的阶段来代替原始页面缓存。同样，另一位没有Haboob结构知识的开发人员能够花很少的工作将Haboob使用异步文件层替换为备用文件系统接口。不包括Sandstorm平台，Web服务器代码仅包含3283个非注释源语句，其中676个NCSS专用于HTTP协议处理库。</p><p><strong>基准配置</strong></p><p>​      为了进行比较，我们提供了来自流行的Apache [6] Web服务器（版本1.3.14，与Linux Red Hat 6.2系统一起提供）以及Rice大学的Flash [44] Web服务器的性能测量。Apache使用150个进程的固定大小的进程池; 每个进程一次管理一个连接，从磁盘读取文件数据并使用阻塞I/O操作以8 KB块的形式将其发送到客户端。Flash使用高效的事件驱动设计，单个进程处理大多数请求处理任务。一组帮助程序进程执行（阻止）磁盘I/O，路径名解析和其他操作。Flash静态页面缓存的最大大小设置为204800 KB，与Haboob中的大小相同。Apache和Flash都是用C实现的，而Haboob是用Java实现的。<br>​      以下所有测量均在服务器上运行，该服务器运行在具有2 GB RAM和Linux 2.2.14的4路SMP 500 MHz Pentium III系统上。IBM JDK v1.3.0用作Java平台。32台具有类似配置的机器用于生成负载，每台客户机使用多个线程来模拟许多实际客户机。所有机器都通过交换式千兆以太网互连。虽然这种配置不能模拟广域网效果，但我们感兴趣的是服务器在高负载下的性能和稳定性。<br>​      客户端负载生成器循环，不断请求网页（使用SPECweb99套件指定的分发），读取结果，并在请求下一页之前休眠20毫秒的固定时间。 为了更密切地模拟广域中客户端的连接行为，每个客户端在5个HTTP请求之后关闭TCP连接，并在继续之前重新建立连接。该值是根据[39]的HTTP流量观察结果选择的。所有基准测试均使用热文件系统和网页缓存运行。请注意，3.31 GB的文件集大小远远大于物理内存，Haboob和Flash的静态页面缓存仅设置为200 MB; 因此，这些测量包括大量的磁盘I/O.</p><p><strong>性能分析</strong></p><p>​      图12显示了Haboob与Apache和Flash在聚合吞吐量和响应时间方面的性能。还显示了每个客户完成的请求数量的the Jain fairness index(公平指数)[27]。</p><h3 id="Gnutella数据包路由器"><a href="#Gnutella数据包路由器" class="headerlink" title="Gnutella数据包路由器"></a>Gnutella数据包路由器</h3><p>​      我们选择实现Gnutella数据包路由器来演示SEDA在非传统互联网服务中的使用。Gnutella路由器代表了一种与HTTP服务器完全不同的服务方式：在对等文件共享网络中的参与者之间路由数据包。像Gnutella这样的服务的重要性日益增加，因为新的分布式应用程序的开发是为了利用广域内主机的良好连接性。对等模型已被多个分布式存储系统采用，如Freenet [14]，OceanStore [30]和Intermemory [13]。<br>​      Gnutella [19]允许用户搜索和下载来自其他Gnutella用户的文件。该协议完全去中心化的;运行Gnutella客户端的节点形成一个通过TCP/IP分层的adhoc多跳路由网络，节点通过将收到的消息转发给它们的相邻节点来进行通信。Gnutella节点倾向于同时连接到几个（通常是四个或更多）其他节点，并且网络上节点的初始发现是通过众所周知的主机完成的。Gnutella中有五种消息类型：ping用于发现网络上的其他节点; pong是对ping的回应; query用于搜索其他Gnutella主机服务的文件; queryhits是对查询的响应;和push用于允许客户端通过防火墙下载文件。数据包路由器负责向所有其他相邻接点广播接收到的ping和查询消息，并沿着相应的ping或查询消息的路径路由pong，queryhits和push消息。有关消息格式和路由协议的详细信息，请参见[19]。</p><p><strong>架构</strong></p><p>​      除了异步套接字I/O层之外，基于SEDA的Gnutella数据包路由器使用3个阶段实现。该代码由1294个非注释源语句组成，其中880个NCSS专门用于Gnutella协议处理。GnutellaServer阶段接受TCP连接并处理数据包，将数据包事件传递到GnutellaRouter阶段，该阶段执行路由表的实际数据包路由和维护。 GnutellaCatcher是用于连接Gnutella网络的助手阶段，它通过联系周所周知的站点（well-known site）来接收要连接的主机列表。除了由其他广域客户端建立的任何连接之外，它还尝试保持至少4个同时连接到网络的连接。加入“实时”Gnutella网络和路由数据包使我们能够在真实环境中测试SEDA，以及测量通过路由器的流量。在一个37小时的运行期间，路由器处理了2480万个数据包（平均每秒179个数据包），并从网络上的其他主机接收了72,396个连接，在任何给定时间平均有12个同时连接。路由器每秒能够支持超过20,000个数据包。</p><p> <strong>防止慢套接字</strong></p><p>​      我们原始的数据包路由器原型展示了一个有趣的内存泄漏：在通过网络正确路由数据包几个小时之后，服务器会在耗尽内存后崩溃。观察各个阶段队列长度使我们能够轻松地检测问题的根源：大量的传出数据包正在排队等待某些广域连接，导致队列长度（因此内存使用）变得无限制。我们测量了Gnutella消息的平均数据包大小约为32个字节;每秒仅115个数据包的数据包速率可以使28.8千比特的调制解调器链路饱和，这仍然是许多Gnutella软件用户常用的。在这种情况下，解决方案是对每个套接字的传出数据包队列施加一个阈值，并关闭超过其阈值的连接。此解决方案是可以接受的，因为Gnutella客户端会自动发现并连接到网络上的多个主机;跨网络节点的冗余意味着客户端不需要依赖于特定主机来保持连接到网络。</p><p><strong>负载调节行为</strong></p><p>​      为了评估SEDA资源控制器在负载调节中的使用，我们在Gnutella路由器中引入了一个故意的瓶颈，其中每个查询消息都会导致20 ms的服务延迟。这是通过让应用程序事件处理程序在收到查询数据包时休眠20毫秒来实现的。 我们实现了一个负载生成客户端，它连接到服务器并根据与实际Gnutella流量相近的分布生成数据包流。在我们的Gnutella流量模型中，查询消息构成了生成数据包的15％。使用单个线程执行数据包路由，很明显，随着流入服务器的数据包数量的增加，此延迟将导致其他消息的大量积压。<br>​      图14（a）显示了ping和查询数据包通过服务器的平均延迟，提供的负载从100到1000包/秒增加。客户端和服务器计算机使用与HTTP服务器基准测试中相同的配置。当提供的负载超过服务器的容量时，数据包延迟会急剧增加。在1000个数据包/秒的情况下，服务器崩溃（由于内存不足以缓冲传入的数据包），然后才能进行延迟测量。</p><p>​      此时，可以采用若干负载调节策略。一个简单的策略是对每个阶段的传入事件队列进行阈值处理，并在超过阈值时丢弃数据包。或者，可以使用类似于随机早期检测（RED）拥塞避免方案[17]中使用的方法，其中基于输入队列的长度概率地丢弃数据包。虽然这些策略会导致许多数据包在过载期间被丢弃，但由于Gnutella网络流量的有损性质，这可能是一种可接受的解决方案。另一种策略是允许所有数据包进入系统，但让应用程序事件处理程序过滤掉查询数据包（这是过载的来源）。另一个策略是利用asyncSocket输入速率控制器将进入的数据包速率限制在系统中。</p><p>​      另一种方法是利用SEDA的资源控制器自动克服瓶颈。 在这种方法中，线程池控制器在检测到需要额外的并发时将线程添加到GnutellaRouter阶段; 这种机制类似于基于集群的TACC [18]系统中的动态工作者分配。图14（b）显示了启用SEDA线程池控制器的Gnutella路由器的平均延迟。如图14（c）所示，2个线程被添加到GnutellaRouter线程池中，允许服务器处理增加的数据包负载，尽管存在瓶颈。这个数字与从Little的结果中获得的理论值相匹配：如果我们将阶段建模为具有n个线程的排队系统，平均数据包到达率为λ，查询数据包频率为p，查询服务延迟为L秒， 那么维持λ完成率所需的线程数是n =λpL=（1000）（0.15）（20 ms）= 3个线程。</p><h2 id="讨论和结论"><a href="#讨论和结论" class="headerlink" title="讨论和结论"></a>讨论和结论</h2><p>​      因特网服务引发了一系列新的系统设计要求，因为必须以强大，易于编程的方式提供大规模并发，以便优雅地处理负载的巨大变化。 SEDA是为该制度建立设计原则的一步。在本文中，我们介绍了SEDA设计和执行模型，介绍了由显式事件队列连接的阶段的概念。SEDA利用一组动态控制器来管理每个阶段的资源使用和调度; 我们已经描述了几个控制器，包括两个跨阶段的控制线程分配和一个阶段内部使用的批处理程度。我们还分析了两个高效的异步I/O组件，以及使用SEDA设计构建的两个应用程序，表明SEDA在负载下表现出良好的性能和稳健的行为。<br>​      SEDA模型在互联网服务设计领域开辟了新的问题。显式事件队列和动态资源控制器的使用提高了专门针对服务进行调整的新颖调度和资源管理算法的可能性。作为未来的工作，我们计划实施一个广义的流量控制方案，用于各阶段之间的通信; 在此方案中，每个事件都需要一定数量的信用才能排入目标阶段的事件队列。 通过为每个事件分配可变数量的信用，可以实现有趣的负载调节策略。<br>​      我们认为，测量和控制是繁忙的互联网服务中资源管理和过载保护的关键。这与基于资源遏制的长期存在的方法形成对比，后者为系统中的每个任务（例如进程，线程或服务器请求）分配固定资源，并努力控制每个任务消耗的资源。尽管这些技术在互联网服务中提供差异化服务方面已经取得了一些成功[57]，但是遏制通常要求对每项任务进行先验的资源分配，从而限制了适用的负载调节策略的范围。相反，我们认为动态资源控制，加上面对过载的特定应用适应，是接近负载调节的正确方法。<br>​      当控制被视为资源管理的基础时，会出现两个新的挑战。第一个是检测过载情况：许多变量会影响服务的交付性能，而确定服务实际上是过载的以及原因是一个有趣的问题。第二是确定适当的控制策略来抵抗过载。 我们计划对当前实施中的资源控制器进行多项改进，以及针对备用指标进行优化的新控制器。 例如，为了减少资源消耗，可能需要优先考虑释放资源而不是消耗资源的阶段。在SEDA下，控制系统的工作主体[43,45]可以用于服务资源管理，我们只是触及了这种技术潜力的表面。<br>​      关于事件驱动的并发模型的一个共同关注点是易于编程。现代语言和编程工具支持线程应用程序的开发和调试，许多开发人员认为事件驱动编程本质上更加困难。事实上，大多数事件驱动的服务器应用程序通常非常复杂，并且在设计上有点特别，这使得这种观点持续存在。根据我们的经验，SEDA模型中的编程比多线程应用程序设计和传统的事件驱动模型更容易。当线程被隔离到单个阶段时，线程同步和竞争条件等问题更易于管理。阶段之间面向消息的通信建立了明确的排序;在传统的事件驱动设计中，通过系统跟踪事件流程要困难得多。我们认为SEDA是线程和事件驱动设计之间的理想中间点，对编程模型的进一步探索是未来工作的重要方向。<br>​      虽然SEDA有助于在商品操作系统上构建条件良好的服务，但SEDA模型为操作系统设计提供了新的方向。我们设想一个直接支持SEDA执行模型的操作系统，并为应用程序提供对调度和资源使用的更大控制。这种方法类似于各种研究系统[5,11,28,34]中提供的方法，可以实现特定于应用程序的资源管理。更为根本的是，基于SEDA的操作系统无需设计为允许多个应用程序透明地共享资源。Internet服务是高度专业化的，并不是为了与其他应用程序共享机器而设计的：例如，Web服务器通常不希望与数据库引擎在同一台机器上运行（更不用说科学计算或文字处理器）。尽管操作系统可以实施保护（以防止一个阶段破坏内核状态或另一个阶段），但系统不需要以掩盖应用程序可用性的方式虚拟化资源。</p>]]></content>
    
    
    <summary type="html">SEDA论文翻译</summary>
    
    
    
    <category term="网络编程" scheme="https://penge666.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="网络编程" scheme="https://penge666.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Cpp设计模式</title>
    <link href="https://penge666.github.io/posts/1155b381.html"/>
    <id>https://penge666.github.io/posts/1155b381.html</id>
    <published>2024-05-30T09:04:07.000Z</published>
    <updated>2024-05-30T09:04:55.992Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>设计模式：就是在解决某一类问题场景时，有既定的优秀的代码框架可以直接使用，有以下优点可取：</p><p>（1）代码更易于维护，代码的可读性、复用性、可移植性、健壮性更好。</p><p>（2）当软件原有需求有变更或者增加新的需求时，合理的设计模式的应用，能够做到软件设计要求的”开-闭原则”，即对修改关闭，对扩展开放，使软件原有功能修改，新功能扩充非常灵活。</p><p>（3）合理的设计模式的选择，会使软件设计更加模块化，积极的做到软件设计遵循的“高内聚，低耦合”这一根本原则。</p><h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><p>单例模式顾名思义，保证一个类仅可以有一个实例化对象，并且提供一个可以访问它的全局接口。这是一个创建性模式（主要是指对象的创建方式）。<strong>单例模式和多线程结合到是很紧密的。包括两种单例模式，以及线程安全的问题</strong>。</p><p><strong>应用</strong></p><p>第一种：日志模块</p><p>假如 这里有一个类，提供了很多方法来封装了一个日志模块。一个软件本身可能有很多的功能模块，那么这么多的模块都要通过日志模块进行写入一些软件运行的日志信息到磁盘内。应该是把这些所有的日志信息都给到一个日志模块的对象上。</p><p>第二种：数据库模块</p><p>作为一个个的数据库客户端，是要通过数据库模块与数据库服务器进行交互通信的。那么这个数据库client就可以设计成一个单例：应用软件的其他功能模块如果要与数据库服务器进行交互通信，可以调用一个数据库模块对象的某一个方法即可，不需要去创建那么多的对象。毕竟数据库的请求那么多，不可能做到 每一次处理请求都生成一个数据库对象，这样会导致数据库模块对象特别特别多和数据库的连接也特别的多，占用大量内存且非常麻烦。</p><p><strong>实现单例模式必须注意一下几点：</strong></p><p>（1）单例类只能有一个实例化对象。</p><p>（2）单例类必须自己提供一个实例化对象。</p><p>（3）单例类必须提供一个可以访问唯一实例化对象的接口。</p><p>（4）单例模式分为懒汉和饿汉两种实现方式。</p><p>单例：</p><p>饿汉式    对象在程序执行时优先创建【线程安全】</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> Singleton *<span class="title">getInstance</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> &amp;instance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">Singleton</span>(<span class="type">const</span> Singleton &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    Singleton &amp;<span class="keyword">operator</span>=(<span class="type">const</span> Singleton &amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">static</span> Singleton instance;</span><br><span class="line">    <span class="built_in">Singleton</span>() &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line">Singleton Singleton::instance;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Singleton *p1 = Singleton::<span class="built_in">getInstance</span>();</span><br><span class="line">    Singleton *p2 = Singleton::<span class="built_in">getInstance</span>();</span><br><span class="line">    cout &lt;&lt; p1 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; p2 &lt;&lt; endl;</span><br><span class="line">    <span class="comment">// Singleton p = *p1;</span></span><br><span class="line">    <span class="comment">// cout &lt;&lt; &amp;p &lt;&lt; endl;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>懒汉式： 对象的创建在第一次调用getInstance函数时创建【线程不安全】</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> Singleton *<span class="title">getInstance</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">nullptr</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="built_in">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">Singleton</span>(<span class="type">const</span> Singleton &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    Singleton &amp;<span class="keyword">operator</span>=(<span class="type">const</span> Singleton &amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">static</span> Singleton *instance;</span><br><span class="line">    <span class="built_in">Singleton</span>() &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line">Singleton *Singleton::instance = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Singleton *p1 = Singleton::<span class="built_in">getInstance</span>();</span><br><span class="line">    Singleton *p2 = Singleton::<span class="built_in">getInstance</span>();</span><br><span class="line">    cout &lt;&lt; p1 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; p2 &lt;&lt; endl;</span><br><span class="line">    <span class="comment">// Singleton p = *p1;</span></span><br><span class="line">    <span class="comment">// cout &lt;&lt; &amp;p &lt;&lt; endl;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述懒汉式如何改成线程安全的</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> Singleton *<span class="title">getInstance</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">nullptr</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 锁加双重判断</span></span><br><span class="line">            <span class="built_in">unique_lock</span>&lt;mutex&gt;(mtx);</span><br><span class="line">            <span class="keyword">if</span> (instance == <span class="literal">nullptr</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                instance = <span class="keyword">new</span> <span class="built_in">Singleton</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">Singleton</span>(<span class="type">const</span> Singleton &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">    Singleton &amp;<span class="keyword">operator</span>=(<span class="type">const</span> Singleton &amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">static</span> Singleton *instance;</span><br><span class="line">    mutex mtx;</span><br><span class="line">    <span class="built_in">Singleton</span>() &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line">Singleton *Singleton::instance = <span class="literal">nullptr</span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Singleton *p1 = Singleton::<span class="built_in">getInstance</span>();</span><br><span class="line">    Singleton *p2 = Singleton::<span class="built_in">getInstance</span>();</span><br><span class="line">    cout &lt;&lt; p1 &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; p2 &lt;&lt; endl;</span><br><span class="line">    <span class="comment">// Singleton p = *p1;</span></span><br><span class="line">    <span class="comment">// cout &lt;&lt; &amp;p &lt;&lt; endl;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="简单工厂和工厂方法"><a href="#简单工厂和工厂方法" class="headerlink" title="简单工厂和工厂方法"></a>简单工厂和工厂方法</h2><p>简单工厂：它不属于标准的OOP设计模式中，而后面两种是包含在标准的OOP的23种设计模式中的。</p><p><strong>为什么要工厂模式：主要是封装了对象的创建过程。</strong> 创建性模式本身就是体现了：对象的创建过程的封装和隐藏。没有工厂模式的封装就是：对象的new 和 new等。当代码里面出现很多的类，每次创建在对象的时候，都需要通过new 类名称的方式来生成对象。</p><p>先来看个代码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span> :</span><br><span class="line"><span class="comment">//在构造函数的初始化列表里面给name初始化</span></span><br><span class="line"><span class="built_in">Car</span>(std::string name):_name(name)&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//提供一个给派生类（具体的汽车）重写的接口</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>= <span class="number">0</span>;<span class="comment">//纯虚函数</span></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">std::string _name;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BMW</span>:<span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">BMW</span> (std::string name):<span class="built_in">Car</span>(name)&#123;&#125;</span><br><span class="line"><span class="comment">//重写从基类基类继承过来的纯虚函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;宝马  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Audi</span> :<span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">Audi</span>(std::string name) :<span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line"><span class="comment">//重写从基类基类继承过来的纯虚函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;奥迪  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">Car* p1 = <span class="keyword">new</span> <span class="built_in">BMW</span>(<span class="string">&quot;x1&quot;</span>);</span><br><span class="line">Car* p2 = <span class="keyword">new</span> <span class="built_in">Audi</span>(<span class="string">&quot;A6&quot;</span>);</span><br><span class="line">p1-&gt;<span class="built_in">show</span>();</span><br><span class="line">p2-&gt;<span class="built_in">show</span>();</span><br><span class="line"><span class="keyword">delete</span> p1;</span><br><span class="line"><span class="keyword">delete</span> p2;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">上面的缺点在于：</span></span><br><span class="line"><span class="comment">1 需要记住派生类的名字，不然没法new对象</span></span><br><span class="line"><span class="comment">2 创建对象的时候，直接使用了对象</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">其实我们不需要去了解对象创建的具体内容</span></span><br><span class="line"><span class="comment">只要给我汽车就OK了，劳资不需要去知道怎么造车的</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用<strong>简单工厂</strong></p><p>解决办法为：把这些对象都给 封装到一个简单的工厂里面。如下：</p><p>通过下面这个简单的工厂把所有对象的创建给封装起来了，下面造汽车劳资不用管，我只是想要一辆车，通过传入不同的参数，得到不同的对象。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 在构造函数的初始化列表里面给name初始化</span></span><br><span class="line">    <span class="built_in">Car</span>(std::string name) : _name(name) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提供一个给派生类（具体的汽车）重写的接口</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>= <span class="number">0</span>; <span class="comment">// 纯虚函数</span></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    std::string _name;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bmw</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Bmw</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;宝马  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Audi</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Audi</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;奥迪  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">CarType</span></span><br><span class="line">&#123;</span><br><span class="line">    BMW,</span><br><span class="line">    AUDI</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleFactory</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">Car *<span class="title">createCar</span><span class="params">(CarType type)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (type)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> BMW:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Bmw</span>(<span class="string">&quot;x1&quot;</span>);</span><br><span class="line">        <span class="keyword">case</span> AUDI:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Audi</span>(<span class="string">&quot;A6&quot;</span>);</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    SimpleFactory *factory = <span class="keyword">new</span> <span class="built_in">SimpleFactory</span>();</span><br><span class="line">    Car *car1 = factory-&gt;<span class="built_in">createCar</span>(BMW);</span><br><span class="line">    Car *car2 = factory-&gt;<span class="built_in">createCar</span>(AUDI);</span><br><span class="line">    car1-&gt;<span class="built_in">show</span>();</span><br><span class="line">    car2-&gt;<span class="built_in">show</span>();</span><br><span class="line">    <span class="keyword">delete</span> factory;</span><br><span class="line">    <span class="keyword">delete</span> car1;</span><br><span class="line">    <span class="keyword">delete</span> car2;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用智能指针管理对象</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 在构造函数的初始化列表里面给name初始化</span></span><br><span class="line">    <span class="built_in">Car</span>(std::string name) : _name(name) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提供一个给派生类（具体的汽车）重写的接口</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>= <span class="number">0</span>; <span class="comment">// 纯虚函数</span></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    std::string _name;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bmw</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Bmw</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;宝马  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Audi</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Audi</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;奥迪  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">CarType</span></span><br><span class="line">&#123;</span><br><span class="line">    BMW,</span><br><span class="line">    AUDI</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleFactory</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">Car *<span class="title">createCar</span><span class="params">(CarType type)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (type)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> BMW:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Bmw</span>(<span class="string">&quot;x1&quot;</span>);</span><br><span class="line">        <span class="keyword">case</span> AUDI:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Audi</span>(<span class="string">&quot;A6&quot;</span>);</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;SimpleFactory&gt; <span class="title">factory</span><span class="params">(<span class="keyword">new</span> SimpleFactory())</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// SimpleFactory *factory = new SimpleFactory();</span></span><br><span class="line">    <span class="function">std::unique_ptr&lt;Car&gt; <span class="title">car1</span><span class="params">(factory-&gt;createCar(BMW))</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;Car&gt; <span class="title">car2</span><span class="params">(factory-&gt;createCar(AUDI))</span></span>;</span><br><span class="line">    car1-&gt;<span class="built_in">show</span>();</span><br><span class="line">    car2-&gt;<span class="built_in">show</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单工厂的缺点：</p><p>同一个工厂既建宝马，也整奥迪。不可能用一个工厂把所有对象的创建都封装起来。而且工厂里面的设计也不符合 <strong>开闭原则</strong>。</p><p><strong>开闭原则</strong></p><p>开闭原则是面向对象设计的一种重要原则，它的全称是“对扩展开放，对修改关闭”。这个原则的核心思想是，当应用的需求改变时，我们应该尽量通过添加新的代码进行扩展，而不是去修改已有的代码。</p><p>具体来说，开闭原则包含两个方面：</p><ul><li>对扩展开放：意味着我们应该设计出可以容易添加新功能的系统，只需要添加新的代码，而不需要修改原有的代码。</li><li>对修改关闭：意味着一旦我们完成了系统的设计和编码，应该尽量避免对已有的代码进行修改。因为修改已有的代码会带来很多风险，可能会引入新的错误。</li></ul><p>遵守开闭原则的好处是，可以使得系统更加稳定，更具有弹性，更容易进行维护和扩展。但同时，实现开闭原则也需要一定的设计和编码技巧，可能会增加系统的设计和实现的复杂性。</p><p>因此，需要根据上述根据<strong>对修改关闭，对扩展开放</strong>的原则进行修改。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 在构造函数的初始化列表里面给name初始化</span></span><br><span class="line">    <span class="built_in">Car</span>(std::string name) : _name(name) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提供一个给派生类（具体的汽车）重写的接口</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>= <span class="number">0</span>; <span class="comment">// 纯虚函数</span></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    std::string _name;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bmw</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Bmw</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;宝马  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Audi</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Audi</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;奥迪  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">CarType</span></span><br><span class="line">&#123;</span><br><span class="line">    BMW,</span><br><span class="line">    AUDI</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleFactory</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> Car *<span class="title">createCar</span><span class="params">(string name)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BmwFactoryMethod</span> : <span class="keyword">public</span> SimpleFactory</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function">Car *<span class="title">createCar</span><span class="params">(string name)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Bmw</span>(name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AUDIFactoryMethod</span> : <span class="keyword">public</span> SimpleFactory</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function">Car *<span class="title">createCar</span><span class="params">(string name)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Audi</span>(name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;SimpleFactory&gt; <span class="title">Afactory</span><span class="params">(<span class="keyword">new</span> AUDIFactoryMethod())</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;SimpleFactory&gt; <span class="title">Bfactory</span><span class="params">(<span class="keyword">new</span> BmwFactoryMethod())</span></span>;</span><br><span class="line">    <span class="comment">// SimpleFactory *factory = new SimpleFactory();</span></span><br><span class="line">    <span class="function">std::unique_ptr&lt;Car&gt; <span class="title">car1</span><span class="params">(Afactory-&gt;createCar(<span class="string">&quot;x1&quot;</span>))</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;Car&gt; <span class="title">car2</span><span class="params">(Bfactory-&gt;createCar(<span class="string">&quot;A5&quot;</span>))</span></span>;</span><br><span class="line">    car1-&gt;<span class="built_in">show</span>();</span><br><span class="line">    car2-&gt;<span class="built_in">show</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把工厂划分为一个继承结构：封装了一个工厂方法（纯虚函数）。派生类代表具体的工厂，产生具体的产品。（相应的工厂创建相应的产品），达到了一个工厂其相应的产品。</p><p>这就是对已有的功能进行封闭。开闭原则：对修改关闭，对扩展开放 此时要是删除一种产品的工厂，直接删除相应的派生类即可（也不会改动其他的类）。在调用的时候，想要获取一个对象，只需要调用 工厂相应的工厂方法就可以了，不需要去了解派生类叫什么名字、也不需要知道对象是怎么创建的（这些细节由工厂进行维护）。</p><h2 id="抽象工厂"><a href="#抽象工厂" class="headerlink" title="抽象工厂"></a>抽象工厂</h2><p>简单工厂的缺点如下：</p><p>比如说是 一类有关联关系的产品：手机、手机上的耳机等。根据上面的工厂方法，创建耳机，也得整上一个相应的耳机工厂，这样做 就有些不太现实（具体的一个个工厂类就太多了）。也就是这些一系列有关联关系的产品 应该放在一个工厂进行创建的。 毕竟有关联关系的产品太多了，不可能各个产品都创建相对应的工厂（工厂类将会极为庞大）。</p><p><strong>解决方法：将工厂方法升级为抽象工厂。抽象工厂也是需要工厂方法的，抽象工厂：对一系列有关联关系的产品簇提供产品对象的统一创建。</strong></p><p>就可以把一组有关联关系的产品簇提供产品对象的统一创建 放到一个工厂里面做了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 一系列产品1 汽车</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 在构造函数的初始化列表里面给name初始化</span></span><br><span class="line">    <span class="built_in">Car</span>(std::string name) : _name(name) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提供一个给派生类（具体的汽车）重写的接口</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>= <span class="number">0</span>; <span class="comment">// 纯虚函数</span></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    std::string _name;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bmw</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Bmw</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;宝马  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Audi</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Audi</span>(std::string name) : <span class="built_in">Car</span>(name) &#123;&#125;</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;奥迪  &quot;</span> &lt;&lt; _name &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 一系列产品2  车灯</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CarLight</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">light</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BmwLight</span> : <span class="keyword">public</span> CarLight</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">light</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;宝马车灯  &quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AudiLight</span> : <span class="keyword">public</span> CarLight</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 重写从基类基类继承过来的纯虚函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">light</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;奥迪车灯  &quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 工厂方法 升级为 抽象工厂</span></span><br><span class="line"><span class="comment">// 抽象工厂：对有一组关联关系的产品簇提供产品对象的统一创建</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AbstractFactory</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 下面是工厂方法,提供多个产品创建的抽象接口</span></span><br><span class="line">    <span class="comment">// 车子产品方法 创建车子</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> Car *<span class="title">createOneCar</span><span class="params">(std::string)</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 车灯产品方法 创建车灯</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> CarLight *<span class="title">createCarLight</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 下面是宝马工厂，负责创建宝马系列的产品</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BMWAbstractFactory</span> : <span class="keyword">public</span> AbstractFactory</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function">Car *<span class="title">createOneCar</span><span class="params">(std::string name)</span> <span class="comment">// 创建车子</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Bmw</span>(name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">CarLight *<span class="title">createCarLight</span><span class="params">()</span> <span class="comment">// 创建车灯</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">BmwLight</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 下面是奥迪工厂，负责创建奥迪系列的产品</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AUDIAbstractFactory</span> : <span class="keyword">public</span> AbstractFactory</span><br><span class="line">&#123;</span><br><span class="line">    <span class="function">Car *<span class="title">createOneCar</span><span class="params">(std::string name)</span> <span class="comment">// 创建车子</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Audi</span>(name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">CarLight *<span class="title">createCarLight</span><span class="params">()</span> <span class="comment">// 创建车灯</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">AudiLight</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">这里相较于简单工厂：使用一个工厂，通过传入不同的标识 来创建不同的对象</span></span><br><span class="line"><span class="comment">相当于给了一个工厂的基类，然后通过实现具体的产品的工厂。用这个具体产品的工厂</span></span><br><span class="line"><span class="comment">来创建具体的产品对象。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;AbstractFactory&gt; <span class="title">bmwAbstractFactory</span><span class="params">(<span class="keyword">new</span> BMWAbstractFactory())</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;AbstractFactory&gt; <span class="title">audiAbstractFactory</span><span class="params">(<span class="keyword">new</span> AUDIAbstractFactory())</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;Car&gt; <span class="title">p1</span><span class="params">(bmwAbstractFactory-&gt;createOneCar(<span class="string">&quot;x1&quot;</span>))</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;Car&gt; <span class="title">p2</span><span class="params">(audiAbstractFactory-&gt;createOneCar(<span class="string">&quot;A5&quot;</span>))</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::unique_ptr&lt;CarLight&gt; <span class="title">p3</span><span class="params">(bmwAbstractFactory-&gt;createCarLight())</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;CarLight&gt; <span class="title">p4</span><span class="params">(audiAbstractFactory-&gt;createCarLight())</span></span>;</span><br><span class="line">    p1-&gt;<span class="built_in">show</span>();</span><br><span class="line">    p2-&gt;<span class="built_in">show</span>();</span><br><span class="line"></span><br><span class="line">    p3-&gt;<span class="built_in">light</span>();</span><br><span class="line">    p4-&gt;<span class="built_in">light</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="代理模式"><a href="#代理模式" class="headerlink" title="代理模式"></a>代理模式</h2><p>结构型模式：（不是关注于对象的产生，关注于最后通过类与类的组合之后，功能上该怎么使用？以及对问题场景的符合与否？）</p><p> 这些设计模式关注于类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。</p><p>代理模式：Proxy Pattern 。主要体现的是 对象访问权限的控制。这个Proxy代理可以把那些访问对象的权限不够的用户 都给挡回去。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 代理模式</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VedioWebSite</span> <span class="comment">// 抽象类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">freeMovie</span><span class="params">()</span> </span>= <span class="number">0</span>;   <span class="comment">// 免费电影</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">vipMovie</span><span class="params">()</span> </span>= <span class="number">0</span>;    <span class="comment">// VIP电影</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ticketMovie</span><span class="params">()</span> </span>= <span class="number">0</span>; <span class="comment">// VIP + 券电影</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实际的 操作视频服务器后台的所有电影</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OperatorMovieBoss</span> : <span class="keyword">public</span> VedioWebSite <span class="comment">// 这个是 委托类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">freeMovie</span><span class="params">()</span> <span class="comment">// 免费电影</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;你可以看免费电影&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">vipMovie</span><span class="params">()</span> <span class="comment">// VIP电影</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;你可以看VIP电影&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ticketMovie</span><span class="params">()</span> <span class="comment">// VIP + 券电影</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;你可以看VIP + 券电影&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 代理OperatorMovieBoss的代理类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FreeMovieProxy</span> : <span class="keyword">public</span> VedioWebSite <span class="comment">// 免费电影代理类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">FreeMovieProxy</span>()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 指针指向代理的对象</span></span><br><span class="line">        pvedio = <span class="keyword">new</span> <span class="built_in">OperatorMovieBoss</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">FreeMovieProxy</span>()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span> pvedio;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">freeMovie</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 通过代理对象的freeMovie来访问真正委托类对象的freeMovie方法</span></span><br><span class="line">        pvedio-&gt;<span class="built_in">freeMovie</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">vipMovie</span><span class="params">()</span> <span class="comment">// VIP电影</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;你只是普通用户，不可以看VIP电影,请升级为会员&quot;</span></span><br><span class="line">                  &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ticketMovie</span><span class="params">()</span> <span class="comment">// VIP + 券电影</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;你没有电源券，不可以观看电影,请先升级为会员然后购买影券&quot;</span></span><br><span class="line">                  &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 这里需要一个组合的对象</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    基类指针指向派生类对象，只是这里不直接指向委托类对象</span></span><br><span class="line"><span class="comment">    而是直接访问代理对象，用代理对象来控制用户对委托类对象</span></span><br><span class="line"><span class="comment">    访问权限的问题。既然也是从抽象类继承来的，3个纯虚函数都要去</span></span><br><span class="line"><span class="comment">    重写一下。不然这个代理类也成了抽象类</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    VedioWebSite *pvedio;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 代理OperatorMovieBoss的代理类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VIPMovieProxy</span> : <span class="keyword">public</span> VedioWebSite <span class="comment">// VIP电影代理类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">VIPMovieProxy</span>()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 指针指向代理的对象</span></span><br><span class="line">        pvedio = <span class="keyword">new</span> <span class="built_in">OperatorMovieBoss</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    ~<span class="built_in">VIPMovieProxy</span>()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">delete</span> pvedio;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">freeMovie</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 通过代理对象的freeMovie来访问真正委托类对象的freeMovie方法</span></span><br><span class="line">        pvedio-&gt;<span class="built_in">freeMovie</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">vipMovie</span><span class="params">()</span> <span class="comment">// VIP电影</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        pvedio-&gt;<span class="built_in">vipMovie</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ticketMovie</span><span class="params">()</span> <span class="comment">// VIP + 券电影</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;你没有电源券，不可以观看电影,请先购买影券&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 这里需要一个组合的对象</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">    基类指针指向派生类对象，只是这里不直接指向委托类对象</span></span><br><span class="line"><span class="comment">    而是直接访问代理对象，用代理对象来控制用户对委托类对象</span></span><br><span class="line"><span class="comment">    访问权限的问题。既然也是从抽象类继承来的，3个纯虚函数都要去</span></span><br><span class="line"><span class="comment">    重写一下。不然这个代理类也成了抽象类</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    VedioWebSite *pvedio;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">WhoWatchMovie</span><span class="params">(std::unique_ptr&lt;VedioWebSite&gt; &amp;ptr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ptr-&gt;<span class="built_in">freeMovie</span>();</span><br><span class="line">    ptr-&gt;<span class="built_in">vipMovie</span>();</span><br><span class="line">    ptr-&gt;<span class="built_in">ticketMovie</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 基类指针 指向 普通用户级别的代理类</span></span><br><span class="line">    <span class="function">std::unique_ptr&lt;VedioWebSite&gt; <span class="title">p1</span><span class="params">(<span class="keyword">new</span> FreeMovieProxy())</span></span>;</span><br><span class="line">    <span class="built_in">WhoWatchMovie</span>(p1);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;*****************************&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    <span class="comment">// 基类指针 指向 VIP用户级别的代理类</span></span><br><span class="line">    <span class="function">std::unique_ptr&lt;VedioWebSite&gt; <span class="title">p2</span><span class="params">(<span class="keyword">new</span> VIPMovieProxy())</span></span>;</span><br><span class="line">    <span class="built_in">WhoWatchMovie</span>(p2);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总结：<strong>代理模式涉及到了 抽象类（公共类），委托类（需要从抽象类继承而来），代理类（需要从抽象类继承而来），以组合的方式 使用代理对象，在实际的使用中客户直接访问的是代理对象。</strong></p><h2 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h2><p>结构型模式的一种：Decorator Pattern</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">// 装饰器模式</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Car</span> <span class="comment">// 抽象基类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 下面是三个 汽车实体类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bmw</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;这是宝马汽车的配置为:&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Audi</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;这是奥迪汽车的配置为:&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bnze</span> : <span class="keyword">public</span> Car</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;这是奔驰汽车的配置为:&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">/*进行功能增强了，如下：*/</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CarBaseDecorator</span> : <span class="keyword">public</span> Car <span class="comment">// 装饰器的基类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 装饰器里面，先把基本的功能装饰写好，给谁添加 先不重要</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 装饰器的基类，具体的功能装饰还没有出来呢</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">show</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">其实对于装饰器基类，如果要有一些装饰器公共的方法的话，</span></span><br><span class="line"><span class="comment">可以在装饰器的基类里面进行实现。</span></span><br><span class="line"><span class="comment">这里各个装饰器类没有一些公有的方法需要在统一地在基类书写的</span></span><br><span class="line"><span class="comment">情况下。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">例如这里 就没有公共的方法，这种情况下就可以把装饰器的</span></span><br><span class="line"><span class="comment">基类CarBaseDecorator给省略掉。直接让下面的CarChildDecorator们</span></span><br><span class="line"><span class="comment">直接继承于Car类。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">但是我选择不省略</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 功能装饰器1：定速巡航功能</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CarChildDecorator1</span> : <span class="keyword">public</span> CarBaseDecorator</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">CarChildDecorator1</span>(Car *p)</span><br><span class="line">    &#123;</span><br><span class="line">        _ptr = p;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        _ptr-&gt;<span class="built_in">show</span>();</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot; 定速巡航功能&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Car *_ptr;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 功能装饰器2：自动驾驶功能</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CarChildDecorator2</span> : <span class="keyword">public</span> CarBaseDecorator</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">CarChildDecorator2</span>(Car *p)</span><br><span class="line">    &#123;</span><br><span class="line">        _ptr = p;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        _ptr-&gt;<span class="built_in">show</span>();</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot; 自动驾驶功能&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Car *_ptr;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 功能装饰器3：车道偏离功能</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CarChildDecorator3</span> : <span class="keyword">public</span> CarBaseDecorator</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">CarChildDecorator3</span>(Car *p)</span><br><span class="line">    &#123;</span><br><span class="line">        _ptr = p;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        _ptr-&gt;<span class="built_in">show</span>();</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot; 车道偏离功能&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Car *_ptr;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Car *p1 = <span class="keyword">new</span> <span class="built_in">CarChildDecorator1</span>(<span class="keyword">new</span> <span class="built_in">Bmw</span>());</span><br><span class="line">    p1 = <span class="keyword">new</span> <span class="built_in">CarChildDecorator2</span>(p1);</span><br><span class="line">    p1 = <span class="keyword">new</span> <span class="built_in">CarChildDecorator3</span>(p1);</span><br><span class="line">    p1-&gt;<span class="built_in">show</span>();</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;************************************&quot;</span> &lt;&lt; endl;</span><br><span class="line">    Car *p2 = <span class="keyword">new</span> <span class="built_in">CarChildDecorator2</span>(<span class="keyword">new</span> <span class="built_in">Audi</span>());</span><br><span class="line">    p2-&gt;<span class="built_in">show</span>();</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;************************************&quot;</span> &lt;&lt; endl;</span><br><span class="line">    Car *p3 = <span class="keyword">new</span> <span class="built_in">CarChildDecorator3</span>(<span class="keyword">new</span> <span class="built_in">Bnze</span>());</span><br><span class="line">    p3-&gt;<span class="built_in">show</span>();</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从深入理解对象模型的角度看有点套娃的味了，应用了虚函数指针的运行时多态实现。</p><p>上述代码详细解释：</p><p>在这个代码中，我们使用了装饰器模式，也称为包装器模式。装饰器模式允许我们在运行时动态地添加行为或状态到现有的对象中，而不需要修改其原始类的源代码。</p><p>当我们执行 <code>p1-&gt;show();</code> 时，输出的结果是 “这是宝马汽车的配置为: 定速巡航功能 自动驾驶功能 车道偏离功能”，这是因为我们在创建 <code>p1</code> 时，逐步地向它添加了这些功能：</p><ol><li><code>Car *p1 = new CarChildDecorator1(new Bmw());</code> 在这一步，我们创建了一个 <code>Bmw</code> 对象，并将其作为参数传递给 <code>CarChildDecorator1</code> 的构造函数。这个操作把 “定速巡航功能” 添加到了 <code>Bmw</code> 对象中。</li><li><code>p1 = new CarChildDecorator2(p1);</code> 在这一步，我们创建了一个 <code>CarChildDecorator2</code> 对象，并将已经包含了 “定速巡航功能” 的 <code>p1</code> 作为参数传递给 <code>CarChildDecorator2</code> 的构造函数。这个操作把 “自动驾驶功能” 添加到了 <code>p1</code> 中。</li><li><code>p1 = new CarChildDecorator3(p1);</code> 在这一步，我们创建了一个 <code>CarChildDecorator3</code> 对象，并将已经包含了 “定速巡航功能” 和 “自动驾驶功能” 的 <code>p1</code> 作为参数传递给 <code>CarChildDecorator3</code> 的构造函数。这个操作把 “车道偏离功能” 添加到了 <code>p1</code> 中。</li></ol><p>因此，当我们调用 <code>p1-&gt;show();</code> 时，<code>p1</code> 中的每个装饰器都会调用其内部存储的 <code>Car</code> 对象的 <code>show</code> 方法，并在此基础上添加自己的功能描述，从而得到了 “这是宝马汽车的配置为: 定速巡航功能 自动驾驶功能 车道偏离功能” 这个结果。</p><p><strong>这就是装饰器模式的魅力，它允许我们动态地添加和组合功能，而不需要修改原始类的代码</strong>。</p><h2 id="适配器模式"><a href="#适配器模式" class="headerlink" title="适配器模式"></a>适配器模式</h2><p>这个适配器有点意思。</p><p>在项目中 使用到第三方的插件或者库，但是因为<strong>接口不兼容</strong> 就需要去添加很多的适配器类。</p><p>例如场景：电脑使用一个<strong>接口</strong>，把桌面演示投影到 投影仪上。</p><p>假如：现在有三种类型的接口：VGA HDMI TypeC 。但是目前电脑就用VGA，那么我们就需要用适配器将HDMI转成VGA的格式。把它想成显卡适配器就好理解了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">// 适配器模式：让不兼容的接口可以在一起工作</span></span><br><span class="line"><span class="comment">// 电脑 = 》   投影到 = 》   投影仪上   VGA  HDMI  TypeC</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// VGA接口的电脑，(TV)投影仪也是VGA接口</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGA</span> <span class="comment">// VGA接口   抽象类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">play</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// TV01表示支持VGA接口的投影仪</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TV01</span> : <span class="keyword">public</span> VGA</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">play</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;通过VGA接口连接投影仪，进行视频播放&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现一个电脑类(只支持VGA接口)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Computer</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 由于电脑只支持VGA接口，所以该方法的参数也只能支持VGA接口的指针/引用</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">playVideo</span><span class="params">(VGA *pVGA)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        pVGA-&gt;<span class="built_in">play</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">方法1：换一个支持HDMI接口的电脑，这个就叫代码重构</span></span><br><span class="line"><span class="comment">方法2：买一个转换头（适配器），能够把VGA信号转成HDMI信号，这个叫添加适配器类</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 进了一批新的投影仪，但是新的投影仪都是只支持HDMI接口</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HDMI</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">play</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TV02</span> : <span class="keyword">public</span> HDMI</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">play</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;通过HDMI接口连接投影仪，进行视频播放&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 由于电脑（VGA接口）和投影仪（HDMI接口）无法直接相连，所以需要添加适配器类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGAToHDMIAdapter</span> : <span class="keyword">public</span> VGA</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">VGAToHDMIAdapter</span>(HDMI *p) : <span class="built_in">pHdmi</span>(p) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">play</span><span class="params">()</span> <span class="comment">// 该方法相当于就是转换头，做不同接口的信号转换的</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        pHdmi-&gt;<span class="built_in">play</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    HDMI *pHdmi;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Computer computer;</span><br><span class="line">    <span class="comment">// computer.playVideo(new TV01());</span></span><br><span class="line">    <span class="comment">// 不可以直接在里面传入TV02对象的指针，所以需要加上一层转换适配</span></span><br><span class="line">    <span class="comment">// 因为playVideo方法接收的还是VGA接口，而适配器也是从VGA 继承而来的</span></span><br><span class="line">    <span class="comment">// 适配器类的构造函数接收的是HDMI接口的对象指针 所以这里传入的是newTV02()对象指针</span></span><br><span class="line">    computer.<span class="built_in">playVideo</span>(<span class="keyword">new</span> <span class="built_in">VGAToHDMIAdapter</span>(<span class="keyword">new</span> <span class="built_in">TV02</span>()));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a>观察者模式</h2><p>观察者-监听者模式（发布订阅模式），隶属于行为型模式。</p><p>行为型模式：主要关注的是对象之间的通信，例如：对象A调用对象B的成员方法等。</p><p>观察者-监听者模式：主要处理 对象的一对多的关系，也就是多个对象都依赖于一个对象。<strong>当该对象的状态发生改变时，其他对象都可以接受到相应的通知</strong>。假如现在一个类表示了一组数据，生成一个对象。通过这同一个数据对象， 可以得到一组 圆饼图、柱状图、条形图等。</p><p>简单解释：</p><p>这段代码实现的是发布-订阅模式，也称为观察者模式。这是一种在对象之间定义一对多的依赖关系，当一个对象状态改变时，所有依赖于它的对象都会受到通知并被自动更新。</p><p>在这个代码中，<code>Observer</code> 是观察者的抽象基类，<code>Observer1</code>、<code>Observer2</code> 和 <code>Observer3</code> 都是具体的观察者，他们分别对1、2、3号的消息感兴趣。<code>Subject</code> 是主题类，用来存储每个观察者对哪个消息感兴趣。</p><p>当一个消息发生改变时，主题类 <code>Subject</code> 会通过 <code>dispatch</code> 方法找到对这个消息感兴趣的所有观察者，然后调用它们的 <code>upData</code> 方法，通知它们消息已经发生改变。这就是观察者模式的核心。</p><p>例如，如果1号消息发生改变，主题类就会找到对1号消息感兴趣的 <code>Observer1</code> 和 <code>Observer2</code>，然后通知他们。如果2号消息发生改变，主题类就会找到对2号消息感兴趣的 <code>Observer1</code> 和 <code>Observer3</code>，然后通知他们。如果3号消息发生改变，主题类就会找到对3号消息感兴趣的 <code>Observer2</code> 和 <code>Observer3</code>，然后通知他们。</p><p>这种模式在很多实际应用中都非常有用，比如在GUI编程中，一个按钮的点击事件就可以看作是一个主题，而对这个点击事件感兴趣的所有监听器就是观察者。当用户点击按钮时，所有的监听器都会收到通知。</p><p>代码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unordered_map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;list&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="comment">// 发布订阅模式</span></span><br><span class="line"><span class="comment">// 观察者接收到消息之后，就要去处理消息，更新图像</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Observer</span> <span class="comment">// 观察者抽象类</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 统一的处理事件,messageid表示消息    回调函数</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">upData</span><span class="params">(<span class="type">int</span> messageid)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下全部是观察者实例</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Observer1</span> : <span class="keyword">public</span> Observer</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">upData</span><span class="params">(<span class="type">int</span> id)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (id)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;观察者1 对1 和 2号消息感兴趣.1号消息发生改变&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;观察者1 对1 和 2号消息感兴趣.2号消息发生改变&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Observer2</span> : <span class="keyword">public</span> Observer</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">upData</span><span class="params">(<span class="type">int</span> id)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (id)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;观察者2 对1 和 3号消息感兴趣.1号消息发生改变&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;观察者2 对1 和 3号消息感兴趣.3号消息发生改变&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Observer3</span> : <span class="keyword">public</span> Observer</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">upData</span><span class="params">(<span class="type">int</span> id)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (id)</span><br><span class="line">        &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;观察者3 对2 和 3号消息感兴趣.2号消息发生改变&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">            cout &lt;&lt; <span class="string">&quot;观察者3 对2 和 3号消息感兴趣.3号消息发生改变&quot;</span> &lt;&lt; endl;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 主题类</span></span><br><span class="line"><span class="comment">// 需要存储一下 每个Observer对哪个id感兴趣</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Subject</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// 向list里面添加一个Observer 还有其感兴趣消息id</span></span><br><span class="line">    <span class="comment">// 给主题添加观察者对象</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">addObserver</span><span class="params">(Observer *obser, <span class="type">int</span> messageid)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// mapping[messageid].push_back(obser);</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        上面的这一句话</span></span><br><span class="line"><span class="comment">        map的【】运算符重载函数</span></span><br><span class="line"><span class="comment">        messageid存在 则返回键对应值的引用，插入到list。</span></span><br><span class="line"><span class="comment">        键不存在的话，则默认插入一对。（新增加一个messageid，其值为</span></span><br><span class="line"><span class="comment">        默认构造的list，把obser添加进去）</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        unordered_map&lt;<span class="type">int</span>, list&lt;Observer *&gt;&gt;::iterator it = mapping.<span class="built_in">find</span>(messageid);</span><br><span class="line">        <span class="keyword">if</span> (it != mapping.<span class="built_in">end</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            it-&gt;second.<span class="built_in">push_back</span>(obser);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            list&lt;Observer *&gt; mylist;</span><br><span class="line">            mylist.<span class="built_in">push_back</span>(obser);</span><br><span class="line">            mapping.<span class="built_in">insert</span>(&#123;messageid, mylist&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 主题发生改变，给相应的观察者进行广播</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">dispatch</span><span class="params">(<span class="type">int</span> messageid)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 看看  谁对这个消息主题感兴趣</span></span><br><span class="line">        <span class="keyword">auto</span> it = mapping.<span class="built_in">find</span>(messageid);</span><br><span class="line">        <span class="keyword">if</span> (it != mapping.<span class="built_in">end</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 有人对这个消息感兴趣，进行查看list 分发</span></span><br><span class="line">            <span class="keyword">for</span> (Observer *pObserver : it-&gt;second)</span><br><span class="line">            &#123;</span><br><span class="line">                pObserver-&gt;<span class="built_in">upData</span>(messageid); <span class="comment">// 最核心的代码</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// 消息id 具体感兴趣的Observer</span></span><br><span class="line">    <span class="comment">// 但是对于一个id的消息，可能有多个Observer</span></span><br><span class="line">    <span class="comment">// 所以 很多个观察者串成一个列表</span></span><br><span class="line">    unordered_map&lt;<span class="type">int</span>, list&lt;Observer *&gt;&gt; mapping;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Subject subject; <span class="comment">// 消息主题对象</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 观察者1 对1 和 2号消息感兴趣</span></span><br><span class="line">    subject.<span class="built_in">addObserver</span>(<span class="keyword">new</span> <span class="built_in">Observer1</span>(), <span class="number">1</span>);</span><br><span class="line">    subject.<span class="built_in">addObserver</span>(<span class="keyword">new</span> <span class="built_in">Observer1</span>(), <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 观察者2 对1 和 3号消息感兴趣</span></span><br><span class="line">    subject.<span class="built_in">addObserver</span>(<span class="keyword">new</span> <span class="built_in">Observer2</span>(), <span class="number">1</span>);</span><br><span class="line">    subject.<span class="built_in">addObserver</span>(<span class="keyword">new</span> <span class="built_in">Observer2</span>(), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 观察者3 对2 和 3号消息感兴趣</span></span><br><span class="line">    subject.<span class="built_in">addObserver</span>(<span class="keyword">new</span> <span class="built_in">Observer3</span>(), <span class="number">2</span>);</span><br><span class="line">    subject.<span class="built_in">addObserver</span>(<span class="keyword">new</span> <span class="built_in">Observer3</span>(), <span class="number">3</span>);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;************************************&quot;</span> &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> changeMessid;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;请输入一个发生改变的消息  输入-1结束&quot;</span> &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;哪个消息改变了：&quot;</span>;</span><br><span class="line">    <span class="keyword">while</span> (cin &gt;&gt; changeMessid &amp;&amp; changeMessid != <span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        subject.<span class="built_in">dispatch</span>(changeMessid);</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;哪个消息改变了：&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>学习自：</p><ul><li><p><a href="https://refactoringguru.cn/design-patterns/proxy">https://refactoringguru.cn/design-patterns/proxy</a></p></li><li><p><a href="https://rng-songbaobao.blog.csdn.net/article/details/97764912">C++的学习心得和知识总结 第十三章（完）</a></p></li><li><a href="https://blog.csdn.net/weixin_45712636/article/details/124328504">C++设计模式（全23种）</a></li></ul>]]></content>
    
    
    <summary type="html">Cpp常用设计模式</summary>
    
    
    
    <category term="Cpp" scheme="https://penge666.github.io/categories/Cpp/"/>
    
    
    <category term="Cpp" scheme="https://penge666.github.io/tags/Cpp/"/>
    
  </entry>
  
  <entry>
    <title>云风coroutine协程库</title>
    <link href="https://penge666.github.io/posts/7dd61686.html"/>
    <id>https://penge666.github.io/posts/7dd61686.html</id>
    <published>2024-05-29T14:39:34.000Z</published>
    <updated>2024-05-30T01:53:12.666Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><blockquote><p><strong>库介绍</strong></p></blockquote><p>协程是一种共享堆，不共享栈，由用户主动调度的执行体（一般需要提供 yield 和 resume 语义）。</p><p>这个coroutine协程库实现是基于多个协程共享栈的方式。但是每个 coroutine 都会从 heap 上分配内存来保存自己 stack 的内容，当前运行实只有一个 stack。</p><p>随着 Golang 的兴起，协程尤其是有栈协程 (stackful coroutine) 越来越受到程序员的关注。协程几乎成了程序员的一套必备技能。</p><p>云风实现了一套 <a href="https://github.com/cloudwu/coroutine/">C 语言的协程库</a>，整体背景可以参考其 <a href="https://blog.codingnow.com/2012/07/c_coroutine.html">博客</a>。</p><p>这个协程库非常轻量级，一共也才 200 多行代码，使用上更贴近于 lua 的写法（众所周知，云风是知名的 lua 粉)。整体基于 ucontext 和共享栈模型实现了有栈协程，代码质量毋庸置疑，本文将详细剖析该协程库的实现原理。</p><blockquote><p><strong>协程的几种实现方式及原理</strong></p></blockquote><p>协程又可以称为用户线程,微线程，可以将其理解为单个进程或线程中的多个<strong>用户态线程</strong>，这些微线程在用户态进程控制和调度.协程的实现方式有很多种，包括</p><ol><li>使用glibc中的ucontext库实现</li><li>利用汇编代码切换上下文</li><li>利用C语言语法中的switch-case的奇淫技巧实现(protothreads)</li><li>利用C语言的setjmp和longjmp实现</li></ol><p>实际上，无论是上述那种方式实现协程,其原理是相同的，都是通过保存和恢复寄存器的状态，来进行各协程上下文的保存和切换。</p><blockquote><p><strong>协程较于函数和线程的优点</strong></p></blockquote><ul><li>相比于函数:协程避免了传统的函数调用栈，几乎可以无限地递归</li><li>相比与线程:协程没有内核态的上下文切换，近乎可以无限并发。协程在用户态进程显式的调度，可以把异步操作转换为同步操作，也意味着不需要加锁,避免了加锁过程中不必要的开销。</li></ul><p>进程,线程以及协程的设计都是为了并发任务可以更好的利用CPU资源，他们之间最大的区别在于CPU资源的使用上:</p><ul><li>进程和线程的任务调度是由内核控制的，是抢占式的；</li><li>协程的任务调度是在用户态完成,需要代码里显式地将CPU交给其他协程,是协作式的</li></ul><p>由于我们可以在用户态调度协程任务，所以我们可以把<strong>一组相互依赖的任务设计为协程。这样,当一个协程任务完成之后,可以手动的进行任务切换，把当前任务挂起(yield),切换到另一个协程区工作</strong>.由于我们可以控制程序主动让出资源，很多情况下将不需要对资源进行加锁。</p><h2 id="前置知识">前置知识</h2><h3 id="ucontext-函数族">ucontext 函数族</h3><p>ucontext 函数有 4 个，如下所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ucontext.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 用户上下文的获取和设置</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">getcontext</span><span class="params">(<span class="type">ucontext_t</span> *ucp)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">setcontext</span><span class="params">(<span class="type">const</span> <span class="type">ucontext_t</span> *ucp)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 操纵用户上下文</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">makecontext</span><span class="params">(<span class="type">ucontext_t</span> *ucp, <span class="type">void</span> (*func)(<span class="type">void</span>), <span class="type">int</span> argc, ...)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">swapcontext</span><span class="params">(<span class="type">ucontext_t</span> *oucp, <span class="type">const</span> <span class="type">ucontext_t</span> *ucp)</span></span>;</span><br></pre></td></tr></table></figure><p>ucontext 函数用户进程内部的 context 控制，帮助用户更方便实现 coroutine，可视为更先进的 setjmp/longjmp。</p><p>4 个函数都依赖于 <code>ucontext_t</code> 类型，这个类型大致为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="type">ucontext_t</span> *uc_link;</span><br><span class="line">    <span class="type">sigset_t</span>    uc_sigmask;</span><br><span class="line">    <span class="type">stack_t</span>     uc_stack;</span><br><span class="line">    <span class="type">mcontext_t</span>  uc_mcontext;</span><br><span class="line">    ...</span><br><span class="line">&#125; <span class="type">ucontext_t</span>;</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li><code>uc_link</code>：当前上下文结束时要恢复到的上下文，其中上下文由 <code>makecontext()</code> 创建；</li><li><code>uc_sigmask</code>：上下文要阻塞的信号集合；</li><li><code>uc_stack</code>：上下文所使用的 stack；</li><li><code>uc_mcontext</code>：其中 <code>mcontext_t</code></li></ul><p>类型与机器相关的类型。这个字段是机器特定的保护上下文的表示，包括协程的机器寄存器；</p><p>这几个 API 的作用：</p><p><code>getcontext(ucontext_t *ucp)</code></p><p>将当前的 context 保存在 <code>ucp</code> 中。成功返回 0，错误时返回 -1 并设置 errno；</p><p><code>setcontext(const ucontext_t *ucp)</code></p><p>恢复用户上下文为 <code>ucp</code> 所指向的上下文，成功调用<strong>不用返回</strong>。错误时返回 -1 并设置 errno。 <code>ucp</code> 所指向的上下文应该是 <code>getcontext()</code> 或者 <code>makecontext()</code> 产生。 如果上下文是由 <code>getcontext()</code> 产生，则切换到该上下文后，程序的执行在 <code>getcontext()</code> 后继续执行。比如下面这个例子每隔 1 秒将打印 1 个字符串：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">ucontext_t</span> context;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">getcontext</span>(&amp;context);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world\n&quot;</span>);</span><br><span class="line">    <span class="built_in">sleep</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">setcontext</span>(&amp;context);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果上下文是由 <code>makecontext(ucontext_t *ucp, void (*func)(void), int argc, ...)</code> 产生，切换到该上下文，程序的执行切换到 <code>makecontext()</code> 调用所指定的第二个参数的函数上。当函数返回后，如果 <code>ucp.uc_link</code> 为 NULL，则结束运行；反之跳转到对应的上下文。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;foo\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">ucontext_t</span> context;</span><br><span class="line">    <span class="type">char</span> stack[<span class="number">1024</span>];</span><br><span class="line">       </span><br><span class="line">    <span class="built_in">getcontext</span>(&amp;context);</span><br><span class="line">    context.uc_stack.ss_sp = stack;</span><br><span class="line">    context.uc_stack.ss_size = <span class="built_in">sizeof</span>(stack);</span><br><span class="line">    context.uc_link = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">makecontext</span>(&amp;context, foo, <span class="number">0</span>);</span><br><span class="line">       </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world\n&quot;</span>);</span><br><span class="line">    <span class="built_in">sleep</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">setcontext</span>(&amp;context);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上输出 <code>Hello world</code> 之后会执行 <code>foo()</code>，然后由于 <code>uc_link</code> 为 NULL，将结束运行。</p><p>下面这个例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;foo\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">bar</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;bar\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">ucontext_t</span> context1, context2;</span><br><span class="line">    <span class="type">char</span> stack1[<span class="number">1024</span>];</span><br><span class="line">    <span class="type">char</span> stack2[<span class="number">1024</span>];</span><br><span class="line">       </span><br><span class="line">    <span class="built_in">getcontext</span>(&amp;context1);</span><br><span class="line">    context.uc_stack.ss_sp = stack1;</span><br><span class="line">    context.uc_stack.ss_size = <span class="built_in">sizeof</span>(stack1);</span><br><span class="line">    context.uc_link = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">makecontext</span>(&amp;context1, foo, <span class="number">0</span>);</span><br><span class="line">       </span><br><span class="line">    <span class="built_in">getcontext</span>(&amp;context2);</span><br><span class="line">    context.uc_stack.ss_sp = stack2;</span><br><span class="line">    context.uc_stack.ss_size = <span class="built_in">sizeof</span>(stack2);</span><br><span class="line">    context.uc_link = &amp;context1;</span><br><span class="line">    <span class="built_in">makecontext</span>(&amp;context1, bar, <span class="number">0</span>);</span><br><span class="line">        </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Hello world\n&quot;</span>);</span><br><span class="line">    <span class="built_in">sleep</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">setcontext</span>(&amp;context2);</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时调用 <code>makecontext()</code> 后将切换到 <code>context2</code> 执行 <code>bar()</code>，然后再调用 <code>context1</code> 的 <code>foo()</code>。由于 <code>context1</code> 的 <code>uc_link</code> 为 <code>NULL</code>，程序停止。</p><p><code>makecontext()</code></p><p>修改 <code>ucp</code> 所指向的上下文；</p><p><code>swapcontext(ucontext_t *oucp, const ucontext_t *ucp)</code></p><p>保存当前的上下文到 <code>ocup</code>，并且设置到 <code>ucp</code> 所指向的上下文。成功返回 0，失败返回 -1 并设置 errno。</p><p>如下面这个例子所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ucontext.h&gt;</span></span></span><br><span class="line">    </span><br><span class="line"><span class="type">static</span> <span class="type">ucontext_t</span> ctx[<span class="number">3</span>];</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">f1</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;start f1\n&quot;</span>);</span><br><span class="line">    <span class="comment">// 将当前 context 保存到 ctx[1]，切换到 ctx[2]</span></span><br><span class="line">    <span class="built_in">swapcontext</span>(&amp;ctx[<span class="number">1</span>], &amp;ctx[<span class="number">2</span>]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;finish f1\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">f2</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;start f2\n&quot;</span>);</span><br><span class="line">    <span class="comment">// 将当前 context 保存到 ctx[2]，切换到 ctx[1]</span></span><br><span class="line">    <span class="built_in">swapcontext</span>(&amp;ctx[<span class="number">2</span>], &amp;ctx[<span class="number">1</span>]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;finish f2\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">char</span> stack1[<span class="number">8192</span>];</span><br><span class="line">    <span class="type">char</span> stack2[<span class="number">8192</span>];</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">getcontext</span>(&amp;ctx[<span class="number">1</span>]);</span><br><span class="line">    ctx[<span class="number">1</span>].uc_stack.ss_sp = stack1;</span><br><span class="line">    ctx[<span class="number">1</span>].uc_stack.ss_size = <span class="built_in">sizeof</span>(stack1);</span><br><span class="line">    ctx[<span class="number">1</span>].uc_link = &amp;ctx[<span class="number">0</span>]; <span class="comment">// 将执行 return 0</span></span><br><span class="line">    <span class="built_in">makecontext</span>(&amp;ctx[<span class="number">1</span>], f1, <span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">getcontext</span>(&amp;ctx[<span class="number">2</span>]);</span><br><span class="line">    ctx[<span class="number">2</span>].uc_stack.ss_sp = stack2;</span><br><span class="line">    ctx[<span class="number">2</span>].uc_stack.ss_size = <span class="built_in">sizeof</span>(stack2);</span><br><span class="line">    ctx[<span class="number">2</span>].uc_link = &amp;ctx[<span class="number">1</span>];</span><br><span class="line">    <span class="built_in">makecontext</span>(&amp;ctx[<span class="number">2</span>], f2, <span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 将当前 context 保存到 ctx[0]，切换到 ctx[2]</span></span><br><span class="line">    <span class="built_in">swapcontext</span>(&amp;ctx[<span class="number">0</span>], &amp;ctx[<span class="number">2</span>]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;      </span><br></pre></td></tr></table></figure><p>此时将输出：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">start f2</span><br><span class="line">start f1</span><br><span class="line">finish f2</span><br><span class="line">finish f1</span><br></pre></td></tr></table></figure><h3 id="无栈协程">无栈协程</h3><p>无栈协程，顾名思义，就是不需要使用栈的协程。在常规的协程或者线程中，我们通常会为每一个协程或线程分配一个栈。这个栈用于存储协程的执行状态，包括局部变量、函数调用关系等。当我们从一个协程切换到另一个协程时，我们会保存当前协程的栈信息，以便在切换回来时能够恢复到切换前的状态。</p><p>然而，在无栈协程中，我们并不为每个协程分配一个栈。相反，所有的协程共享全局的执行状态。这意味着，在无栈协程中，协程的执行状态不是保存在栈上，而是保存在堆上。换句话说，协程的栈帧内保存的不是状态，而是指向状态的指针。当我们需要切换协程时，我们只需要改变这些指针的指向，而不需要保存和恢复栈信息。</p><p>无栈协程的优点是节省了内存空间，因为我们不需要为每个协程分配一个栈。此外，因为不需要保存和恢复栈信息，所以无栈协程的切换速度更快。然而，无栈协程的缺点是编程模型更复杂，因为我们需要自己管理协程的执行状态。</p><p>总的来说，无栈协程是一种更轻量级的协程实现方式，它通过共享全局的执行状态，避免了栈的使用，从而实现了更快速的协程切换和更小的内存占用。</p><h2 id="coroutine-的使用">coroutine 的使用</h2><p>我们首先基于 coroutine 的例子来讲下 coroutine 的基本使用，以方便后面原理的讲解</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">args</span> &#123;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">struct</span> schedule * S, <span class="type">void</span> *ud)</span> </span>&#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">args</span> * arg = ud;</span><br><span class="line"><span class="type">int</span> start = arg-&gt;n;</span><br><span class="line"><span class="type">int</span> i;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;<span class="number">5</span>;i++) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;coroutine %d : %d\n&quot;</span>,<span class="built_in">coroutine_running</span>(S) , start + i);</span><br><span class="line"><span class="comment">// 切出当前协程</span></span><br><span class="line"><span class="built_in">coroutine_yield</span>(S);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">test</span><span class="params">(<span class="keyword">struct</span> schedule *S)</span> </span>&#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">args</span> arg1 = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">args</span> arg2 = &#123;<span class="number">100</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建两个协程</span></span><br><span class="line"><span class="type">int</span> co1 = <span class="built_in">coroutine_new</span>(S, foo, &amp;arg1);</span><br><span class="line"><span class="type">int</span> co2 = <span class="built_in">coroutine_new</span>(S, foo, &amp;arg2);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;main start\n&quot;</span>);</span><br><span class="line"><span class="keyword">while</span> (<span class="built_in">coroutine_status</span>(S,co1) &amp;&amp; <span class="built_in">coroutine_status</span>(S,co2)) &#123;</span><br><span class="line"><span class="comment">// 使用协程 co1</span></span><br><span class="line"><span class="built_in">coroutine_resume</span>(S,co1);</span><br><span class="line"><span class="comment">// 使用协程 co2</span></span><br><span class="line"><span class="built_in">coroutine_resume</span>(S,co2);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;main end\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// 创建一个协程调度器</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">schedule</span> * S = <span class="built_in">coroutine_open</span>();</span><br><span class="line"></span><br><span class="line"><span class="built_in">test</span>(S);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭协程调度器</span></span><br><span class="line"><span class="built_in">coroutine_close</span>(S);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv/pengeHome/coroutine$ ./main</span><br><span class="line">main start</span><br><span class="line">coroutine 0 : 0</span><br><span class="line">coroutine 1 : 100</span><br><span class="line">coroutine 0 : 1</span><br><span class="line">coroutine 1 : 101</span><br><span class="line">coroutine 0 : 2</span><br><span class="line">coroutine 1 : 102</span><br><span class="line">coroutine 0 : 3</span><br><span class="line">coroutine 1 : 103</span><br><span class="line">coroutine 0 : 4</span><br><span class="line">coroutine 1 : 104</span><br><span class="line">main end</span><br></pre></td></tr></table></figure><p>从代码看来，首先利用 <code>coroutine_open</code> 创建了协程调度器 S，用来统一管理全部的协程。<br>同时在 test 函数中，创建了两个协程 co1 和 co2，不断的反复 yield 和 resume 协程，直至两个协程执行完毕。</p><p>可以看出，最核心的几个对象和函数是:</p><ol><li><code>struct schedule* S</code> 协程调度器</li><li><code>coroutine_resume(S,co1);</code> 切入该协程</li><li><code>coroutine_yield(S);</code> 切出该协程</li></ol><p>接下来，会从这几点出发，分析 coroutine 的原理。</p><h2 id="struct-schedule-协程调度器">struct schedule 协程调度器</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 协程调度器</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">schedule</span> &#123;</span><br><span class="line"><span class="type">char</span> stack[STACK_SIZE];<span class="comment">// 运行时栈</span></span><br><span class="line"></span><br><span class="line"><span class="type">ucontext_t</span> main; <span class="comment">// 主协程的上下文</span></span><br><span class="line"><span class="type">int</span> nco; <span class="comment">// 当前存活的协程个数</span></span><br><span class="line"><span class="type">int</span> cap; <span class="comment">// 协程管理器的当前最大容量，即可以同时支持多少个协程。如果不够了，则进行扩容</span></span><br><span class="line"><span class="type">int</span> running; <span class="comment">// 正在运行的协程ID</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">coroutine</span> **co; <span class="comment">// 一个一维数组，用于存放协程 </span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>协程调度器 schedule 负责管理所有协程，有几个属性非常重要：</p><ol><li><code>struct coroutine **co;</code> 是一个一维数组，存放了目前所有的协程。</li><li><code>ucontext_t main;</code> 主协程的上下文，方便后面协程执行完后切回到主协程。</li><li><code>char stack[STACK_SIZE];</code> 这个非常重要，是所有协程的运行时栈。具体共享栈的原理会在下文讲到。</li></ol><p>此外，<code>coroutine_open</code> 负责创建并初始化一个协程调度器，<code>coroutine_close</code> 负责销毁协程调度器以及清理其管理的所有协程。</p><h2 id="协程的创建-coroutine-new">协程的创建: coroutine_new</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* 协程</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">coroutine</span> &#123;</span><br><span class="line">coroutine_func func; <span class="comment">// 协程所用的函数</span></span><br><span class="line"><span class="type">void</span> *ud;  <span class="comment">// 协程参数</span></span><br><span class="line"><span class="type">ucontext_t</span> ctx; <span class="comment">// 协程上下文</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">schedule</span> * sch; <span class="comment">// 该协程所属的调度器</span></span><br><span class="line"><span class="type">ptrdiff_t</span> cap;  <span class="comment">// 已经分配的内存大小</span></span><br><span class="line"><span class="type">ptrdiff_t</span> size; <span class="comment">// 当前协程运行时栈，保存起来后的大小</span></span><br><span class="line"><span class="type">int</span> status;<span class="comment">// 协程当前的状态</span></span><br><span class="line"><span class="type">char</span> *stack; <span class="comment">// 当前协程的保存起来的运行时栈</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>创建协程</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> </span></span><br><span class="line"><span class="function"><span class="title">coroutine_new</span><span class="params">(<span class="keyword">struct</span> schedule *S, coroutine_func func, <span class="type">void</span> *ud)</span> </span>&#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">coroutine</span> *co = _co_new(S, func , ud);</span><br><span class="line"><span class="keyword">if</span> (S-&gt;nco &gt;= S-&gt;cap) &#123;</span><br><span class="line"><span class="comment">// 如果目前协程的数量已经大于调度器的容量，那么进行扩容</span></span><br><span class="line"><span class="type">int</span> id = S-&gt;cap;<span class="comment">// 新的协程的id直接为当前容量的大小</span></span><br><span class="line"><span class="comment">// 扩容的方式为，扩大为当前容量的2倍，这种方式和Hashmap的扩容略像</span></span><br><span class="line">S-&gt;co = <span class="built_in">realloc</span>(S-&gt;co, S-&gt;cap * <span class="number">2</span> * <span class="built_in">sizeof</span>(<span class="keyword">struct</span> coroutine *));</span><br><span class="line"><span class="comment">// 初始化内存</span></span><br><span class="line"><span class="built_in">memset</span>(S-&gt;co + S-&gt;cap , <span class="number">0</span> , <span class="built_in">sizeof</span>(<span class="keyword">struct</span> coroutine *) * S-&gt;cap);</span><br><span class="line"><span class="comment">//将协程放入调度器</span></span><br><span class="line">S-&gt;co[S-&gt;cap] = co;</span><br><span class="line"><span class="comment">// 将容量扩大为两倍</span></span><br><span class="line">S-&gt;cap *= <span class="number">2</span>;</span><br><span class="line"><span class="comment">// 尚未结束运行的协程的个数 </span></span><br><span class="line">++S-&gt;nco; </span><br><span class="line"><span class="keyword">return</span> id;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">// 如果目前协程的数量小于调度器的容量，则取一个为NULL的位置，放入新的协程</span></span><br><span class="line"><span class="type">int</span> i;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;S-&gt;cap;i++) &#123;</span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment"> * 为什么不 i%S-&gt;cap,而是要从nco+i开始呢 </span></span><br><span class="line"><span class="comment"> * 这其实也算是一种优化策略吧，因为前nco有很大概率都非NULL的，直接跳过去更好</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">int</span> id = (i+S-&gt;nco) % S-&gt;cap;</span><br><span class="line"><span class="keyword">if</span> (S-&gt;co[id] == <span class="literal">NULL</span>) &#123;</span><br><span class="line">S-&gt;co[id] = co;</span><br><span class="line">++S-&gt;nco;</span><br><span class="line"><span class="keyword">return</span> id;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">assert</span>(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>coroutine_new</code> 负责创建并初始化一个新协程对象，同时将该协程对象放到协程调度器里面。</p><p>这里的实现有两个非常有意思的点：</p><ol><li><strong>扩容</strong>：当目前尚存活的线程个数 <code>nco</code> 已经等于协程调度器的容量 <code>cap</code> 了，这个时候需要对协程调度器进行扩容，这里直接就是非常经典简单的 2 倍扩容。</li><li><strong>如果无需扩容，则需要找到一个空的位置，放置初始化好的协程</strong>。这里一般直接从数组第一位开始找，直到找到空的位置即可。但是云风把这里处理成从第 <code>nco</code> 位开始寻找（<code>nco</code> 代表当前存活的个数。因为一般来说，前面几位最开始都是存活的，从第 <code>nco</code> 位开始找，效率会更高。</li></ol><p>这样，一个协程对象就被创建好，此时该协程的状态是 <code>READY</code>，但尚未正式执行。</p><p><code>coroutine_resume</code> 函数会切入到指定协程中执行。当前正在执行的协程的上下文会被保存起来，同时上下文替换成新的协程，该协程的状态将被置为 <code>RUNNING</code>。</p><p>进入 <code>coroutine_resume</code> 函数的前置状态有两个 <code>READY</code> 和 <code>SUSPEND</code>，这两个状态下 <code>coroutine_resume</code> 的处理方法也是有很大不同。我们先看下协程在 READY 状态下进行 <code>coroutine_resume</code> 的流程。</p><h2 id="coroutine-resume-READY-RUNNING）">coroutine_resume(READY -&gt; RUNNING）</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 切换到对应协程中执行</span></span><br><span class="line"><span class="comment">* </span></span><br><span class="line"><span class="comment">* @param S 协程调度器</span></span><br><span class="line"><span class="comment">* @param id 协程ID</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> </span></span><br><span class="line"><span class="function"><span class="title">coroutine_resume</span><span class="params">(<span class="keyword">struct</span> schedule * S, <span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line"><span class="built_in">assert</span>(S-&gt;running == <span class="number">-1</span>);</span><br><span class="line"><span class="built_in">assert</span>(id &gt;=<span class="number">0</span> &amp;&amp; id &lt; S-&gt;cap);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取出协程</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">coroutine</span> *C = S-&gt;co[id];</span><br><span class="line"><span class="keyword">if</span> (C == <span class="literal">NULL</span>)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> status = C-&gt;status;</span><br><span class="line"><span class="keyword">switch</span>(status) &#123;</span><br><span class="line"><span class="keyword">case</span> COROUTINE_READY:</span><br><span class="line">    <span class="comment">//初始化ucontext_t结构体,将当前的上下文放到C-&gt;ctx里面</span></span><br><span class="line"><span class="built_in">getcontext</span>(&amp;C-&gt;ctx);</span><br><span class="line"><span class="comment">// 将当前协程的运行时栈的栈顶设置为S-&gt;stack</span></span><br><span class="line"><span class="comment">// 每个协程都这么设置，这就是所谓的共享栈。（注意，这里是栈顶）</span></span><br><span class="line">C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack; </span><br><span class="line">C-&gt;ctx.uc_stack.ss_size = STACK_SIZE;</span><br><span class="line">C-&gt;ctx.uc_link = &amp;S-&gt;main; <span class="comment">// 如果协程执行完，将切换到主协程中执行</span></span><br><span class="line">S-&gt;running = id;</span><br><span class="line">C-&gt;status = COROUTINE_RUNNING;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置执行C-&gt;ctx函数, 并将S作为参数传进去</span></span><br><span class="line"><span class="type">uintptr_t</span> ptr = (<span class="type">uintptr_t</span>)S;</span><br><span class="line"><span class="built_in">makecontext</span>(&amp;C-&gt;ctx, (<span class="built_in">void</span> (*)(<span class="type">void</span>)) mainfunc, <span class="number">2</span>, (<span class="type">uint32_t</span>)ptr, (<span class="type">uint32_t</span>)(ptr&gt;&gt;<span class="number">32</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将当前的上下文放入S-&gt;main中，并将C-&gt;ctx的上下文替换到当前上下文</span></span><br><span class="line"><span class="built_in">swapcontext</span>(&amp;S-&gt;main, &amp;C-&gt;ctx);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> COROUTINE_SUSPEND:</span><br><span class="line">    <span class="comment">// 将协程所保存的栈的内容，拷贝到当前运行时栈中</span></span><br><span class="line"><span class="comment">// 其中C-&gt;size在yield时有保存</span></span><br><span class="line">        <span class="comment">// 这块这里先不看</span></span><br><span class="line"><span class="built_in">memcpy</span>(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size);</span><br><span class="line">S-&gt;running = id;</span><br><span class="line">C-&gt;status = COROUTINE_RUNNING;</span><br><span class="line"><span class="built_in">swapcontext</span>(&amp;S-&gt;main, &amp;C-&gt;ctx);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="built_in">assert</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段函数非常的重要，有几个不可忽视的点：</p><ol><li><code>getcontext(&amp;C-&gt;ctx);</code> 初始化 ucontext_t 结构体，将当前的上下文放到 C-&gt;ctx 里面</li><li><code>C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack;</code> 设置当前协程的运行时栈，也是共享栈。</li><li><code>C-&gt;ctx.uc_link = &amp;S-&gt;main;</code> 如果协程执行完，则切换到 <code>S-&gt;main</code> 主协程中进行执行。如果不设置, 则默认为 NULL，那么协程执行完，整个程序就结束了。</li></ol><p>接下来是 makecontext，这个函数用来设置对应 ucontext 的执行函数。如上，将 <code>C-&gt;ctx</code> 的执行函数体设置为了 mainfunc。</p><p>makecontext 后面的两个参数也非常有意思，这个可以看出来是把一个指针掰成了两个 int 作为参数传给 mainfunc 了。而在 mainfunc 的实现可以看出来，又会把这两个 int 拼成了一个 <code>struct schedule*</code>。</p><p>那么，为什么不直接传 <code>struct schedule*</code> 呢，而要这么做，通过先拆两半，再在函数中拼起来？</p><p>这是因为 makecontext 的函数指针的参数是 <code>uint32_t</code> 类型，在 64 位系统下，一个 <code>uint32_t</code> 没法承载一个指针, 所以基于兼容性的考虑，才采用了这种做法。</p><p>接下来调用了 <code>swapcontext</code> 函数，这个函数比较简单，但也非常核心。作用是将当前的上下文内容放入 <code>S-&gt;main</code> 中，并将 <code>C-&gt;ctx</code> 的上下文替换到当前上下文。这样的话，将会执行新的上下文对应的程序了。在 coroutine 中, 也就是开始执行 <code>mainfunc</code> 这个函数。(<code>mainfunc</code> 是对用户提供的协程函数的封装)。</p><p><strong>mainfunc</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 通过low32和hi32 拼出了struct schedule的指针，这里为什么要用这种方式，而不是直接传struct schedule*呢？</span></span><br><span class="line"><span class="comment"> * 因为makecontext的函数指针的参数是int可变列表，在64位下，一个int没法承载一个指针</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">mainfunc</span><span class="params">(<span class="type">uint32_t</span> low32, <span class="type">uint32_t</span> hi32)</span> </span>&#123;</span><br><span class="line"><span class="type">uintptr_t</span> ptr = (<span class="type">uintptr_t</span>)low32 | ((<span class="type">uintptr_t</span>)hi32 &lt;&lt; <span class="number">32</span>);</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">schedule</span> *S = (<span class="keyword">struct</span> schedule *)ptr;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> id = S-&gt;running;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">coroutine</span> *C = S-&gt;co[id];</span><br><span class="line">C-&gt;<span class="built_in">func</span>(S,C-&gt;ud);<span class="comment">// 中间有可能会有不断的yield</span></span><br><span class="line">_co_delete(C);</span><br><span class="line">S-&gt;co[id] = <span class="literal">NULL</span>;</span><br><span class="line">--S-&gt;nco;</span><br><span class="line">S-&gt;running = <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="协程的切出：coroutine-yield">协程的切出：coroutine_yield</h2><p>用 <code>coroutine_yield</code> 可以使当前正在运行的协程切换到主协程中运行。此时，该协程会进入 <code>SUSPEND</code> 状态</p><p><code>coroutine_yield</code> 的具体实现依赖于两个行为：</p><ol><li>调用 <code>_save_stack</code> 将当前协程的栈保存起来。因为 coroutine 是基于共享栈的，所以协程的栈内容需要单独保存起来。</li><li><code>swapcontext</code> 将当前上下文保存到当前协程的 ucontext 里面，同时替换当前上下文为主协程的上下文。 这样的话，当前协程会被挂起，主协程会被继续执行。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 将当前正在运行的协程让出，切换到主协程上</span></span><br><span class="line"><span class="comment">* @param S 协程调度器</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">coroutine_yield</span><span class="params">(<span class="keyword">struct</span> schedule * S)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 取出当前正在运行的协程</span></span><br><span class="line"><span class="type">int</span> id = S-&gt;running;</span><br><span class="line"><span class="built_in">assert</span>(id &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">coroutine</span> * C = S-&gt;co[id];</span><br><span class="line"><span class="built_in">assert</span>((<span class="type">char</span> *)&amp;C &gt; S-&gt;stack);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将当前运行的协程的栈内容保存起来</span></span><br><span class="line">_save_stack(C,S-&gt;stack + STACK_SIZE);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将当前栈的状态改为 挂起</span></span><br><span class="line">C-&gt;status = COROUTINE_SUSPEND;</span><br><span class="line">S-&gt;running = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 所以这里可以看到，只能从协程切换到主协程中</span></span><br><span class="line"><span class="built_in">swapcontext</span>(&amp;C-&gt;ctx , &amp;S-&gt;main);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里也有个点极其关键, 就是如何保存当前协程的运行时栈, 也就是如何获取整个栈的内存空间。</p><p>这里我们需要了解下栈内存空间的布局，即栈的生长方向是从高地址往低地址。我们只要找到栈的栈顶和栈底的地址，就可以找到整个栈内存空间了。</p><p>在 coroutine 中，因为协程的运行时栈的内存空间是自己分配的。在 coroutine_resume 阶段设置了 <code>C-&gt;ctx.uc_stack.ss_sp = S.S-&gt;stack</code>。根据以上理论，栈的生长方向是高地址到低地址，因此栈底的就是内存地址最大的位置，即 <code>S-&gt;stack + STACK_SIZE</code> 就是栈底位置。</p><p>那么，如何找到栈顶的位置呢？coroutine 是基于以下方法做的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* 将本协程的栈内容保存起来</span></span><br><span class="line"><span class="comment">* @top 栈顶 </span></span><br><span class="line"><span class="comment">* </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">static</span> <span class="type">void</span></span><br><span class="line">_save_stack(<span class="keyword">struct</span> coroutine *C, <span class="type">char</span> *top) &#123;</span><br><span class="line">    <span class="comment">// 这个dummy很关键，是求取整个栈的关键</span></span><br><span class="line">    <span class="comment">// dummy变量在栈上分配，其地址即为当前栈顶地址</span></span><br><span class="line">    <span class="type">char</span> dummy = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断当前协程的栈大小是否超过了最大栈大小</span></span><br><span class="line">    <span class="comment">// 如果超过，程序将终止运行</span></span><br><span class="line">    <span class="built_in">assert</span>(top - &amp;dummy &lt;= STACK_SIZE);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果当前协程的栈容量不足以保存所有的栈内容</span></span><br><span class="line">    <span class="comment">// 那么就需要重新分配一个更大的栈空间</span></span><br><span class="line">    <span class="keyword">if</span> (C-&gt;cap &lt; top - &amp;dummy) &#123;</span><br><span class="line">        <span class="comment">// 释放原来的栈空间</span></span><br><span class="line">        <span class="built_in">free</span>(C-&gt;stack);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 计算新的栈容量</span></span><br><span class="line">        C-&gt;cap = top - &amp;dummy;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 分配新的栈空间</span></span><br><span class="line">        C-&gt;stack = <span class="built_in">malloc</span>(C-&gt;cap);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算当前协程的栈大小</span></span><br><span class="line">    C-&gt;size = top - &amp;dummy;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将当前协程的栈内容复制到新的栈空间中</span></span><br><span class="line">    <span class="built_in">memcpy</span>(C-&gt;stack, &amp;dummy, C-&gt;size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里特意用到了一个 dummy 变量，这个 dummy 的作用非常关键也非常巧妙，大家可以细细体会下。因为 dummy 变量是刚刚分配到栈上的，此时就位于 <strong>栈的最顶部位置</strong>。整个内存布局如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240529225723491.png" alt="image-20240529225723491"></p><p>因此整个栈的大小就是从栈底到栈顶，<code>S-&gt;stack + STACK_SIZE - &amp;dummy</code>。</p><p>最后又调用了 memcpy 将当前运行时栈的内容，拷贝到了 <code>C-&gt;stack</code> 中保存了起来。</p><h2 id="coroutine-resume-SUSPEND-RUNNING）">coroutine_resume(SUSPEND -&gt; RUNNING）</h2><p>当协程被 yield 之后会进入 <code>SUSPEND</code> 阶段，对该协程调用 <code>coroutine_resume</code> 会再次切入该协程。</p><p>这里的实现有两个重要的点：</p><ol><li><code>memcpy(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size);</code><br>我们知道，在 yield 的时候，协程的栈内容保存到了 C-&gt;stack 数组中。<br>这个时候，就是用 memcpy 把协程的之前保存的栈内容，重新拷贝到运行时栈里面。这里有个点，拷贝的开始位置，需要简单计算下<br><code>S-&gt;stack + STACK_SIZE - C-&gt;size</code> 这个位置就是之前协程的栈顶位置。</li><li><code>swapcontext(&amp;S-&gt;main, &amp;C-&gt;ctx);</code> 交换上下文。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 切换到对应协程中执行</span></span><br><span class="line"><span class="comment">* </span></span><br><span class="line"><span class="comment">* @param S 协程调度器</span></span><br><span class="line"><span class="comment">* @param id 协程ID</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="type">void</span> </span></span><br><span class="line"><span class="function"><span class="title">coroutine_resume</span><span class="params">(<span class="keyword">struct</span> schedule * S, <span class="type">int</span> id)</span> </span>&#123;</span><br><span class="line"><span class="built_in">assert</span>(S-&gt;running == <span class="number">-1</span>);</span><br><span class="line"><span class="built_in">assert</span>(id &gt;=<span class="number">0</span> &amp;&amp; id &lt; S-&gt;cap);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 取出协程</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">coroutine</span> *C = S-&gt;co[id];</span><br><span class="line"><span class="keyword">if</span> (C == <span class="literal">NULL</span>)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> status = C-&gt;status;</span><br><span class="line"><span class="keyword">switch</span>(status) &#123;</span><br><span class="line"><span class="keyword">case</span> COROUTINE_READY:</span><br><span class="line">...</span><br><span class="line"><span class="keyword">case</span> COROUTINE_SUSPEND:</span><br><span class="line">    <span class="comment">// 将协程所保存的栈的内容，拷贝到当前运行时栈中</span></span><br><span class="line"><span class="comment">// 其中C-&gt;size在yield时有保存</span></span><br><span class="line"><span class="built_in">memcpy</span>(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size);</span><br><span class="line">S-&gt;running = id;</span><br><span class="line">C-&gt;status = COROUTINE_RUNNING;</span><br><span class="line"><span class="built_in">swapcontext</span>(&amp;S-&gt;main, &amp;C-&gt;ctx);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="built_in">assert</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="状态机转换">状态机转换</h2><p>在 coroutine 中协程定义了四种状态，整个运行期间，也是根据这四种状态进行轮转。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240529225836906.png" alt=""></p><p>简单点说，就是每个协程的调用信息保存在堆内，然后共享一个栈进行运行。</p><p>有个疑问： 为什么要有这个S-&gt;stack结构？</p><p><code>context.uc_stack.ss_sp = stack;</code> 这行代码是设置协程的栈的起始位置为 <code>stack</code>，也就是 <code>stack</code> 数组的起始地址。这个 <code>stack</code> 数组就是协程的运行时栈，协程可以在这个栈上存储自己的局部变量和函数调用关系。</p><p>我的理解是专门指定一个空间，让其将上下文的信息放进去。</p><p>强烈推荐这篇：<a href="https://www.cyhone.com/articles/analysis-of-libco/">微信 libco 协程库源码分析</a></p><p>本文学习自：<a href="https://chenyahui.github.io/articles/analysis-of-cloudwu-coroutine/">云风 coroutine 协程库源码分析</a></p>]]></content>
    
    
    <summary type="html">云风coroutine协程库源码剖析</summary>
    
    
    
    <category term="Cpp" scheme="https://penge666.github.io/categories/Cpp/"/>
    
    
    <category term="Cpp" scheme="https://penge666.github.io/tags/Cpp/"/>
    
  </entry>
  
  <entry>
    <title>分布式基础理论</title>
    <link href="https://penge666.github.io/posts/76302eca.html"/>
    <id>https://penge666.github.io/posts/76302eca.html</id>
    <published>2024-05-28T08:28:59.000Z</published>
    <updated>2024-05-28T08:29:31.290Z</updated>
    
    <content type="html"><![CDATA[<h2 id="拜占庭将军问题">拜占庭将军问题</h2><h3 id="简介">简介</h3><p>拜占庭错误是莱斯利·兰伯特在《拜占庭将军问题》中提出的一个错误模型，描述了一个完全不可信的场景，除了存在故障行为，还存在恶意行为。顾名思义，<strong>拜占庭容错（Byzantine Fault Tolerance，BFT），就是指能容忍拜占庭错误了</strong>。莱斯利·兰伯特（ Leslie Lamport ）通过这个比喻，表达了计算机网络中所存在的一致性问题。</p><p><strong>非拜占庭容错，又叫故障容错（Crash Fault Tolerance，CFT），解决的是分布式系统中存在故障，但不存在恶意节点的共识问题</strong>，比如进程奔溃，服务器硬件故障等等。</p><h3 id="问题描述">问题描述</h3><p><strong>共识问题</strong></p><p>共识难题，也就是如何在可能有误导信息的情况下，采用合适的通讯机制，让多个将军达成共识，制定一致性的作战计划？</p><p>李牧作为合纵长，燕，齐，韩三国合纵想要攻打秦国，但是只有3国出半数以上的将军才能打赢秦国。</p><p>共识在这里表示的就是三国将军都收到准确的消息，达成一致性决定在某个时间攻打。一般情况下，每国投票，最后少数服从多数即可达成一致决定，例如：</p><p>燕，齐将军决定要打秦国</p><p>韩国将军想撤退</p><p><strong>按照少数服从多数的原则</strong>，韩国将军也会出兵攻打秦国。</p><p><strong>两忠一叛</strong></p><p>可以看到，在正常情况下，信息一致，是能够形成共识的。但是，只要一旦燕，齐国将军有其中一国通秦，就会形成作战计划不一致的问题。例如燕国将军通秦，燕国将军向韩国将军发攻打，给齐国将军发送撤退：</p><ul><li>韩国将军收到的信息就是，2攻打：1撤退</li><li>齐国将军看到的信息就是，1攻打：2撤退</li></ul><p>按照少数服从多数的原则，最终就是韩国将军自己面对秦国，最后败于秦国。这里的问题就出在，其中里面有一国出了叛徒，导致发送了错误的信息。</p><h3 id="解决方案">解决方案</h3><p><strong>口信消息型拜占庭问题之解</strong></p><p>首先，3位将军都分拨一部分军队，由李牧率领，李牧参与作战计划讨论并执行作战指令。这样，3 位将军的作战讨论，就变为了 4位将军的作战讨论，这能够增加讨论中忠诚国家的数量。</p><p>然后，4 位将军还约定了，如果没有收到命令，就执行预设的默认命令，比如“撤退”。除此之外，还约定一些流程来发送作战信息、执行作战指令。</p><p><strong>第一轮</strong></p><p>先发送作战信息的将军作为指挥官，其他的将军作为副官；指挥官将他的作战信息发送给每位副官；每位副官，将从指挥官处收到的作战信息，作为他的作战指令；如果没有收到作战信息，将把默认的“撤退”作为作战指令。</p><p><strong>第二轮</strong></p><p>除了第一轮的指挥官外，剩余的 3 位将军将分别作为指挥官，向另外 2 位将军发送作战信息；然后，这 3 位将军按照“少数服从多数”，执行收到的作战指令。</p><p><strong>忠诚将军先发起命令</strong></p><p>假设先由李牧向3个将军发起进攻的命令，在第一轮作战信息协商中，李牧向燕、齐、韩发送作战指令“进攻”。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528153829489.png" alt="image-20240528153829489"></p><p>在第二轮作战信息协商中，燕、齐、韩分别作为指挥官，向另外 2 位发送作战信息“进攻”，因为韩国将军已经通敌了，所以，为了干扰作战计划，韩国将军发送“撤退”作战指令。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528153851640.png" alt="image-20240528153851640"></p><p>最终，齐和燕收到的作战信息都是“进攻、进攻、撤退”，按照原则，齐和燕与李牧一起执行作战指令“进攻”，实现了作战计划的一致性，保证了作战的胜利。</p><p><strong>通敌国先发送作战命令</strong></p><p>假设先由韩过将军向3个将军发起进攻的命令，在第一轮作战信息协商中，韩国将军向李牧、燕发送作战指令“撤退”，向齐国将军发送作战指令&quot;进攻&quot;。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528154005852.png" alt="image-20240528154005852"></p><p>然后，在第二轮作战信息协商中，李牧、赵、燕分别作为指挥官，向另外两位发送作战信息。.</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528154020184.png" alt="image-20240528154020184"></p><p>最终，李牧、燕和齐收到的作战信息都是“撤退、撤退、进攻”，按照原则，李牧、齐和燕一起执行作战指令“撤退”，实现了作战计划的一致性。也就是说，无论叛将楚如何捣乱，李牧、齐和燕，都执行一致的作战计划，保证作战的胜利。</p><p>这个解决办法，其实是兰伯特在论文《The Byzantine Generals Problem》中提到的口信消息型拜占庭问题之解：如果叛将人数为 m，将军人数不能少于 3m + 1 ，那么拜占庭将军问题就能解决了。</p><p>这个算法有个前提，也就是叛将人数 m，或者说能容忍的叛将数 m，是已知的。在这个算法中，叛将数 m 决定递归循环的次数（也就是说，叛将数 m 决定将军们要进行多少轮作战信息协商），即 m+1 轮（所以，你看，只有魏是叛变的，那么就进行了两轮）。你也可以从另外一个角度理解：n 位将军，最多能容忍 (n - 1) / 3 位叛将。</p><p>不过，这个算法虽然能解决拜占庭将军问题，但它有一个限制：如果叛将人数为 m，那么将军总人数必须不小于 3m + 1。</p><p><strong>签名消息型拜占庭问题之解</strong></p><p>口信消息型需要增加更多的忠诚的将军，签名消息型就是允许在不添加新的将军的前提下，达到最后的一致性。</p><p>签名就好比李牧的印章、虎符等信物，并且必须满足以下条件：</p><p>忠诚将军的签名无法伪造，而且对他签名消息的内容进行任何更改都会被发现；</p><p>任何人都能验证将军签名的真伪。</p><p><strong>忠诚将军先发起命令</strong></p><p>如果忠诚的将军，比如韩国先发起作战信息协商，一旦齐国修改或伪造收到的作战信息，那么燕国在接收到齐国的作战信息的时候，会发现韩国的作战信息被修改，齐国已叛变，这时他将忽略来自齐国的作战信息，最终执行韩国发送的作战信息。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528154102135.png" alt="image-20240528154102135"></p><p><strong>通敌国先发起命令</strong></p><p>如果叛变将军齐先发送误导的作战信息，那么，韩和燕将按照一定规则（比如取中间的指令）在排序后的所有已接收到的指令中（比如撤退、进攻）中选取一个指令，进行执行，最终执行一致的作战计划。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528154123384.png" alt="image-20240528154123384"></p><p>签名消息的拜占庭问题之解，也是需要进行 m+1 轮（其中 m 为叛将数）。你也可以从另外一个角度理解：n 位将军，能容忍 (n - 2) 位叛将（只有一位忠将没有意义，因为此时不需要达成共识了）。可以尝试去思考在2忠2叛的情况，在这里不做过多的赘述。可能你会觉得怎么可能事先知道叛军的，m根本就不知道。记住，轮次是通过n-1次定义的，而不是通过确定的叛军数确定的。</p><h2 id="CAP-理论">CAP 理论</h2><p>这个理论就是 CAP 理论，先想下面几个问题：</p><ul><li>什么是 CAP，全称是什么，之间的关系是什么？</li><li>CAP 之间是什么关系，场景对应是怎样的？</li><li>P 跟 A 都保证了可用性，但怎么区分？</li><li>如何运用 CAP？</li></ul><p><strong>注意，如果是单体系统，不存在什么 CAP 理论 ，就不存在分区。</strong></p><table><thead><tr><th>属性</th><th>全称</th><th>中文</th><th>描述</th></tr></thead><tbody><tr><td>C</td><td>Consistency</td><td>一致性</td><td>集群节点要么读到集群<strong>最新一致数据</strong>，要么全部都返回读取失败。【所有节点访问<strong>同一份最新</strong>的数据副本】【也叫副本一致性】</td></tr><tr><td>A</td><td>Availability</td><td>可用性</td><td>任何来自客户端的请求，不管访问哪个<strong>非故障节点</strong>，<strong>都能得到响应数据，但不保证是同一份最新数据。</strong></td></tr><tr><td>P</td><td>Partition Tolerance</td><td>分区容错性</td><td>当节点间出现任意数量的消息丢失或高延迟的时候，系统仍然在继续工作</td></tr></tbody></table><p><strong>分区容错性解释</strong>：</p><p>举个例子，假设我们有一个分布式数据库系统，该系统有三个节点，分别是A、B和C。在正常情况下，这三个节点可以互相通信，共享数据。</p><p>现在，假设网络发生了分区，节点A与节点B、C之间的通信被切断，也就是说，A不能与B、C交换信息，但B和C之间的通信仍然正常。</p><p>在这种情况下，如果我们的系统能够继续提供服务（也就是说，客户端可以继续从节点A、B、C读取或写入数据），那么我们就说这个系统具有分区容错性。</p><p>需要注意的是，分区容错性并不意味着系统的所有功能都能在网络分区时正常工作。例如，在上述例子中，由于A不能与B、C交换信息，所以A可能无法获取到B、C最新的数据更新，这就可能影响到系统的一致性。这就是CAP理论中的一个基本权衡：在网络分区的情况下，系统必须在一致性和可用性之间做出选择。</p><p><strong>CAP 不可兼得</strong></p><p>因为分区容错性是前提，P一定有。可以这么理解，一个蓄水池，恒水位，有一个出水口和入水口。入水口坏了，你是想要这个蓄水池先供水，还是先保证水位正确，不要触发水位报警。这个蓄水池，肯定不能在没有入水的前提下，还能让水位保持恒定。因此，CAP 是不能兼容的。要想兼容，除非这个系统不需要分区。</p><p>CAP 不可兼得最初是埃里克·布鲁尔（Eric Brewer）基于自己的工程实践，提出的一个猜想，后被赛斯·吉尔伯特（Seth Gilbert）和南希·林奇（Nancy Lynch）证明，证明过程可以参考论文《Brewer’s conjecture and the feasibility of consistent, available, partition-tolerant web services》，记住结论就好了。</p><p>补充一点：基于证明严谨性的考虑，赛斯·吉尔伯特（Seth Gilbert）和南希·林奇（Nancy Lynch）对指标的含义做了预设和限制，比如，将一致性限制为原子一致性。</p><p><strong>如何使用 CAP 理论</strong></p><p>有网络交互就一定会有延迟和数据丢失，而这种状况我们必须接受，还必须保证系统不能挂掉。所以就像前面提到的，节点间的分区故障是必然发生的。也就是说，分区容错性 P 是前提，是必须要保证的。</p><p>现在就只剩下一致性 C 和可用性 A 可以选择了：要么选择一致性，保证数据正确；要么选择可用性，保证服务可用。</p><p>那么 CP 和 AP 的含义是什么呢？</p><p>选择了一致性 C ：一定会读到最新的数据，不会读到旧数据，但如果因为消息丢失、延迟过高发生了网络分区，那么这个时候，当集群节点接收到来自客户端的读请求时，为了不破坏一致性，可能会因为无法响应最新数据，而返回出错信息。</p><p>选择了可用性 A ：系统将始终处理客户端的查询，返回特定信息，如果发生了网络分区，一些节点将无法返回最新的特定信息，它们将返回自己当前的相对新的信息。</p><p>CAP 适用场景</p><p>CA：典型的应用是 Etcd，Consul 和 Hbase，Zookeeper</p><p>AP：Cassandra 和 DynamoDB，服务注册中心。</p><h2 id="ACID理论">ACID理论</h2><p>**ACID 是数据库管理系统为了保证事务的正确性而提出来的一个理论，**ACID 包含四个约束，分别是：</p><p><strong>1.Atomicity（原子性）</strong><br>一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。</p><p><strong>2.Consistency（一致性）</strong><br>在事务开始之前和事务结束以后，数据库的完整性没有被破坏。</p><p><strong>3.Isolation（隔离性）</strong><br>数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。</p><p><strong>4.Durability（持久性）</strong></p><p>事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p><p><strong>ACID 中的 C 是指数据库的数据完整性，而 CAP 中的 C 是指分布式节点中的数据一致性。ACID 的应用场景是数据库事务，CAP 关注的是分布式系统数据读写。</strong></p><p>但是，这只能保证单个节点上操作的 ACID 特性，无法保证节点间操作的 ACID 特性。因此需要掌握分布式事务协议，比如二阶段提交协议和 TCC（Try-Confirm-Cancel）</p><h3 id="二阶段提交协议">二阶段提交协议</h3><p>2PC(tow phase commit)两阶段提交。所谓的两个阶段是指：</p><ol><li>第一阶段：准备阶段(投票阶段)</li><li>第二阶段：提交阶段（执行阶段）。</li></ol><p>我们将提议的节点称为协调者(coordinator)，其他参与决议节点称为参与者(participants, 或cohorts)。</p><p><strong>2PC第一阶段</strong></p><p>2PC的第一阶段是投票环节，投票由协调者节点发起，可以进一步细分为以下步骤：</p><ol><li>事务询问：协调者向所有的参与者发送事务预处理请求，称之为Prepare，并开始等待各参与者的响应。</li><li>执行本地事务：各个参与者节点执行本地事务操作,但在执行完成后并不会真正提交数据库本地事务，而是先向协调者报告说：“我这边可以处理了/我这边不能处理”。</li><li>各参与者向协调者反馈事务询问的响应：如果参与者成功执行了事务操作，那么就反馈给协调者Yes响应，表示事务可以执行，如果没有参与者成功执行事务，那么就反馈给协调者No响应，表示事务不可以执行。</li></ol><p>第一阶段执行完后，会有两种可能。1、所有都返回Yes. 2、有一个或者多个返回No。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528162359332.png" alt="image-20240528162359332"></p><p><strong>2PC第二阶段：正常提交</strong></p><p>如果第一阶段所有的参与者都返回Yes，那么我们就可以继续执行2PC第二阶段的正常提交步骤：</p><ol><li>协调者节点通知所有的参与者Commit事务请求；</li><li>参与者收到Commit请求之后，就会正式执行本地事务Commit操作，并在完成提交之后释放整个事务执行期间占用的事务资源。</li></ol><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528162426879.png" alt="image-20240528162426879"></p><p><strong>2PC第二阶段：异常回滚</strong></p><p>如果任何一个参与者向协调者反馈了No响应，或者等待超时之后，协调者尚未收到所有参与者的反馈响应，那么我们就需要执行2PC第二阶段的回滚操作：</p><ol><li>协调者节点通知所有的参与者Rollback请求；</li><li>参与者收到Rollback请求之后，就会正式执行本地事务Rollback操作，并在完成提交之后释放整个事务执行期间占用的事务资源。</li></ol><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528162442350.png" alt="image-20240528162442350"></p><p><strong>2PC存在的问题</strong></p><p>通过上面的演示，很容易想到2pc所带来的缺陷：</p><ul><li>性能问题：无论是在第一阶段的过程中,还是在第二阶段,所有的参与者资源和协调者资源都是被锁住的,只有当所有节点准备完毕，事务 协调者 才会通知进行全局提交，参与者进行本地事务提交后才会释放资源。这样的过程会比较漫长，对性能影响比较大。</li><li>单节点故障：由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（虽然协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）。</li></ul><h2 id="Base理论">Base理论</h2><p><strong>BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency），核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。</strong></p><p><strong>1. 基本可用（Basically Available）</strong></p><p>分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。</p><p><strong>2. 软状态（Soft State）</strong></p><p>允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。</p><p><strong>3. 最终一致性（Eventual Consistency）</strong></p><p>系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。</p><p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。前面在剖析 CAP 理论时，提到了其实和 BASE 相关的两点：</p><ul><li>CAP 理论是忽略延时的，而实际应用中延时是无法避免的。</li><li>AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。</li></ul><p>总结，<strong>ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</strong></p><p>参考自：</p><ul><li><a href="https://blog.csdn.net/weixin_40242845/article/details/115434216">分布式系统–拜占庭将军问题(The Byzantine Generals Problem)</a></li><li><a href="https://www.cnblogs.com/yuhushen/p/15434594.html">分布式事务（二）之两阶段提交</a></li></ul>]]></content>
    
    
    <summary type="html">分布式基础理论</summary>
    
    
    
    <category term="分布式" scheme="https://penge666.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://penge666.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>LSM-Tree</title>
    <link href="https://penge666.github.io/posts/b5f22718.html"/>
    <id>https://penge666.github.io/posts/b5f22718.html</id>
    <published>2024-05-28T03:30:23.000Z</published>
    <updated>2024-05-28T07:00:16.636Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-前言">0 前言</h2><p>对于存储介质为磁盘或SSD的数据库，长期以来主流使用B+树这种索引结构来实现快速数据查找。当数据量不太大时，B+树读写性能表现非常好。<strong>但是在海量数据情况下，B+树越来越高，由于B+树更新和删除数据时需要沿着B+树逐层进行页分裂和页合并，严重影响数据写入性能</strong>。为了应对这种情况，google在论文<code>《Bigtable: A Distributed Storage System for Structured Data》</code>中介绍了一种新的数据组织结构<code>LSM Tree(Log-Structured Merge Tree)</code>，随后，<code>Bigtable</code>主要作者<code>Jeffrey Dean</code>和 <code>Sanjay Ghemawat</code>开源了一款基于<code>LSM Tree</code>实现的数据库<code>LevelDB</code>，让大家对<code>LSM Tree</code>的思想和实现理解得更为透彻、深入。</p><p>当前，比较流行的NoSQL数据库，如Cassandra、<strong>RocksDB、HBase、LevelDB</strong>等，newSQL数据库，如TiDB，均是使用<code>LSM Tree</code>来组织磁盘数据的。</p><ul><li>rocksdb 是 Facebook 使用纯 C++ 研发的嵌入式 kv 存储引擎，依赖的核心数据结构是 lsm tree 存储引擎，底层正是基于追加写策略实现，适用于写多读少的使用场景。</li></ul><p>甚至像SQLite这种传统的关系型数据库和MongoDB这种传统的文档型数据库都提供了<strong>基于<code>LSM Tree</code>的存储引擎作为可选的存储引擎</strong>。</p><p>【读多写少：MySQL引擎、写多读少：LSM Why?】</p><h2 id="1-基本原理简述">1 基本原理简述</h2><p><code>LSM Tree</code>的全称为<code>Log-Structured Merge Tree</code>，是一个分层、有序、针对块存储设备（机械硬盘和SSD）特点而设计的数据存储结构。<strong>它的核心理论基础还是磁盘的顺序写速度比随机写速度快非常多</strong>，即使是SSD，由于块擦除和垃圾回收的影响，顺序写速度还是比随机写速度快很多。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528113331734.png" alt="image-20240528113331734"></p><p>【其实很直观的就知道是追加形式写的，保证顺序性。但是会存在2个问题，<strong>读数据慢以及写的空间浪费</strong>，请看后文是LSM是如何解决这2个问题的~】</p><p><code>LSM Tree</code>将存储数据切分为一系列的<code>SSTable</code>（<code>Sorted String Table</code>），一个<code>SSTable</code>内的数据是有序的任意字节组（即<code>arbitrary byte string</code>，并不是指编程语言中的String字符串），而且，<code>SSTable</code>一但写入磁盘中，就像日志一样不能再修改（这就是<code>Log-Structured Merge Tree</code>名字中<code>Log-Structured</code>一词的由来）。当要修改现有数据时，<code>LSM Tree</code>并不直接修改旧数据，而是直接将新数据写入新的<code>SSTable中</code>。同样的，删除数据时，<code>LSM Tree</code>也不直接删除旧数据，而是写一个相应数据的删除标记的记录到一个新的<code>SSTable</code>中。这样一来，<code>LSM Tree</code>写数据时对磁盘的操作都是顺序块写入操作，而没有随机写操作。</p><p><code>LSM Tree</code>这种独特的写入方式，导致在查找数据时，<code>LSM Tree</code>就不能像<code>B+树</code>那样在一个统一的索引表中进行查找，而是从最新的<code>SSTable</code>到老的<code>SSTable</code>依次进行查找。如果在新<code>SSTable</code>中找到了需查找的数据或相应的删除标记，则直接返回查找结果；如果没有找到，再到老的<code>SSTable</code>中进行查找，直到最老的<code>SSTable</code>查找完。为了提高查找效率，<code>LSM Tree</code>对<code>SSTable</code>进行分层、有序组织，也就是说把<code>SSTable</code>组织成多层，同一层可以有多个<code>SSTable</code>，同一个数据在同一层的多个<code>SSTable</code>中可以不重复，而且数据可以做到在同一层中是有序的，即每一个<code>SSTable</code>内的数据是有序的，前一个<code>SSTable</code>的最大数据值小于后一个<code>SSTable</code>的最小数据值（实际情况比这个复杂，后面会介绍）。这样可以加快在同一层<code>SSTable</code>中的数据查询速度。同时，<code>LSM Tree</code>会将多个<code>SSTable</code>合并（<code>Compact</code>）为一个新的<code>SSTable</code>，这样可以减少<code>SSTable</code>的数量，同时把修改前的数据或删除的数据真正从<code>SSTable</code>中删除，减小了<code>SSTable</code>的大小（这就是<code>Log-Structured Merge Tree</code>名字中<code>Merge</code>一词的由来），对提高查找性能极其重要（<code>SSTable</code>合并（<code>Compact</code>）过程对LSM Tree查找如此重要，以至于把它作为名字的一部分）。</p><h2 id="2-读写过程详述">2 读写过程详述</h2><h3 id="2-1-LSM-Tree框架图">2.1 LSM Tree框架图</h3><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528113731067.png" alt="image-20240528113731067"></p><p>【对着上述图得描述清楚】</p><p>上图中，<code>WAL</code>（<code>Write Ahead LOG</code>）严格来说本身并不是<code>LSM Tree</code>数据结构的一部分，但是实际系统中，<code>WAL</code>是数据库不可或缺的一部分，<code>把WAL</code>包括进来才能更准确的理解<code>LSM Tree</code>。</p><p>从图中可知，<code>LSM Tree</code>的数据由两部分组成：内存部分和持久到磁盘中的部分。<strong>内存部分由一个<code>MemTable</code>和一个或多个<code>Immutable MemTable</code>【防止写阻塞】组成</strong>。磁盘中的部分由分布在多个level的<code>SSTable</code>组成。level级数越小（<code>level 0</code>）表示处于该level的<code>SSTable</code>越新，level级数越大（<code>level 1...level N</code>）表示处于该level的<code>SSTable</code>越老，最大级数（<code>level N</code>）大小由系统设定。在本图中，磁盘中最小的级数为<code>level 0</code>，也有的系统把内存中的<code>Immutable MemTable</code>定义为<code>level 0</code>，而磁盘中的数据从<code>Level 1</code>开始，这只是level定义的不同，并不影响系统的工作流程和对系统的理解。</p><p><code>WAL</code>的结构和作用跟其他数据库一样，是一个只能在尾部以<code>Append Only</code>方式追加记录的日志结构文件，它用来当系统崩溃重启时重放操作，使<code>MemTable</code>和<code>Immutable MemTable</code>中未持久化到磁盘中的数据不会丢失。</p><p><strong><code>MemTable</code>往往是一个跳表（<code>Skip List</code>）组织的有序数据结构（当然，也可以是有序数组或红黑树等二叉搜索树）</strong>，跳表既支持高效的动态插入数据，对数据进行排序，也支持高效的对数据进行精确查找和范围查找。</p><p><code>SSTable</code>一般由一组数据block和一组元数据block组成。元数据block存储了<code>SSTable</code>数据block的描述信息，如索引、BloomFilter、压缩、统计等信息。因为<code>SSTable</code>是不可更改的，且是有序的，索引往往采用二分法数组结构就可以了。为了节省存储空间和提升数据块block的读写效率，可以对数据block进行压缩。</p><p>论文<code>《BigTable》</code>对<code>SSTable</code>的描述我觉得是比较清晰的，现摘录如下，供大家参考：</p><blockquote><p>An SSTable provides a persistent, ordered immutable map from keys to values, where both keys and values are arbitrary byte strings. Operations are provided to look up the value associated with a specified key, and to iterate over all key/value pairs in a specified key range. Internally, each SSTable contains a sequence of blocks (typically each block is 64KB in size, but this is configurable). A block index (stored at the end of the SSTable) is used to locate blocks; the index is loaded into memory when the SSTable is opened. A lookup can be performed with a single disk seek: we first find the appropriate block by performing a binary search in the in-memory index, and then reading the appropriate block from disk. Optionally, an SSTable can be completely mapped into memory, which allows us to perform lookups and scans without touching disk.</p></blockquote><h3 id="2-2-数据写入过程">2.2 数据写入过程</h3><p>如上图所示，<code>LSM Tree</code>写入数据时，先写一条记录到<code>WAL</code>中，然后将数据写入内存中的<code>MemTable</code>中，这样写入操作就完成了。</p><p>写<code>MemTable</code>时，写入新的数据，与修改现有数据的部分字段以及修改现有数据的所有字段，写入操作过程几乎是一样的，都是把传入的数据（合并）写入到<code>MemTable</code>中。删除数据时，则是在<code>MemTable</code>中写入一条删除标记。当<code>MemTable</code>的大小达到设定的大小（典型值是64KB）时，<code>LSM Tree</code>会把当前<code>MemTable</code>冻结为一个不可修改的<code>Immutable MemTable</code>，然后创建一个新的<code>MemTable</code>供新的数据写入。同时，<code>LSM Tree</code>一般会有一些与写入线程（或进程）相独立的背景线程（或进程）负责将<code>Immutable MemTable</code> flush到磁盘中，将数据持久化。已经flush到磁盘中的<code>Immutable MemTable</code>对应的<code>WAL</code>就可以从磁盘中删除了。而内存中<code>Immutable MemTable</code>数量的多少处决于<code>Immutable MemTable</code> flush的速度与<code>Immutable MemTable</code>生成的速度（数据写入速度）的差值</p><p>从<code>LSM Tree</code>数据写入过程可知，<code>LSM Tree</code>数据写入的操作非常简单，过程也非常少，只要写<code>WAL</code>和内存中的<code>MemTable</code>即可。而写<code>WAL</code>是以在文件末尾追加记录方式的顺序写，无需操作任何数据结构，写入速度非常快。写<code>MemTable</code>虽然也需要进行跳表的插入和排序操作，但是MemTable是一个内存数据结构，同时MemTable的大小控制在一个非常非常小的规模（比如64KB），所以写MemTable也是一个非常非常快的过程。</p><p>同时，我们还可以看到，数据的写入速度与数据库中数据总量的多少没有关系。而且，不管是写入新的数据，还是全量修改或部分修改现有数据，或是删除现有数据，<code>LSM Tree</code>的写入速度也几乎没多大差别。也就是说，<code>LSM Tree</code>的写入速度是稳定的，跟数据规模和数据更新类型都没有关系。</p><h3 id="2-3-数据查找过程">2.3 数据查找过程</h3><p>根据<code>LSM Tree</code>的写入特点我们知道，如果一项数据更新多次，这项数据可能会存储在多个不同的<code>SSTable</code>中，甚至一项数据的不同部分的最新数据内容存储在不同的<code>SSTable</code>中（数据部分更新的场景）。<code>LSM Tree</code>把这种现象叫做空间放大（<code>space amplification</code>），因为一项数据在磁盘中存储了多份副本，而老的副本是已经过时了的，不需要的，数据实际占用的存储空间比有效数据需要的大。</p><p>空间放大这种现象导致<code>LSM Tree</code>的查找过程是这样的：按新到老的顺序查找<code>SSTable</code>，直到在某个（或某些个）<code>SSTable</code>中查找到了所需的数据，或者最老的<code>SSTable</code>查找完也没有找到需要的数据。具体查找顺序为：先在内存<code>MemTable</code>中查找，然后在内存中的<code>Immutable MemTable</code>中查找，然后在<code>level 0 SSTable</code>中查找，最后在<code>level N SSTable</code>中查找。</p><p>查找某个具体的SSTable时，一般先把SSTable的元数据block读到内存中，根据BloomFilter可以快速确定数据在当前SSTable中是否存在，如果存在，则采用二分法确定数据在哪个数据block，然后将相应数据block读到内存中进行精确查找。</p><p>从<code>LSM Tree</code>数据查找过程我们可以看到，为了查找到目标数据，我们需要读取并查找不包含目标数据的SSTable，如果目标数据在最底层level N的SSTable中，我们需要读取和查找所有的SSTable！<code>LSM Tree</code>把这种读取和查找了无关SSTable的现象叫做读放大(<code>read amplification</code>)。</p><p><strong>读放大现象严重影响了<code>LSM Tree</code>数据查找性能，甚至是灾难性的（数据压根不存在或在最老的SSTable中），论文《BigTable》提到了几种提升数据查找性能的方法</strong>：【读放大的应对策略】</p><ol><li><p>压缩（Compression）</p><p>介绍SSTable时已经提到了，对数据block进行压缩，通过增加占用CPU压缩和解压缩资源来降低数据block磁盘空间占用和读写时间。</p></li><li><p>BloomFilter</p><p>描述查找过程时也已经提到了，BloomFilter可以快速确定数据不在SSTable中，而不用读取数据block内容</p></li><li><p>缓存（Cache）</p><p>因为SSTable是不可变的，非常适合缓存到内存中，这样热点数据不用访问磁盘</p></li><li><p>SSTable合并(Compaction)</p><p>将多个SSTable合并为一个SSTable，删除旧数据或物理删除已经被删除的数据，降低空间放大；同时减少SSTable数量，降低读放大</p></li></ol><p>其实这些优化措施，除了SSTable合并是<code>LSM Tree</code>独有的，前面三条都是数据库通用的措施，甚至SSTable合并也不是<code>LSM Tree</code>独有的，它与更早出现的lucene的段合并（<code>Segment Merge</code>）的原理和目标其实是有相似的地方的(当然他们的写入和查找过程还是有本质区别的)。下面详细介绍下SSTable合并</p><h2 id="3-SSTable合并">3 SSTable合并</h2><p>【写放大的应对策略】</p><p>这部分学习自：<a href="https://mp.weixin.qq.com/s/kqpBZ2aCC0CGvvL2Lm6mzA">初探 rocksdb 之 lsm tree</a></p><p>所有 disktable 是由内存中的 memtable 溢写得到的，这样 disktable 就天然具有两大优势：</p><ul><li>disktable 内部不存在重复 kv 对数据，因为 memtable 执行的是就地写操作</li><li>disktable 内部的 kv 对数据是有序的，因为 memtable 数据本身就是有序的</li></ul><p>然而，disktable 间还存在一个局限：由于每个 memtable 视野有限，只能做到自身范围内的 k 去重和排序. 因此，不同 disktable 之间可能存在重复冗余的 kv 对数据，且不同 disktable 之间的数据无法做到全局有序.</p><p>理清了现状，我们再在此基础之上，进一步引入磁盘 disktable 分层的概念.</p><ul><li>首先，我们将磁盘整体分为 level0-levelk 共计 k+1层.</li><li>每个 level 层中的 disktable 数量保持一致</li><li>level(i+1) 中 disktable 的容量大小固定为 level(i) 的 T 倍，T 为常量，通常取值为 10 左右</li><li>数据流向是由浅入深，层层递进，即由 level(i) -&gt; level(i+1)</li><li>memtable 溢写的数据落到 level0</li><li>levelk 作为兜底</li><li>当某个 level 内数据总量达到达到阈值时，会发起 level(i) -&gt; level(i+1) 的归并操作</li><li>数据从 level(i) 流向 level(i+1) 过程中，通过归并操作进行去重和排序，保证 level(i+1) 中 kv 数据无重复且全局有序</li></ul><p>结合上述设定，我们可以得出以下结论：</p><ul><li>level0 是特殊的，其中 disktable 之间可能存在冗余的 kv 对数据且不保证全局有序，因为其数据来自 memtable</li><li>level1~levelk 中单层之内没有冗余的 kv 对数据，且保证全局有序</li><li>不同 level 层之间可能存在冗余的 kv 数据</li><li>较热（最近写入）的数据位于浅层，较冷（更早写入）的数据位于深层</li><li>levelk 作为最深的一层，整体沉淀的数量达到全局的百分之九十左右</li></ul><p>下面举一例，说明一下从 level1 到 level2 的数据归并过程.</p><p>假设此时 level1 层的数据总量已经达到阈值，接下来需要发起 level(1) -&gt; level(2) 的归并操作：</p><ul><li>从 level1 中随机选择一个 disktable，尝试将其合并到 level2. 由于数据是有序的，我们可以拿到其中 k 的取值范围. 假设其中最小的 key k_min = 3， 最大的 key k_max = 30，记为[3,30]</li><li>假设 level2 中有 2 个 disktable 的 k 范围和待合并文件存在重叠，分别为 [0,16] 和 [17,32]</li><li>将 level1 的 [3,30] 与 level2 的 [0,10] 和 [11,20] 合并，这个过程本质上是个归并排序操作</li><li>新生成的 disktable [0,30] 不急于插入 level2 ，会根据 level2 中 disktable 的大小规模将其拆分为合适的数量</li><li>假设拆分得到的两个新的 disktable 分别为 [0,15] 和 [16,30]，将其插入到 level2</li><li>对应的老数据 level1 的[3,30] 以及 level2 的 [0,10] 和 [11,20] 都被被新数据替代，因此需要删除</li></ul><p>值得一提的是，倘若因为这一合并操作，导致 level2 的数据容量又超出阈值，则会进一步引起 level 2 到 level 3 的数据合并操作，以此类推，层层递进.</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240528114100478.png" alt="image-20240528114100478"></p><h2 id="4-LSM-Tree原理对系统读写性能提升的几点启示">4 LSM Tree原理对系统读写性能提升的几点启示</h2><ol><li>写数据时尽量批量操作。LSM Tree数据写入性能已经很高了，但是批量操作时可以节省网络传输RTT时间。</li><li>将数据进行分片。这样多个分片可以并行写，如果数据路由处理得当，也可以提升数据查询速度。但是增加了维护多个分片数据读写的复杂度。</li><li>选择合适的主键。两个比较流行的选择是：1）采用递增的数字作为主键；2）采用业务本身标识符作为主键。数字作为主键可以减少写入和查询时进行比较、排序等操作的时间，还能提升索引缓存的效率；递增的数字往往保证是顺序写入的，可以减少排序时间。但是递增的数字往往不具备业务语义，业务实际查询时需要先查二级索引，然后进行主键查找。业务标识符往往是业务实际的身份区分符号，业务也往往通过业务标识符进行数据查询。但是业务标识符往往是一个字符串，可能会比较长，这样比较、排序、缓存效率方面不如数字。一般情况下，本人建议LSM Tree数据库采用业务标识符作为主键。因为为业务标识符建立索引以及维护索引的成本是免不了的，与其建立二级索引，不如直接建立主键索引。</li><li>设计合理的二级索引，不建立不需要的二级索引。二级索引可以提升相应数据的查询速度，每增加一个二级索引，就需要额外维护相应的二级索引文件，严重影响写入数据性能。</li><li>根据具体场景使用合适的SSTable合并策略。单次写，频繁读场景选择leveled compaction策略。</li><li>在允许情况下关闭自动SSTable合并，在业务量低的时间段强制执行SSTable合并。</li><li>数据更新时合理选择全量更新（覆盖写）方式还是部分更新（增量写）方式。全量更新方式增加了传输和写入的数据量，但是可以提升数据查询速度。部分更新方式会使数据分布在多个SSTable中，需要查询和合并多个SSTable中的数据才能得到完整的数据，会降低数据查询速度。如果数据修改比较频繁，且需要较高查询速度，建议采用全量更新方式。</li></ol><p>参考资料</p><ul><li><a href="https://www.jianshu.com/p/b43b856e09bb">LSM Tree原理详解</a></li><li><a href="https://wingsxdu.com/posts/database/leveldb/#sstable">LSM-Tree 与 LevelDB 的原理和实现 · Analyze</a></li></ul>]]></content>
    
    
    <summary type="html">LSM Tree：Log-Structured Merge Tree</summary>
    
    
    
    <category term="数据库" scheme="https://penge666.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="数据库" scheme="https://penge666.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>一致性Hash算法</title>
    <link href="https://penge666.github.io/posts/aca386f3.html"/>
    <id>https://penge666.github.io/posts/aca386f3.html</id>
    <published>2024-05-27T13:58:45.000Z</published>
    <updated>2024-05-27T14:12:20.143Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hash算法">Hash算法</h2><p>我们想将图片A保存在服务器上，目前有3台服务器。我们只想保存一台服务器上，那么考虑到下次取的话还要到服务器上去取，那么使用hash算法就行。</p><p>但是当服务器数量的变更，就导致算出来的服务器里面没有我们想要的数据，那么会发生缓存雪崩的问题，因此有了下面的方法。</p><h2 id="一致性Hash算法背景">一致性Hash算法背景</h2><p>一致性哈希算法在1997年由麻省理工学院的Karger等人在解决分布式Cache中提出的，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得DHT可以在P2P环境中真正得到应用。</p><p>但现在一致性hash算法在分布式系统中也得到了广泛应用，研究过memcached缓存数据库的人都知道，memcached服务器端本身不提供分布式cache的一致性，而是由客户端来提供，具体在计算一致性hash时采用如下步骤：</p><ol><li>首先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。</li><li>然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。</li><li>然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。</li></ol><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527215930526.png" alt="image-20240527215930526"></p><p>从上图的状态中添加一台memcached服务器。余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在园（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527215942900.png" alt="image-20240527215942900"></p><p>分布式一致性哈希的优点，如果缓存服务器的数量发生改变，并不是所有的缓存都会失效，而是只有部分缓存失效，不容易出现。</p><h2 id="一致性Hash性质">一致性Hash性质</h2><p>考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其实在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要，良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面：</p><ul><li><strong>平衡性(Balance)</strong></li></ul><p>平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</p><ul><li><strong>单调性(Monotonicity)</strong></li></ul><p>单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希：x = (ax + b) mod §，在上式中，P表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从P1到P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要求。哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更新。而在P2P系统内，缓冲的变化等价于Peer加入或退出系统，这一情况在P2P系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。</p><ul><li><strong>分散性(Spread)</strong></li></ul><p>在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</p><ul><li><strong>负载(Load)</strong></li></ul><p>负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p><ul><li><strong>平滑性(Smoothness)</strong></li></ul><p>平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。</p><h3 id="基本概念">基本概念</h3><p>一致性哈希算法（Consistent Hashing）最早在论文《<a href="http://dl.acm.org/citation.cfm?id=258660">Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</a>》中被提出。简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希空间环如下：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527220707089.png" alt="image-20240527220707089"></p><p>整个空间按顺时针方向组织。0和232-1在零点中方向重合。</p><p>下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用ip地址哈希后在环空间的位置如下：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527220725275.png" alt="image-20240527220725275"></p><p>接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。</p><p>例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527220739718.png" alt="image-20240527220739718"></p><p>根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。</p><p>下面分析一致性哈希算法的容错性和可扩展性。现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。</p><p>下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527220755417.png" alt="image-20240527220755417"></p><p>此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。</p><p>综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p><p>另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下，</p><p>那么，如何解决这个问题呢？一种常见的做法是引入虚拟节点。也就是说，每个真实节点对应多个虚拟节点，每个虚拟节点都有自己在哈希环上的位置。这样，当一个数据项来到时，我们不是将它映射到真实节点，而是映射到虚拟节点。由于虚拟节点明显多于真实节点，这大大增加了在哈希环上的“节点”数量，从而使得数据更加均匀地分布在各个节点上，减轻了数据倾斜的问题。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527221105098.png" alt="image-20240527221105098"></p><p>此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527221125000.png" alt="image-20240527221125000"></p><p>同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。</p><p>【普通哈希问题，一致性哈希怎么解决，最后存在数据倾斜问题，使用虚拟节点解决】</p><p>学习自：</p><p><a href="https://blog.csdn.net/en_joker/article/details/80690800">论文：一致性Hash算法</a></p>]]></content>
    
    
    <summary type="html">一致性Hash算法</summary>
    
    
    
    <category term="分布式" scheme="https://penge666.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="分布式" scheme="https://penge666.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Memcached笔记</title>
    <link href="https://penge666.github.io/posts/69dcf386.html"/>
    <id>https://penge666.github.io/posts/69dcf386.html</id>
    <published>2024-05-27T13:32:41.000Z</published>
    <updated>2024-05-27T13:58:24.950Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、NoSQL-介绍">一、NoSQL 介绍</h2><p>NoSQL是对 Not Only SQL、非传统关系型数据库的统称</p><p>NoSQL一词诞生于1998年，2009年这个词汇被再次提出指非关系型、分布式、不提供ACID的数据库设计模式</p><p>随着互联网时代的到来，数据爆发式增长，数据库技术发展日新月异，要适应新的业务需求</p><p>而随着移动互联网、物联网的到来，大数据的技术中NoSQL也同样重要</p><p>NoSQL 分类</p><p>Key-value Store  k/v数据库</p><ul><li>性能好 O(1) , 如: redis、memcached</li></ul><p>Document Store 文档数据库</p><ul><li>mongodb、CouchDB</li></ul><p>Column Store  列存数据库，Column-Oriented DB</p><ul><li>HBase、Cassandra，大数据领域应用广泛</li></ul><p>Graph DB 图数据库</p><ul><li>Neo4j</li></ul><p>Time Series 时序数据库</p><ul><li>InfluxDB、Prometheus</li></ul><p>注：</p><p>关系型数据库：数据存放在硬盘，调度数据速率慢</p><p>非关系型数据库：数据存放在内存，调度数据速率快</p><p>安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv$ sudo apt-get install memcached</span><br></pre></td></tr></table></figure><h2 id="二、Memcached">二、Memcached</h2><h3 id="1、Memcached-介绍">1、Memcached 介绍</h3><h4 id="1-1-Memcached-概念">1.1 Memcached 概念</h4><p>Memcached 只支持能序列化的数据类型，不支持持久化，基于Key-Value的内存缓存系统</p><p>memcached 虽然没有像redis所具备的数据持久化功能，比如RDB和AOF都没有，但是可以通过做集群同步的方式，让各memcached服务器的数据进行同步，从而实现数据的一致性，即保证各memcached的数据是一样的，即使有任何一台 memcached 发生故障，只要集群中有一台 memcached 可用就不会出现数据丢失，当其他memcached 重新加入到集群的时候,可以自动从有数据的memcached 当中自动获取数据并提供服务。</p><p>Memcached 借助了操作系统的 libevent 工具做高效的读写。libevent是个程序库，它将Linux的epoll、BSD类操作系统的kqueue等事件处理功能封装成统一的接口。即使对服务器的连接数增加，也能发挥高性能。memcached使用这个libevent库，因此能在Linux、BSD、Solaris等操作系统上发挥其高性能</p><p>Memcached 支持最大的内存存储对象为1M，超过1M的数据可以使用客户端压缩或拆分报包放到多个key中，比较大的数据在进行读取的时候需要消耗的时间比较长，memcached 最适合保存用户的session实现session共享</p><p>Memcached存储数据时, Memcached会去申请1MB的内存, 把该块内存称为一个slab, 也称为一个page</p><p>Memcached 支持多种开发语言，包括：JAVA,C,Python,PHP,C#,Ruby,Perl等</p><p>Memcached 是一个高性能、分布式的内存对象缓存系统，用于减轻数据库负载，提升动态Web应用的性能。它基于内存键值存储系统设计，通过在内存中存储数据来减少对慢速数据库的访问次数，从而提高网站或应用程序的速度和响应能力</p><p>尽管 Memcached 在功能上有时被当作一种辅助数据库使用，但其主要角色是作为一个高性能、分布式的缓存层，适用于实时性要求高且数据可以容忍一定程度丢失的应用场景</p><h4 id="1-2-Memcached-特性">1.2 Memcached 特性</h4><p>分布式缓存： 可以在多台服务器上分布数据，允许构建大规模的缓存系统</p><p>内存中存储： 数据存储在内存中，因此读写速度非常快</p><p>简单的键值存储： 它使用简单的键值对存储方式，适合于存储对象、文本和其他数据类型</p><p>缓存数据过期： 可以为缓存的数据设置过期时间，确保缓存中的数据不会永远存在</p><p>支持多种语言： 提供了多种编程语言的客户端库，便于在不同的应用程序中使用</p><p>减轻数据库负载： 通过缓存频繁访问的数据，可以显著减轻数据库的负载，提高网站或应用程序的性能</p><p>LRU（最近最少使用）淘汰策略：当内存达到预设上限时，Memcached 将根据 LRU 算法自动删除最近最少使用的数据，为新数据腾出空间</p><p>非持久化：Memcached 不支持持久化存储，主要用于临时缓存</p><p>高性能： 由于数据存储在内存中，因此具有非常高的读取和写入性能</p><p>开源： Memcached 是一个开源项目，可以自由使用和修改</p><h4 id="1-3-Memcached-和-Redis-区别">1.3 Memcached 和 Redis 区别</h4><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527192201465.png" alt="image-20240527192201465"></p><h4 id="1-4-Memcached-工作机制">1.4 Memcached 工作机制</h4><h5 id="1-4-1-内存分配机制">1.4.1 内存分配机制</h5><p>应用程序运行需要使用内存存储数据，但对于一个缓存系统来说，申请内存、释放内存将十分频繁，非常容易导致大量内存碎片，最后导致无连续可用内存可用。</p><p>Memcached 采用了 Slab Allocator 机制来分配、管理内存。</p><p>Page：分配给 Slab 的内存空间，默认为1MB，分配后就得到一个Slab。Slab分配之后内存按照固定字节大小等分成 chunk。</p><p>Chunk：用于缓存记录 k/v 值的内存空间。Memcached 会根据数据大小选择存到哪一个chunk中，假设chunk有128bytes、64bytes等多种，数据只有100bytes存储在128bytes中，存在少许浪费。</p><p>Chunk 最大就是 Page的大小，即一个Page中就一个Chunk</p><p>Slab Class：Slab 按照 Chunk 的大小分组，就组成不同的 Slab Class, 第一个Chunk大小为 96B的Slab为Class1,Chunk 120B为Class 2,如果有100bytes要存，那么 Memcached 会选择下图中Slab Class 2 存储，因为它是120bytes的Chunk。Slab之间的差异可以使用Growth Factor 控制，默认1.25</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527211045176.png" alt="image-20240527211045176"></p><hr><p>简单说</p><p>Memcached采用的Slab Allocator机制是一种特别适合于处理大量小数据对象的内存管理机制。它把内存划分为多个相同大小的Slab，然后每个Slab再划分为多个相同大小的Chunk，用于存储数据。</p><p>以书店为例，你可以把Memcached想象成一个大书店，Slab就像书店里的书架，Chunk就像书架上的格子，而数据就像书本。</p><p>这个书店里有很多种类型的书架(Slab)，每个书架的大小都是固定的，比如说1MB。每个书架又被划分成很多个大小相同的格子(Chunk)，比如说有的书架的格子大小是96B，有的是120B等等。这些不同格子大小的书架被分别组织在不同的区域(Slab Class)。</p><p>当有一本新书(数据)需要上架时，书店会根据这本书的大小，选择一个合适的书架，然后在这个书架上找一个空的格子来放这本书。比如说，如果这本书的大小是100B，书店就会选择120B的书架来存储，因为96B的格子太小放不下，而120B的格子又是最接近100B的。</p><p>通过这种方式，Memcached可以有效地管理内存，尽量减少内存的浪费，并且由于每个格子的大小是固定的，所以在内存分配和回收时，可以避免复杂的内存管理操作，提高了系统的性能。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv$ memcached -u memcached -f 2 -vv</span><br><span class="line">slab class   1: chunk size        96 perslab   10922</span><br><span class="line">slab class   2: chunk size       192 perslab    5461</span><br><span class="line">slab class   3: chunk size       384 perslab    2730</span><br><span class="line">slab class   4: chunk size       768 perslab    1365</span><br><span class="line">slab class   5: chunk size      1536 perslab     682</span><br><span class="line">slab class   6: chunk size      3072 perslab     341</span><br><span class="line">slab class   7: chunk size      6144 perslab     170</span><br><span class="line">slab class   8: chunk size     12288 perslab      85</span><br><span class="line">slab class   9: chunk size     24576 perslab      42</span><br><span class="line">slab class  10: chunk size     49152 perslab      21</span><br><span class="line">slab class  11: chunk size     98304 perslab      10</span><br><span class="line">slab class  12: chunk size    196608 perslab       5</span><br><span class="line">slab class  13: chunk size    524288 perslab       2</span><br><span class="line">&lt;26 server listening (auto-negotiate)</span><br></pre></td></tr></table></figure><h5 id="1-4-2-懒惰期-Lazy-Expiration">1.4.2 懒惰期 Lazy Expiration</h5><p>memcached 不会监视数据是否过期，而是在取数据时才看是否过期，如果过期,把数据有效期限标识为0，并不清除该数据。以后可以覆盖该位置存储其它数据。</p><h5 id="1-4-3-LRU（最近最少使用算法）">1.4.3 LRU（最近最少使用算法）</h5><p>当内存不足时，memcached 会使用 LRU（Least Recently Used）机制来查找可用空间，分配给新记录使用</p><h5 id="1-4-4-集群">1.4.4 集群</h5><p>Memcached 集群，称为基于客户端的分布式集群，即由客户端实现集群功能，即 Memcached本身不支持集群</p><p>Memcached集群内部并不互相通信，一切都需要客户端连接到Memcached服务器后自行组织这些节点，并决定数据存储的节点</p><h3 id="2、安装-Memcached">2、安装 Memcached</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) sv<span class="variable">@sv</span>-<span class="variable constant_">NF5280M5</span><span class="symbol">:/home/sv</span><span class="variable">$ </span>sudo apt-get install memcached</span><br></pre></td></tr></table></figure><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> ~]<span class="meta">#rpm -ql memcached   #查看memcached的相关文件</span></span><br></pre></td></tr></table></figure><p>查看memcached信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv$ apt show memcached</span><br><span class="line">Package: memcached</span><br><span class="line">Version: 1.5.22-2ubuntu0.3</span><br><span class="line">Priority: optional</span><br><span class="line">Section: web</span><br><span class="line">Origin: Ubuntu</span><br><span class="line">Maintainer: Ubuntu Developers &lt;ubuntu-devel-discuss@lists.ubuntu.com&gt;</span><br><span class="line">Original-Maintainer: Chris Lamb &lt;lamby@debian.org&gt;</span><br><span class="line">Bugs: https://bugs.launchpad.net/ubuntu/+filebug</span><br><span class="line">Installed-Size: 340 kB</span><br><span class="line">Pre-Depends: init-system-helpers (&gt;= 1.54~)</span><br><span class="line">Depends: adduser, libssl1.1 (&gt;= 1.1.0), lsb-base, perl, perl:any, libc6 (&gt;= 2.17), libevent-2.1-7 (&gt;= 2.1.8-stable), libsasl2-2 (&gt;= 2.1.27+dfsg)</span><br><span class="line">Suggests: libanyevent-perl, libcache-memcached-perl, libmemcached, libterm-readkey-perl, libyaml-perl</span><br><span class="line">Homepage: https://memcached.org/</span><br><span class="line">Download-Size: 128 kB</span><br><span class="line">APT-Manual-Installed: <span class="built_in">yes</span></span><br><span class="line">APT-Sources: http://mirrors.tuna.tsinghua.edu.cn/ubuntu focal-updates/main amd64 Packages</span><br><span class="line">Description: High-performance in-memory object caching system</span><br><span class="line"> Danga Interactive developed memcached to enhance the speed of LiveJournal.com,</span><br><span class="line"> a site <span class="built_in">which</span> was already doing 20 million+ dynamic page views per day <span class="keyword">for</span> 1</span><br><span class="line"> million <span class="built_in">users</span> with a bunch of webservers and a bunch of database servers.</span><br><span class="line"> memcached dropped the database load to almost nothing, yielding faster page</span><br><span class="line"> load <span class="built_in">times</span> <span class="keyword">for</span> <span class="built_in">users</span>, better resource utilization, and faster access to the</span><br><span class="line"> databases on a memcache miss.</span><br><span class="line"> .</span><br><span class="line"> memcached optimizes specific high-load serving applications that are designed</span><br><span class="line"> to take advantage of its versatile no-locking memory access system. Clients</span><br><span class="line"> are available <span class="keyword">in</span> several different programming languages, to suit the needs</span><br><span class="line"> of the specific application. Traditionally this has been used <span class="keyword">in</span> mod_perl</span><br><span class="line"> apps to avoid storing large chunks of data <span class="keyword">in</span> Apache memory, and to share</span><br><span class="line"> this burden across several machines</span><br></pre></td></tr></table></figure><p>在Ubuntu上，Memcached的配置文件通常位于<code>/etc/memcached.conf</code>。如果你想要查看Memcached的配置，你可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv$ <span class="built_in">cat</span> /etc/memcached.conf</span><br><span class="line"><span class="comment"># memcached default config file</span></span><br><span class="line"><span class="comment"># 2003 - Jay Bonci &lt;jaybonci@debian.org&gt;</span></span><br><span class="line"><span class="comment"># This configuration file is read by the start-memcached script provided as</span></span><br><span class="line"><span class="comment"># part of the Debian GNU/Linux distribution.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run memcached as a daemon. This command is implied, and is not needed for the</span></span><br><span class="line"><span class="comment"># daemon to run. See the README.Debian that comes with this package for more</span></span><br><span class="line"><span class="comment"># information.</span></span><br><span class="line">-d</span><br><span class="line"></span><br><span class="line"><span class="comment"># Log memcached&#x27;s output to /var/log/memcached</span></span><br><span class="line">logfile /var/log/memcached.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># Be verbose</span></span><br><span class="line"><span class="comment"># -v</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Be even more verbose (print client commands as well)</span></span><br><span class="line"><span class="comment"># -vv</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start with a cap of 64 megs of memory. It&#x27;s reasonable, and the daemon default</span></span><br><span class="line"><span class="comment"># Note that the daemon will grow to this size, but does not start out holding this much</span></span><br><span class="line"><span class="comment"># memory</span></span><br><span class="line">-m 64</span><br><span class="line"></span><br><span class="line"><span class="comment"># Default connection port is 11211</span></span><br><span class="line">-p 11211</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the daemon as root. The start-memcached will default to running as root if no</span></span><br><span class="line"><span class="comment"># -u command is present in this config file</span></span><br><span class="line">-u memcache</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify which IP address to listen on. The default is to listen on all IP addresses</span></span><br><span class="line"><span class="comment"># This parameter is one of the only security measures that memcached has, so make sure</span></span><br><span class="line"><span class="comment"># it&#x27;s listening on a firewalled interface.</span></span><br><span class="line">-l 127.0.0.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Limit the number of simultaneous incoming connections. The daemon default is 1024</span></span><br><span class="line"><span class="comment"># -c 1024</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Lock down all paged memory. Consult with the README and homepage before you do this</span></span><br><span class="line"><span class="comment"># -k</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Return error when memory is exhausted (rather than removing items)</span></span><br><span class="line"><span class="comment"># -M</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Maximize core file limit</span></span><br><span class="line"><span class="comment"># -r</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a pidfile</span></span><br><span class="line">-P /var/run/memcached/memcached.pid</span><br></pre></td></tr></table></figure><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527211807087.png" alt="image-20240527211807087"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv$ systemctl start memcached.service</span><br><span class="line">==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ===</span><br><span class="line">启动“memcached.service”需要认证。</span><br><span class="line">Authenticating as: sv,,, (sv)</span><br><span class="line">Password:</span><br><span class="line">==== AUTHENTICATION COMPLETE ===</span><br><span class="line">(base) sv@sv-NF5280M5:/home/sv$ systemctl status memcached.service</span><br><span class="line">● memcached.service - memcached daemon</span><br><span class="line">     Loaded: loaded (/lib/systemd/system/memcached.service; enabled; vendor preset: enabled)</span><br><span class="line">     Active: active (running) since Mon 2024-05-27 19:15:06 CST; 2h 3min ago</span><br><span class="line">       Docs: man:memcached(1)</span><br><span class="line">   Main PID: 89046 (memcached)</span><br><span class="line">      Tasks: 10 (<span class="built_in">limit</span>: 76739)</span><br><span class="line">     Memory: 1.5M</span><br><span class="line">     CGroup: /system.slice/memcached.service</span><br><span class="line">             └─89046 /usr/bin/memcached -m 64 -p 11211 -u memcache -l 127.0.0.1 -P /var/run/memcached/memcached.pid</span><br><span class="line"></span><br><span class="line">5月 27 19:15:06 sv-NF5280M5 systemd[1]: Started memcached daemon.</span><br><span class="line">(base) sv@sv-NF5280M5:/home/sv$ ss -natp | grep memcached</span><br><span class="line">LISTEN   0        1024                  [::]:11211                 [::]:*        <span class="built_in">users</span>:((&quot;memcached&quot;,pid=<span class="number">89397</span>,fd=<span class="number">26</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3、memcached选项">3、memcached选项</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv$ memcached -h</span><br><span class="line">memcached 1.5.22</span><br><span class="line">-p, --port=&lt;num&gt;          TCP port to listen on (default: 11211)</span><br><span class="line">-U, --udp-port=&lt;num&gt;      UDP port to listen on (default: 0, off)</span><br><span class="line">-s, --unix-socket=&lt;file&gt;  UNIX socket to listen on (disables network support)</span><br><span class="line">-A, --enable-shutdown     <span class="built_in">enable</span> ascii <span class="string">&quot;shutdown&quot;</span> <span class="built_in">command</span></span><br><span class="line">-a, --unix-mask=&lt;mask&gt;    access mask <span class="keyword">for</span> UNIX socket, <span class="keyword">in</span> octal (default: 700)</span><br><span class="line">-l, --listen=&lt;addr&gt;       interface to listen on (default: INADDR_ANY)</span><br><span class="line">                          <span class="keyword">if</span> TLS/SSL is enabled, <span class="string">&#x27;notls&#x27;</span> prefix can be used to</span><br><span class="line">                          <span class="built_in">disable</span> <span class="keyword">for</span> specific listeners (-l notls:&lt;ip&gt;:&lt;port&gt;)</span><br><span class="line">-d, --daemon              run as a daemon</span><br><span class="line">-r, --enable-coredumps    maximize core file <span class="built_in">limit</span></span><br><span class="line">-u, --user=&lt;user&gt;         assume identity of &lt;username&gt; (only when run as root)</span><br><span class="line">-m, --memory-limit=&lt;num&gt;  item memory <span class="keyword">in</span> megabytes (default: 64)</span><br><span class="line">-M, --disable-evictions   <span class="built_in">return</span> error on memory exhausted instead of evicting</span><br><span class="line">-c, --conn-limit=&lt;num&gt;    max simultaneous connections (default: 1024)</span><br><span class="line">-k, --lock-memory         lock down all paged memory</span><br><span class="line">-v, --verbose             verbose (<span class="built_in">print</span> errors/warnings <span class="keyword">while</span> <span class="keyword">in</span> event loop)</span><br><span class="line">-vv                       very verbose (also <span class="built_in">print</span> client commands/responses)</span><br><span class="line">-vvv                      extremely verbose (internal state transitions)</span><br><span class="line">-h, --<span class="built_in">help</span>                <span class="built_in">print</span> this <span class="built_in">help</span> and <span class="built_in">exit</span></span><br><span class="line">-i, --license             <span class="built_in">print</span> memcached and libevent license</span><br><span class="line">-V, --version             <span class="built_in">print</span> version and <span class="built_in">exit</span></span><br><span class="line">-P, --pidfile=&lt;file&gt;      save PID <span class="keyword">in</span> &lt;file&gt;, only used with -d option</span><br><span class="line">-f, --slab-growth-factor=&lt;num&gt; chunk size growth <span class="built_in">factor</span> (default: 1.25)</span><br><span class="line">-n, --slab-min-size=&lt;bytes&gt; min space used <span class="keyword">for</span> key+value+flags (default: 48)</span><br><span class="line">-L, --enable-largepages  try to use large memory pages (<span class="keyword">if</span> available)</span><br><span class="line">-D &lt;char&gt;     Use &lt;char&gt; as the delimiter between key prefixes and IDs.</span><br><span class="line">              This is used <span class="keyword">for</span> per-prefix stats reporting. The default is</span><br><span class="line">              <span class="string">&quot;:&quot;</span> (colon). If this option is specified, stats collection</span><br><span class="line">              is turned on automatically; <span class="keyword">if</span> not, <span class="keyword">then</span> it may be turned on</span><br><span class="line">              by sending the <span class="string">&quot;stats detail on&quot;</span> <span class="built_in">command</span> to the server.</span><br><span class="line">-t, --threads=&lt;num&gt;       number of threads to use (default: 4)</span><br><span class="line">-R, --max-reqs-per-event  maximum number of requests per event, limits the</span><br><span class="line">                          requests processed per connection to prevent</span><br><span class="line">                          starvation (default: 20)</span><br><span class="line">-C, --disable-cas         <span class="built_in">disable</span> use of CAS</span><br><span class="line">-b, --listen-backlog=&lt;num&gt; <span class="built_in">set</span> the backlog queue <span class="built_in">limit</span> (default: 1024)</span><br><span class="line">-B, --protocol=&lt;name&gt;     protocol - one of ascii, binary, or auto (default: auto-negotiate)</span><br><span class="line">-I, --max-item-size=&lt;num&gt; adjusts max item size</span><br><span class="line">                          (default: 1m, min: 1k, max: 1024m)</span><br><span class="line">-S, --enable-sasl         turn on Sasl authentication</span><br><span class="line">-F, --disable-flush-all   <span class="built_in">disable</span> flush_all <span class="built_in">command</span></span><br><span class="line">-X, --disable-dumping     <span class="built_in">disable</span> stats cachedump and lru_crawler metadump</span><br><span class="line">-W  --disable-watch       <span class="built_in">disable</span> watch commands (live logging)</span><br><span class="line">-Y, --auth-file=&lt;file&gt;    (EXPERIMENTAL) <span class="built_in">enable</span> ASCII protocol authentication. format:</span><br><span class="line">                          user:pass\nuser2:pass2\n</span><br><span class="line">-e, --memory-file=&lt;file&gt;  (EXPERIMENTAL) mmap a file <span class="keyword">for</span> item memory.</span><br><span class="line">                          use only <span class="keyword">in</span> ram disks or persistent memory mounts!</span><br><span class="line">                          enables restartable cache (stop with SIGUSR1)</span><br><span class="line">-Z, --enable-ssl          <span class="built_in">enable</span> TLS/SSL</span><br><span class="line">-o, --extended            comma separated list of extended options</span><br><span class="line">                          most options have a <span class="string">&#x27;no_&#x27;</span> prefix to <span class="built_in">disable</span></span><br><span class="line">   - maxconns_fast:       immediately close new connections after <span class="built_in">limit</span> (default: enabled)</span><br><span class="line">   - hashpower:           an <span class="built_in">integer</span> multiplier <span class="keyword">for</span> how large the <span class="built_in">hash</span></span><br><span class="line">                          table should be. normally grows at runtime. (default starts at: 0)</span><br><span class="line">                          <span class="built_in">set</span> based on <span class="string">&quot;STAT hash_power_level&quot;</span></span><br><span class="line">   - tail_repair_time:    time <span class="keyword">in</span> seconds <span class="keyword">for</span> how long to <span class="built_in">wait</span> before</span><br><span class="line">                          forcefully killing LRU <span class="built_in">tail</span> item.</span><br><span class="line">                          disabled by default; very dangerous option.</span><br><span class="line">   - hash_algorithm:      the <span class="built_in">hash</span> table algorithm</span><br><span class="line">                          default is murmur3 <span class="built_in">hash</span>. options: jenkins, murmur3</span><br><span class="line">   - no_lru_crawler:      <span class="built_in">disable</span> LRU Crawler background thread.</span><br><span class="line">   - lru_crawler_sleep:   microseconds to <span class="built_in">sleep</span> between items</span><br><span class="line">                          default is 100.</span><br><span class="line">   - lru_crawler_tocrawl: max items to crawl per slab per run</span><br><span class="line">                          default is 0 (unlimited)</span><br><span class="line">   - no_lru_maintainer:   <span class="built_in">disable</span> new LRU system + background thread.</span><br><span class="line">   - hot_lru_pct:         pct of slab memory to reserve <span class="keyword">for</span> hot lru.</span><br><span class="line">                          (requires lru_maintainer, default pct: 20)</span><br><span class="line">   - warm_lru_pct:        pct of slab memory to reserve <span class="keyword">for</span> warm lru.</span><br><span class="line">                          (requires lru_maintainer, default pct: 40)</span><br><span class="line">   - hot_max_factor:      items idle &gt; cold lru age * drop from hot lru. (default: 0.20)</span><br><span class="line">   - warm_max_factor:     items idle &gt; cold lru age * this drop from warm. (default: 2.00)</span><br><span class="line">   - temporary_ttl:       TTL<span class="string">&#x27;s below get separate LRU, can&#x27;</span>t be evicted.</span><br><span class="line">                          (requires lru_maintainer, default: 61)</span><br><span class="line">   - idle_timeout:        <span class="built_in">timeout</span> <span class="keyword">for</span> idle connections. (default: 0, no <span class="built_in">timeout</span>)</span><br><span class="line">   - slab_chunk_max:      (EXPERIMENTAL) maximum slab size <span class="keyword">in</span> kilobytes. use extreme care. (default: 512)</span><br><span class="line">   - watcher_logbuf_size: size <span class="keyword">in</span> kilobytes of per-watcher write buffer. (default: 256)</span><br><span class="line">   - worker_logbuf_size:  size <span class="keyword">in</span> kilobytes of per-worker-thread buffer</span><br><span class="line">                          <span class="built_in">read</span> by background thread, <span class="keyword">then</span> written to watchers. (default: 64)</span><br><span class="line">   - track_sizes:         <span class="built_in">enable</span> dynamic reports <span class="keyword">for</span> <span class="string">&#x27;stats sizes&#x27;</span> <span class="built_in">command</span>.</span><br><span class="line">   - no_hashexpand:       disables <span class="built_in">hash</span> table expansion (dangerous)</span><br><span class="line">   - modern:              enables options <span class="built_in">which</span> will be default <span class="keyword">in</span> future.</span><br><span class="line">                          currently: nothing</span><br><span class="line">   - no_modern:           uses defaults of previous major version (1.4.x)</span><br><span class="line">   - ssl_chain_cert:      certificate chain file <span class="keyword">in</span> PEM format</span><br><span class="line">   - ssl_key:             private key, <span class="keyword">if</span> not part of the -ssl_chain_cert</span><br><span class="line">   - ssl_keyformat:       private key format (PEM, DER or ENGINE) (default: PEM)</span><br><span class="line">   - ssl_verify_mode:     peer certificate verification mode, default is 0(None).</span><br><span class="line">                          valid values are 0(None), 1(Request), 2(Require)</span><br><span class="line">                          or 3(Once)</span><br><span class="line">   - ssl_ciphers:         specify cipher list to be used</span><br><span class="line">   - ssl_ca_cert:         PEM format file of acceptable client CA<span class="string">&#x27;s</span></span><br><span class="line"><span class="string">   - ssl_wbuf_size:       size in kilobytes of per-connection SSL output buffer</span></span><br><span class="line"><span class="string">                          (default: 16)</span></span><br></pre></td></tr></table></figure><p>修改memcached 运行参数，可以使用下面的选项修改/etc/sysconfig/memcached文件</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527212039815.png" alt="image-20240527212039815"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#memcached -u memcached -m 1024 -c 65536 -f 2 -vv</span></span><br><span class="line"><span class="comment">#设置默认前台执行，</span></span><br><span class="line">-u memcached：设置 Memcached 以 memcached 用户身份运行</span><br><span class="line">-m 1024：为 Memcached 分配最大内存为 1024 MB（即1GB），用于缓存数据</span><br><span class="line">-c 65536：设置最大并发连接数为 65536，这意味着同时可以有这么多的客户端连接到 Memcached 实例</span><br><span class="line">-f 2：设置核心文件大小限制，这里的“2”表示如果 Memcached 进程崩溃，将创建一个大小为当前内存两倍的核心转储文件，以便于调试。但在一些系统中，这个参数可能已经被弃用或不支持</span><br><span class="line">-vv：开启详细模式（verbose mode），让 Memcached 在运行时输出更多的信息和日志</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(base) sv@sv-NF5280M5:/home/sv$ memcached -u memcached -m 1024 -c 65536 -f 2 -vv</span><br><span class="line">slab class   1: chunk size        96 perslab   10922</span><br><span class="line">slab class   2: chunk size       192 perslab    5461</span><br><span class="line">slab class   3: chunk size       384 perslab    2730</span><br><span class="line">slab class   4: chunk size       768 perslab    1365</span><br><span class="line">slab class   5: chunk size      1536 perslab     682</span><br><span class="line">slab class   6: chunk size      3072 perslab     341</span><br><span class="line">slab class   7: chunk size      6144 perslab     170</span><br><span class="line">slab class   8: chunk size     12288 perslab      85</span><br><span class="line">slab class   9: chunk size     24576 perslab      42</span><br><span class="line">slab class  10: chunk size     49152 perslab      21</span><br><span class="line">slab class  11: chunk size     98304 perslab      10</span><br><span class="line">slab class  12: chunk size    196608 perslab       5</span><br><span class="line">slab class  13: chunk size    524288 perslab       2</span><br><span class="line">failed to listen on TCP port 11211: Address already <span class="keyword">in</span> use</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#memcached -u memcached -m 1024 -c 65536 -d</span></span><br><span class="line"><span class="comment">#设置默认后台执行，</span></span><br><span class="line">-d：该选项会让 Memcached 在后台作为守护进程运行（daemonize），这样在终端窗口关闭后，Memcached 服务依然会继续运行，提供缓存服务</span><br></pre></td></tr></table></figure><h3 id="4、Memcached的基本使用方法">4、Memcached的基本使用方法</h3><h4 id="4-1-Memcached开发库和工具">4.1 Memcached开发库和工具</h4><p>与memcached通信的不同语言的连接器。libmemcached提供了C库和命令行工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#yum install  libmemcached -y </span></span><br><span class="line"><span class="comment">#安装工具包</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#memping --servers 172.16.12.10    #检测172.16.12.10设备的memcached服务是否能通</span></span><br><span class="line">[root@localhost ~]<span class="comment">#echo $?</span></span><br><span class="line">[root@localhost ~]<span class="comment">#systemctl stop memcached.service </span></span><br><span class="line">[root@localhost ~]<span class="comment">#memping --servers 172.16.12.10</span></span><br></pre></td></tr></table></figure><h5 id="4-1-2-Memstat">4.1.2 Memstat</h5><p>用于获取 Memcached 服务的统计信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#memstat --servers=172.16.12.10</span></span><br></pre></td></tr></table></figure><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527212252442.png" alt="image-20240527212252442"></p><p>4.2 memcached操作命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/share/doc/memcached-1.4.15//protocol.txt</span><br><span class="line"><span class="comment">#操作命令帮助文档</span></span><br></pre></td></tr></table></figure><p><strong>Memcached服务只支持Telnet连接</strong></p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> ~]<span class="meta">#yum install -y telnet   #安装telnet服务</span></span><br></pre></td></tr></table></figure><p>五种基本 memcached 命令执行最简单的操作。这些命令和操作包括：</p><ul><li>set</li><li>add</li><li>flush</li><li>get</li><li>delete</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#前三个命令是用于操作存储在 memcached 中的键值对的标准修改命令,都使用如下所示的语法：</span></span><br><span class="line"><span class="built_in">command</span> &lt;key&gt; &lt;flags&gt; &lt;expiration time&gt; &lt;bytes&gt;</span><br><span class="line">&lt;value&gt;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#参数说明：</span></span><br><span class="line"><span class="built_in">command</span>：一般为<span class="built_in">set</span>/add/replace</span><br><span class="line">key：key 用于查找缓存值</span><br><span class="line">flags：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息</span><br><span class="line">expiration time：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远）</span><br><span class="line">bytes：在缓存中存储的字节数</span><br><span class="line">value：存储的值（始终位于第二行）</span><br><span class="line"> </span><br><span class="line"><span class="comment">#如</span></span><br><span class="line"><span class="comment">#增加key，过期时间为秒，bytes为存储数据的字节数</span></span><br><span class="line">add key flags exptime bytes  </span><br></pre></td></tr></table></figure><h5 id="4-2-1-显示服务状态">4.2.1 显示服务状态</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#telnet 172.16.12.10 11211</span></span><br><span class="line">stats       <span class="comment">#显示服务状态</span></span><br><span class="line"> </span><br><span class="line">stats items <span class="comment">#显示各个 slab 中 item 的数目和存储时长(最后一次访问距离现在的秒数)。</span></span><br><span class="line"> </span><br><span class="line">stats slabs <span class="comment">#用于显示各个slab的信息，包括chunk的大小、数目、使用情况等</span></span><br></pre></td></tr></table></figure><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527212638674.png" alt="image-20240527212638674"></p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527212646738.png" alt="image-20240527212646738"></p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527212656266.png" alt="image-20240527212656266"></p><h5 id="4-2-2-添加数据">4.2.2 添加数据</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#telnet 172.16.12.10 11211</span></span><br><span class="line">add name 1 10 5</span><br><span class="line">hello </span><br><span class="line"> </span><br><span class="line"><span class="comment">#说明</span></span><br><span class="line">add  添加</span><br><span class="line">name  键的名字</span><br><span class="line">1    flages标志，描述信息</span><br><span class="line">10   超时时间，默认0秒代表永久有效</span><br><span class="line">4    字节数，数据的大小</span><br><span class="line">hello 具体的值</span><br></pre></td></tr></table></figure><h5 id="4-2-3-修改数据">4.2.3 修改数据</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> name 1 0 5</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改键名为name的键，flages标志位1，永不超时，且长度为5字节</span></span><br><span class="line"></span><br><span class="line">world</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改的内容为world</span></span><br></pre></td></tr></table></figure><h5 id="4-2-4-调用数据">4.2.4 调用数据</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">get name</span><br><span class="line"></span><br><span class="line"><span class="comment">#调用键名为name的数据</span></span><br></pre></td></tr></table></figure><h5 id="4-2-5-删除数据">4.2.5 删除数据</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">delete name</span><br><span class="line"></span><br><span class="line"><span class="comment">#删除键名为name的数据</span></span><br></pre></td></tr></table></figure><h5 id="4-2-6-清空数据">4.2.6 清空数据</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flush_all</span><br><span class="line"></span><br><span class="line"><span class="comment">#清空所有的数据</span></span><br></pre></td></tr></table></figure><h3 id="三、memcached-集群部署架构">三、memcached 集群部署架构</h3><h4 id="1、基于magent的部署架构">1、基于magent的部署架构</h4><p>Magent 是google开发的项目,应用端通过负载均衡服务器连接到 magent，然后再由 magent 代理用户应用请求到 memcached 处理，底层的 memcached 为双主结构会自动同步数据，本部署方式存在 magent 单点问题，因此需要两个 magent 做高可用。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527212832617.png" alt="image-20240527212832617"></p><h4 id="2、Repcached实现原理">2、Repcached实现原理</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">项目站点：http://repcached.sourceforge.net/</span><br></pre></td></tr></table></figure><p>在 master上可以通过 -X 选项指定 replication port(默认为11212/tcp)，在 slave上通过 -x 指定复制的master并连接，事实上，如果同时指定了 -x/-X， repcached先会尝试连接对端的master，但如果连接失败，它就会用 -X参数来自己 listen（成为master）；如果 master坏掉， slave侦测到连接断了，它会自动 listen而成为 master；而如果 slave坏掉，master也会侦测到连接断开，它就会重新 listen等待新的 slave加入。</p><p>从这方案的技术实现来看，其实它是一个单 master单 slave的方案，但它的 master/slave都是可读写的，而且可以相互同步，所以从功能上看，也可以认为它是双机 master-master方案。</p><p><strong>简单说</strong></p><p>这段描述主要在解释repcached（一个memcached的复制版本）中的master-slave复制机制，以及如何通过-X和-x选项来设置复制端口和复制的master。</p><p>首先，我们可以将master和slave理解为一对伙伴，他们之间通过网络互相通信和协调工作。在repcached中，master负责提供数据，而slave则从master那里复制数据。</p><p>在启动repcached的时候，可以通过-X选项在master上指定复制端口（默认为11212/tcp），这个端口就像是master的“电话号码”，slave可以通过这个“电话号码”连接到master。同样，可以通过-x选项在slave上指定要复制的master，也就是告诉slave要向哪个master“打电话”。</p><p>有一个有趣的地方是，如果同时指定了-X和-x，repcached会先尝试作为slave连接到master，但如果连接失败，它就会变成master，开始等待别的slave来连接。</p><p>另外，repcached还有一个自动故障转移的特性。如果master坏掉了，slave会侦测到连接断了，然后它会自动变成master，开始等待新的slave加入。而如果slave坏掉了，master也会侦测到连接断开，它就会重新等待新的slave加入。</p><p>这种机制保证了当一方出现故障时，系统仍然可以继续运行，只不过角色会发生变化。这就是repcached的master-slave复制机制和故障转移机制。</p><h4 id="3、简化后的部署架构">3、简化后的部署架构</h4><p>magent 已经有很长时间没有更新，因此可以不再使用 magent，直接通过负载均衡连接到memcached，仍然有两台 memcached 做高可用，repcached 版本的 memcached 之间会自动同步数据，以保持数据一致性，即使其中的一台 memcached 故障也不影响业务正常运行，故障的memcached 修复上线后再自动从另外一台同步数据即可保持数据一致性。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527213406322.png" alt="image-20240527213406322"></p><p>关注：和redis的对比，内存机制，libevent，分布式集群</p><p><strong>为什么memcached的QPS比redis高？</strong></p><p>Memcached是全内存的数据缓冲系统，Redis虽然支持数据的持久化，但是全内存才是其高性能的本质。作为基于内存的存储系统来说，机器物理内存的大小就是系统能够容纳的最大数据量。如果需要处理的数据量超过了单台机器的物理内存大小，就需要构建分布式集群来扩展存储能力。</p><p>Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。</p><hr><p>Memcached和Redis在设计和使用上都有一些不同，这些不同可能会影响它们的QPS（每秒查询率）。</p><p>Memcached可以利用多核处理器的优势，因为它可以在多个核心中运行多个线程。这使得Memcached在处理大量并发请求时，能够更好地分摊负载，从而提高了QPS。</p><p>而对于Redis来说，它是单线程的，只会使用一个核心。尽管Redis在小数据存储时的性能可能会优于Memcached，但在处理大数据时，尤其是在100k以上的数据中，Memcached的性能可能会更高。</p><p>因此，如果你的应用主要处理大型数据并且需要高并发，Memcached可能会是一个更好的选择，它的QPS可能会比Redis高。</p><p><strong>memcached关机数据就没有了</strong></p><p><strong>内存机制？</strong></p><p><strong>Memcacahed的Slab Allocation机制</strong></p><p>首先对于开发人员来说不匹配的malloc和free容易造成内存泄露；其次频繁调用会造成大量内存碎片无法回收重新利用，降低内存利用率；</p><p>然后作为系统调用，其系统开销远远大于一般函数调用。所以，为了提高内存的管理效率，高效的内存管理方案都不会直接使用malloc/free调用。</p><p>Memcached默认使用Slab Allocation机制管理内存，其主要思想是按照预先规定的大小，将分配的内存分割成特定长度的块以存储相应长度的key-value数据记录，以完全解决内存碎片问题。</p><p>Slab Allocation机制只为<strong>存储外部数据</strong>而设计，也就是说所有的key-value数据都存储在Slab Allocation系统里，而Memcached的其它内存请求则通过普通的malloc/free来申请，因为这些请求的数量和频率决定了它们不会对整个系统的性能造成影响。</p><p><strong>Redis内存分配机制</strong></p><p>Redis的内存管理主要通过源码中zmalloc.h和zmalloc.c两个文件来实现的。</p><p><strong>集群与分布式方面？</strong></p><p>Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储，关于分布式一致性哈希算法见总结：【<strong>分布式一致性hash算法</strong>】。当客户端向Memcached集群发送数据之前，首先会通过内置的分布式算法计算出该条数据的目标节点，然后数据会直接发送到该节点上存储。但客户端查询数据时，同样要计算出查询数据所在的节点，然后直接向该节点发送查询请求以获取数据。</p><p><strong>Redis主从复制</strong></p><p>学习自：</p><p><a href="https://blog.csdn.net/m0_71815887/article/details/136722664">Memcached-分布式内存对象缓存系统</a></p><p><a href="https://www.cnblogs.com/Courage129/p/14331520.html">Memcached与Redis对比及其优劣分析</a></p>]]></content>
    
    
    <summary type="html">Memcached：一个高性能的分布式内存对象缓存系统</summary>
    
    
    
    <category term="数据库" scheme="https://penge666.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="数据库" scheme="https://penge666.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>libevent源码剖析</title>
    <link href="https://penge666.github.io/posts/32933883.html"/>
    <id>https://penge666.github.io/posts/32933883.html</id>
    <published>2024-05-24T11:02:48.000Z</published>
    <updated>2024-06-02T09:21:44.819Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一-序幕">一 序幕</h2><h3 id="1-前言">1 前言</h3><p>libevent是一个轻量级的开源高性能网络库，使用者众多，研究者更甚，相关文章也不少。写这一系列文章的用意在于，一则分享心得；二则对libevent代码和设计思想做系统的、更深层次的分析，写出来，也可供后来者参考。</p><blockquote><p>libevent是用c语言编写的（MS大牛们都偏爱c语言哪），而且几乎是无处不函数指针，学习其源代码也需要相当的c语言基础。</p></blockquote><h3 id="2-libevent简介">2 libevent简介</h3><p>上来当然要先夸奖啦，libevent 有几个显著的亮点：<br>1）事件驱动（event-driven），高性能;<br>2）轻量级，专注于网络，不如ACE那么臃肿庞大；<br>3）源代码相当精炼、易读；<br>4）跨平台，支持Windows、Linux、*BSD和Mac Os；<br>5）支持多种I/O多路复用技术， epoll、poll、dev/poll、select和kqueue等；<br>6）支持I/O，定时器和信号等事件；<br>7）注册事件优先级；</p><p>libevent已经被广泛的应用，作为底层的网络库；比如memcached、Vomit、Nylon、Netchat等等。<br>libevent当前的最新稳定版是1.4.13；这也是本文参照的版本。</p><h3 id="3-学习的好处">3 学习的好处</h3><p>学习libevent有助于提升程序设计功力，除了网络程序设计方面外，libevent的代码里有很多有用的设计技巧和基础数据结构，比如信息隐藏、函数指针、c语言的多态支持、链表和堆等等，都有助于提升自身的程序功力。</p><p>程序设计不止要了解框架，很多细节之处恰恰也是事关整个系统成败的关键。只对libevent本身的框架大概了解，那或许仅仅是一知半解，不深入代码分析，就难以了解其设计的精巧之处，也就难以为自己所用。</p><p>事实上libevent本身就是一个典型的Reactor模型，理解Reactor模式是理解libevent的基石；因此下一节将介绍典型的事件驱动设计模式—Reactor模式。</p><p>参考资料：<br>libevent: <a href="http://monkey.org/~provos/libevent/">http://monkey.org/~provos/libevent/</a></p><h2 id="二-reactor模式">二 reactor模式</h2><p>前面讲到，整个libevent本身就是一个Reactor，因此本节将专门对Reactor模式进行必要的介绍，并列出libevent中的几个重要组件和Reactor的对应关系，在后面的章节中可能还会提到本节介绍的基本概念。</p><h3 id="1-reactor的事件处理机制">1 reactor的事件处理机制</h3><p>首先来回想一下普通函数调用的机制：程序调用某函数?函数执行，程序等待?函数将结果和控制权返回给程序?程序继续处理。</p><p>reactor释义“反应堆”，是一种事件驱动机制。和普通函数调用的不同之处在于：应用程序不是主动的调用某个API完成处理，而是恰恰相反，reactor逆置了事件处理流程，应用程序需要提供相应的接口并注册到reactor上，如果相应的时间发生，reactor将主动调用应用程序注册的接口，这些接口又称为“回调函数”。使用libevent也是想libevent框架注册相应的事件和回调函数；当这些时间发声时，libevent会调用这些回调函数处理相应的事件（I/O读写、定时和信号）。用“<strong>好莱坞原则</strong>”来形容reactor再合适不过了：<strong>不要打电话给我们，我们会打电话通知你。</strong></p><p>举个例子：你去应聘某xx公司，面试结束后。“普通函数调用机制”公司HR比较懒，不会记你的联系方式，那怎么办呢，你只能面试完后自己打电话去问结果；有没有被录取啊，还是被据了；</p><p>“reactor”公司HR就记下了你的联系方式，结果出来后会主动打电话通知你：有没有被录取啊，还是被据了；你不用自己打电话去问结果，事实上也不能，你没有HR的留联系方式。</p><h3 id="2-reactor模式的优点">2 reactor模式的优点</h3><p>reactor模式是编写高性能网络服务器的必备技术之一，它具有如下的优点：<br>1）响应快，不必为单个同步时间所阻塞，虽然reactor本身依然是同步的；<br>2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；<br>3）可扩展性，可以方便的通过增加reactor实例个数来充分利用CPU资源；<br>4）可复用性，reactor框架本身与具体事件处理逻辑无关，具有很高的复用性；</p><h3 id="3-reactor模式框架">3 reactor模式框架</h3><p>使用reactor模型，必备的几个组件：事件源、reactor框架、多路复用机制和事件处理程序，先来看看reactor模型的整体框架，接下来再对每个组件做逐一说明。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602172134310.png" alt="image-20240602172134310"></p><p>1）事件源<br>Linux上是文件描述符，Windows上就是Socket或者Handle了，这里统一称为“句柄集”；程序在指定的句柄上注册关心的事件，比如I/O事件。</p><p>2）event demultiplexer——事件多路分发机制<br>由操作系统提供的I/O多路复用机制，比如select和epoll。程序首先将其关心的句柄（事件源）及其事件注册到event demultiplexer上；<br>当有事件到达时，event demultiplexer会发出通知“在已经注册的句柄集中，一个或多个句柄的事件已经就绪”；程序收到通知后，就可以在非阻塞的情况下对事件进行处理了。对应到libevent中，依然是select、poll、epoll等，但是libevent使用结构体eventop进行了封装，以统一的接口来支持这些I/O多路复用机制，达到了对外隐藏底层系统机制的目的。</p><p>3）reactor——反应器<br>reactor，是事件管理的接口，内部使用event demultiplexer注册、注销事件；并运行事件循环，当有事件进入“就绪”状态时，调用注册事件的回调函数处理事件。对应到libevent中，就是event_base结构体。一个典型的Reactor声明方式</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Reactor</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">register_handler</span><span class="params">(Event_Handler *pHandler, <span class="type">int</span> event)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">remove_handler</span><span class="params">(Event_Handler *pHandler, <span class="type">int</span> event)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">handle_events</span><span class="params">(timeval *ptv)</span></span>;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>反应器的理解：</p><p>这段代码是描述了一个典型的Reactor（反应器）设计模式在事件驱动编程中的应用。</p><p>Reactor设计模式是一种事件处理模式，用于处理服务请求，这些服务请求被发送至一个或多个服务处理程序。</p><p>在这个类中：</p><ul><li><code>register_handler</code>方法用于注册事件处理程序，当某个事件发生时，将调用该事件处理程序。</li><li><code>remove_handler</code>方法用于移除事件处理程序，不再对该事件进行处理。</li><li><code>handle_events</code>方法是事件循环，用于处理所有已经就绪的事件。</li></ul><p>通俗易懂的说，Reactor就像是一个电话交换员或者邮局。当有电话打入或者邮件发送到邮局时，交换员或者邮局就会根据电话或者邮件的目的地，将它们转发给对应的接收者。在这个过程中，电话交换员或者邮局就扮演了Reactor的角色，电话或者邮件就是事件，接收者就是事件处理程序。当电话打入或者邮件到达时（事件发生），交换员或者邮局就会调用对应的接收者（事件处理程序）来处理电话或者邮件（处理事件）。</p><p>4）Event Handler——事件处理程序<br>事件处理程序提供了一组接口，每个接口对应了一种类型的事件，供Reactor在相应的事件发生时调用，执行相应的事件处理。通常它会绑定一个有效的句柄。对应到libevent中，就是event结构体。</p><p>下面是两种典型的Event Handler类声明方式，二者互有优缺点。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Event_Handler</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">handle_read</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">handle_write</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">handle_timeout</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">handle_close</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> HANDLE <span class="title">get_handle</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Event_Handler</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// events maybe read/write/timeout/close .etc</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">handle_events</span><span class="params">(<span class="type">int</span> events)</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> HANDLE <span class="title">get_handle</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="4-reactor事件处理流程">4 reactor事件处理流程</h3><p>前面说过reactor将事件流“逆置”了，那么使用reactor模式后，事件控制流是什么样子呢？<br>可以参见下面的序列图。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602172127005.png" alt="image-20240602172127005"></p><h3 id="5-小结">5 小结</h3><p>上面讲到了reactor的基本概念、框架和处理流程，对reactor有个基本清晰的了解后，再来对比看libevent就会更容易理解了，接下来就正式进入到libevent的代码世界了，加油！</p><p>参考资料：<br>Pattern-Oriented Software Architecture, Patterns for Concurrent and Networked Objects, Volume 2</p><h2 id="三-libevent基本使用场景和事件流程">三 libevent基本使用场景和事件流程</h2><h3 id="1-前言-2">1 前言</h3><p>学习源代码该从哪里入手？我觉得从程序的基本使用场景和代码的整体处理流程入手是个不错的方法，至少从个人的经验上讲，用此方法分析libevent是比较有效的。</p><h3 id="2-基本应用场景">2 基本应用场景</h3><p>基本应用场景也是使用libevnet的基本流程，下面来考虑一个最简单的场景，使用livevent设置定时器，应用程序只需要执行下面几个简单的步骤即可。</p><p>1）首先初始化libevent库，并保存返回的指针<br><code>struct event_base * base = event_init();</code>实际上这一步相当于初始化一个reactor实例；在初始化libevent后，就可以注册事件了。</p><p>2）初始化事件event，设置回调函数和关注的事件<br><code>evtimer_set(&amp;ev, timer_cb, NULL);</code>事实上这等价于调用<code>event_set(&amp;ev, -1, 0, timer_cb, NULL);</code><br>event_set的函数原型是：<br><code>void event_set(struct event *ev, int fd, short event, void (*cb)(int, short, void *), void *arg)</code><br>ev：执行要初始化的event对象；<br>fd：该event绑定的“句柄”，对于信号事件，它就是关注的信号；<br>event：在该fd上关注的事件类型，它可以是EV_READ, EV_WRITE, EV_SIGNAL；<br>cb：这是一个函数指针，当fd上的事件event发生时，调用该函数执行处理，它有三个参数，调用时由event_base负责传入，按顺序，实际上就是event_set时的fd, event和arg；<br>arg：传递给cb函数指针的参数；<br>由于定时事件不需要fd，并且定时事件是根据添加时（event_add）的超时值设定的，因此这里event也不需要设置。这一步相当于初始化一个event handler，在libevent中事件类型保存在event结构体中。<br>注意：libevent并不会管理event事件集合，这需要应用程序自行管理；</p><p>3）设置event从属的event_base<br><code>event_base_set(base, &amp;ev);</code><br>这一步相当于指明event要注册到哪个event_base实例上；</p><p>4）是正式的添加事件的时候了<br><code>event_add(&amp;ev, timeout);</code><br>基本信息都已设置完成，只要简单的调用event_add()函数即可完成，其中timeout是定时值；<br>这一步相当于调用Reactor::register_handler()函数注册事件。</p><p>5）程序进入无限循环，等待就绪事件并执行事件处理<br><code>event_base_dispatch(base);</code></p><h3 id="3-实例代码">3 实例代码</h3><p>上面例子的程序代码如下所示</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">event</span> ev;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">timeval</span> tv;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">time_cb</span><span class="params">(<span class="type">int</span> fd, <span class="type">short</span> event, <span class="type">void</span> *argc)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;timer wakeup/n&quot;</span>);</span><br><span class="line">    <span class="built_in">event_add</span>(&amp;ev, &amp;tv); <span class="comment">// reschedule timer</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">event_base</span> *base = <span class="built_in">event_init</span>();</span><br><span class="line">    tv.tv_sec = <span class="number">10</span>; <span class="comment">// 10s period</span></span><br><span class="line">    tv.tv_usec = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">evtimer_set</span>(&amp;ev, time_cb, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">event_add</span>(&amp;ev, &amp;tv);</span><br><span class="line">    <span class="built_in">event_base_dispatch</span>(base);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-事件处理流程">4 事件处理流程</h3><p>当应用程序向libevent注册一个事件后，libevent内部是怎么样进行处理的呢？下面的图就给出了这一基本流程。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240602172116761.png" alt="image-20240602172116761"></p><p>1）首先应用程序准备并初始化event，设置好事件类型和回调函数；这对应于前面第步骤2和3；<br>2）向libevent添加该事件event。对于定时事件，libevent使用一个小根堆管理，key为超时时间；对于Signal和I/O事件，libevent将其放入到等待链表（wait list）中，这是一个双向链表结构；<br>3）程序调用event_base_dispatch()系列函数进入无限循环，等待事件，以select()函数为例；每次循环前libevent会检查定时事件的最小超时时间tv，根据tv设置select()的最大等待时间，以便于后面及时处理超时事件；当select()返回后，首先检查超时事件，然后检查I/O事件；libevent将所有的就绪事件，放入到激活链表中；然后对激活链表中的事件，调用事件的回调函数执行事件处理；、</p><p><strong>解释1</strong>：每次循环前libevent会检查定时事件的最小超时时间tv，根据tv设置select()的最大等待时间，以便于后面及时处理超时事件。</p><p>【重点】举个例子，假设我们有一个定时事件，10秒后触发。我们调用event_base_dispatch开始事件循环，然后libevent检查定时事件的最小超时时间，发现是10秒后。于是，libevent调用select函数，设置最大等待时间为10秒。10秒后，即使没有I/O事件发生，select函数也会返回，然后libevent就知道这个定时事件已经就绪，就会调用相应的回调函数处理这个定时事件。</p><h3 id="5-小结-2">5 小结</h3><p>本节介绍了libevent的简单实用场景，并介绍了libevent的事件处理流程，读者应该对libevent有了基本的印象，下面将会详细介绍libevent的事件管理框架（reactor模式中的reactor框架），在此之前会对源代码文件做简单的分类。</p><h2 id="四-libevent源代码文件组织">四 libevent源代码文件组织</h2><h3 id="1-前言-3">1 前言</h3><p>详细分析源代码之前，如果能对其代码文件的基本结构有个大概的认识和分类，对于代码的分析将是大有裨益的。本节内容不多，但并不是说它不重要！</p><h3 id="2-源代码组织结构">2 源代码组织结构</h3><p>libevent的源代码虽然都在一层文件夹下面，但是其代码分类还是相当清晰的，主要可分为头文件、内部使用的头文件、辅助功能函数、日志、libevent框架、对系统I/O多路复用机制的封装、信号管理、定时事件管理、缓冲区管理、基本数据结构和基于libevent的两个实用库等几个部分，有些部分可能就是一个源文件。</p><p>源代码中的test部分就不在我们关注的范畴了。<br>1）头文件<br>主要就是<strong>event.h</strong>：事件宏定义、接口函数声明，主要结构体event的声明；</p><p>2）内部头文件<br><strong>xxx-internal.h</strong>：内部数据结构和函数，对外不可见，以达到信息隐藏的目的；</p><p>3）libevent框架<br><strong>event.c</strong>：event整体框架的代码实现；</p><p>4）对系统I/O多路复用机制的封装<br><strong>epoll.c</strong>：对epoll的封装；<br><strong>select.c</strong>：对select的封装；<br><strong>devpoll.c</strong>：对dev/poll的封装;<br><strong>kqueue.c</strong>：对kqueue的封装；</p><p>5）定时事件管理<br><strong>min-heap.h</strong>：其实就是一个以时间作为key的小根堆结构；</p><p>6）信号管理<br><strong>signal.c</strong>：对信号事件的处理；</p><p>7）辅助功能函数<br><strong>evutil.h 和evutil.c</strong>：一些辅助功能函数，包括创建socket pair和一些时间操作函数：加、减和比较等。</p><p>8）日志<br>log.h和log.c：log日志函数</p><p>9）缓冲区管理<br><strong>evbuffer.c</strong>和<strong>buffer.c</strong>：libevent对缓冲区的封装；</p><p>10）基本数据结构<br>compat/sys下的两个源文件：queue.h是libevent基本数据结构的实现，包括链表，双向链表，队列等；_libevent_time.h：一些用于时间操作的结构体定义、函数和宏定义；</p><p>11）实用网络库<br>http和evdns：是基于libevent实现的http服务器和异步dns查询库；</p><h3 id="3-小结">3 小结</h3><p>本节介绍了libevent的组织和分类，下面将会详细介绍libevent的核心部分event结构。</p><h2 id="五-libevent的核心：事件event">五 libevent的核心：事件event</h2><p>对事件处理流程有了高层的认识后，本节将详细介绍libevent的核心结构event，以及libevent对event的管理。</p><h3 id="1-libevent的核心-event">1 libevent的核心-event</h3><p>libevent是基于事件驱动（event-driven）的，从名字也可以看到event是整个库的核心。event就是reactor框架中的事件处理程序组件；它提供了函数接口，供reactor在事件发生时调用，以执行相应的事件处理，通常它会绑定一个有效的句柄。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">event</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">TAILQ_ENTRY</span> (event) ev_next;</span><br><span class="line"><span class="built_in">TAILQ_ENTRY</span> (event) ev_active_next;</span><br><span class="line"><span class="built_in">TAILQ_ENTRY</span> (event) ev_signal_next;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> min_heap_idx; <span class="comment">/* for managing timeouts */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">event_base</span> *ev_base;</span><br><span class="line"><span class="type">int</span> ev_fd;</span><br><span class="line"><span class="type">short</span> ev_events;</span><br><span class="line"><span class="type">short</span> ev_ncalls;</span><br><span class="line"><span class="type">short</span> *ev_pncalls; <span class="comment">/* Allows deletes in callback */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">timeval</span> ev_timeout;</span><br><span class="line"><span class="type">int</span> ev_pri;  <span class="comment">/* smaller numbers are higher priority */</span></span><br><span class="line"><span class="built_in">void</span> (*ev_callback)(<span class="type">int</span>, <span class="type">short</span>, <span class="type">void</span> *arg);</span><br><span class="line"><span class="type">void</span> *ev_arg;</span><br><span class="line"><span class="type">int</span> ev_res;  <span class="comment">/* result passed to event callback */</span></span><br><span class="line"><span class="type">int</span> ev_flags;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>首先给出event结构体的声明，它位于event.h文件中：</p><p>下面简单解释一下结构体中各字段的含义。</p><p>1）<strong>ev_events</strong>：event关注的事件类型，它可以是以下3种类型：<br>I/O事件： EV_WRITE和EV_READ<br>定时事件：EV_TIMEOUT<br>信号： EV_SIGNAL<br>辅助选项：EV_PERSIST，表明是一个永久事件</p><p>libevent中的定义为：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> EV_TIMEOUT 0x01</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EV_READ    0x02</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EV_WRITE   0x04</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EV_SIGNAL  0x08</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EV_PERSIST 0x10 <span class="comment">/* Persistant event */</span></span></span><br></pre></td></tr></table></figure><p>可以看出事件类型可以使用“|”运算符进行组合，需要说明的是，信号和I/O事件不能同时设置；还可以看出libevent使用event结构体将这3种事件的处理统一起来；</p><p>2）<strong>ev_next</strong>，<strong>ev_active_nex</strong>t和<strong>ev_signal_next</strong>都是双向链表节点指针；它们是libevent对不同事件类型和在不同的时期，对事件的管理时使用到的字段。libevent使用双向链表保存所有注册的I/O和Signal事件，ev_next就是该I/O事件在链表中的位置；称此链表为“已注册事件链表”；同样ev_signal_next就是signal事件在signal事件链表中的位置；ev_active_next：libevent将所有的激活事件放入到链表active list中，然后遍历active list执行调度，ev_active_next就指明了event在active list中的位置；</p><p>2）<strong>min_heap_idx</strong>和<strong>ev_timeout</strong>，如果是timeout事件，它们是event在小根堆中的索引和超时值，libevent使用小根堆来管理定时事件，这将在后面定时事件处理时专门讲解。</p><p>3）<strong>ev_base</strong>该事件所属的反应堆实例，这是一个event_base结构体，下一节将会详细讲解；</p><p>4）<strong>ev_fd</strong>，对于I/O事件，是绑定的文件描述符；对于signal事件，是绑定的信号；</p><p>5）<strong>ev_callback</strong>，event的回调函数，被ev_base调用，执行事件处理程序，这是一个函数指针，原型为：<br><code>void (*ev_callback)(int fd, short events, void *arg);</code>其中参数fd对应于ev_fd；events对应于ev_events；arg对应于ev_arg；</p><p>6）<strong>ev_arg</strong>：void*，表明可以是任意类型的数据，在设置event时指定；</p><p>7）<strong>eb_flags</strong>：libevent用于标记event信息的字段，表明其当前的状态，可能的值有：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> EVLIST_TIMEOUT  0x01 <span class="comment">// event在time堆中</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EVLIST_INSERTED 0x02 <span class="comment">// event在已注册事件链表中</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EVLIST_SIGNAL   0x04 <span class="comment">// 未见使用</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EVLIST_ACTIVE   0x08 <span class="comment">// event在激活链表中</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EVLIST_INTERNAL 0x10 <span class="comment">// 内部使用标记</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> EVLIST_INIT     0x80 <span class="comment">// event已被初始化</span></span></span><br></pre></td></tr></table></figure><p>8）<strong>ev_ncalls</strong>：事件就绪执行时，调用ev_callback的次数，通常为1；</p><p>9）<strong>ev_pncalls</strong>：指针，通常指向ev_ncalls或者为NULL；</p><p>10）<strong>ev_res</strong>：记录了当前激活事件的类型；</p><h3 id="2-libevent对event的管理">2 libevent对event的管理</h3><p>从event结构体中的3个链表节点指针和一个堆索引出发，大体上也能窥出libevent对event的管理方法了，可以参见下面的示意图</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240526115502487.png" alt="image-20240526115502487"></p><p>每次当有事件event转变为就绪状态时，libevent就会把它移入到active event list[priority]中，其中priority是event的优先级；接着libevent会根据自己的调度策略选择就绪事件，调用其cb_callback()函数执行事件处理；并根据就绪的句柄和事件类型填充cb_callback函数的参数。</p><h3 id="3-事件设置的接口函数">3 事件设置的接口函数</h3><p>要向libevent添加一个事件，需要首先设置event对象，这通过调用libevent提供的函数有：event_set(), event_base_set(), event_priority_set()来完成；下面分别进行讲解。</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">event_set</span>(<span class="params"><span class="keyword">struct</span> <span class="keyword">event</span> *ev, <span class="built_in">int</span> fd, <span class="built_in">short</span> events, <span class="keyword">void</span> (*callback</span>)(<span class="params"><span class="built_in">int</span>, <span class="built_in">short</span>, <span class="keyword">void</span> *</span>), <span class="keyword">void</span> *arg)</span>;</span><br></pre></td></tr></table></figure><p>1）设置事件ev绑定的文件描述符或者信号，对于定时事件，设为-1即可；<br>2）设置事件类型，比如EV_READ|EV_PERSIST, EV_WRITE, EV_SIGNAL等；<br>3）设置事件的回调函数以及参数arg；<br>4）初始化其它字段，比如缺省的event_base和优先级；</p><p><code>int event_base_set(struct event_base *base, struct event *ev)</code><br>设置event ev将要注册到的event_base；libevent有一个全局event_base指针current_base，默认情况下事件ev将被注册到current_base上，使用该函数可以指定不同的event_base；如果一个进程中存在多个libevent实例，则必须要调用该函数为event设置不同的event_base；</p><p><code>int event_priority_set(struct event *ev, int pri);</code><br>设置event ev的优先级，没什么可说的，注意的一点就是：当ev正处于就绪状态时，不能设置，返回-1。</p><h3 id="4-小结">4 小结</h3><p>本节讲述了libevent的核心event结构，以及libevent支持的事件类型和libevent对event的管理模型；接下来将会描述libevent的事件处理框架，以及其中使用的重要的结构体event_base；</p><h2 id="六-初见事件处理框架">六 初见事件处理框架</h2><p>前面已经对libevent的事件处理框架和event结构体做了描述，现在是时候剖析libevent对事件的详细处理流程了，本节将分析libevent的事件处理框架event_base和libevent注册、删除事件的具体流程，可结合前一节libevent对event的管理。</p><h3 id="1-事件处理框架-event-base">1 事件处理框架-event_base</h3><p>回想Reactor模式的几个基本组件，本节讲解的部分对应于reactor框架组件。在libevent中，这就表现为event_base结构体，结构体声明如下，它位于event-internal.h文件中：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">event_base</span></span><br><span class="line"> &#123;</span><br><span class="line"> <span class="type">const</span> <span class="keyword">struct</span> <span class="title class_">eventop</span> *evsel;</span><br><span class="line"> <span class="type">void</span> *evbase;　</span><br><span class="line"> <span class="type">int</span> event_count;  <span class="comment">/* counts number of total events */</span></span><br><span class="line"> <span class="type">int</span> event_count_active; <span class="comment">/* counts number of active events */</span></span><br><span class="line"> <span class="type">int</span> event_gotterm;  <span class="comment">/* Set to terminate loop */</span></span><br><span class="line"> <span class="type">int</span> event_break;  <span class="comment">/* Set to terminate loop immediately */</span></span><br><span class="line"> <span class="comment">/* active event management */</span></span><br><span class="line"> <span class="keyword">struct</span> <span class="title class_">event_list</span> **activequeues;</span><br><span class="line"> <span class="type">int</span> nactivequeues;</span><br><span class="line"> <span class="comment">/* signal handling info */</span></span><br><span class="line"> <span class="keyword">struct</span> <span class="title class_">evsignal_info</span> sig;</span><br><span class="line"> <span class="keyword">struct</span> <span class="title class_">event_list</span> eventqueue;</span><br><span class="line"> <span class="keyword">struct</span> <span class="title class_">timeval</span> event_tv;</span><br><span class="line"> <span class="keyword">struct</span> <span class="title class_">min_heap</span> timeheap;</span><br><span class="line"> <span class="keyword">struct</span> <span class="title class_">timeval</span> tv_cache;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>下面详细解释一下结构体中各字段的含义。</p><p>1）<strong>evsel</strong>和<strong>evbase</strong>这两个字段的设置可能会让人有些迷惑，这里你可以把evsel和evbase看作是类和静态函数的关系，比如添加事件时的调用行为：evsel-&gt;add(evbase, ev)，实际执行操作的是evbase；这相当于class::add(instance, ev)，instance就是class的一个对象实例。<br>evsel指向了全局变量static const struct eventop *eventops[]中的一个；</p><p>前面也说过，libevent将系统提供的I/O demultiplex机制统一封装成了eventop结构；因此eventops[]包含了select、poll、kequeue和epoll等等其中的若干个全局实例对象。evbase实际上是一个eventop实例对象；先来看看eventop结构体，它的成员是一系列的函数指针, 在event-internal.h文件中：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">eventop</span> </span><br><span class="line">&#123;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *name;</span><br><span class="line"><span class="type">void</span> *(*init)(<span class="keyword">struct</span> event_base *); <span class="comment">// 初始化</span></span><br><span class="line"><span class="built_in">int</span> (*add)(<span class="type">void</span> *, <span class="keyword">struct</span> event *); <span class="comment">// 注册事件</span></span><br><span class="line"><span class="built_in">int</span> (*del)(<span class="type">void</span> *, <span class="keyword">struct</span> event *); <span class="comment">// 删除事件</span></span><br><span class="line"><span class="built_in">int</span> (*dispatch)(<span class="keyword">struct</span> event_base *, <span class="type">void</span> *, <span class="keyword">struct</span> timeval *); <span class="comment">// 事件分发</span></span><br><span class="line"><span class="built_in">void</span> (*dealloc)(<span class="keyword">struct</span> event_base *, <span class="type">void</span> *); <span class="comment">// 注销，释放资源</span></span><br><span class="line"><span class="comment">/* set if we need to reinitialize the event base */</span></span><br><span class="line"><span class="type">int</span> need_reinit;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>也就是说，在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了，这个在后面会再次提到。</p><p>2）<strong>activequeues</strong>是一个二级指针，前面讲过libevent支持事件优先级，因此你可以把它看作是数组，其中的元素activequeues[priority]是一个链表，链表的每个节点指向一个优先级为priority的就绪事件event。</p><p>3）<strong>eventqueue</strong>，链表，保存了所有的注册事件event的指针。</p><p>4）<strong>sig</strong>是由来管理信号的结构体，将在后面信号处理时专门讲解；</p><p>5）<strong>timeheap</strong>是管理定时事件的小根堆，将在后面定时事件处理时专门讲解；</p><p>6）<strong>event_tv</strong>和<strong>tv_cache</strong>是libevent用于时间管理的变量，将在后面讲到；</p><p>其它各个变量都能因名知意，就不再啰嗦了。</p><h3 id="2-创建和初始化event-base">2 创建和初始化event_base</h3><p>创建一个event_base对象也既是创建了一个新的libevent实例，程序需要通过调用<code>event_init()</code>（内部调用event_base_new函数执行具体操作）函数来创建，该函数同时还对新生成的libevent实例进行了初始化。该函数首先为event_base实例申请空间，然后初始化timer mini-heap，选择并初始化合适的系统I/O 的demultiplexer机制，初始化各事件链表；函数还检测了系统的时间设置，为后面的时间管理打下基础。</p><h3 id="3-接口函数">3 接口函数</h3><p>前面提到reactor框架的作用就是提供事件的注册、注销接口；根据系统提供的事件多路分发机制执行事件循环，当有事件进入“就绪”状态时，调用注册事件的回调函数来处理事件。libevent中对应的接口函数主要就是：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span>  <span class="title">event_add</span><span class="params">(<span class="keyword">struct</span> event *ev, <span class="type">const</span> <span class="keyword">struct</span> timeval *timeout)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">event_del</span><span class="params">(<span class="keyword">struct</span> event *ev)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">event_base_loop</span><span class="params">(<span class="keyword">struct</span> event_base *base, <span class="type">int</span> loops)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">event_active</span><span class="params">(<span class="keyword">struct</span> event *event, <span class="type">int</span> res, <span class="type">short</span> events)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">event_process_active</span><span class="params">(<span class="keyword">struct</span> event_base *base)</span></span>;</span><br><span class="line"><span class="number">12345</span></span><br></pre></td></tr></table></figure><p>本节将按介绍事件注册和删除的代码流程，libevent的事件循环框架将在下一节再具体描述。<br>对于定时事件，这些函数将调用timer heap管理接口执行插入和删除操作；对于I/O和Signal事件将调用eventopadd和delete接口函数执行插入和删除操作（eventop会对Signal事件调用Signal处理接口执行操作）；这些组件将在后面的内容描述。</p><p>1）注册事件<br>函数原型：<code>int event_add(struct event *ev, const struct timeval *tv);</code><br>参数：<br>ev：指向要注册的事件；<br>tv：超时时间；<br>函数将ev注册到ev-&gt;ev_base上，事件类型由ev-&gt;ev_events指明，如果注册成功，ev将被插入到已注册链表中；如果tv不是NULL，则会同时注册定时事件，将ev添加到timer堆上；<br>如果其中有一步操作失败，那么函数保证没有事件会被注册，可以讲这相当于一个原子操作。这个函数也体现了libevent细节之处的巧妙设计，且仔细看程序代码，部分有省略，注释直接附在代码中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">event_add</span><span class="params">(<span class="keyword">struct</span> event *ev, <span class="type">const</span> <span class="keyword">struct</span> timeval *tv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">event_base</span> *base = ev-&gt;ev_base; <span class="comment">// 要注册到的event_base</span></span><br><span class="line"><span class="type">const</span> <span class="keyword">struct</span> <span class="title class_">eventop</span> *evsel = base-&gt;evsel;</span><br><span class="line"><span class="type">void</span> *evbase = base-&gt;evbase; <span class="comment">// base使用的系统I/O策略</span></span><br><span class="line"> <span class="comment">// 新的timer事件，调用timer heap接口在堆上预留一个位置</span></span><br><span class="line"> <span class="comment">// 注：这样能保证该操作的原子性：</span></span><br><span class="line"> <span class="comment">// 向系统I/O机制注册可能会失败，而当在堆上预留成功后，</span></span><br><span class="line"> <span class="comment">// 定时事件的添加将肯定不会失败；</span></span><br><span class="line"> <span class="comment">// 而预留位置的可能结果是堆扩充，但是内部元素并不会改变</span></span><br><span class="line"><span class="keyword">if</span> (tv != <span class="literal">NULL</span> &amp;&amp; !(ev-&gt;ev_flags &amp; EVLIST_TIMEOUT)) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">min_heap_reserve</span>(&amp;base-&gt;timeheap,</span><br><span class="line"><span class="number">1</span> + <span class="built_in">min_heap_size</span>(&amp;base-&gt;timeheap)) == <span class="number">-1</span>)</span><br><span class="line"><span class="keyword">return</span> (<span class="number">-1</span>);  <span class="comment">/* ENOMEM == errno */</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 如果事件ev不在已注册或者激活链表中，则调用evbase注册事件</span></span><br><span class="line"><span class="keyword">if</span> ((ev-&gt;ev_events &amp; (EV_READ | EV_WRITE | EV_SIGNAL)) &amp;&amp;</span><br><span class="line">!(ev-&gt;ev_flags &amp; (EVLIST_INSERTED | EVLIST_ACTIVE))) &#123;</span><br><span class="line">res = evsel-&gt;<span class="built_in">add</span>(evbase, ev);</span><br><span class="line"><span class="keyword">if</span> (res != <span class="number">-1</span>) <span class="comment">// 注册成功，插入event到已注册链表中</span></span><br><span class="line"><span class="built_in">event_queue_insert</span>(base, ev, EVLIST_INSERTED);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 准备添加定时事件</span></span><br><span class="line"><span class="keyword">if</span> (res != <span class="number">-1</span> &amp;&amp; tv != <span class="literal">NULL</span>) &#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">timeval</span> now;</span><br><span class="line"><span class="comment">// EVLIST_TIMEOUT表明event已经在定时器堆中了，删除旧的</span></span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_flags &amp; EVLIST_TIMEOUT)</span><br><span class="line"><span class="built_in">event_queue_remove</span>(base, ev, EVLIST_TIMEOUT);</span><br><span class="line"><span class="comment">// 如果事件已经是就绪状态则从激活链表中删除</span></span><br><span class="line"><span class="keyword">if</span> ((ev-&gt;ev_flags &amp; EVLIST_ACTIVE) &amp;&amp;</span><br><span class="line">(ev-&gt;ev_res &amp; EV_TIMEOUT)) &#123;</span><br><span class="line"><span class="comment">// 将ev_callback调用次数设置为0</span></span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_ncalls &amp;&amp; ev-&gt;ev_pncalls) &#123;</span><br><span class="line">*ev-&gt;ev_pncalls = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">event_queue_remove</span>(base, ev, EVLIST_ACTIVE);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 计算时间，并插入到timer小根堆中</span></span><br><span class="line"><span class="built_in">gettime</span>(base, &amp;now);</span><br><span class="line"><span class="built_in">evutil_timeradd</span>(&amp;now, tv, &amp;ev-&gt;ev_timeout);</span><br><span class="line"><span class="built_in">event_queue_insert</span>(base, ev, EVLIST_TIMEOUT);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> (res);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">event_queue_insert</span>()负责将事件插入到对应的链表中，下面是程序代码；</span><br><span class="line"><span class="built_in">event_queue_remove</span>()负责将事件从对应的链表中删除，这里就不再重复贴代码了；</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">event_queue_insert</span><span class="params">(<span class="keyword">struct</span> event_base *base, <span class="keyword">struct</span> event *ev, <span class="type">int</span> queue)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">// ev可能已经在激活列表中了，避免重复插入</span></span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_flags &amp; queue) &#123;</span><br><span class="line"><span class="keyword">if</span> (queue &amp; EVLIST_ACTIVE)</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">ev-&gt;ev_flags |= queue; <span class="comment">// 记录queue标记</span></span><br><span class="line"><span class="keyword">switch</span> (queue) &#123;</span><br><span class="line"><span class="keyword">case</span> EVLIST_INSERTED: <span class="comment">// I/O或Signal事件，加入已注册事件链表</span></span><br><span class="line"><span class="built_in">TAILQ_INSERT_TAIL</span>(&amp;base-&gt;eventqueue, ev, ev_next);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> EVLIST_ACTIVE: <span class="comment">// 就绪事件，加入激活链表</span></span><br><span class="line">base-&gt;event_count_active++;</span><br><span class="line"><span class="built_in">TAILQ_INSERT_TAIL</span>(base-&gt;activequeues[ev-&gt;ev_pri], ev, ev_active_next);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> EVLIST_TIMEOUT: <span class="comment">// 定时事件，加入堆</span></span><br><span class="line"><span class="built_in">min_heap_push</span>(&amp;base-&gt;timeheap, ev);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2）删除事件：<br>函数原型为：int event_del(struct event *ev);<br>该函数将删除事件ev，对于I/O事件，从I/O 的demultiplexer上将事件注销；对于Signal事件，将从Signal事件链表中删除；对于定时事件，将从堆上删除；<br>同样删除事件的操作则不一定是原子的，比如删除时间事件之后，有可能从系统I/O机制中注销会失败。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">event_del</span><span class="params">(<span class="keyword">struct</span> event *ev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">event_base</span> *base;</span><br><span class="line"><span class="type">const</span> <span class="keyword">struct</span> <span class="title class_">eventop</span> *evsel;</span><br><span class="line"><span class="type">void</span> *evbase;</span><br><span class="line"><span class="comment">// ev_base为NULL，表明ev没有被注册</span></span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_base == <span class="literal">NULL</span>)</span><br><span class="line"><span class="keyword">return</span> (<span class="number">-1</span>);</span><br><span class="line"><span class="comment">// 取得ev注册的event_base和eventop指针</span></span><br><span class="line">base = ev-&gt;ev_base;</span><br><span class="line">evsel = base-&gt;evsel;</span><br><span class="line">evbase = base-&gt;evbase;</span><br><span class="line"><span class="comment">// 将ev_callback调用次数设置为</span></span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_ncalls &amp;&amp; ev-&gt;ev_pncalls) &#123;</span><br><span class="line">*ev-&gt;ev_pncalls = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从对应的链表中删除</span></span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_flags &amp; EVLIST_TIMEOUT)</span><br><span class="line"><span class="built_in">event_queue_remove</span>(base, ev, EVLIST_TIMEOUT);</span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_flags &amp; EVLIST_ACTIVE)</span><br><span class="line"><span class="built_in">event_queue_remove</span>(base, ev, EVLIST_ACTIVE);</span><br><span class="line"><span class="keyword">if</span> (ev-&gt;ev_flags &amp; EVLIST_INSERTED) &#123;</span><br><span class="line"><span class="built_in">event_queue_remove</span>(base, ev, EVLIST_INSERTED);</span><br><span class="line"><span class="comment">// EVLIST_INSERTED表明是I/O或者Signal事件，</span></span><br><span class="line"><span class="comment">// 需要调用I/O demultiplexer注销事件</span></span><br><span class="line"><span class="keyword">return</span> (evsel-&gt;<span class="built_in">del</span>(evbase, ev));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-小节">4 小节</h3><p>分析了event_base这一重要结构体，初步看到了libevent对系统的I/O demultiplex机制的封装event_op结构，并结合源代码分析了事件的注册和删除处理，下面将会接着分析事件管理框架中的主事件循环部分。</p><h2 id="七-事件主循环">七 事件主循环</h2><p><strong>事件主循环</strong></p><p>现在我们已经初步了解了libevent的Reactor组件——<strong>event_base</strong>和<strong>事件管理框架</strong>，接下来就是libevent事件处理的中心部分——<strong>事件主循环</strong>，根据系统提供的事件多路分发机制执行事件循环，对已注册的就绪事件，调用注册事件的回调函数来处理事件。</p><h3 id="1-阶段性的胜利">1. 阶段性的胜利</h3><p>libevent将I/O事件、定时器和信号事件处理很好的结合到了一起，本节也会介绍libevent是如何做到这一点的。<br>在看完本节的内容后，读者应该会对Libevent的基本框架：事件管理和主循环有比较清晰的认识了，并能够把libevent的事件控制流程清晰的串通起来，剩下的就是一些细节的内容了。</p><h3 id="2-事件处理主循环">2. 事件处理主循环</h3><p>libevent的事件主循环主要是通过**event_base_loop ()**函数完成的，其主要操作如下面的流程图所示，<strong>event_base_loop</strong>所作的就是持续执行下面的循环。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240526121015838.png" alt="image-20240526121015838"></p><p>清楚了event_base_loop所作的主要操作，就可以对比源代码看个究竟了，代码结构还是相当清晰的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">event_base_loop</span><span class="params">(<span class="keyword">struct</span> event_base *base, <span class="type">int</span> flags)</span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">eventop</span> *<span class="title">evsel</span> =</span> base-&gt;evsel;</span><br><span class="line">    <span class="type">void</span> *evbase = base-&gt;evbase;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">tv</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> *<span class="title">tv_p</span>;</span></span><br><span class="line">    <span class="type">int</span> res, done;</span><br><span class="line">    <span class="comment">// 清空时间缓存</span></span><br><span class="line">    base-&gt;tv_cache.tv_sec = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// evsignal_base是全局变量，在处理signal时，用于指名signal所属的event_base实例</span></span><br><span class="line">    <span class="keyword">if</span> (base-&gt;sig.ev_signal_added)</span><br><span class="line">        evsignal_base = base;</span><br><span class="line">    done = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (!done) &#123; <span class="comment">// 事件主循环</span></span><br><span class="line">        <span class="comment">// 查看是否需要跳出循环，程序可以调用event_loopexit_cb()设置event_gotterm标记</span></span><br><span class="line">        <span class="comment">// 调用event_base_loopbreak()设置event_break标记</span></span><br><span class="line">        <span class="keyword">if</span> (base-&gt;event_gotterm) &#123;</span><br><span class="line">            base-&gt;event_gotterm = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (base-&gt;event_break) &#123;</span><br><span class="line">            base-&gt;event_break = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 校正系统时间，如果系统使用的是非MONOTONIC时间，用户可能会向后调整了系统时间</span></span><br><span class="line">        <span class="comment">// 在timeout_correct函数里，比较last wait time和当前时间，如果当前时间&lt; last wait time</span></span><br><span class="line">        <span class="comment">// 表明时间有问题，这是需要更新timer_heap中所有定时事件的超时时间。</span></span><br><span class="line">        timeout_correct(base, &amp;tv);</span><br><span class="line">        <span class="comment">// 根据timer heap中事件的最小超时时间，计算系统I/O demultiplexer的最大等待时间</span></span><br><span class="line">        tv_p = &amp;tv;</span><br><span class="line">        <span class="keyword">if</span> (!base-&gt;event_count_active &amp;&amp; !(flags &amp; EVLOOP_NONBLOCK)) &#123;</span><br><span class="line">            timeout_next(base, &amp;tv_p);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 依然有未处理的就绪时间，就让I/O demultiplexer立即返回，不必等待</span></span><br><span class="line">            <span class="comment">// 下面会提到，在libevent中，低优先级的就绪事件可能不能立即被处理</span></span><br><span class="line">            evutil_timerclear(&amp;tv);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果当前没有注册事件，就退出</span></span><br><span class="line">        <span class="keyword">if</span> (!event_haveevents(base)) &#123;</span><br><span class="line">            event_debug((<span class="string">&quot;%s: no events registered.&quot;</span>, __func__));</span><br><span class="line">            <span class="keyword">return</span> (<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 更新last wait time，并清空time cache</span></span><br><span class="line">        gettime(base, &amp;base-&gt;event_tv);</span><br><span class="line">        base-&gt;tv_cache.tv_sec = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 调用系统I/O demultiplexer等待就绪I/O events，可能是epoll_wait，或者select等；</span></span><br><span class="line">        <span class="comment">// 在evsel-&gt;dispatch()中，会把就绪signal event、I/O event插入到激活链表中</span></span><br><span class="line">        res = evsel-&gt;dispatch(base, evbase, tv_p);</span><br><span class="line">        <span class="keyword">if</span> (res == <span class="number">-1</span>)</span><br><span class="line">            <span class="keyword">return</span> (<span class="number">-1</span>);</span><br><span class="line">        <span class="comment">// 将time cache赋值为当前系统时间</span></span><br><span class="line">        gettime(base, &amp;base-&gt;tv_cache);</span><br><span class="line">        <span class="comment">// 检查heap中的timer events，将就绪的timer event从heap上删除，并插入到激活链表中</span></span><br><span class="line">        timeout_process(base);</span><br><span class="line">        <span class="comment">// 调用event_process_active()处理激活链表中的就绪event，调用其回调函数执行事件处理</span></span><br><span class="line">        <span class="comment">// 该函数会寻找最高优先级（priority值越小优先级越高）的激活事件链表，</span></span><br><span class="line">        <span class="comment">// 然后处理链表中的所有就绪事件；</span></span><br><span class="line">        <span class="comment">// 因此低优先级的就绪事件可能得不到及时处理；</span></span><br><span class="line">        <span class="keyword">if</span> (base-&gt;event_count_active) &#123;</span><br><span class="line">            event_process_active(base);</span><br><span class="line">            <span class="keyword">if</span> (!base-&gt;event_count_active &amp;&amp; (flags &amp; EVLOOP_ONCE))</span><br><span class="line">                done = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (flags &amp; EVLOOP_NONBLOCK)</span><br><span class="line">            done = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 循环结束，清空时间缓存</span></span><br><span class="line">    base-&gt;tv_cache.tv_sec = <span class="number">0</span>;</span><br><span class="line">    event_debug((<span class="string">&quot;%s: asked to terminate loop.&quot;</span>, __func__));</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-I-O和Timer事件的统一">3. I/O和Timer事件的统一</h3><p>libevent将Timer和Signal事件都统一到了系统的I/O 的<strong>demultiplex</strong>机制中了，相信读者从上面的流程和代码中也能窥出一斑了，下面就再啰嗦一次了。<br>首先将Timer事件融合到系统I/O多路复用机制中，还是相当清晰的，因为系统的I/O机制像select()和epoll_wait()都允许程序制定一个最大等待时间（也称为最大超时时间）<strong>timeout</strong>，即使没有I/O事件发生，它们也保证能在timeout时间内返回。<br>那么根据所有Timer事件的最小超时时间来设置系统I/O的timeout时间；当系统I/O返回时，再激活所有就绪的Timer事件就可以了，这样就能将Timer事件完美的融合到系统的I/O机制中了。<br>这是在Reactor和Proactor模式（主动器模式，比如Windows上的IOCP）中处理Timer事件的经典方法了，ACE采用的也是这种方法，大家可以参考POSA vol2书中的Reactor模式一节。<br>堆是一种经典的数据结构，向堆中插入、删除元素时间复杂度都是O(lgN)，N为堆中元素的个数，而获取最小key值（小根堆）的复杂度为O(1)；因此变成了管理Timer事件的绝佳人选（当然是非唯一的），libevent就是采用的堆结构。</p><h3 id="4-I-O和Signal事件的统一">4. I/O和Signal事件的统一</h3><p>Signal是异步事件的经典事例，将Signal事件统一到系统的I/O多路复用中就不像Timer事件那么自然了，Signal事件的出现对于进程来讲是完全随机的，进程不能只是测试一个变量来判别是否发生了一个信号，而是必须告诉内核“在此信号发生时，请执行如下的操作”。<br>如果当Signal发生时，并不立即调用event的callback函数处理信号，而是设法通知系统的I/O机制，让其返回，然后再统一和I/O事件以及Timer一起处理，不就可以了嘛。是的，这也是libevent中使用的方法。<br>问题的核心在于，当Signal发生时，如何通知系统的I/O多路复用机制，这里先买个小关子，放到信号处理一节再详细说明，我想读者肯定也能想出通知的方法，比如使用<strong>pipe</strong>。</p><h3 id="5-小节">5 小节</h3><p>介绍了libevent的事件主循环，描述了libevent是如何处理就绪的I/O事件、定时器和信号事件，以及如何将它们无缝的融合到一起。</p><h2 id="八-集成信号处理">八 集成信号处理</h2><p>简单说</p><p>Libevent处理信号事件的方式类似于它处理socket事件的方式。它提供了一个统一的接口，使得你可以在一次事件循环中等待多个不同类型的事件，包括信号事件。</p><p>在libevent中，你可以通过<code>event_new</code>函数创建一个信号事件。这个函数需要你提供一个信号号码（如SIGINT，代表终端中断信号），一个回调函数，以及一个可选的回调函数参数。当这个信号发生时，libevent会调用你指定的回调函数。</p><p>创建信号事件后，你需要通过<code>event_add</code>函数将这个事件添加到事件循环中。这个函数需要你提供一个事件，以及一个可选的超时参数（如果你希望这个事件在一段时间后自动超时）。</p><p>在事件循环中，libevent使用<code>sigaction</code>系统调用来接收信号。当一个信号发生时，libevent的内部信号处理函数会被调用。这个函数会查看每个信号事件，看看是否有任何事件的信号号码与当前发生的信号相匹配。如果有，libevent就会将这个事件添加到“就绪”队列中，等待事件循环下一次迭代时被处理。</p><p>在事件循环的每次迭代中，libevent会检查“就绪”队列中的事件，调用每个事件的回调函数。这个过程会一直持续，直到没有更多的就绪事件，或者你停止了事件循环。</p><p>总的来说，libevent通过提供一个统一的事件处理接口，以及内部的信号处理机制，使得处理信号事件变得相当简单。你只需要创建一个信号事件，提供一个回调函数，然后将事件添加到事件循环中，libevent就会在相应的信号发生时调用你的回调函数，处理事件。</p><hr><p>现在我们已经了解了libevent的基本框架：事件管理框架和事件主循环。上节提到了libevent中I/O事件和Signal以及Timer事件的集成，这一节将分析如何将Signal集成到事件主循环的框架中。</p><h3 id="1-集成策略——使用socket-pair">1 集成策略——使用socket pair</h3><p>前一节已经做了足够多的介绍了，基本方法就是采用“消息机制”。在libevent中这是通过socket pair完成的，下面就来详细分析一下。<br>Socket pair就是一个socket对，包含两个socket，一个读socket，一个写socket。工作方式如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527184944634.png" alt="image-20240527184944634"></p><p>创建一个socket pair并不是复杂的操作，可以参见下面的流程图，清晰起见，其中忽略了一些错误处理和检查。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527185026436.png" alt="image-20240527185026436"></p><p>Libevent提供了辅助函数evutil_socketpair()来创建一个socket pair，可以结合上面的创建流程来分析该函数。</p><h3 id="2-集成到事件主循环——通知event-base">2 集成到事件主循环——通知event_base</h3><p>Socket pair创建好了，可是libevent的事件主循环还是不知道Signal是否发生了啊，看来我们还差了最后一步，那就是：为socket pair的读socket在libevent的event_base实例上注册一个persist的读事件。</p><p>这样当向写socket写入数据时，读socket就会得到通知，触发读事件，从而event_base就能相应的得到通知了。<br>前面提到过，Libevent会在事件主循环中检查标记，来确定是否有触发的signal，如果标记被设置就处理这些signal，这段代码在各个具体的I/O机制中，以Epoll为例，在epoll_dispatch()函数中，代码片段如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">res = <span class="built_in">epoll_wait</span>(epollop-&gt;epfd, events, epollop-&gt;nevents, timeout);</span><br><span class="line"><span class="keyword">if</span> (res == <span class="number">-1</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> (errno != EINTR) &#123;</span><br><span class="line"><span class="built_in">event_warn</span>(<span class="string">&quot;epoll_wait&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> (<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">evsignal_process</span>(base);<span class="comment">// 处理signal事件</span></span><br><span class="line"><span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (base-&gt;sig.evsignal_caught) &#123;</span><br><span class="line"><span class="built_in">evsignal_process</span>(base);<span class="comment">// 处理signal事件</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完整的处理框架如下所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527185103712.png" alt="image-20240527185103712"></p><p>注1：libevent中，初始化阶段并不注册读socket的读事件，而是在注册信号阶段才会测试并注册；<br>注2：libevent中，检查I/O事件是在各系统I/O机制的dispatch()函数中完成的，该dispatch()函数在event_base_loop()函数中被调用；</p><h3 id="3-evsignal-info结构体">3 evsignal_info结构体</h3><p>Libevent中Signal事件的管理是通过结构体evsignal_info完成的，结构体位于evsignal.h文件中，定义如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">evsignal_info</span></span><br><span class="line"> &#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">event</span> ev_signal;</span><br><span class="line">    <span class="type">int</span> ev_signal_pair[<span class="number">2</span>];</span><br><span class="line">    <span class="type">int</span> ev_signal_added;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="type">sig_atomic_t</span> evsignal_caught;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">event_list</span> evsigevents[NSIG];</span><br><span class="line">    <span class="type">sig_atomic_t</span> evsigcaught[NSIG];</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_SIGACTION</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">sigaction</span> **sh_old;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="type">ev_sighandler_t</span> **sh_old;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="type">int</span> sh_old_max;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>下面详细介绍一下个字段的含义和作用：<br>1）ev_signal， 为socket pair的读socket向event_base注册读事件时使用的event结构体；<br>2）ev_signal_pair，socket pair对，作用见第一节的介绍；<br>3）ev_signal_added，记录ev_signal事件是否已经注册了；<br>4）evsignal_caught，是否有信号发生的标记；是volatile类型，因为它会在另外的线程中被修改；<br>5）evsigvents[NSIG]，数组，evsigevents[signo]表示注册到信号signo的事件链表；<br>6）evsigcaught[NSIG]，具体记录每个信号触发的次数，evsigcaught[signo]是记录信号signo被触发的次数；<br>7）sh_old记录了原来的signal处理函数指针，当信号signo注册的event被清空时，需要重新设置其处理函数；<br>evsignal_info的初始化包括，创建socket pair，设置ev_signal事件（但并没有注册，而是等到有信号注册时才检查并注册），并将所有标记置零，初始化信号的注册事件链表指针等。</p><h3 id="4-注册、注销signal事件">4 注册、注销signal事件</h3><p>注册signal事件是通过evsignal_add(struct event *ev)函数完成的，libevent对所有的信号注册同一个处理函数evsignal_handler()，该函数将在下一段介绍，注册过程如下：<br>1）取得ev要注册到的信号signo；<br>2） 如果信号signo未被注册，那么就为signo注册信号处理函数evsignal_handler()；<br>3） 如果事件ev_signal还没哟注册，就注册ev_signal事件；<br>4） 将事件ev添加到signo的event链表中；</p><p>从signo上注销一个已注册的signal事件就更简单了，直接从其已注册事件的链表中移除即可。如果事件链表已空，那么就恢复旧的处理函数；</p><p>下面的讲解都以signal()函数为例，sigaction()函数的处理和signal()相似。<br>处理函数evsignal_handler()函数做的事情很简单，就是记录信号的发生次数，并通知event_base有信号触发，需要处理：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">evsignal_handler</span><span class="params">(<span class="type">int</span> sig)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> save_errno = errno; <span class="comment">// 不覆盖原来的错误代码</span></span><br><span class="line">    <span class="keyword">if</span> (evsignal_base == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">event_warn</span>(<span class="string">&quot;%s: received signal %d, but have no base configured&quot;</span>, __func__, sig);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 记录信号sig的触发次数，并设置event触发标记</span></span><br><span class="line">    evsignal_base-&gt;sig.evsigcaught[sig]++;</span><br><span class="line">    evsignal_base-&gt;sig.evsignal_caught = <span class="number">1</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> HAVE_SIGACTION</span></span><br><span class="line">    <span class="built_in">signal</span>(sig, evsignal_handler); <span class="comment">// 重新注册信号</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="comment">// 向写socket写一个字节数据，触发event_base的I/O事件，从而通知其有信号触发，需要处理</span></span><br><span class="line">    <span class="built_in">send</span>(evsignal_base-&gt;sig.ev_signal_pair[<span class="number">0</span>], <span class="string">&quot;a&quot;</span>, <span class="number">1</span>, <span class="number">0</span>);</span><br><span class="line">    errno = save_errno; <span class="comment">// 错误代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-小节-2">5 小节</h3><p>本节介绍了libevent对signal事件的具体处理框架，包括事件注册、删除和socket pair通知机制，以及是如何将Signal事件集成到事件主循环之中的。</p><h2 id="九-集成定时器事件">九 集成定时器事件</h2><p>现在再来详细分析libevent中I/O事件和Timer事件的集成，与Signal相比，Timer事件的集成会直观和简单很多。Libevent对堆的调整操作做了一些优化，本节还会描述这些优化方法。</p><h3 id="1-集成到事件主循环">1 集成到事件主循环</h3><p>因为系统的I/O机制像select()和epoll_wait()都允许程序制定一个最大等待时间（也称为最大超时时间）timeout，即使没有I/O事件发生，它们也保证能在timeout时间内返回。</p><p>那么根据所有Timer事件的最小超时时间来设置系统I/O的timeout时间；当系统I/O返回时，再激活所有就绪的Timer事件就可以了，这样就能将Timer事件完美的融合到系统的I/O机制中了。</p><p>具体的代码在源文件event.c的event_base_loop()中，现在就对比代码来看看这一处理方法：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!base-&gt;event_count_active &amp;&amp; !(flags &amp; EVLOOP_NONBLOCK))</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 根据Timer事件计算evsel-&gt;dispatch的最大等待时间</span></span><br><span class="line"><span class="built_in">timeout_next</span>(base, &amp;tv_p);</span><br><span class="line">&#125; </span><br><span class="line"><span class="keyword">else</span> </span><br><span class="line">&#123; </span><br><span class="line"><span class="comment">// 如果还有活动事件，就不要等待，让evsel-&gt;dispatch立即返回</span></span><br><span class="line"><span class="built_in">evutil_timerclear</span>(&amp;tv);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// 调用select() or epoll_wait() 等待就绪I/O事件</span></span><br><span class="line">res = evsel-&gt;<span class="built_in">dispatch</span>(base, evbase, tv_p);</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="comment">// 处理超时事件，将超时事件插入到激活链表中</span></span><br><span class="line"><span class="built_in">timeout_process</span>(base);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>timeout_next()函数根据堆中具有最小超时值的事件和当前时间来计算等待时间，下面看看代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">timeout_next</span><span class="params">(<span class="keyword">struct</span> event_base *base, <span class="keyword">struct</span> timeval **tv_p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">timeval</span> now;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">event</span> *ev;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">timeval</span> *tv = *tv_p;</span><br><span class="line">    <span class="comment">// 堆的首元素具有最小的超时值</span></span><br><span class="line">    <span class="keyword">if</span> ((ev = <span class="built_in">min_heap_top</span>(&amp;base-&gt;timeheap)) == <span class="literal">NULL</span>) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 如果没有定时事件，将等待时间设置为NULL,表示一直阻塞直到有I/O事件发生</span></span><br><span class="line">        *tv_p = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 取得当前时间</span></span><br><span class="line">    <span class="built_in">gettime</span>(base, &amp;now);</span><br><span class="line">    <span class="comment">// 如果超时时间&lt;=当前值，不能等待，需要立即返回</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">evutil_timercmp</span>(&amp;ev-&gt;ev_timeout, &amp;now, &lt;=)) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">evutil_timerclear</span>(tv);</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 计算等待的时间=当前时间-最小的超时时间</span></span><br><span class="line">    <span class="built_in">evutil_timersub</span>(&amp;ev-&gt;ev_timeout, &amp;now, tv);</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-Timer小根堆">2 Timer小根堆</h3><p>Libevent使用堆来管理Timer事件，其key值就是事件的超时时间，源代码位于文件min_heap.h中。</p><p>所有的数据结构书中都有关于堆的详细介绍，向堆中插入、删除元素时间复杂度都是O(lgN)，N为堆中元素的个数，而获取最小key值（小根堆）的复杂度为O(1)。堆是一个完全二叉树，基本存储方式是一个数组。</p><p>Libevent实现的堆还是比较轻巧的，虽然我不喜欢这种编码方式（搞一些复杂的表达式）。轻巧到什么地方呢，就以插入元素为例，来对比说明，下面伪代码中的size表示当前堆的元素个数：</p><p>典型的代码逻辑如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Heap[size++] = <span class="keyword">new</span>; <span class="comment">// 先放到数组末尾，元素个数+1</span></span><br><span class="line"><span class="comment">// 下面就是shift_up()的代码逻辑，不断的将new向上调整</span></span><br><span class="line">_child = size;</span><br><span class="line"><span class="keyword">while</span>(_child&gt;<span class="number">0</span>) <span class="comment">// 循环</span></span><br><span class="line">&#123;</span><br><span class="line">   _parent = (_child<span class="number">-1</span>)/<span class="number">2</span>; <span class="comment">// 计算parent</span></span><br><span class="line">   <span class="keyword">if</span>(Heap[_parent].key &lt; Heap[_child].key)</span><br><span class="line">      <span class="keyword">break</span>; <span class="comment">// 调整结束，跳出循环</span></span><br><span class="line">   <span class="built_in">swap</span>(_parent, _child); <span class="comment">// 交换parent和child</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而libevent的heap代码对这一过程做了优化，在插入新元素时，只是为新元素预留了一个位置hole（初始时hole位于数组尾部），但并不立刻将新元素插入到hole上，而是不断向上调整hole的值，将父节点向下调整，最后确认hole就是新元素的所在位置时，才会真正的将新元素插入到hole上，因此在调整过程中就比上面的代码少了一次赋值的操作，代码逻辑是：</p><p>下面就是shift_up()的代码逻辑，不断的将new的“预留位置”向上调整</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 下面就是shift_up()的代码逻辑，不断的将new的“预留位置”向上调整</span></span><br><span class="line">_hole = size; <span class="comment">// _hole就是为new预留的位置，但并不立刻将new放上</span></span><br><span class="line"><span class="keyword">while</span>(_hole&gt;<span class="number">0</span>) <span class="comment">// 循环</span></span><br><span class="line">&#123;</span><br><span class="line">    _parent = (_hole<span class="number">-1</span>)/<span class="number">2</span>; <span class="comment">// 计算parent</span></span><br><span class="line">    <span class="keyword">if</span>(Heap[_parent].key &lt; <span class="keyword">new</span>.key)</span><br><span class="line">        <span class="keyword">break</span>; <span class="comment">// 调整结束，跳出循环</span></span><br><span class="line">    Heap[_hole] = Heap[_parent]; <span class="comment">// 将parent向下调整</span></span><br><span class="line">    _hole = _parent; <span class="comment">// 将_hole调整到_parent</span></span><br><span class="line">&#125;</span><br><span class="line">Heap[_hole] = <span class="keyword">new</span>; <span class="comment">// 调整结束，将new插入到_hole指示的位置</span></span><br><span class="line">size++; <span class="comment">// 元素个数+1</span></span><br></pre></td></tr></table></figure><p>由于每次调整都少做一次赋值操作，在调整路径比较长时，调整效率会比第一种有所提高。libevent中的min_heap_shift_up_()函数就是上面逻辑的具体实现，对应的向下调整函数是min_heap_shift_down_()。</p><p>举个例子，向一个小根堆3, 5, 8, 7, 12中插入新元素2，使用第一中典型的代码逻辑，其调整过程如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527185307526.png" alt="image-20240527185307526"></p><p>使用libevent中的堆调整逻辑，调整过程如下图所示：</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527185319336.png" alt="image-20240527185319336"></p><p>对于删除和元素修改操作，也遵从相同的逻辑，就不再罗嗦了。</p><h3 id="3-小节">3 小节</h3><p>通过设置系统I/O机制的wait时间，从而简捷的集成Timer事件；主要分析了libevent对堆调整操作的优化。</p><h2 id="十-支持I-O多路复用技术">十 支持I/O多路复用技术</h2><p>Libevent的核心是事件驱动、同步非阻塞，为了达到这一目标，必须采用系统提供的I/O多路复用技术，而这些在Windows、Linux、Unix等不同平台上却各有不同，如何能提供优雅而统一的支持方式，是首要关键的问题，这其实不难，本节就来分析一下。</p><h3 id="1-统一的关键">1 统一的关键</h3><p>Libevent支持多种I/O多路复用技术的关键就在于结构体eventop，这个结构体前面也曾提到过，它的成员是一系列的函数指针, 定义在event-internal.h文件中：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">eventop</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> *name;</span><br><span class="line">    <span class="type">void</span> *(*init)(<span class="keyword">struct</span> event_base *); <span class="comment">// 初始化</span></span><br><span class="line">    <span class="built_in">int</span> (*add)(<span class="type">void</span> *, <span class="keyword">struct</span> event *); <span class="comment">// 注册事件</span></span><br><span class="line">    <span class="built_in">int</span> (*del)(<span class="type">void</span> *, <span class="keyword">struct</span> event *); <span class="comment">// 删除事件</span></span><br><span class="line">    <span class="built_in">int</span> (*dispatch)(<span class="keyword">struct</span> event_base *, <span class="type">void</span> *, <span class="keyword">struct</span> timeval *); <span class="comment">// 事件分发</span></span><br><span class="line">    <span class="built_in">void</span> (*dealloc)(<span class="keyword">struct</span> event_base *, <span class="type">void</span> *); <span class="comment">// 注销，释放资源</span></span><br><span class="line">    <span class="comment">/* set if we need to reinitialize the event base */</span></span><br><span class="line">    <span class="type">int</span> need_reinit;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。</p><p>比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了。</p><h3 id="2-设置I-O-demultiplex机制">2 设置I/O demultiplex机制</h3><p>Libevent把所有支持的I/O demultiplex机制存储在一个全局静态数组eventops中，并在初始化时选择使用何种机制，数组内容根据优先级顺序声明如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* In order of preference */</span></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="keyword">struct</span> <span class="title class_">eventop</span> *eventops[] = &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_EVENT_PORTS</span></span><br><span class="line">    &amp;evportops,</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_WORKING_KQUEUE</span></span><br><span class="line">    &amp;kqops,</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_EPOLL</span></span><br><span class="line">    &amp;epollops,</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_DEVPOLL</span></span><br><span class="line">    &amp;devpollops,</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_POLL</span></span><br><span class="line">    &amp;pollops,</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> HAVE_SELECT</span></span><br><span class="line">    &amp;selectops,</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> WIN32</span></span><br><span class="line">    &amp;win32ops,</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="literal">NULL</span></span><br><span class="line">&#125;; </span><br></pre></td></tr></table></figure><p>然后libevent根据系统配置和编译选项决定使用哪一种I/O demultiplex机制，这段代码在函数event_base_new()中：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">base-&gt;evbase = <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; eventops[i] &amp;&amp; !base-&gt;evbase; i++) </span><br><span class="line">&#123;</span><br><span class="line">    base-&gt;evsel = eventops[i];</span><br><span class="line">    base-&gt;evbase = base-&gt;evsel-&gt;<span class="built_in">init</span>(base);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p>可以看出，libevent在编译阶段选择系统的I/O demultiplex机制，而不支持在运行阶段根据配置再次选择。<br>以Linux下面的epoll为例，实现在源文件epoll.c中，eventops对象epollops定义如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="keyword">struct</span> <span class="title class_">eventop</span> epollops = </span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;epoll&quot;</span>,</span><br><span class="line">    epoll_init,</span><br><span class="line">    epoll_add,</span><br><span class="line">    epoll_del,</span><br><span class="line">    epoll_dispatch,</span><br><span class="line">    epoll_dealloc,</span><br><span class="line">    <span class="number">1</span> <span class="comment">/* need reinit */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>变量epollops中的函数指针具体声明如下，注意到其返回值和参数都和eventop中的定义严格一致，这是函数指针的语法限制。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> *<span class="title">epoll_init</span>    <span class="params">(<span class="keyword">struct</span> event_base *)</span></span>;</span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">epoll_add</span>    <span class="params">(<span class="type">void</span> *, <span class="keyword">struct</span> event *)</span></span>;</span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">epoll_del</span>    <span class="params">(<span class="type">void</span> *, <span class="keyword">struct</span> event *)</span></span>;</span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">epoll_dispatch</span><span class="params">(<span class="keyword">struct</span> event_base *, <span class="type">void</span> *, <span class="keyword">struct</span> timeval *)</span></span>;</span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">epoll_dealloc</span>    <span class="params">(<span class="keyword">struct</span> event_base *, <span class="type">void</span> *)</span></span>;</span><br></pre></td></tr></table></figure><p>那么如果选择的是epoll，那么调用结构体eventop的init和dispatch函数指针时，实际调用的函数就是epoll的初始化函数epoll_init()和事件分发函数epoll_dispatch()了；</p><p>关于epoll的具体用法这里就不多说了，可以参见介绍epoll的文章（本人的哈哈）：<br><a href="http://blog.csdn.net/sparkliang/archive/2009/11/05/4770655.aspx">http://blog.csdn.net/sparkliang/archive/2009/11/05/4770655.aspx</a></p><p>C++语言提供了虚函数来实现多态，在C语言中，这是通过函数指针实现的。对于各类函数指针的详细说明可以参见文章：<br><a href="http://blog.csdn.net/sparkliang/archive/2009/06/09/4254115.aspx">http://blog.csdn.net/sparkliang/archive/2009/06/09/4254115.aspx</a></p><p>同样的，上面epollops以及epoll的各种函数都直接定义在了epoll.c源文件中，对外都是不可见的。对于libevent的使用者而言，完全不会知道它们的存在，对epoll的使用也是通过eventop来完成的，达到了信息隐藏的目的。</p><h3 id="3-小节-2">3 小节</h3><p>支持多种I/O demultiplex机制的方法其实挺简单的，借助于函数指针就OK了。通过对源代码的分析也可以看出，Libevent是在编译阶段选择系统的I/O demultiplex机制的，而不支持在运行阶段根据配置再次选择。</p><h2 id="十一-时间管理">十一 时间管理</h2><p>为了支持定时器，Libevent必须和系统时间打交道，这一部分的内容也比较简单，主要涉及到时间的加减辅助函数、时间缓存、时间校正和定时器堆的时间值调整等。下面就结合源代码来分析一下。</p><h3 id="1-初始化检测">1 初始化检测</h3><p>Libevent在初始化时会检测系统时间的类型，通过调用函数detect_monotonic()完成，它通过调用clock_gettime()来检测系统是否支持monotonic时钟类型：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">detect_monotonic</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(HAVE_CLOCK_GETTIME) &amp;&amp; defined(CLOCK_MONOTONIC)</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">timespec</span>    ts;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">clock_gettime</span>(CLOCK_MONOTONIC, &amp;ts) == <span class="number">0</span>)</span><br><span class="line">        use_monotonic = <span class="number">1</span>; <span class="comment">// 系统支持monotonic时间</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Monotonic时间指示的是系统从boot后到现在所经过的时间，如果系统支持Monotonic时间就将全局变量use_monotonic设置为1，设置use_monotonic到底有什么用，这个在后面说到时间校正时就能看出来了。</p><h3 id="2-时间缓存">2 时间缓存</h3><p>结构体event_base中的tv_cache，用来记录时间缓存。这个还要从函数gettime()说起，先来看看该函数的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">gettime</span><span class="params">(<span class="keyword">struct</span> event_base *base, <span class="keyword">struct</span> timeval *tp)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 如果tv_cache时间缓存已设置，就直接使用</span></span><br><span class="line">    <span class="keyword">if</span> (base-&gt;tv_cache.tv_sec) &#123;</span><br><span class="line">        *tp = base-&gt;tv_cache;</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果支持monotonic，就用clock_gettime获取monotonic时间</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(HAVE_CLOCK_GETTIME) &amp;&amp; defined(CLOCK_MONOTONIC)</span></span><br><span class="line">    <span class="keyword">if</span> (use_monotonic) &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">timespec</span>    ts;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">clock_gettime</span>(CLOCK_MONOTONIC, &amp;ts) == <span class="number">-1</span>)</span><br><span class="line">            <span class="keyword">return</span> (<span class="number">-1</span>);</span><br><span class="line">        tp-&gt;tv_sec = ts.tv_sec;</span><br><span class="line">        tp-&gt;tv_usec = ts.tv_nsec / <span class="number">1000</span>;</span><br><span class="line">        <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="comment">// 否则只能取得系统当前时间</span></span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">evutil_gettimeofday</span>(tp, <span class="literal">NULL</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果tv_cache已经设置，那么就直接使用缓存的时间；否则需要再次执行系统调用获取系统时间。</p><p>函数evutil_gettimeofday()用来获取当前系统时间，在Linux下其实就是系统调用gettimeofday()；Windows没有提供函数gettimeofday，而是通过调用_ftime()来完成的。</p><p>在每次系统事件循环中，时间缓存tv_cache将会被相应的清空和设置，再次来看看下面event_base_loop的主要代码逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">event_base_loop</span><span class="params">(<span class="keyword">struct</span> event_base *base, <span class="type">int</span> flags)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 清空时间缓存</span></span><br><span class="line">    base-&gt;tv_cache.tv_sec = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(!done)&#123;</span><br><span class="line">        <span class="built_in">timeout_correct</span>(base, &amp;tv); <span class="comment">// 时间校正</span></span><br><span class="line">        <span class="comment">// 更新event_tv到tv_cache指示的时间或者当前时间（第一次）</span></span><br><span class="line">         <span class="comment">// event_tv &lt;--- tv_cache</span></span><br><span class="line">        <span class="built_in">gettime</span>(base, &amp;base-&gt;event_tv);</span><br><span class="line">        <span class="comment">// 清空时间缓存-- 时间点1</span></span><br><span class="line">        base-&gt;tv_cache.tv_sec = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 等待I/O事件就绪</span></span><br><span class="line">        res = evsel-&gt;<span class="built_in">dispatch</span>(base, evbase, tv_p);</span><br><span class="line">        <span class="comment">// 缓存tv_cache存储了当前时间的值-- 时间点2</span></span><br><span class="line">         <span class="comment">// tv_cache &lt;--- now</span></span><br><span class="line">        <span class="built_in">gettime</span>(base, &amp;base-&gt;tv_cache);</span><br><span class="line">        <span class="comment">// .. 处理就绪事件</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 退出时也要清空时间缓存</span></span><br><span class="line">    base-&gt;tv_cache.tv_sec = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间event_tv指示了dispatch()上次返回，也就是I/O事件就绪时的时间，第一次进入循环时，由于tv_cache被清空，因此gettime()执行系统调用获取当前系统时间；而后将会更新为tv_cache指示的时间。</p><p>时间tv_cache在dispatch()返回后被设置为当前系统时间，因此它缓存了本次I/O事件就绪时的时间（event_tv）。<br>从代码逻辑里可以看出event_tv取得的是tv_cache上一次的值，因此event_tv应该小于tv_cache的值。</p><p>设置时间缓存的优点是不必每次获取时间都执行系统调用，这是个相对费时的操作；在上面标注的时间点2到时间点1的这段时间（处理就绪事件时），调用gettime()取得的都是tv_cache缓存的时间。</p><h3 id="3-时间校正">3 时间校正</h3><p>如果系统支持monotonic时间，该时间是系统从boot后到现在所经过的时间，因此不需要执行校正。<br>根据前面的代码逻辑，如果系统不支持monotonic时间，用户可能会手动的调整时间，如果时间被向前调整了（MS前面第7部分讲成了向后调整，要改正），比如从5点调整到了3点，那么在时间点2取得的值可能会小于上次的时间，这就需要调整了，下面来看看校正的具体代码，由函数timeout_correct()完成：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">timeout_correct</span><span class="params">(<span class="keyword">struct</span> event_base *base, <span class="keyword">struct</span> timeval *tv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">event</span> **pev;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> size;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">timeval</span> off;</span><br><span class="line">    <span class="keyword">if</span> (use_monotonic) <span class="comment">// monotonic时间就直接返回，无需调整</span></span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    <span class="built_in">gettime</span>(base, tv); <span class="comment">// tv &lt;---tv_cache</span></span><br><span class="line">    <span class="comment">// 根据前面的分析可以知道event_tv应该小于tv_cache</span></span><br><span class="line">    <span class="comment">// 如果tv &lt; event_tv表明用户向前调整时间了，需要校正时间</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">evutil_timercmp</span>(tv, &amp;base-&gt;event_tv, &gt;=)) &#123;</span><br><span class="line">        base-&gt;event_tv = *tv;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 计算时间差值</span></span><br><span class="line">    <span class="built_in">evutil_timersub</span>(&amp;base-&gt;event_tv, tv, &amp;off);</span><br><span class="line">    <span class="comment">// 调整定时事件小根堆</span></span><br><span class="line">    pev = base-&gt;timeheap.p;</span><br><span class="line">    size = base-&gt;timeheap.n;</span><br><span class="line">    <span class="keyword">for</span> (; size-- &gt; <span class="number">0</span>; ++pev) &#123;</span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">timeval</span> *ev_tv = &amp;(**pev).ev_timeout;</span><br><span class="line">        <span class="built_in">evutil_timersub</span>(ev_tv, &amp;off, ev_tv);</span><br><span class="line">    &#125;</span><br><span class="line">    base-&gt;event_tv = *tv; <span class="comment">// 更新event_tv为tv_cache</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在调整小根堆时，因为所有定时事件的时间值都会被减去相同的值，因此虽然堆中元素的时间键值改变了，但是相对关系并没有改变，不会改变堆的整体结构。因此只需要遍历堆中的所有元素，将每个元素的时间键值减去相同的值即可完成调整，不需要重新调整堆的结构。<br>当然调整完后，要将event_tv值重新设置为tv_cache值了。</p><h3 id="4-小节-2">4 小节</h3><p>主要分析了一下libevent对系统时间的处理，时间缓存、时间校正和定时堆的时间值调整等，逻辑还是很简单的，时间的加减、设置等辅助函数则非常简单，主要在头文件evutil.h中，就不再多说了。</p><h2 id="十二-让libevent支持多线程">十二 让libevent支持多线程</h2><p>Libevent本身不是多线程安全的，在多核的时代，如何能充分利用CPU的能力呢，这一节来说说如何在多线程环境中使用libevent，跟源代码并没有太大的关系，纯粹是使用上的技巧。</p><h3 id="1-错误使用示例">1 错误使用示例</h3><p>在多核的CPU上只使用一个线程始终是对不起CPU的处理能力啊，那好吧，那就多创建几个线程，比如下面的简单服务器场景。<br>1）主线程创建工作线程1；<br>2）接着主线程监听在端口上，等待新的连接；<br>3）在线程1中执行event事件循环，等待事件到来；<br>4）新连接到来，主线程调用libevent接口event_add将新连接注册到libevent上；<br>… …<br>上面的逻辑看起来没什么错误，在很多服务器设计中都可能用到主线程和工作线程的模式….<br>可是就在线程1注册事件时，主线程很可能也在操作事件，比如删除，修改，通过libevent的源代码也能看到，没有同步保护机制，问题麻烦了，看起来不能这样做啊，难道只能使用单线程不成！？</p><h3 id="2-支持多线程的几种模式">2 支持多线程的几种模式</h3><p>Libevent并不是线程安全的，但这不代表libevent不支持多线程模式，其实方法在前面已经将signal事件处理时就接触到了，那就是消息通知机制。</p><p>一句话，“你发消息通知我，然后再由我在合适的时间来处理”；<br>说到这就再多说几句，再打个比方，把你自己比作一个工作线程，而你的头是主线程，你有一个消息信箱来接收别人发给你的消息，当时头有个新任务要指派给你。</p><h4 id="2-1-暴力抢占">2.1 暴力抢占</h4><p>那么第一节中使用的多线程方法相当下面的流程：<br>1）当时你正在做事，比如在写文档；<br>2）你的头找到了一个任务，要指派给你，比如帮他搞个PPT，哈；<br>3）头命令你马上搞PPT，你这是不得不停止手头的工作，把PPT搞定了再接着写文档；<br>…</p><h4 id="2-2-纯粹的消息通知机制">2.2 纯粹的消息通知机制</h4><p>那么基于纯粹的消息通知机制的多线程方式就像下面这样：<br>1 当时你正在写文档；<br>2 你的头找到了一个任务，要指派给你，帮他搞个PPT；<br>3 头发个消息到你信箱，有个PPT要帮他搞定，这时你并不鸟他；<br>4 你写好文档，接着检查消息发现头有个PPT要你搞定，你开始搞PPT；<br>…</p><p>第一种的好处是消息可以立即得到处理，但是很方法很粗暴，你必须立即处理这个消息，所以你必须处理好切换问题，省得把文档上的内容不小心写到PPT里。在操作系统的进程通信中，消息队列（消息信箱）都是操作系统维护的，你不必关心。<br>第二种的优点是通过消息通知，切换问题省心了，不过消息是不能立即处理的（基于消息通知机制，这个总是难免的），而且所有的内容都通过消息发送，比如PPT的格式、内容等等信息，这无疑增加了通信开销。</p><h4 id="2-3-消息通知-同步层">2.3 消息通知+同步层</h4><p>有个折中机制可以减少消息通信的开销，就是提取一个同步层，还拿上面的例子来说，你把工作安排都存放在一个工作队列中，而且你能够保证“任何人把新任务扔到这个队列”，“自己取出当前第一个任务”等这些操作都能够保证不会把队列搞乱（其实就是个加锁的队列容器）。<br>再来看看处理过程和上面有什么不同：<br>1）当时你正在写文档；<br>2）你的头找到了一个任务，要指派给你，帮他搞个PPT；<br>3) 头有个PPT要你搞定，他把任务push到你的工作队列中，包括了PPT的格式、内容等信息；<br>4) 头发个消息（一个字节）到你信箱，有个PPT要帮他搞定，这时你并不鸟他；<br>5) 你写好文档，发现有新消息（这预示着有新任务来了），检查工作队列知道头有个PPT要你搞定，你开始搞PPT；<br>…</p><p>工作队列其实就是一个加锁的容器（队列、链表等等），这个很容易实现实现；而消息通知仅需要一个字节，具体的任务都push到了在工作队列中，因此想比2.2减少了不少通信开销。</p><p>多线程编程有很多陷阱，线程间资源的同步互斥不是一两句能说得清的，而且出现bug很难跟踪调试；这也有很多的经验和教训，因此如果让我选择，在绝大多数情况下都会选择机制3作为实现多线程的方法。</p><h3 id="3例子——memcached">3例子——memcached</h3><p>Memcached中的网络部分就是基于libevent完成的，其中的多线程模型就是典型的消息通知+同步层机制。下面的图足够说明其多线程模型了，其中有详细的文字说明。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527185527228.png" alt="image-20240527185527228"></p><h3 id="4-小节-3">4 小节</h3><p>本节更是libevent的使用方面的技巧，讨论了一下如何让libevent支持多线程，以及几种支持多线程的机制，和memcached使用libevent的多线程模型。</p><blockquote><p><strong>libevent解决了网络编程哪些痛点？</strong></p></blockquote><p><strong>高效的网络缓冲区</strong><br>在内核中有读缓冲区和写缓冲区，减少用户态和内核态的切换。<br>用户态读缓冲区的存在是为了处理粘包的问题，因为网络协议栈是不知道用户界定数据包的格式，没法确定一个完整的数据包。<br>用户态写缓冲区的存在是因为用户根本不清楚内核写缓存区的状态，需要把没有写出去的数据缓存起来等待下次写事件时把数据写出去。<br>buffer的设计有三种类型：<br>（1）固定数组，固定长度。限定了处理数据包的能力，没有动态伸缩的能力；需要<strong>频繁挪动数据。</strong><br>（2）ring buffer。可伸缩性差。<br>（3）chain buffer。解决可伸缩性差的问题，避免频繁挪动数据；同时也引进了新的问题，一个数据可能在多个buffer中都有，即数据分割，这会导致多次系统调用，从而引起中断上下文的切换。解决办法是使用readv()将内核中连续的buffer读到用户态不连续的buffer中，writev()把用户态不连续的buffer写到内核连续的buffer中；从而减少<strong>系统调用</strong>。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240527185935359.png" alt="image-20240527185935359"></p><p>evbuffer就是chain buffer类型的缓冲区。</p><p><strong>IO函数使用与网络原理</strong><br>（1）有了libevent可以不使用IO函数。因为如果使用IO函数，既需要知道这些IO函数里面的系统调用返回值的含义。<br>（2）有了libevent就可以不清楚数据拷贝原理。<br>（3）有了libevent就可以不清楚网络原理以及网络编程流程。<br>（4）有了libevent只需要知道事件处理，IO操作完全交由libevent处理。</p><p><strong>多线程</strong><br>加锁的效果比较好。<br>一个线程尽量只处理一个reactor的事件。<br>（1）buffer加锁时，读要读出一个完整的数据包。<br>（2）buffer加锁时，写要写一个完整的数据包。</p>]]></content>
    
    
    <summary type="html">libevent源码剖析</summary>
    
    
    
    <category term="网络编程" scheme="https://penge666.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
    
    <category term="网络编程" scheme="https://penge666.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>模块5:数据中心</title>
    <link href="https://penge666.github.io/posts/d696d4de.html"/>
    <id>https://penge666.github.io/posts/d696d4de.html</id>
    <published>2024-05-23T08:13:23.000Z</published>
    <updated>2024-05-23T08:46:38.010Z</updated>
    
    <content type="html"><![CDATA[<p>胸有惊雷而面如平湖者，可拜上将军！</p><h2 id="第18讲-DNS协议：网络世界的地址簿">第18讲 | DNS协议：网络世界的地址簿</h2><h3 id="18-1-DNS-服务器">18.1 DNS 服务器</h3><p>你肯定记得住网站的名称，但是很难记住网站的 IP 地址，因而也需要一个地址簿，就是<strong>DNS 服务器</strong>。</p><p>由此可见，DNS 在日常生活中多么重要。每个人上网，都需要访问它，但是同时，这对它来讲也是非常大的挑战。一旦它出了故障，整个互联网都将瘫痪。另外，上网的人分布在全世界各地，如果大家都去同一个地方访问某一台服务器，时延将会非常大。因而，<strong>DNS 服务器，一定要设置成高可用、高并发和分布式的</strong>。</p><p>于是，就有了这样树状的层次结构。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523161658954.png" alt="image-20240523161658954"></p><ul><li>根 DNS 服务器 ：返回顶级域 DNS 服务器的 IP 地址</li><li>顶级域 DNS 服务器：返回权威 DNS 服务器的 IP 地址</li><li>权威 DNS 服务器 ：返回相应主机的 IP 地址</li></ul><h3 id="18-2-DNS-解析流程">18.2 DNS 解析流程</h3><p>为了提高 DNS 的解析性能，很多网络都会就近部署 DNS 缓存服务器。于是，就有了以下的 DNS 解析流程。</p><ol><li>电脑客户端会发出一个 DNS 请求，问 <a href="http://www.163.com">www.163.com</a> 的 IP 是啥啊，并发给本地域名服务器 (本地 DNS)。那本地域名服务器 (本地 DNS) 是什么呢？如果是通过 DHCP 配置，本地 DNS 由你的网络服务商（ISP），如电信、移动等自动分配，它通常就在你网络服务商的某个机房。</li><li>本地 DNS 收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应 IP 地址的大表格。如果能找到 <a href="http://www.163.com">www.163.com</a>，它直接就返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：”老大，能告诉我 <a href="http://www.163.com">www.163.com</a> 的 IP 地址吗？”根域名服务器是最高层次的，全球共有 13 套。它不直接用于域名解析，但能指明一条道路。</li><li>根 DNS 收到来自本地 DNS 的请求，发现后缀是 .com，说：”哦，<a href="http://www.163.com">www.163.com</a> 啊，<a href="http://xn--ciq66l2rd1tt4vryr0b.com">这个域名是由.com</a> 区域管理，我给你它的顶级域名服务器的地址，你去问问它吧。”</li><li>本地 DNS 转向问顶级域名服务器：”老二，你能告诉我 <a href="http://www.163.com">www.163.com</a> 的 IP 地址吗？”顶级域名服务器就是大名鼎鼎的比如 .com、.net、 .org 这些一级域名，它负责管理二级域名，比如 <a href="http://163.com">163.com</a>，所以它能提供一条更清晰的方向。</li><li>顶级域名服务器说：”我给你负责 <a href="http://www.163.com">www.163.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到。”</li><li>本地 DNS 转向问权威 DNS 服务器：”您好，<a href="http://www.163.com">www.163.com</a> 对应的 IP 是啥呀？”<a href="http://163.com">163.com</a> 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li><li>权限 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</li><li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li></ol><p>至此，我们完成了 DNS 的解析过程。现在总结一下，整个过程我画成了一个图。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523161727131.png" alt="image-20240523161727131"></p><h3 id="18-3-负载均衡">18.3 负载均衡</h3><p>站在客户端角度，这是一次<strong>DNS 递归查询过程</strong>。因为本地 DNS 全权为它效劳，它只要坐等结果即可。在这个过程中，DNS 除了可以通过名称映射为 IP 地址，它还可以做另外一件事，就是<strong>负载均衡</strong>。</p><p>DNS 首先可以做<strong>内部负载均衡</strong>。</p><p>例如，一个应用要访问数据库，在这个应用里面应该配置这个数据库的 IP 地址，还是应该配置这个数据库的域名呢？显然应该配置域名，因为一旦这个数据库，因为某种原因，换到了另外一台机器上，而如果有多个应用都配置了这台数据库的话，一换 IP 地址，就需要将这些应用全部修改一遍。但是如果配置了域名，则只要在 DNS 服务器里，将域名映射为新的 IP 地址，这个工作就完成了，大大简化了运维。</p><p>在这个基础上，我们可以再进一步。例如，某个应用要访问另外一个应用，如果配置另外一个应用的 IP 地址，那么这个访问就是一对一的。但是当被访问的应用撑不住的时候，我们其实可以部署多个。但是，访问它的应用，如何在多个之间进行负载均衡？只要配置成为域名就可以了。在域名解析的时候，我们只要配置策略，这次返回第一个 IP，下次返回第二个 IP，就可以实现负载均衡了。</p><p>另外一个更加重要的是，DNS 还可以做<strong>全局负载均衡</strong>。</p><p>为了保证我们的应用高可用，往往会部署在多个机房，每个地方都会有自己的 IP 地址。当用户访问某个域名的时候，这个 IP 地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要在 DNS 服务器里面，将这个数据中心对应的 IP 地址删除，就可以实现一定的高可用。</p><p>另外，我们肯定希望北京的用户访问北京的数据中心，上海的用户访问上海的数据中心，这样，客户体验就会非常好，访问速度就会超快。这就是全局负载均衡的概念。</p><h3 id="18-3-负载均衡-2">18.3 负载均衡</h3><p>站在客户端角度，这是一次<strong>DNS 递归查询过程</strong>。因为本地 DNS 全权为它效劳，它只要坐等结果即可。在这个过程中，DNS 除了可以通过名称映射为 IP 地址，它还可以做另外一件事，就是<strong>负载均衡</strong>。</p><p>DNS 首先可以做<strong>内部负载均衡</strong>。</p><p>例如，一个应用要访问数据库，在这个应用里面应该配置这个数据库的 IP 地址，还是应该配置这个数据库的域名呢？显然应该配置域名，因为一旦这个数据库，因为某种原因，换到了另外一台机器上，而如果有多个应用都配置了这台数据库的话，一换 IP 地址，就需要将这些应用全部修改一遍。但是如果配置了域名，则只要在 DNS 服务器里，将域名映射为新的 IP 地址，这个工作就完成了，大大简化了运维。</p><p>在这个基础上，我们可以再进一步。例如，某个应用要访问另外一个应用，如果配置另外一个应用的 IP 地址，那么这个访问就是一对一的。但是当被访问的应用撑不住的时候，我们其实可以部署多个。但是，访问它的应用，如何在多个之间进行负载均衡？只要配置成为域名就可以了。在域名解析的时候，我们只要配置策略，这次返回第一个 IP，下次返回第二个 IP，就可以实现负载均衡了。</p><p>另外一个更加重要的是，DNS 还可以做<strong>全局负载均衡</strong>。</p><p>为了保证我们的应用高可用，往往会部署在多个机房，每个地方都会有自己的 IP 地址。当用户访问某个域名的时候，这个 IP 地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要在 DNS 服务器里面，将这个数据中心对应的 IP 地址删除，就可以实现一定的高可用。</p><p>另外，我们肯定希望北京的用户访问北京的数据中心，上海的用户访问上海的数据中心，这样，客户体验就会非常好，访问速度就会超快。这就是全局负载均衡的概念。</p><h3 id="18-4-示例：DNS-访问数据中心中对象存储上的静态资源">18.4 示例：DNS 访问数据中心中对象存储上的静态资源</h3><p>我们通过 DNS 访问数据中心中对象存储上的静态资源为例，看一看整个过程。</p><p>假设全国有多个数据中心，托管在多个运营商，每个数据中心三个可用区（Available Zone）。对象存储通过跨可用区部署，实现高可用性。在每个数据中心中，都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器（Proxy-server）。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523161924726.png" alt="image-20240523161924726"></p><ol><li>当一个客户端要访问 <a href="http://object.yourcompany.com">object.yourcompany.com</a> 的时候，需要将域名转换为 IP 地址进行访问，所以它要请求本地 DNS 解析器。</li><li>本地 DNS 解析器先查看看本地的缓存是否有这个记录。如果有则直接使用，因为上面的过程太复杂了，如果每次都要递归解析，就太麻烦了。</li><li>如果本地无缓存，则需要请求本地的 DNS 服务器。</li><li>本地的 DNS 服务器一般部署在你的数据中心或者你所在的运营商的网络中，本地 DNS 服务器也需要看本地是否有缓存，如果有则返回，因为它也不想把上面的递归过程再走一遍。</li><li>至 7. 如果本地没有，本地 DNS 才需要递归地从根 DNS 服务器，<a href="http://xn--rcrz24c.com">查到.com</a> 的顶级域名服务器，最终查到 <a href="http://yourcompany.com">yourcompany.com</a> 的权威 DNS 服务器，给本地 DNS 服务器，权威 DNS 服务器按说会返回真实要访问的 IP 地址。</li></ol><p>对于不需要做全局负载均衡的简单应用来讲，<a href="http://yourcompany.com">yourcompany.com</a> 的权威 DNS 服务器可以直接将 <a href="http://object.yourcompany.com">object.yourcompany.com</a> 这个域名解析为一个或者多个 IP 地址，然后客户端可以通过多个 IP 地址，进行简单的轮询，实现简单的负载均衡。</p><p>但是对于复杂的应用，尤其是跨地域跨运营商的大型应用，则需要更加复杂的全局负载均衡机制，因而需要专门的设备或者服务器来做这件事情，这就是<strong>全局负载均衡器（GSLB，Global Server Load Balance）</strong>。</p><p>在 <a href="http://yourcompany.com">yourcompany.com</a> 的 DNS 服务器中，一般是通过配置 CNAME 的方式，给 <a href="http://object.yourcompany.com">object.yourcompany.com</a> 起一个别名，例如 <a href="http://object.vip.yourcomany.com">object.vip.yourcomany.com</a>，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。</p><p>图中画了两层的 GSLB，是因为分运营商和地域。我们希望不同运营商的客户，可以访问相同运营商机房中的资源，这样不跨运营商访问，有利于提高吞吐量，减少时延。</p><ol><li>第一层 GSLB，通过查看请求它的本地 DNS 服务器所在的运营商，就知道用户所在的运营商。假设是移动，通过 CNAME 的方式，通过另一个别名 <a href="http://object.yd.yourcompany.com">object.yd.yourcompany.com</a>，告诉本地 DNS 服务器去请求第二层的 GSLB。</li><li>第二层 GSLB，通过查看请求它的本地 DNS 服务器所在的地址，就知道用户所在的地理位置，然后将距离用户位置比较近的 Region 里面，六个**内部负载均衡（SLB，Server Load Balancer）**的地址，返回给本地 DNS 服务器。</li><li>本地 DNS 服务器将结果返回给本地 DNS 解析器。</li><li>本地 DNS 解析器将结果缓存后，返回给客户端。</li><li>客户端开始访问属于相同运营商的距离较近的 Region 1 中的对象存储，当然客户端得到了六个 IP 地址，它可以通过负载均衡的方式，随机或者轮询选择一个可用区进行访问。对象存储一般会有三个备份，从而可以实现对存储读写的负载均衡。</li></ol><h3 id="18-5-小结">18.5 小结</h3><p>总结一下：</p><ul><li>DNS 是网络世界的地址簿，可以通过域名查地址，因为域名服务器是按照树状结构组织的，因而域名查找是使用递归的方法，并通过缓存的方式增强性能；</li><li>在域名和 IP 的映射过程中，给了应用基于域名做负载均衡的机会，可以是简单的负载均衡，也可以根据地址和运营商做全局的负载均衡。</li></ul><h2 id="第19讲-HTTPDNS：网络世界的地址簿也会指错路">第19讲 | HTTPDNS：网络世界的地址簿也会指错路</h2><p>上一节我们知道了 DNS 的两项功能，第一是根据名称查到具体的地址，另外一个是可以针对多个地址做负载均衡，而且可以在多个地址中选择一个距离你近的地方访问。</p><p>然而有时候这个地址簿也经常给你指错路，明明距离你 500 米就有个吃饭的地方，非要把你推荐到 5 公里外。为什么会出现这样的情况呢？</p><p>还记得吗？当我们发出请求解析 DNS 的时候，首先，会先连接到运营商本地的 DNS 服务器，由这个服务器帮我们去整棵 DNS 树上进行解析，然后将解析的结果返回给客户端。但是本地的 DNS 服务器，作为一个本地导游，往往有自己的”小心思”。</p><h3 id="19-1-传统-DNS-存在哪些问题？">19.1 传统 DNS 存在哪些问题？</h3><ol><li><p>域名缓存问题【简单来说，就是缓存失效】</p><p>它可以在本地做一个缓存，也就是说，不是每一个请求，它都会去访问权威 DNS 服务器，而是访问过一次就把结果缓存到自己本地，当其他人来问的时候，直接就返回这个缓存数据。</p><p>这就相当于导游去过一个饭店，自己脑子记住了地址，当有一个游客问的时候，他就凭记忆回答了，不用再去查地址簿。这样经常存在的一个问题是，人家那个饭店明明都已经搬了，结果作为导游，他并没有刷新这个缓存，结果你辛辛苦苦到了这个地点，发现饭店已经变成了服装店，你是不是会非常失望？</p><p>另外，有的运营商会把一些静态页面，缓存到本运营商的服务器内，这样用户请求的时候，就不用跨运营商进行访问，这样既加快了速度，也减少了运营商之间流量计算的成本。在域名解析的时候，不会将用户导向真正的网站，而是指向这个缓存的服务器。</p><p>很多情况下是看不出问题的，但是当页面更新，用户会访问到老的页面，问题就出来了。例如，你听说一个餐馆推出了一个新菜，你想去尝一下。结果导游告诉你，在这里吃也是一样的。有的游客会觉得没问题，但是对于想尝试新菜的人来说，如果导游说带你去，但其实并没有吃到新菜，你是不是也会非常失望呢？</p><p>再就是本地的缓存，往往使得全局负载均衡失败，因为上次进行缓存的时候，缓存中的地址不一定是这次访问离客户最近的地方，如果把这个地址返回给客户，那肯定就会绕远路。</p><p>就像上一次客户要吃西湖醋鱼的事，导游知道西湖边有一家，因为当时游客就在西湖边，可是，下一次客户在灵隐寺，想吃西湖醋鱼的时候，导游还指向西湖边的那一家，那这就绕的太远了。</p></li></ol><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523162219587.png" alt="image-20240523162219587"></p><p>2.域名转发问题</p><p>缓存问题还是说本地域名解析服务，还是会去权威 DNS 服务器中查找，只不过不是每次都要查找。可以说这还是大导游、大中介。还有一些小导游、小中介，有了请求之后，直接转发给其他运营商去做解析，自己只是外包了出去。</p><p>这样的问题是，如果是 A 运营商的客户，访问自己运营商的 DNS 服务器，如果 A 运营商去权威 DNS 服务器查询的话，权威 DNS 服务器知道你是 A 运营商的，就返回给一个部署在 A 运营商的网站地址，这样针对相同运营商的访问，速度就会快很多。</p><p>但是 A 运营商偷懒，将解析的请求转发给 B 运营商，B 运营商去权威 DNS 服务器查询的话，权威服务器会误认为，你是 B 运营商的，那就返回给你一个在 B 运营商的网站地址吧，结果客户的每次访问都要跨运营商，速度就会很慢。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523162815367.png" alt="image-20240523162815367"></p><p>3.出口 NAT 问题</p><p>前面讲述网关的时候，我们知道，出口的时候，很多机房都会配置NAT，也即网络地址转换，使得从这个网关出去的包，都换成新的 IP 地址，当然请求返回的时候，在这个网关，再将 IP 地址转换回去，所以对于访问来说是没有任何问题。</p><p>但是一旦做了网络地址的转换，权威的 DNS 服务器，就没办法通过这个地址，来判断客户到底是来自哪个运营商，而且极有可能因为转换过后的地址，误判运营商，导致跨运营商的访问。</p><p>4.域名更新问题</p><p>本地 DNS 服务器是由不同地区、不同运营商独立部署的。对域名解析缓存的处理上，实现策略也有区别，有的会偷懒，忽略域名解析结果的 TTL 时间限制，在权威 DNS 服务器解析变更的时候，解析结果在全网生效的周期非常漫长。但是有的时候，在 DNS 的切换中，场景对生效时间要求比较高。</p><p>例如双机房部署的时候，跨机房的负载均衡和容灾多使用 DNS 来做。当一个机房出问题之后，需要修改权威 DNS，将域名指向新的 IP 地址，但是如果更新太慢，那很多用户都会出现访问异常。</p><p>这就像，有的导游比较勤快、敬业，时时刻刻关注酒店、餐馆、交通的变化，问他的时候，往往会得到最新情况。有的导游懒一些，8 年前背的导游词就没换过，问他的时候，指的路往往就是错的。</p><p>5.解析延迟问题</p><p>从上一节的 DNS 查询过程来看，DNS 的查询过程需要递归遍历多个 DNS 服务器，才能获得最终的解析结果，这会带来一定的时延，甚至会解析超时。</p><h3 id="19-2-HTTPDNS-的工作模式">19.2 HTTPDNS 的工作模式</h3><p>既然 DNS 解析中有这么多问题，那怎么办呢？难不成退回到直接用 IP 地址？这样显然不合适，所以就有了<strong>HTTPDNS</strong>。</p><p><strong>HTTPNDS 其实就是，不走传统的 DNS 解析，而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个运营商。当客户端需要 DNS 解析的时候，直接通过 HTTP 协议进行请求这个服务器集群，得到就近的地址</strong>。</p><p>这就相当于每家基于 HTTP 协议，自己实现自己的域名解析，自己做一个自己的地址簿，而不使用统一的地址簿。但是默认的域名解析都是走 DNS 的，因而使用 HTTPDNS 需要绕过默认的 DNS 路径，就不能使用默认的客户端。使用 HTTPDNS 的，往往是手机应用，需要在手机端嵌入支持 HTTPDNS 的客户端 SDK。</p><p>通过自己的 HTTPDNS 服务器和自己的 SDK，实现了从依赖本地导游，到自己上网查询做旅游攻略，进行自由行，爱怎么玩怎么玩。这样就能够避免依赖导游，而导游又不专业，你还不能把他怎么样的尴尬。</p><p>下面我来解析一下<strong>HTTPDNS 的工作模式</strong>。</p><p>在客户端的 SDK 里动态请求服务端，获取 HTTPDNS 服务器的 IP 列表，缓存到本地。随着不断地解析域名，SDK 也会在本地缓存 DNS 域名解析的结果。</p><p>当手机应用要访问一个地址的时候，首先看是否有本地的缓存，如果有就直接返回。这个缓存和本地 DNS 的缓存不一样的是，这个是手机应用自己做的，而非整个运营商统一做的。如何更新、何时更新，手机应用的客户端可以和服务器协调来做这件事情。</p><p>如果本地没有，就需要请求 HTTPDNS 的服务器，在本地 HTTPDNS 服务器的 IP 列表中，选择一个发出 HTTP 的请求，会返回一个要访问的网站的 IP 列表。</p><p>请求的方式是这样的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://106.2.xxx.xxx/d?dn=c.m.163.com</span><br><span class="line">&#123;<span class="string">&quot;dns&quot;</span>:[&#123;<span class="string">&quot;host&quot;</span>:<span class="string">&quot;c.m.163.com&quot;</span>,<span class="string">&quot;ips&quot;</span>:[<span class="string">&quot;223.252.199.12&quot;</span>],<span class="string">&quot;ttl&quot;</span>:300,<span class="string">&quot;http2&quot;</span>:0&#125;],<span class="string">&quot;client&quot;</span>:&#123;<span class="string">&quot;ip&quot;</span>:<span class="string">&quot;106.2.81.50&quot;</span>,<span class="string">&quot;line&quot;</span>:269692944&#125;&#125;</span><br></pre></td></tr></table></figure><p>手机客户端自然知道手机在哪个运营商、哪个地址。由于是直接的 HTTP 通信，HTTPDNS 服务器能够准确知道这些信息，因而可以做精准的全局负载均衡。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523163048109.png" alt="image-20240523163048109"></p><p>当然，当所有这些都不工作的时候，可以切换到传统的 LocalDNS 来解析，慢也比访问不到好。那 HTTPDNS 是如何解决上面的问题的呢？</p><p>其实归结起来就是两大问题。一是解析速度和更新速度的平衡问题，二是智能调度的问题，对应的解决方案是 HTTPDNS 的缓存设计和调度设计。</p><h3 id="19-3-HTTPDNS-的缓存设计">19.3 HTTPDNS 的缓存设计</h3><p>解析 DNS 过程复杂，通信次数多，对解析速度造成很大影响。为了加快解析，因而有了缓存，但是这又会产生缓存更新速度不及时的问题。最要命的是，这两个方面都掌握在别人手中，也即本地 DNS 服务器手中，它不会为你定制，你作为客户端干着急没办法。</p><p>而 HTTPDNS 就是将解析速度和更新速度全部掌控在自己手中。一方面，解析的过程，不需要本地 DNS 服务递归的调用一大圈，一个 HTTP 的请求直接搞定，要实时更新的时候，马上就能起作用；另一方面为了提高解析速度，本地也有缓存，缓存是在客户端 SDK 维护的，过期时间、更新时间，都可以自己控制。</p><p>HTTPDNS 的缓存设计策略也是咱们做应用架构中常用的缓存设计模式，也即分为客户端、缓存、数据源三层。</p><ul><li>对于应用架构来讲，就是应用、缓存、数据库。常见的是 Tomcat、Redis、MySQL。</li><li>对于 HTTPDNS 来讲，就是手机客户端、DNS 缓存、HTTPDNS 服务器。</li></ul><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523163104850.png" alt="image-20240523163104850"></p><p>只要是缓存模式，就存在缓存的过期、更新、不一致的问题，解决思路也是很像的。</p><p>例如 DNS 缓存在内存中，也可以持久化到存储上，从而 APP 重启之后，能够尽快从存储中加载上次累积的经常访问的网站的解析结果，就不需要每次都全部解析一遍，再变成缓存。这有点像 Redis 是基于内存的缓存，但是同样提供持久化的能力，使得重启或者主备切换的时候，数据不会完全丢失。</p><p>SDK 中的缓存会严格按照缓存过期时间，如果缓存没有命中，或者已经过期，而且客户端不允许使用过期的记录，则会发起一次解析，保障记录是更新的。</p><p>解析可以<strong>同步进行</strong>，也就是直接调用 HTTPDNS 的接口，返回最新的记录，更新缓存；也可以<strong>异步进行</strong>，添加一个解析任务到后台，由后台任务调用 HTTPDNS 的接口。</p><p>同步更新的优点是实时性好，缺点是如果有多个请求都发现过期的时候，同时会请求 HTTPDNS 多次，其实是一种浪费。</p><p>同步更新的方式对应到应用架构中缓存的<strong>Cache-Aside 机制</strong>，也即先读缓存，不命中读数据库，同时将结果写入缓存。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523163132939.png" alt="image-20240523163132939"></p><p>异步更新的优点是，可以将多个请求都发现过期的情况，合并为一个对于 HTTPDNS 的请求任务，只执行一次，减少 HTTPDNS 的压力。同时可以在即将过期的时候，就创建一个任务进行预加载，防止过期之后再刷新，称为<strong>预加载</strong>。</p><p>它的缺点是当前请求拿到过期数据的时候，如果客户端允许使用过期数据，需要冒一次风险。如果过期的数据还能请求，就没问题；如果不能请求，则失败一次，等下次缓存更新后，再请求方能成功。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523163149681.png" alt="image-20240523163149681"></p><p>异步更新的机制对应到应用架构中缓存的Refresh-Ahead 机制，即业务仅仅访问缓存，当过期的时候定期刷新。在著名的应用缓存 Guava Cache 中，有个 RefreshAfterWrite 机制，对于并发情况下，多个缓存访问不命中从而引发并发回源的情况，可以采取只有一个请求回源的模式。在应用架构的缓存中，也常常用<strong>数据预热</strong>或者<strong>预加载</strong>的机制。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523163204576.png" alt="image-20240523163204576"></p><h3 id="19-4-HTTPDNS-的调度设计">19.4 HTTPDNS 的调度设计</h3><p>由于客户端嵌入了 SDK，因而就不会因为本地 DNS 的各种缓存、转发、NAT，让权威 DNS 服务器误会客户端所在的位置和运营商，而可以拿到第一手资料。</p><p>在<strong>客户端</strong>，可以知道手机是哪个国家、哪个运营商、哪个省，甚至哪个市，HTTPDNS 服务端可以根据这些信息，选择最佳的服务节点返回。</p><p>如果有多个节点，还会考虑错误率、请求时间、服务器压力、网络状况等，进行综合选择，而非仅仅考虑地理位置。当有一个节点宕机或者性能下降的时候，可以尽快进行切换。</p><p>要做到这一点，需要客户端使用 HTTPDNS 返回的 IP 访问业务应用。客户端的 SDK 会收集网络请求数据，如错误率、请求时间等网络请求质量数据，并发送到统计后台，进行分析、聚合，以此查看不同的 IP 的服务质量。</p><p>在<strong>服务端</strong>，应用可以通过调用 HTTPDNS 的管理接口，配置不同服务质量的优先级、权重。HTTPDNS 会根据这些策略综合地理位置和线路状况算出一个排序，优先访问当前那些优质的、时延低的 IP 地址。</p><p>HTTPDNS 通过智能调度之后返回的结果，也会缓存在客户端。为了不让缓存使得调度失真，客户端可以根据不同的移动网络运营商 WIFI 的 SSID 来分维度缓存。不同的运营商或者 WIFI 解析出来的结果会不同。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523163220546.png" alt="image-20240523163220546"></p><h3 id="19-5-小结">19.5 小结</h3><p>两个重点：</p><ul><li>传统的 DNS 有很多问题，例如解析慢、更新不及时。因为缓存、转发、NAT 问题导致客户端误会自己所在的位置和运营商，从而影响流量的调度。</li><li>HTTPDNS 通过客户端 SDK 和服务端，通过 HTTP 直接调用解析 DNS 的方式，绕过了传统 DNS 的这些缺点，实现了智能的调度。</li></ul><h2 id="第20讲-CDN：你去小卖部取过快递么？">第20讲 | CDN：你去小卖部取过快递么？</h2><p>当一个用户想访问一个网站的时候，指定这个网站的域名，DNS 就会将这个域名解析为地址，然后用户请求这个地址，返回一个网页。就像你要买个东西，首先要查找商店的位置，然后去商店里面找到自己想要的东西，最后拿着东西回家。</p><p><strong>那这里面还有没有可以优化的地方呢？</strong></p><p>例如你去电商网站下单买个东西，这个东西一定要从电商总部的中心仓库送过来吗？原来基本是这样的，每一单都是单独配送，所以你可能要很久才能收到你的宝贝。但是后来电商网站的物流系统学聪明了，他们在全国各地建立了很多仓库，而不是只有总部的中心仓库才可以发货。</p><p>电商网站根据统计大概知道，北京、上海、广州、深圳、杭州等地，每天能够卖出去多少书籍、卫生纸、包、电器等存放期比较长的物品。这些物品用不着从中心仓库发出，所以平时就可以将它们分布在各地仓库里，客户一下单，就近的仓库发出，第二天就可以收到了。</p><p>这样，用户体验大大提高。当然，这里面也有个难点就是，生鲜这类东西保质期太短，如果提前都备好货，但是没有人下单，那肯定就坏了。这个问题，我后文再说。</p><p><strong>我们先说，我们的网站访问可以借鉴”就近配送”这个思路</strong>。</p><p>全球有这么多的数据中心，无论在哪里上网，临近不远的地方基本上都有数据中心。是不是可以在这些数据中心里部署几台机器，形成一个缓存的集群来缓存部分数据，那么用户访问数据的时候，就可以就近访问了呢？</p><p>当然是可以的。这些分布在各个地方的各个数据中心的节点，就称为<strong>边缘节点</strong>。</p><p>由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上。有区域节点，规模就要更大，缓存的数据会更多，命中的概率也就更大。在区域节点之上是中心节点，规模更大，缓存数据更多。如果还不命中，就只好回源网站访问了。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164056912.png" alt="image-20240523164056912"></p><p>这就是<strong>CDN 的分发系统的架构</strong>。CDN 系统的缓存，也是一层一层的，能不访问后端真正的源，就不打扰它。这也是电商网站物流系统的思路，北京局找不到，找华北局，华北局找不到，再找北方局。</p><p>有了这个分发系统之后，接下来就是，<strong>客户端如何找到相应的边缘节点进行访问呢？</strong></p><p>还记得我们讲过的基于 DNS 的全局负载均衡吗？这个负载均衡主要用来选择一个就近的同样运营商的服务器进行访问。你会发现，CDN 分发网络也是一个分布在多个区域、多个运营商的分布式系统，也可以用相同的思路选择最合适的边缘节点。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164112433.png" alt="image-20240523164112433"></p><p><strong>在没有 CDN 的情况下</strong>，用户向浏览器输入 <a href="http://www.web.com">www.web.com</a> 这个域名，客户端访问本地 DNS 服务器的时候，如果本地 DNS 服务器有缓存，则返回网站的地址；如果没有，递归查询到网站的权威 DNS 服务器，这个权威 DNS 服务器是负责 <a href="http://web.com">web.com</a> 的，它会返回网站的 IP 地址。本地 DNS 服务器缓存下 IP 地址，将 IP 地址返回，然后客户端直接访问这个 IP 地址，就访问到了这个网站。</p><p>然而<strong>有了 CDN 之后，情况发生了变化</strong>。在 <a href="http://web.com">web.com</a> 这个权威 DNS 服务器上，会设置一个 CNAME 别名，指向另外一个域名 <a href="http://www.web.cdn.com">www.web.cdn.com</a>，返回给本地 DNS 服务器。</p><p>当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是 <a href="http://web.com">web.com</a> 的权威 DNS 服务器了，而是 <a href="http://web.cdn.com">web.cdn.com</a> 的权威 DNS 服务器，这是 CDN 自己的权威 DNS 服务器。在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也即 CDN 网络的全局负载均衡器。</p><p>接下来，本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：</p><ul><li>根据用户 IP 地址，判断哪一台服务器距用户最近；</li><li>用户所处的运营商；</li><li>根据用户所请求的 URL 中携带的内容名称，判断哪一台服务器上有用户所需的内容；</li><li>查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。</li></ul><p>基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的 IP 地址。</p><p>本地 DNS 服务器缓存这个 IP 地址，然后将 IP 返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。</p><p><strong>CDN 可以进行缓存的内容有很多种。</strong></p><p>保质期长的日用品比较容易缓存，因为不容易过期，对应到就像电商仓库系统里，就是静态页面、图片等，因为这些东西也不怎么变，所以适合缓存.</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164208297.png" alt="image-20240523164208297"></p><p>还记得这个<strong>接入层缓存的架构</strong>吗？在进入数据中心的时候，我们希望通过最外层接入层的缓存，将大部分静态资源的访问拦在边缘。而 CDN 则更进一步，将这些静态资源缓存到离用户更近的数据中心外。越接近客户，访问性能越好，时延越低。</p><p>但是静态内容中，有一种特殊的内容，也大量使用了 CDN，这个就是前面讲过的流媒体。</p><p>CDN 支持<strong>流媒体协议</strong>，例如前面讲过的 RTMP 协议。在很多情况下，这相当于一个代理，从上一级缓存读取内容，转发给用户。由于流媒体往往是连续的，因而可以进行预先缓存的策略，也可以预先推送到用户的客户端。</p><p>对于静态页面来讲，内容的分发往往采取<strong>拉取</strong>的方式，也即当发现未命中的时候，再去上一级进行拉取。但是，流媒体数据量大，如果出现<strong>回源</strong>，压力会比较大，所以往往采取主动<strong>推送</strong>的模式，将热点数据主动推送到边缘节点。</p><p>对于流媒体来讲，很多 CDN 还提供<strong>预处理服务</strong>，也即文件在分发之前，经过一定的处理。例如将视频转换为不同的码流，以适应不同的网络带宽的用户需求；再如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。这就是我们常见的，”我要看超清、标清、流畅等”。</p><p>对于流媒体 CDN 来讲，有个关键的问题是<strong>防盗链</strong>问题。因为视频是要花大价钱买版权的，为了挣点钱，收点广告费，如果流媒体被其他的网站盗走，在人家的网站播放，那损失可就大了。</p><p>最常用也最简单的方法就是<strong>HTTP 头的 refer 字段</strong>， 当浏览器发送请求的时候，一般会带上 referer，告诉服务器是从哪个页面链接过来的，服务器基于此可以获得一些信息用于处理。如果 refer 信息不是来自本站，就阻止访问或者跳到其它链接。</p><p><strong>refer 的机制相对比较容易破解，所以还需要配合其他的机制。</strong></p><p>一种常用的机制是<strong>时间戳防盗链</strong>。使用 CDN 的管理员可以在配置界面上，和 CDN 厂商约定一个加密字符串。</p><p>客户端取出当前的时间戳，要访问的资源及其路径，连同加密字符串进行签名算法得到一个字符串，然后生成一个下载链接，带上这个签名字符串和截止时间戳去访问 CDN。</p><p>在 CDN 服务端，根据取出过期时间，和当前 CDN 节点时间进行比较，确认请求是否过期。然后 CDN 服务端有了资源及路径，时间戳，以及约定的加密字符串，根据相同的签名算法计算签名，如果匹配则一致，访问合法，才会将资源返回给客户。</p><p>然而比如在电商仓库中，我在前面提过，有关生鲜的缓存就是非常麻烦的事情，这对应着就是动态的数据，比较难以缓存。怎么办呢？现在也有<strong>动态 CDN，主要有两种模式</strong>。</p><ul><li>一种为<strong>生鲜超市模式</strong>，也即<strong>边缘计算的模式</strong>。既然数据是动态生成的，所以数据的逻辑计算和存储，也相应的放在边缘的节点。其中定时从源数据那里同步存储的数据，然后在边缘进行计算得到结果。就像对生鲜的烹饪是动态的，没办法事先做好缓存，因而将生鲜超市放在你家旁边，既能够送货上门，也能够现场烹饪，也是边缘计算的一种体现。</li><li>另一种是<strong>冷链运输模式</strong>，也即<strong>路径优化的模式</strong>。数据不是在边缘计算生成的，而是在源站生成的，但是数据的下发则可以通过 CDN 的网络，对路径进行优化。因为 CDN 节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由 CDN 来规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。</li></ul><p>对于常用的 TCP 连接，在公网上传输的时候经常会丢数据，导致 TCP 的窗口始终很小，发送速度上不去。根据前面的 TCP 流量控制和拥塞控制的原理，在 CDN 加速网络中可以调整 TCP 的参数，使得 TCP 可以更加激进地传输数据。</p><p>可以通过多个请求复用一个连接，保证每次动态请求到达时。连接都已经建立了，不必临时三次握手或者建立过多的连接，增加服务器的压力。另外，可以通过对传输数据进行压缩，增加传输效率。</p><p>所有这些手段就像冷链运输，整个物流优化了，全程冷冻高速运输。不管生鲜是从你旁边的超市送到你家的，还是从产地送的，保证到你家是新鲜的。</p><h3 id="20-1-小结">20.1 小结</h3><p>总结一下：</p><ul><li>CDN 和电商系统的分布式仓储系统一样，分为中心节点、区域节点、边缘节点，而数据缓存在离用户最近的位置。</li><li>CDN 最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据，这时候要注意使用防盗链。它也支持动态数据的缓存，一种是边缘计算的生鲜超市模式，另一种是链路优化的冷链运输模式。</li></ul><h2 id="第21讲-数据中心：我是开发商，自己拿地盖别墅">第21讲 | 数据中心：我是开发商，自己拿地盖别墅</h2><p>无论你是看新闻、下订单、看视频、下载文件，最终访问的目的地都在数据中心里面。我们前面学了这么多的网络协议和网络相关的知识，你是不是很好奇，数据中心究竟长啥样呢？</p><p>数据中心是一个大杂烩，几乎要用到前面学过的所有知识。</p><p>前面讲办公室网络的时候，我们知道办公室里面有很多台电脑。如果要访问外网，需要经过一个叫<strong>网关</strong>的东西，而网关往往是一个路由器。</p><p>数据中心里面也有一大堆的电脑，但是它和咱们办公室里面的笔记本或者台式机不一样。数据中心里面是服务器。服务器被放在一个个叫作**机架（Rack）**的架子上面。</p><p>数据中心的入口和出口也是路由器，由于在数据中心的边界，就像在一个国家的边境，称为<strong>边界路由器（Border Router）</strong>。为了高可用，边界路由器会有多个。</p><p>一般家里只会连接一个运营商的网络，而为了高可用， 为了当一个运营商出问题的时候，还可以通过另外一个运营商来提供服务，所以数据中心的边界路由器会连接多个运营商网络。</p><p>既然是路由器，就需要跑路由协议，数据中心往往就是路由协议中的自治区域（AS）。数据中心里面的机器要想访问外面的网站，数据中心里面也是有对外提供服务的机器，都可以通过 BGP 协议，获取内外互通的路由信息。这就是我们常听到的<strong>多线 BGP</strong>的概念。</p><p>如果数据中心非常简单，没几台机器，那就像家里或者宿舍一样，所有的服务器都直接连到路由器上就可以了。但是数据中心里面往往有非常多的机器，当塞满一机架的时候，需要有交换机将这些服务器连接起来，可以互相通信。</p><p>这些交换机往往是放在机架顶端的，所以经常称为<strong>TOR（Top Of Rack）交换机</strong>。这一层的交换机常常称为<strong>接入层（Access Layer）</strong>。注意这个接入层和原来讲过的应用的接入层不是一个概念。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164315816.png" alt="image-20240523164315816"></p><p>当一个机架放不下的时候，就需要多个机架，还需要有交换机将多个机架连接在一起。这些交换机对性能的要求更高，带宽也更大。这些交换机称为<strong>汇聚层交换机（Aggregation Layer）</strong>。</p><p>数据中心里面的每一个连接都是需要考虑高可用的。这里首先要考虑的是，如果一台机器只有一个网卡，上面连着一个网线，接入到 TOR 交换机上。如果网卡坏了，或者不小心网线掉了，机器就上不去了。所以，需要至少两个网卡、两个网线插到 TOR 交换机上，但是两个网卡要工作得像一张网卡一样，这就是常说的<strong>网卡绑定（bond）</strong>。</p><p>这就需要服务器和交换机都支持一种协议<strong>LACP（Link Aggregation Control Protocol）</strong>。它们互相通信，将多个网卡聚合称为一个网卡，多个网线聚合成一个网线，在网线之间可以进行负载均衡，也可以为了高可用作准备。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164339792.png" alt="image-20240523164339792"></p><p>网卡有了高可用保证，但交换机还有问题。如果一个机架只有一个交换机，它挂了，那整个机架都不能上网了。因而 TOR 交换机也需要高可用，同理接入层和汇聚层的连接也需要高可用性，也不能单线连着。</p><p>最传统的方法是，部署两个接入交换机、两个汇聚交换机。服务器和两个接入交换机都连接，接入交换机和两个汇聚都连接，当然这样会形成环，所以需要启用 STP 协议，去除环，但是这样两个汇聚就只能一主一备了。STP 协议里我们学过，只有一条路会起作用。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164353521.png" alt="image-20240523164353521"></p><p>交换机有一种技术叫作<strong>堆叠</strong>，所以另一种方法是，将多个交换机形成一个逻辑的交换机，服务器通过多根线分配连到多个接入层交换机上，而接入层交换机多根线分别连接到多个交换机上，并且通过堆叠的私有协议，形成<strong>双活</strong>的连接方式。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164404687.png" alt="image-20240523164404687"></p><p>由于对带宽要钱求更大，而且挂了影响也更大，所以两个堆叠可能就不够了，可以就会有更多的，比如四个堆叠为一个逻辑的交换机。</p><p>汇聚层将大量的计算节点相互连接在一起，形成一个集群。在这个集群里面，服务器之间通过二层互通，这个区域常称为一个<strong>POD（Point Of Delivery）</strong>，有时候也称为一个<strong>可用区（Available Zone）</strong>。</p><p>当节点数目再多的时候，一个可用区放不下，需要将多个可用区连在一起，连接多个可用区的交换机称为<strong>核心交换机</strong>。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164426258.png" alt="image-20240523164426258"></p><p>核心交换机吞吐量更大，高可用要求更高，肯定需要堆叠，但是往往仅仅堆叠，不足以满足吞吐量，因而还是需要部署多组核心交换机。核心和汇聚交换机之间为了高可用，也是全互连模式的。</p><p>这个时候还存在那个问题，出现环路怎么办？</p><p>一种方式是，不同的可用区在不同的二层网络，需要分配不同的网段。汇聚和核心之间通过三层网络互通的，二层都不在一个广播域里面，不会存在二层环路的问题。三层有环是没有问题的，只要通过路由协议选择最佳的路径就可以了。那为啥二层不能有环路，而三层可以呢？你可以回忆一下二层环路的情况。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164436601.png" alt="image-20240523164436601"></p><p>如图，核心层和汇聚层之间通过内部的路由协议 OSPF，找到最佳的路径进行访问，而且还可以通过 ECMP 等价路由，在多个路径之间进行负载均衡和高可用。</p><p>但是随着数据中心里面的机器越来越多，尤其是有了云计算、大数据，集群规模非常大，而且都要求在一个二层网络里面。这就需要二层互连从<strong>汇聚层</strong>上升为<strong>核心层</strong>，也即在核心以下，全部是二层互连，全部在一个广播域里面，这就是常说的<strong>大二层</strong>。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164447725.png" alt="image-20240523164447725"></p><p>如果大二层横向流量不大，核心交换机数目不多，可以做堆叠，但是如果横向流量很大，仅仅堆叠满足不了，就需要部署多组核心交换机，而且要和汇聚层进行全互连。由于堆叠只解决一个核心交换机组内的无环问题，而组之间全互连，还需要其他机制进行解决。</p><p>如果是 STP，那部署多组核心无法扩大横向流量的能力，因为还是只有一组起作用。</p><p>于是大二层就引入了<strong>TRILL（Transparent Interconnection of Lots of Link），即多链接透明互联协议</strong>。它的基本思想是，二层环有问题，三层环没有问题，那就把三层的路由能力模拟在二层实现。</p><p>运行 TRILL 协议的交换机称为<strong>RBridge</strong>，是<strong>具有路由转发特性的网桥设备</strong>，只不过这个路由是根据 MAC 地址来的，不是根据 IP 来的。</p><p>Rbridage 之间通过<strong>链路状态协议</strong>运作。记得这个路由协议吗？通过它可以学习整个大二层的拓扑，知道访问哪个 MAC 应该从哪个网桥走；还可以计算最短的路径，也可以通过等价的路由进行负载均衡和高可用性。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164459752.png" alt="image-20240523164459752"></p><p>TRILL 协议在原来的 MAC 头外面加上自己的头，以及外层的 MAC 头。TRILL 头里面的 Ingress RBridge，有点像 IP 头里面的源 IP 地址，Egress RBridge 是目标 IP 地址，这两个地址是端到端的，在中间路由的时候，不会发生改变。而外层的 MAC，可以有下一跳的 Bridge，就像路由的下一跳，也是通过 MAC 地址来呈现的一样。</p><p>如图中所示的过程，有一个包要从主机 A 发送到主机 B，中间要经过 RBridge 1、RBridge 2、RBridge X 等等，直到 RBridge 3。在 RBridge 2 收到的包里面，分内外两层，内层就是传统的主机 A 和主机 B 的 MAC 地址以及内层的 VLAN。</p><p>在外层首先加上一个 TRILL 头，里面描述这个包从 RBridge 1 进来的，要从 RBridge 3 出去，并且像三层的 IP 地址一样有跳数。然后再外面，目的 MAC 是 RBridge 2，源 MAC 是 RBridge 1，以及外层的 VLAN。</p><p>当 RBridge 2 收到这个包之后，首先看 MAC 是否是自己的 MAC，如果是，要看自己是不是 Egress RBridge，也即是不是最后一跳；如果不是，查看跳数是不是大于 0，然后通过类似路由查找的方式找到下一跳 RBridge X，然后将包发出去。</p><p>RBridge 2 发出去的包，内层的信息是不变的，外层的 TRILL 头里面。同样，描述这个包从 RBridge 1 进来的，要从 RBridge 3 出去，但是跳数要减 1。外层的目标 MAC 变成 RBridge X，源 MAC 变成 RBridge 2。</p><p>如此一直转发，直到 RBridge 3，将外层解出来，发送内层的包给主机 B。</p><p>这个过程是不是和 IP 路由很像？</p><p>对于大二层的广播包，也需要通过分发树的技术来实现。我们知道 STP 是将一个有环的图，通过去掉边形成一棵树，而分发树是一个有环的图形成多棵树，不同的树有不同的 VLAN，有的广播包从 VLAN A 广播，有的从 VLAN B 广播，实现负载均衡和高可用。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164513430.png" alt="image-20240523164513430"></p><p>核心交换机之外，就是边界路由器了。至此从服务器到数据中心边界的层次情况已经清楚了。</p><p>在核心交换上面，往往会挂一些安全设备，例如入侵检测、DDoS 防护等等。这是整个数据中心的屏障，防止来自外来的攻击。核心交换机上往往还有负载均衡器，原理前面的章节已经说过了。</p><p>在有的数据中心里面，对于存储设备，还会有一个存储网络，用来连接 SAN 和 NAS。但是对于新的云计算来讲，往往不使用传统的 SAN 和 NAS，而使用部署在 x86 机器上的软件定义存储，这样存储也是服务器了，而且可以和计算节点融合在一个机架上，从而更加有效率，也就没有了单独的存储网络了。</p><p>于是整个数据中心的网络如下图所示。</p><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164529974.png" alt="image-20240523164529974"></p><p>这是一个典型的三层网络结构。这里的三层不是指 IP 层，而是指接入层、汇聚层、核心层三层。这种模式非常有利于外部流量请求到内部应用。这个类型的流量，是从外到内或者从内到外，对应到上面那张图里，就是从上到下，从下到上，上北下南，所以称为<strong>南北流量</strong>。</p><p>但是随着云计算和大数据的发展，节点之间的交互越来越多，例如大数据计算经常要在不同的节点将数据拷贝来拷贝去，这样需要经过交换机，使得数据从左到右，从右到左，左西右东，所以称为<strong>东西流量</strong>。</p><p>为了解决东西流量的问题，演进出了<strong>叶脊网络（Spine/Leaf）</strong>。</p><ul><li><strong>叶子交换机（leaf）</strong>，直接连接物理服务器。L2/L3 网络的分界点在叶子交换机上，叶子交换机之上是三层网络。</li><li><strong>脊交换机（spine switch）</strong>，相当于核心交换机。叶脊之间通过 ECMP 动态选择多条路径。脊交换机现在只是为叶子交换机提供一个弹性的 L3 路由网络。南北流量可以不用直接从脊交换机发出，而是通过与 leaf 交换机并行的交换机，再接到边界路由器出去。</li></ul><p><img src="https://penge666blog.oss-cn-beijing.aliyuncs.com/img/image-20240523164541601.png" alt="image-20240523164541601"></p><p>传统的三层网络架构是垂直的结构，而叶脊网络架构是扁平的结构，更易于水平扩展。</p><h4 id="21-1-小结">21.1 小结</h4><p>三个重点：</p><ul><li>数据中心分为三层。服务器连接到接入层，然后是汇聚层，再然后是核心层，最外面是边界路由器和安全设备。</li><li>数据中心的所有链路都需要高可用性。服务器需要绑定网卡，交换机需要堆叠，三层设备可以通过等价路由，二层设备可以通过 TRILL 协议。</li><li>随着云和大数据的发展，东西流量相对于南北流量越来越重要，因而演化为叶脊网络结构。</li></ul><h2 id="第22讲-VPN：朝中有人好做官">第22讲 | VPN：朝中有人好做官</h2><p>待填坑~</p>]]></content>
    
    
    <summary type="html">《趣谈网络协议》</summary>
    
    
    
    <category term="计算机网络" scheme="https://penge666.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="计算机网络" scheme="https://penge666.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
